id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/qupath/qupath/issues/2#issuecomment-258683889:24,Availability,avail,available,24,Linux binaries are only available for the very first release (v0.0.1). There hasn't yet been any audible demand for updated binaries... but they should at least be provided for v0.1. Ideally these would use OpenJDK and OpenJFX... although so far it has proven easier to create them using Oracle's JDK. Any Linux users who would like to see Linux binaries are invited to comment here...,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-258683889
https://github.com/qupath/qupath/issues/2#issuecomment-258683889:53,Deployability,release,release,53,Linux binaries are only available for the very first release (v0.0.1). There hasn't yet been any audible demand for updated binaries... but they should at least be provided for v0.1. Ideally these would use OpenJDK and OpenJFX... although so far it has proven easier to create them using Oracle's JDK. Any Linux users who would like to see Linux binaries are invited to comment here...,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-258683889
https://github.com/qupath/qupath/issues/2#issuecomment-258683889:116,Deployability,update,updated,116,Linux binaries are only available for the very first release (v0.0.1). There hasn't yet been any audible demand for updated binaries... but they should at least be provided for v0.1. Ideally these would use OpenJDK and OpenJFX... although so far it has proven easier to create them using Oracle's JDK. Any Linux users who would like to see Linux binaries are invited to comment here...,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-258683889
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:43,Availability,down,download,43,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:1306,Availability,down,download,1306,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:98,Deployability,release,releases,98,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:462,Deployability,install,installing,462,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:653,Deployability,Install,Installing-QuPath,653,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:1226,Deployability,install,installation,1226,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:1319,Deployability,install,install,1319,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:994,Integrability,depend,dependencies,994,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-261056258:782,Usability,clear,clear,782,"Eventually I managed to create a new Linux download for [v0.0.6](https://github.com/qupath/qupath/releases/tag/v0.0.6) using OpenJDK and OpenJFX. Still, two troubles remain: one minor, one major. The minor trouble is that (at least on Ubuntu 16.04) the build process is not entirely seamless, and `jfxrt.jar` needs to be manually copied into the distribution at the end (perhaps because it's not included in OpenJDK, but rather only a symbolic link is made with installing `openjfx` with Synaptic?). The major trouble is that OpenSlide continues not to be distributed in a ready-to-run fashion (as mentioned [here](https://github.com/qupath/qupath/wiki/Installing-QuPath#linux)). Indeed, I'm not sure if it will work on anyone's machine other than the one I was using. It is likely clear that my Linux use and experience is limited. The suggestions of someone who is more familiar with this would be very welcome. I think one of the following is required:; - Inclusion of OpenSlide and all its dependencies, precompiled (in the same way as QuPath provides for Windows and macOS), or; - A method of ensuring the Java library path in the packaged version of QuPath includes all the places that would be required to find a local installation of OpenSlide. In the second case, the user would still be asked to download and install it... but if this step goes smoothly, it can be expected to work. I plan to investigate this more in the future, but it may take some time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-261056258
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:974,Availability,down,downloads,974,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:989,Availability,down,downloads-,989,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:517,Deployability,install,installation,517,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:149,Integrability,depend,dependencies,149,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:618,Integrability,depend,depending,618,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/2#issuecomment-263157251:479,Testability,test,tested,479,"This situation is hopefully much improved in v0.0.7. OpenSlide and OpenCV were both recompiled, and I attempted to ensure all non-standard, required dependencies are now included - with an appropriate ```rpath``` setting so that they may find one another. Most of the steps taken are documented under the ['Maven' directory](https://github.com/qupath/qupath/tree/master/maven). The Linux version 0.0.7 was created using Ubuntu 16.04 running through VirtualBox on an iMac. I also tested the compiled QuPath on a clean installation of Fedora 25, also through VirtualBox. Both were able to run QuPath, including commands depending on OpenSlide and OpenCV - although things did run a bit more smoothly on Ubuntu (e.g. the *Brush* tool misbehaved on Fedora). Additionally, the Linux version is created using [OpenJDK](http://openjdk.java.net) and [OpenJFX](http://openjdk.java.net/projects/openjfx/) - as opposed to the [Oracle JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) used for Windows and Mac.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/2#issuecomment-263157251
https://github.com/qupath/qupath/issues/5#issuecomment-253588979:37,Deployability,release,release,37,"This should be fixed now in the next release, so that the visibility of an object is used to determine whether it is sent to ImageJ or not. This also includes whether cells are shown with their boundaries and/or nuclei. Regarding converting to ImageJ selections, that should already happen. It should already be the case that the objects are sent as ImageJ Rois on top of an ImageJ overlay - so you can either remove the overlay, or send its Rois to the ROI manager. If you do the latter, you should also see that the names of the Rois have also been set according to their names/classifications within QuPath. Also, the 'primary' selected object (i.e. the one that was currently active whenever the _Extract region to ImageJ_ command was run) should automatically be converted to an ImageJ Roi and set as the active selection in ImageJ - _unless_ it was a rectangle. There isn't really so much point in sending rectangles Rois, since they will simply occupy the whole image (and can easily be recreated in ImageJ if necessary with _Edit &rarr; Selection &rarr; Select All_) - but all non-rectangles should be transferred, as shown below. Hopefully that works well enough to be suitably heroic... ![ij_screenshot](https://cloud.githubusercontent.com/assets/4690904/19360208/7cf2f31c-9175-11e6-9a60-b8878b6e7543.jpg)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/5#issuecomment-253588979
https://github.com/qupath/qupath/issues/5#issuecomment-253588979:945,Usability,simpl,simply,945,"This should be fixed now in the next release, so that the visibility of an object is used to determine whether it is sent to ImageJ or not. This also includes whether cells are shown with their boundaries and/or nuclei. Regarding converting to ImageJ selections, that should already happen. It should already be the case that the objects are sent as ImageJ Rois on top of an ImageJ overlay - so you can either remove the overlay, or send its Rois to the ROI manager. If you do the latter, you should also see that the names of the Rois have also been set according to their names/classifications within QuPath. Also, the 'primary' selected object (i.e. the one that was currently active whenever the _Extract region to ImageJ_ command was run) should automatically be converted to an ImageJ Roi and set as the active selection in ImageJ - _unless_ it was a rectangle. There isn't really so much point in sending rectangles Rois, since they will simply occupy the whole image (and can easily be recreated in ImageJ if necessary with _Edit &rarr; Selection &rarr; Select All_) - but all non-rectangles should be transferred, as shown below. Hopefully that works well enough to be suitably heroic... ![ij_screenshot](https://cloud.githubusercontent.com/assets/4690904/19360208/7cf2f31c-9175-11e6-9a60-b8878b6e7543.jpg)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/5#issuecomment-253588979
https://github.com/qupath/qupath/issues/5#issuecomment-253767302:287,Availability,avail,available,287,"I've now updated the documentation on using ImageJ with QuPath at https://github.com/qupath/qupath/wiki/Working-with-ImageJ. I'll close this issue now, but please reopen it if things aren't working as described. The use of visibility status to influence what is sent to ImageJ should be available in the v0.0.4 release of QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/5#issuecomment-253767302
https://github.com/qupath/qupath/issues/5#issuecomment-253767302:9,Deployability,update,updated,9,"I've now updated the documentation on using ImageJ with QuPath at https://github.com/qupath/qupath/wiki/Working-with-ImageJ. I'll close this issue now, but please reopen it if things aren't working as described. The use of visibility status to influence what is sent to ImageJ should be available in the v0.0.4 release of QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/5#issuecomment-253767302
https://github.com/qupath/qupath/issues/5#issuecomment-253767302:311,Deployability,release,release,311,"I've now updated the documentation on using ImageJ with QuPath at https://github.com/qupath/qupath/wiki/Working-with-ImageJ. I'll close this issue now, but please reopen it if things aren't working as described. The use of visibility status to influence what is sent to ImageJ should be available in the v0.0.4 release of QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/5#issuecomment-253767302
https://github.com/qupath/qupath/issues/6#issuecomment-632217898:90,Deployability,toggle,toggle,90,Closing this because:. * I see no way to fix it completely; * there's now a preference to toggle whether the system menubar is used by QuPath... which provides a way in which to deal with the issue,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/6#issuecomment-632217898
https://github.com/qupath/qupath/issues/7#issuecomment-256326873:73,Deployability,release,releases,73,"This has been much improved in [v0.0.4](https://github.com/qupath/qupath/releases/tag/v0.0.4), with the addition of [connection groups](https://github.com/qupath/qupath/tree/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-core-processing/src/main/java/qupath/lib/objects) - which enable Delaunay computations to be separated from [display](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/PathHierarchyPaintingHelper.java#L716). Nevertheless, the design will continue to be refined and shouldn't be relied upon yet...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/7#issuecomment-256326873
https://github.com/qupath/qupath/issues/9#issuecomment-256318716:1204,Deployability,update,updated,1204,"An extra detail: this is less important if a project is used, since then the image path is stored in two places:; 1. The `.qpdata` file; 2. The `.qpproj` file. The path stored in the `.qpproj` file is used first. Fortunately, this is also the easiest to change: since the `.qpproj` file is text ([JSON](https://en.wikipedia.org/wiki/JSON)), this file can simply be opened in a text editor, and the paths replaced. In the event that a `.qpdata` file has already been created, and now won't open, there are two workarounds to handle this:; 1. Put the original image back in the location where it previously was, or; 2. Create a new project, and add the image to the project in its new location. Whenever any data relating to this image is saved within the project, QuPath will create a new `.qpdata` file inside the `data` directory of the project. If you replace this `.qpdata` file with the old one (after renaming it), then QuPath will treat it as the proper data from then on. Several morals of this story:; - If possible, don't move images to different directories after starting to analyse them with QuPath; - If you do (or might) need to move images, it's better to use projects - since they can be updated more easily later; - QuPath ought to handle moved images in a better way than it currently does...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/9#issuecomment-256318716
https://github.com/qupath/qupath/issues/9#issuecomment-256318716:355,Usability,simpl,simply,355,"An extra detail: this is less important if a project is used, since then the image path is stored in two places:; 1. The `.qpdata` file; 2. The `.qpproj` file. The path stored in the `.qpproj` file is used first. Fortunately, this is also the easiest to change: since the `.qpproj` file is text ([JSON](https://en.wikipedia.org/wiki/JSON)), this file can simply be opened in a text editor, and the paths replaced. In the event that a `.qpdata` file has already been created, and now won't open, there are two workarounds to handle this:; 1. Put the original image back in the location where it previously was, or; 2. Create a new project, and add the image to the project in its new location. Whenever any data relating to this image is saved within the project, QuPath will create a new `.qpdata` file inside the `data` directory of the project. If you replace this `.qpdata` file with the old one (after renaming it), then QuPath will treat it as the proper data from then on. Several morals of this story:; - If possible, don't move images to different directories after starting to analyse them with QuPath; - If you do (or might) need to move images, it's better to use projects - since they can be updated more easily later; - QuPath ought to handle moved images in a better way than it currently does...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/9#issuecomment-256318716
https://github.com/qupath/qupath/issues/9#issuecomment-259219978:21,Safety,avoid,avoiding,21,Fixed in `v0.0.5` by avoiding throwing a `RuntimeException` unnecessarily. A prompt now appears on Windows instead when the image can't be found.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/9#issuecomment-259219978
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:1708,Availability,down,downloaded,1708,"cluded by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (except the `*.mrxs` extension); - be located side-by-side in the same folder; - not be inside a compressed folder (e.g. a zipped folder). If any of these aren't true, then only the coarsest resolution will open. Could you check the files you have and see if any of these could explain the issue, or perhaps compare with the OpenSlide examples to see where any difference lies? I'm also happy to have a look here, if you can somehow transfer one of your images to me. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:1775,Availability,down,download,1775,"cluded by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (except the `*.mrxs` extension); - be located side-by-side in the same folder; - not be inside a compressed folder (e.g. a zipped folder). If any of these aren't true, then only the coarsest resolution will open. Could you check the files you have and see if any of these could explain the issue, or perhaps compare with the OpenSlide examples to see where any difference lies? I'm also happy to have a look here, if you can somehow transfer one of your images to me. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:143,Deployability,install,installed,143,"Hi Arnulf,. Thanks very much for reporting this, and I'm glad you like the software!. From what you say, the Bio-Formats extension is probably installed correctly. It doesn't appear in the 'Extensions' menu because it isn't associated with any particular command you need to run - rather, QuPath will simply start using it if it needs to. When an image is opened, QuPath will go through a list of possible image readers and take the first that works. These include:; - OpenSlide (included by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (exce",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:557,Deployability,install,installed,557,"Hi Arnulf,. Thanks very much for reporting this, and I'm glad you like the software!. From what you say, the Bio-Formats extension is probably installed correctly. It doesn't appear in the 'Extensions' menu because it isn't associated with any particular command you need to run - rather, QuPath will simply start using it if it needs to. When an image is opened, QuPath will go through a list of possible image readers and take the first that works. These include:; - OpenSlide (included by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (exce",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:1794,Testability,test,testdata,1794,"cluded by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (except the `*.mrxs` extension); - be located side-by-side in the same folder; - not be inside a compressed folder (e.g. a zipped folder). If any of these aren't true, then only the coarsest resolution will open. Could you check the files you have and see if any of these could explain the issue, or perhaps compare with the OpenSlide examples to see where any difference lies? I'm also happy to have a look here, if you can somehow transfer one of your images to me. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258165973:301,Usability,simpl,simply,301,"Hi Arnulf,. Thanks very much for reporting this, and I'm glad you like the software!. From what you say, the Bio-Formats extension is probably installed correctly. It doesn't appear in the 'Extensions' menu because it isn't associated with any particular command you need to run - rather, QuPath will simply start using it if it needs to. When an image is opened, QuPath will go through a list of possible image readers and take the first that works. These include:; - OpenSlide (included by default); - ImageJ (included by default); - Bio-Formats (if it's installed). The _Server type_ entry in the table that appears under the _Image_ tab on the right of QuPath shows you which reader was used for whichever image is currently open - in the screenshot below, OpenSlide was used. ![mirax](https://cloud.githubusercontent.com/assets/4690904/19970686/a81eaf8a-a1d4-11e6-810e-491db8fb6612.jpg). Unfortunately, to the best of my knowledge Bio-Formats cannot handle MIRAX files - there is some information [here](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). Bio-Formats also cannot handle CZI files with JPEG-XR compression (which seems to be the default for whole slide scanners) - although the good news is that [this is being worked on](https://www.openmicroscopy.org/community/viewtopic.php?f=13&t=8138). OpenSlide also cannot handle CZI files (possibly for [license reasons](https://github.com/openslide/openslide/issues/144)), although this is discussed on the mailing list sometimes. However, OpenSlide should be able to handle [MIRAX](http://openslide.org/formats/mirax/) (at least 2D RGB images), and I've tried QuPath successfully with several MIRAX files that I [downloaded from the OpenSlide website](http://openslide.cs.cmu.edu/download/openslide-testdata/Mirax/). From the examples I've seen, the MIRAX images consist of two parts: a `*.mrxs` file and a separate directory containing a lot of other data files. These need to:; - have the same name (exce",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258165973
https://github.com/qupath/qupath/issues/12#issuecomment-258226826:407,Safety,avoid,avoid,407,"Actually, it may be that the issues with `*.czi` or `*.mrxs` may be more similar than I realised... it seems that `*.mrxs` may also involve JPEG-XR compression, which [OpenSlide does not currently handle](https://github.com/openslide/openslide/issues/184). If this is the source of the problem, in the short term I'm afraid you may need to change your settings when saving your images in the first place to avoid JPEG-XR (regular JPEG compression should work). There is also an export ability within [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer), although I have not tried this myself.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258226826
https://github.com/qupath/qupath/issues/12#issuecomment-258370511:1166,Availability,avail,available,1166,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511
https://github.com/qupath/qupath/issues/12#issuecomment-258370511:376,Security,access,access,376,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511
https://github.com/qupath/qupath/issues/12#issuecomment-258370511:630,Security,access,access,630,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511
https://github.com/qupath/qupath/issues/12#issuecomment-258370511:1302,Testability,test,test,1302,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511
https://github.com/qupath/qupath/issues/12#issuecomment-258370511:1399,Testability,test,test,1399,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:378,Availability,down,downloads,378,"Dear Arnulf,. Thanks again for your reply. I'm glad that the brightfield/RGB `*.mrxs` files are working. I'm not certain, but since Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:669,Availability,avail,available,669,"Dear Arnulf,. Thanks again for your reply. I'm glad that the brightfield/RGB `*.mrxs` files are working. I'm not certain, but since Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:1222,Deployability,integrat,integrating,1222," Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically concatenate the multiple channels of a TIFF, assuming that they are stored in the same directory with a standard naming scheme (e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:1374,Deployability,update,update,1374,"om/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically concatenate the multiple channels of a TIFF, assuming that they are stored in the same directory with a standard naming scheme (e.g. `name_ch1.tif`, `name_ch2.tif` etc.). That way you wouldn't need to convert to RGB or create a single merged image. Would that be useful? If so, then if you were able to send me an example set of monochrome tiffs that have been exported and",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:1222,Integrability,integrat,integrating,1222," Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically concatenate the multiple channels of a TIFF, assuming that they are stored in the same directory with a standard naming scheme (e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-258467053:1067,Security,access,access,1067," Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically concatenate the multiple channels of a TIFF, assuming that they are stored in the same directory with a standard naming scheme (e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053
https://github.com/qupath/qupath/issues/12#issuecomment-259121186:449,Availability,error,error,449,"Dear Pete,. I understand the problems with the Windows-only algorithms. Unfortunately, we do not have the resources at our institution to create software like that, even though some of our medical physicists may have the programming skills. In the meantime, I was able to load a smaller three channel RGB tiff exported from a *.czi multichannel fluorescence file. However, in my first attempts I could not get QuPath to identify any cells. I get an error message telling me that my image is not brightfield (which is true). Do I understand it correctly that QuPath is not (yet?) ready for the analysis of fluorescence images? Do you plan to implement this functionality? I think that fluorescence files provide some strong advantages with regard to image analysis. . Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259121186
https://github.com/qupath/qupath/issues/12#issuecomment-259121186:455,Integrability,message,message,455,"Dear Pete,. I understand the problems with the Windows-only algorithms. Unfortunately, we do not have the resources at our institution to create software like that, even though some of our medical physicists may have the programming skills. In the meantime, I was able to load a smaller three channel RGB tiff exported from a *.czi multichannel fluorescence file. However, in my first attempts I could not get QuPath to identify any cells. I get an error message telling me that my image is not brightfield (which is true). Do I understand it correctly that QuPath is not (yet?) ready for the analysis of fluorescence images? Do you plan to implement this functionality? I think that fluorescence files provide some strong advantages with regard to image analysis. . Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259121186
https://github.com/qupath/qupath/issues/12#issuecomment-259121186:272,Performance,load,load,272,"Dear Pete,. I understand the problems with the Windows-only algorithms. Unfortunately, we do not have the resources at our institution to create software like that, even though some of our medical physicists may have the programming skills. In the meantime, I was able to load a smaller three channel RGB tiff exported from a *.czi multichannel fluorescence file. However, in my first attempts I could not get QuPath to identify any cells. I get an error message telling me that my image is not brightfield (which is true). Do I understand it correctly that QuPath is not (yet?) ready for the analysis of fluorescence images? Do you plan to implement this functionality? I think that fluorescence files provide some strong advantages with regard to image analysis. . Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259121186
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:589,Deployability,release,releases,589,"Dear Arnulf,. Certainly I'm agreed with you on the benefits of fluorescence for image analysis. I intended that the cell detection should work with fluorescence, but since I have primarily been working with brightfield until now, this was not taken very far. Success with fluorescence cell detection previously relied upon several undocumented tricks in terms of choosing parameters, and the good fortune of having your nuclear counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actua",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:2143,Deployability,toggle,toggle,2143,"ar counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actually better to simply type the number of the channel you want to hide or show several times (i.e. just the number 1, 2 or 3 etc.). This should toggle it on or off. Actually, this last trick to change visible channels also works for brightfield, except that 1 indicates the RGB image, 2 the first color deconvolved channel, 2 the second... and so on through multiple color transforms. I hope this is useful. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:121,Safety,detect,detection,121,"Dear Arnulf,. Certainly I'm agreed with you on the benefits of fluorescence for image analysis. I intended that the cell detection should work with fluorescence, but since I have primarily been working with brightfield until now, this was not taken very far. Success with fluorescence cell detection previously relied upon several undocumented tricks in terms of choosing parameters, and the good fortune of having your nuclear counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actua",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:290,Safety,detect,detection,290,"Dear Arnulf,. Certainly I'm agreed with you on the benefits of fluorescence for image analysis. I intended that the cell detection should work with fluorescence, but since I have primarily been working with brightfield until now, this was not taken very far. Success with fluorescence cell detection previously relied upon several undocumented tricks in terms of choosing parameters, and the good fortune of having your nuclear counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actua",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:331,Usability,undo,undocumented,331,"Dear Arnulf,. Certainly I'm agreed with you on the benefits of fluorescence for image analysis. I intended that the cell detection should work with fluorescence, but since I have primarily been working with brightfield until now, this was not taken very far. Success with fluorescence cell detection previously relied upon several undocumented tricks in terms of choosing parameters, and the good fortune of having your nuclear counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actua",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:1482,Usability,simpl,simply,1482,"ar counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actually better to simply type the number of the channel you want to hide or show several times (i.e. just the number 1, 2 or 3 etc.). This should toggle it on or off. Actually, this last trick to change visible channels also works for brightfield, except that 1 indicates the RGB image, 2 the first color deconvolved channel, 2 the second... and so on through multiple color transforms. I hope this is useful. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-259250203:2015,Usability,simpl,simply,2015,"ar counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actually better to simply type the number of the channel you want to hide or show several times (i.e. just the number 1, 2 or 3 etc.). This should toggle it on or off. Actually, this last trick to change visible channels also works for brightfield, except that 1 indicates the RGB image, 2 the first color deconvolved channel, 2 the second... and so on through multiple color transforms. I hope this is useful. Best wishes,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203
https://github.com/qupath/qupath/issues/12#issuecomment-266718638:370,Safety,detect,detection,370,"I'll close this issue, since I think most things that can and will be fixed now have been:. * CZI images can now be read with QuPath, as described [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi) - thanks to the work of OME with [Bio-Formats 5.3.0](https://www.openmicroscopy.org/site/support/bio-formats5.3/about/whats-new.html).; * Cell detection in fluorescence images now gives the option to select the detection channel, and more sensible defaults; * The Brightness/Contrast tricks mentioned above are now documented more fully on the [wiki](https://github.com/qupath/qupath/wiki/Changing-colors); * Most RGB ```.mrxs``` files should be readable, although unfortunately 16-bit or JPEG-XR-compressed files are not and there are no immediate plans to add this support within QuPath. However, if OpenSlide or Bio-Formats are able to support these images, then QuPath will benefit through its use of these libraries.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-266718638
https://github.com/qupath/qupath/issues/12#issuecomment-266718638:438,Safety,detect,detection,438,"I'll close this issue, since I think most things that can and will be fixed now have been:. * CZI images can now be read with QuPath, as described [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi) - thanks to the work of OME with [Bio-Formats 5.3.0](https://www.openmicroscopy.org/site/support/bio-formats5.3/about/whats-new.html).; * Cell detection in fluorescence images now gives the option to select the detection channel, and more sensible defaults; * The Brightness/Contrast tricks mentioned above are now documented more fully on the [wiki](https://github.com/qupath/qupath/wiki/Changing-colors); * Most RGB ```.mrxs``` files should be readable, although unfortunately 16-bit or JPEG-XR-compressed files are not and there are no immediate plans to add this support within QuPath. However, if OpenSlide or Bio-Formats are able to support these images, then QuPath will benefit through its use of these libraries.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-266718638
https://github.com/qupath/qupath/issues/13#issuecomment-259152982:58,Availability,Error,Error,58,"Both of these issues should now be addressed in `v0.0.5`. Error messages are shown if no objects are selected, or if a region is selected which is particularly large.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/13#issuecomment-259152982
https://github.com/qupath/qupath/issues/13#issuecomment-259152982:64,Integrability,message,messages,64,"Both of these issues should now be addressed in `v0.0.5`. Error messages are shown if no objects are selected, or if a region is selected which is particularly large.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/13#issuecomment-259152982
https://github.com/qupath/qupath/issues/15#issuecomment-258995011:667,Availability,error,error,667,"Both of these issues are now addressed in `v0.0.5`. For now, running _Add intensity features_ will _always_ result in a prompt to confirm which objects will be used - to help force more deliberate choices. Additionally, large regions will be automatically split into tiles. Provisional checks suggest the results are almost identical to the untiled measurements - although further tests are needed. Some small loss in precision is to be expected compared to the 'true' measurement without tiling (e.g. with Haralick features, were adjacencies across tile boundaries will not be computed), but this should be low... and better than QuPath hanging, or an out-of-memory error. Currently, the _implicit_ tiling of large ROIs for the purposes of avoiding memory errors does not make use of parallelization. Therefore it is still _not_ advisable to compute measurements across very large areas at high resolution. However, it is expected that this shouldn't often be needed, because:; 1. the most useful measurement for a large region is the average intensity, which can be computed at a low resolution with good accuracy, and; 2. measurements of texture (e.g. standard deviation, or Haralick textures) are rarely meaningful when computed over very large numbers of pixels, but rather are more normally computed individually for (explicitly-created) tiles generated within such an the area (e.g. using the _Create tiles_ command). Intensity measurements made for _separate_ objects (including tile objects) will be parallelized, as normal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/15#issuecomment-258995011
https://github.com/qupath/qupath/issues/15#issuecomment-258995011:757,Availability,error,errors,757,"Both of these issues are now addressed in `v0.0.5`. For now, running _Add intensity features_ will _always_ result in a prompt to confirm which objects will be used - to help force more deliberate choices. Additionally, large regions will be automatically split into tiles. Provisional checks suggest the results are almost identical to the untiled measurements - although further tests are needed. Some small loss in precision is to be expected compared to the 'true' measurement without tiling (e.g. with Haralick features, were adjacencies across tile boundaries will not be computed), but this should be low... and better than QuPath hanging, or an out-of-memory error. Currently, the _implicit_ tiling of large ROIs for the purposes of avoiding memory errors does not make use of parallelization. Therefore it is still _not_ advisable to compute measurements across very large areas at high resolution. However, it is expected that this shouldn't often be needed, because:; 1. the most useful measurement for a large region is the average intensity, which can be computed at a low resolution with good accuracy, and; 2. measurements of texture (e.g. standard deviation, or Haralick textures) are rarely meaningful when computed over very large numbers of pixels, but rather are more normally computed individually for (explicitly-created) tiles generated within such an the area (e.g. using the _Create tiles_ command). Intensity measurements made for _separate_ objects (including tile objects) will be parallelized, as normal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/15#issuecomment-258995011
https://github.com/qupath/qupath/issues/15#issuecomment-258995011:741,Safety,avoid,avoiding,741,"Both of these issues are now addressed in `v0.0.5`. For now, running _Add intensity features_ will _always_ result in a prompt to confirm which objects will be used - to help force more deliberate choices. Additionally, large regions will be automatically split into tiles. Provisional checks suggest the results are almost identical to the untiled measurements - although further tests are needed. Some small loss in precision is to be expected compared to the 'true' measurement without tiling (e.g. with Haralick features, were adjacencies across tile boundaries will not be computed), but this should be low... and better than QuPath hanging, or an out-of-memory error. Currently, the _implicit_ tiling of large ROIs for the purposes of avoiding memory errors does not make use of parallelization. Therefore it is still _not_ advisable to compute measurements across very large areas at high resolution. However, it is expected that this shouldn't often be needed, because:; 1. the most useful measurement for a large region is the average intensity, which can be computed at a low resolution with good accuracy, and; 2. measurements of texture (e.g. standard deviation, or Haralick textures) are rarely meaningful when computed over very large numbers of pixels, but rather are more normally computed individually for (explicitly-created) tiles generated within such an the area (e.g. using the _Create tiles_ command). Intensity measurements made for _separate_ objects (including tile objects) will be parallelized, as normal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/15#issuecomment-258995011
https://github.com/qupath/qupath/issues/15#issuecomment-258995011:381,Testability,test,tests,381,"Both of these issues are now addressed in `v0.0.5`. For now, running _Add intensity features_ will _always_ result in a prompt to confirm which objects will be used - to help force more deliberate choices. Additionally, large regions will be automatically split into tiles. Provisional checks suggest the results are almost identical to the untiled measurements - although further tests are needed. Some small loss in precision is to be expected compared to the 'true' measurement without tiling (e.g. with Haralick features, were adjacencies across tile boundaries will not be computed), but this should be low... and better than QuPath hanging, or an out-of-memory error. Currently, the _implicit_ tiling of large ROIs for the purposes of avoiding memory errors does not make use of parallelization. Therefore it is still _not_ advisable to compute measurements across very large areas at high resolution. However, it is expected that this shouldn't often be needed, because:; 1. the most useful measurement for a large region is the average intensity, which can be computed at a low resolution with good accuracy, and; 2. measurements of texture (e.g. standard deviation, or Haralick textures) are rarely meaningful when computed over very large numbers of pixels, but rather are more normally computed individually for (explicitly-created) tiles generated within such an the area (e.g. using the _Create tiles_ command). Intensity measurements made for _separate_ objects (including tile objects) will be parallelized, as normal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/15#issuecomment-258995011
https://github.com/qupath/qupath/issues/16#issuecomment-269880806:135,Deployability,release,releases,135,"While there is still no way to classify easily by intensities through the GUI, starting from [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2) several new functions make it very easy by scripting, e.g. [this one](https://github.com/qupath/qupath/blob/master/qupath-core-processing/src/main/java/qupath/lib/scripting/QP.java#L1156). For example, to classify all cells as negative, 1+, 2+ or 3+ according to nuclear DAB staining, you may use; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); ```. Or to classify cells as positive or negative after running the new subcellular detection command, you could try; ```groovy; setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"", 2.5); ```. Finally, a more sophisticated example where the classifications for all cells are first reset, and then a reclassification according to intensity for tumor cells applied:; ```groovy; // Reset all existing intensity classifications; resetIntensityClassifications(). // Select all tumor objects; def tumor = getPathClass(""Tumor""); def tumorObjects = getObjects({p -> tumor.isAncestorOf(p.getPathClass())}). // Apply intensity classification; setIntensityClassifications(tumorObjects, ""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6). // Fire an update event to see the results; fireHierarchyUpdate(); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-269880806
https://github.com/qupath/qupath/issues/16#issuecomment-269880806:1283,Deployability,update,update,1283,"While there is still no way to classify easily by intensities through the GUI, starting from [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2) several new functions make it very easy by scripting, e.g. [this one](https://github.com/qupath/qupath/blob/master/qupath-core-processing/src/main/java/qupath/lib/scripting/QP.java#L1156). For example, to classify all cells as negative, 1+, 2+ or 3+ according to nuclear DAB staining, you may use; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); ```. Or to classify cells as positive or negative after running the new subcellular detection command, you could try; ```groovy; setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"", 2.5); ```. Finally, a more sophisticated example where the classifications for all cells are first reset, and then a reclassification according to intensity for tumor cells applied:; ```groovy; // Reset all existing intensity classifications; resetIntensityClassifications(). // Select all tumor objects; def tumor = getPathClass(""Tumor""); def tumorObjects = getObjects({p -> tumor.isAncestorOf(p.getPathClass())}). // Apply intensity classification; setIntensityClassifications(tumorObjects, ""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6). // Fire an update event to see the results; fireHierarchyUpdate(); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-269880806
https://github.com/qupath/qupath/issues/16#issuecomment-269880806:621,Safety,detect,detection,621,"While there is still no way to classify easily by intensities through the GUI, starting from [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2) several new functions make it very easy by scripting, e.g. [this one](https://github.com/qupath/qupath/blob/master/qupath-core-processing/src/main/java/qupath/lib/scripting/QP.java#L1156). For example, to classify all cells as negative, 1+, 2+ or 3+ according to nuclear DAB staining, you may use; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); ```. Or to classify cells as positive or negative after running the new subcellular detection command, you could try; ```groovy; setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"", 2.5); ```. Finally, a more sophisticated example where the classifications for all cells are first reset, and then a reclassification according to intensity for tumor cells applied:; ```groovy; // Reset all existing intensity classifications; resetIntensityClassifications(). // Select all tumor objects; def tumor = getPathClass(""Tumor""); def tumorObjects = getObjects({p -> tumor.isAncestorOf(p.getPathClass())}). // Apply intensity classification; setIntensityClassifications(tumorObjects, ""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6). // Fire an update event to see the results; fireHierarchyUpdate(); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-269880806
https://github.com/qupath/qupath/issues/16#issuecomment-391777258:424,Safety,detect,detection,424,"Ah, does that mean it's a .czi file, or is there another scanner/source that produces this...?. Anyway, a couple of suggestions:; * You could export summary results three times, and then merge them together into a single table later... but then you won't have any info about whether individual cells are positive in multiple channels (just summary results for each channel independently); * You can use *Measure &rarr; Show detection measurements* to get all the details for every cell in each image, and explore how to summarize this elsewhere (e.g. in Excel, with R, with Python). If you take the second approach, whatever method of summarizing you choose could then potentially be worked back into becoming a QuPath script. But there isn't any built-in way to do that currently (and I'm not sure what would be the appropriate, general-purpose way to summarize this kind of data).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391777258
https://github.com/qupath/qupath/issues/16#issuecomment-391780670:184,Energy Efficiency,efficient,efficient,184,"i initially started with the detection measurements and manually summarized what i wanted to take from that on excel, but i have ~900 cores to analyze and thought their must be a more efficient way. Can this step be automated?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391780670
https://github.com/qupath/qupath/issues/16#issuecomment-391780670:29,Safety,detect,detection,29,"i initially started with the detection measurements and manually summarized what i wanted to take from that on excel, but i have ~900 cores to analyze and thought their must be a more efficient way. Can this step be automated?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391780670
https://github.com/qupath/qupath/issues/16#issuecomment-391780783:577,Deployability,update,update,577,"Something that is a little more complicated that I have done in cases like this (when I did not want to look into sub-classifications) was create a per-cell measurement for positivity in each channel. The additional measurements would look something like:; Ch1 Positive 1; Ch2 Positive 0; Ch3 Positive 0. Then I would use another putMeasurment command to place a summary measurement in the parent annotation for each value. For my purposes I would create a single Percent Positive per channel for the annotation, so ended up with 3 new annotation measurements (that would only update when I ran the script). This way, I could keep re-running the script with different thresholds, though they would only update when the script is run (deleting cells or recreating the cells does not change the annotation measurements until you rerun the script).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391780783
https://github.com/qupath/qupath/issues/16#issuecomment-391780783:703,Deployability,update,update,703,"Something that is a little more complicated that I have done in cases like this (when I did not want to look into sub-classifications) was create a per-cell measurement for positivity in each channel. The additional measurements would look something like:; Ch1 Positive 1; Ch2 Positive 0; Ch3 Positive 0. Then I would use another putMeasurment command to place a summary measurement in the parent annotation for each value. For my purposes I would create a single Percent Positive per channel for the annotation, so ended up with 3 new annotation measurements (that would only update when I ran the script). This way, I could keep re-running the script with different thresholds, though they would only update when the script is run (deleting cells or recreating the cells does not change the annotation measurements until you rerun the script).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391780783
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:88,Safety,detect,detection,88,"Ok first i ran this script in Qupath. selectAnnotations();; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; removeMeasurements(qupath.lib.objects.PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:101,Safety,detect,detection,101,"Ok first i ran this script in Qupath. selectAnnotations();; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; removeMeasurements(qupath.lib.objects.PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:119,Safety,detect,detection,119,"Ok first i ran this script in Qupath. selectAnnotations();; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; removeMeasurements(qupath.lib.objects.PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:1134,Safety,detect,detection,1134,"PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:5857,Safety,detect,detections,5857,"ell: Circularity"", ""Cytoplasm: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum"", ""Nucleus: Channel 2 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 3 mean"", ""Cell: Channel 3 std dev"", ""Cytoplasm: Channel 2 max"", ""Nucleus: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 min"", ""Nucleus: Channel 4 mean"", ""Nucleus: Channel 1 max"", ""Cell: Channel 3 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range"", ""Cell: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 max"", ""Nucleus: Perimeter"", ""Cytoplasm: Channel 2 mean"", ""Cytoplasm: Channel 4 max"", ""Cytoplasm: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Cell: Area"", ""Nucleus: Max caliper"", ""Cell: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum - Smoothed (FWHM 25 µm)"", ""Cell: Channel 2 max"", ""Nucleus: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio"", ""Cytoplasm: Channel 1 std dev"", ""Cytoplasm: Channel 2 min - Smoothed (FWHM 25 µm)"", ""Cell: Min caliper"", ""Cell: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 range"", ""Nucleus: Channel 2 min - Smoothed (FWHM 25 µm)"");. //create dectection results//; saveDetectionMeasurements('D:IFproject_0_19', ). this resulted in a text file being saved with the core name, then i opened it in excel and deleted all remaining columns until i was left with ""class"", ""cell channel 1 mean""-""cell channel 4 mean""; (I am not actually interested in channel 4, that is my nuclear stain).; i sorted the table by 'class' and separated tumor and stroma cell detections, i counted the number of detections for each class type and and summed the intensities for each channel. i divided the intensity for each channel by the totally number of detections in that class. Just to obtain a simple relative amount of the marker within that tissue type.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:5893,Safety,detect,detections,5893,"ell: Circularity"", ""Cytoplasm: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum"", ""Nucleus: Channel 2 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 3 mean"", ""Cell: Channel 3 std dev"", ""Cytoplasm: Channel 2 max"", ""Nucleus: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 min"", ""Nucleus: Channel 4 mean"", ""Nucleus: Channel 1 max"", ""Cell: Channel 3 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range"", ""Cell: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 max"", ""Nucleus: Perimeter"", ""Cytoplasm: Channel 2 mean"", ""Cytoplasm: Channel 4 max"", ""Cytoplasm: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Cell: Area"", ""Nucleus: Max caliper"", ""Cell: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum - Smoothed (FWHM 25 µm)"", ""Cell: Channel 2 max"", ""Nucleus: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio"", ""Cytoplasm: Channel 1 std dev"", ""Cytoplasm: Channel 2 min - Smoothed (FWHM 25 µm)"", ""Cell: Min caliper"", ""Cell: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 range"", ""Nucleus: Channel 2 min - Smoothed (FWHM 25 µm)"");. //create dectection results//; saveDetectionMeasurements('D:IFproject_0_19', ). this resulted in a text file being saved with the core name, then i opened it in excel and deleted all remaining columns until i was left with ""class"", ""cell channel 1 mean""-""cell channel 4 mean""; (I am not actually interested in channel 4, that is my nuclear stain).; i sorted the table by 'class' and separated tumor and stroma cell detections, i counted the number of detections for each class type and and summed the intensities for each channel. i divided the intensity for each channel by the totally number of detections in that class. Just to obtain a simple relative amount of the marker within that tissue type.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:6039,Safety,detect,detections,6039,"ell: Circularity"", ""Cytoplasm: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum"", ""Nucleus: Channel 2 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 3 mean"", ""Cell: Channel 3 std dev"", ""Cytoplasm: Channel 2 max"", ""Nucleus: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 min"", ""Nucleus: Channel 4 mean"", ""Nucleus: Channel 1 max"", ""Cell: Channel 3 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range"", ""Cell: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 max"", ""Nucleus: Perimeter"", ""Cytoplasm: Channel 2 mean"", ""Cytoplasm: Channel 4 max"", ""Cytoplasm: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Cell: Area"", ""Nucleus: Max caliper"", ""Cell: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum - Smoothed (FWHM 25 µm)"", ""Cell: Channel 2 max"", ""Nucleus: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio"", ""Cytoplasm: Channel 1 std dev"", ""Cytoplasm: Channel 2 min - Smoothed (FWHM 25 µm)"", ""Cell: Min caliper"", ""Cell: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 range"", ""Nucleus: Channel 2 min - Smoothed (FWHM 25 µm)"");. //create dectection results//; saveDetectionMeasurements('D:IFproject_0_19', ). this resulted in a text file being saved with the core name, then i opened it in excel and deleted all remaining columns until i was left with ""class"", ""cell channel 1 mean""-""cell channel 4 mean""; (I am not actually interested in channel 4, that is my nuclear stain).; i sorted the table by 'class' and separated tumor and stroma cell detections, i counted the number of detections for each class type and and summed the intensities for each channel. i divided the intensity for each channel by the totally number of detections in that class. Just to obtain a simple relative amount of the marker within that tissue type.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391785100:6082,Usability,simpl,simple,6082,"ell: Circularity"", ""Cytoplasm: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum"", ""Nucleus: Channel 2 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 3 mean"", ""Cell: Channel 3 std dev"", ""Cytoplasm: Channel 2 max"", ""Nucleus: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 min"", ""Nucleus: Channel 4 mean"", ""Nucleus: Channel 1 max"", ""Cell: Channel 3 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range"", ""Cell: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 max"", ""Nucleus: Perimeter"", ""Cytoplasm: Channel 2 mean"", ""Cytoplasm: Channel 4 max"", ""Cytoplasm: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Cell: Area"", ""Nucleus: Max caliper"", ""Cell: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum - Smoothed (FWHM 25 µm)"", ""Cell: Channel 2 max"", ""Nucleus: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio"", ""Cytoplasm: Channel 1 std dev"", ""Cytoplasm: Channel 2 min - Smoothed (FWHM 25 µm)"", ""Cell: Min caliper"", ""Cell: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 range"", ""Nucleus: Channel 2 min - Smoothed (FWHM 25 µm)"");. //create dectection results//; saveDetectionMeasurements('D:IFproject_0_19', ). this resulted in a text file being saved with the core name, then i opened it in excel and deleted all remaining columns until i was left with ""class"", ""cell channel 1 mean""-""cell channel 4 mean""; (I am not actually interested in channel 4, that is my nuclear stain).; i sorted the table by 'class' and separated tumor and stroma cell detections, i counted the number of detections for each class type and and summed the intensities for each channel. i divided the intensity for each channel by the totally number of detections in that class. Just to obtain a simple relative amount of the marker within that tissue type.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100
https://github.com/qupath/qupath/issues/16#issuecomment-391838121:76,Testability,test,test,76,"Not sure if this is exactly what you want, and don't have a great sample to test it on right now, but: . ```; //This assumes there is only one parent annotation for the cell. Multiple annotations would require some adjustment. //Your measurement list and starting values; ch1 = ""Cell: Channel 1 mean""; ch2 = ""Cell: Channel 2 mean""; def ch1Total = 0; def ch2Total = 0. //Create a list of your tumor and stroma cells; def stromaCells = getCellObjects().findAll{it.getPathClass() == getPathClass(""Stroma"")}; def tumorCells = getCellObjects().findAll{it.getPathClass() == getPathClass(""Tumor"")}. stromaCells.each{; ch1Total = it.getMeasurementList().getMeasurementValue(ch1)+ch1Total; ch2Total = it.getMeasurementList().getMeasurementValue(ch2)+ch2Total; }; tumorCells.each{; ch1Total = it.getMeasurementList().getMeasurementValue(ch1)+ch1Total; ch2Total = it.getMeasurementList().getMeasurementValue(ch2)+ch2Total; }. //Assuming there is only one annotation object:; annotation = getAnnotationObjects()[0]. //Add your measurement total divided by the total number of objects for a mean of means.; //Alternatively, get the area measurement AND mean, and get the actual total intensity and divide by the number of cells.; annotation.getMeasurementList().putMeasurement(""Mean Ch1 Tumor"", ch1Total/tumorCells.size); annotation.getMeasurementList().putMeasurement(""Mean Ch2 Tumor"", ch2Total/tumorCells.size). annotation.getMeasurementList().putMeasurement(""Mean Ch1 Stroma"", ch1Total/stromaCells.size); annotation.getMeasurementList().putMeasurement(""Mean Ch2 Stroma"", ch2Total/stromaCells.size); ```; If you combine that with the export script from: https://petebankhead.github.io/qupath/scripting/2018/03/04/script-annotation-export.html. and after that run: https://petebankhead.github.io/qupath/scripting/2018/03/05/script-annotation-results-merge.html. hopefully you will get the output for your entire project. You will probably want to add in the third channel, and rename some of the values as desired",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391838121
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:843,Availability,avail,available,843,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:37,Deployability,integrat,integrated,37,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:37,Integrability,integrat,integrated,37,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:196,Testability,Test,Testing,196,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:448,Testability,test,testing,448,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/18#issuecomment-258824636:873,Usability,clear,clear,873,"The third option listed above is now integrated, and locale information is added to `.qpdata` files. This has been done in a way that should not break compatibility with any existing saved files. Testing involved varying the locale using commands such as those below (one at a time):. ``` groovy; Locale.setDefault(Locale.UK);; Locale.setDefault(Locale.GERMAN);; Locale.setDefault(Locale.JAPAN);; Locale.setDefault(Locale.CHINA);; ```. ...and then testing whether files written with one locale could then be read using another. This appears to be working, but further insights and bug-reports relating to location-specific issues would be welcome. The fix will be included in `v0.0.5`. (Note: I could conceive of trouble with `ClassNotFoundExceptions` in the event of attempting to deserialize a `.qpdata` file where the saved `Locale` is not available... however it's not clear to me whether this could or would ever actually happen. In the even that it does, QuPath should default to not changing the locale at all - and so would still have a reasonable chance of succeeding.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/18#issuecomment-258824636
https://github.com/qupath/qupath/issues/24#issuecomment-494339173:58,Deployability,release,releases,58,This should no longer be the case in the latest milestone releases.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/24#issuecomment-494339173
https://github.com/qupath/qupath/issues/25#issuecomment-261927806:126,Safety,avoid,avoids,126,"This is somewhat by design (in that the command history only logs things that are relevant to batch processing, and generally avoids GUI-related commands for showing/hiding things). Nevertheless, certainly there needs to be some way to script either the display or export of annotation measurements.... and currently there isn't. My feeling is that whenever you run *Show Annotation Measurements* this shouldn't be recorded (because it's purely a display thing, which shouldn't happen in a batch script), but if you press *Save* then the export of the annotation measurements should be recorded in the command history. What do you think? Would this do what you need, or do you think it's also necessary to be able to script showing the table as well?. In the meantime, my way to handle needing to run the same interactive command repeatedly across multiple images in a project is to open the images one at a time while keeping keep *View &rarr; Show command list* open, and turning off the *Auto close* option. It's not optimal, but at least that way there's no need to return to the menus too often. ![command_list](https://cloud.githubusercontent.com/assets/4690904/20482972/917901e2-afe7-11e6-9474-1818edb79985.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-261927806
https://github.com/qupath/qupath/issues/25#issuecomment-261927806:61,Testability,log,logs,61,"This is somewhat by design (in that the command history only logs things that are relevant to batch processing, and generally avoids GUI-related commands for showing/hiding things). Nevertheless, certainly there needs to be some way to script either the display or export of annotation measurements.... and currently there isn't. My feeling is that whenever you run *Show Annotation Measurements* this shouldn't be recorded (because it's purely a display thing, which shouldn't happen in a batch script), but if you press *Save* then the export of the annotation measurements should be recorded in the command history. What do you think? Would this do what you need, or do you think it's also necessary to be able to script showing the table as well?. In the meantime, my way to handle needing to run the same interactive command repeatedly across multiple images in a project is to open the images one at a time while keeping keep *View &rarr; Show command list* open, and turning off the *Auto close* option. It's not optimal, but at least that way there's no need to return to the menus too often. ![command_list](https://cloud.githubusercontent.com/assets/4690904/20482972/917901e2-afe7-11e6-9474-1818edb79985.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-261927806
https://github.com/qupath/qupath/issues/25#issuecomment-265210130:133,Deployability,update,update,133,"This issue is not yet resolved (i.e. script recording of annotation export still needs to be implemented), but there is one relevant update in [v0.1.1](https://github.com/qupath/qupath/releases/tag/v0.1.1). It's now possible to request, and then fire, a [JavaFX MenuItem](http://docs.oracle.com/javase/8/javafx/api/javafx/scene/control/MenuItem.html) from the main QuPath GUI if required. This [gist](https://gist.github.com/petebankhead/c19186a30707b5c51aa5a8a9c0d2c6b1) shows the (not entirely obvious) steps involved - maybe it's useful as a workaround for now, for anyone in need of the ability to do run arbitrary commands from the menus.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-265210130
https://github.com/qupath/qupath/issues/25#issuecomment-265210130:185,Deployability,release,releases,185,"This issue is not yet resolved (i.e. script recording of annotation export still needs to be implemented), but there is one relevant update in [v0.1.1](https://github.com/qupath/qupath/releases/tag/v0.1.1). It's now possible to request, and then fire, a [JavaFX MenuItem](http://docs.oracle.com/javase/8/javafx/api/javafx/scene/control/MenuItem.html) from the main QuPath GUI if required. This [gist](https://gist.github.com/petebankhead/c19186a30707b5c51aa5a8a9c0d2c6b1) shows the (not entirely obvious) steps involved - maybe it's useful as a workaround for now, for anyone in need of the ability to do run arbitrary commands from the menus.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-265210130
https://github.com/qupath/qupath/issues/25#issuecomment-269880610:47,Deployability,release,releases,47,"From [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2), *Measure &rarr; Show Annotation Measurements* should be recorded in the command history - and able to generate a script line, including filtering by specified columns if required. The syntax looks like this:; ```java; saveAnnotationMeasurements('/path/to/exported/file.txt', 'Area', 'Length'); ```. There is also now a small trick that can be used to run short scripts that affect the GUI (which must be run in the [JavaFX Platform thread](https://docs.oracle.com/javase/8/javafx/api/javafx/application/Platform.html#runLater-java.lang.Runnable-)), namely to include ```guiscript=true``` at the top of the script. This isn't a good idea routinely (since it will result in the entire script being run on that thread), but it avoids needing to use ```Platform.runLater(...)``` every time this is required. An example is given [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269880610
https://github.com/qupath/qupath/issues/25#issuecomment-269880610:706,Integrability,rout,routinely,706,"From [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2), *Measure &rarr; Show Annotation Measurements* should be recorded in the command history - and able to generate a script line, including filtering by specified columns if required. The syntax looks like this:; ```java; saveAnnotationMeasurements('/path/to/exported/file.txt', 'Area', 'Length'); ```. There is also now a small trick that can be used to run short scripts that affect the GUI (which must be run in the [JavaFX Platform thread](https://docs.oracle.com/javase/8/javafx/api/javafx/application/Platform.html#runLater-java.lang.Runnable-)), namely to include ```guiscript=true``` at the top of the script. This isn't a good idea routinely (since it will result in the entire script being run on that thread), but it avoids needing to use ```Platform.runLater(...)``` every time this is required. An example is given [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269880610
https://github.com/qupath/qupath/issues/25#issuecomment-269880610:793,Safety,avoid,avoids,793,"From [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2), *Measure &rarr; Show Annotation Measurements* should be recorded in the command history - and able to generate a script line, including filtering by specified columns if required. The syntax looks like this:; ```java; saveAnnotationMeasurements('/path/to/exported/file.txt', 'Area', 'Length'); ```. There is also now a small trick that can be used to run short scripts that affect the GUI (which must be run in the [JavaFX Platform thread](https://docs.oracle.com/javase/8/javafx/api/javafx/application/Platform.html#runLater-java.lang.Runnable-)), namely to include ```guiscript=true``` at the top of the script. This isn't a good idea routinely (since it will result in the entire script being run on that thread), but it avoids needing to use ```Platform.runLater(...)``` every time this is required. An example is given [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269880610
https://github.com/qupath/qupath/issues/25#issuecomment-269953909:128,Testability,log,logged,128,"Ok, so this is not quite fixed yet... For exporting measurements for a single image (not in a project), the full export path is logged. When creating a script from the command history, the result is a line like the following:; ```groovy; saveAnnotationMeasurements('/path/to/export/My export.txt', ); ```; (The comma at the end is unintentional... but it is only cosmetic, and does not prevent the script from running. It can be removed as well.). When logging the command within a project, the output is slightly different. QuPath (intentionally) omits the specific file name from the export path, and instead only stores the directory. When run within a script, QuPath should then build a suitable export name from the image name and the type of data being exported. This is to help when running over an entire project, whenever exporting to the same path would overwrite the file. This *almost* works, but the export currently appears to omit the dot before the extension, i.e. if the image is called ```CMU-1-Small-Region.svs```, then for a command; ```groovy; saveAnnotationMeasurements('/path/to/export'); ```; where ```/path/to/export``` is the path to any existing directory, QuPath would write the output to ```/path/to/export/CMU-1-Small-Region Annotationstxt``` when it should write to ```/path/to/export/CMU-1-Small-Region Annotations.txt```. Of course you can add the missing dot in later, so it is only an inconvenience. However, you can also modify the export command to create your own full path, in which case it will be used. So, for example, you could write the following; ```groovy; saveAnnotationMeasurements('/path/to/export/' + getProjectEntry().getImageName() + "".txt""); ```; and I believe this works. I have reopened this issue until the dot bug is fixed, however if any other problems are found with the export then please report them here as well.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269953909
https://github.com/qupath/qupath/issues/25#issuecomment-269953909:453,Testability,log,logging,453,"Ok, so this is not quite fixed yet... For exporting measurements for a single image (not in a project), the full export path is logged. When creating a script from the command history, the result is a line like the following:; ```groovy; saveAnnotationMeasurements('/path/to/export/My export.txt', ); ```; (The comma at the end is unintentional... but it is only cosmetic, and does not prevent the script from running. It can be removed as well.). When logging the command within a project, the output is slightly different. QuPath (intentionally) omits the specific file name from the export path, and instead only stores the directory. When run within a script, QuPath should then build a suitable export name from the image name and the type of data being exported. This is to help when running over an entire project, whenever exporting to the same path would overwrite the file. This *almost* works, but the export currently appears to omit the dot before the extension, i.e. if the image is called ```CMU-1-Small-Region.svs```, then for a command; ```groovy; saveAnnotationMeasurements('/path/to/export'); ```; where ```/path/to/export``` is the path to any existing directory, QuPath would write the output to ```/path/to/export/CMU-1-Small-Region Annotationstxt``` when it should write to ```/path/to/export/CMU-1-Small-Region Annotations.txt```. Of course you can add the missing dot in later, so it is only an inconvenience. However, you can also modify the export command to create your own full path, in which case it will be used. So, for example, you could write the following; ```groovy; saveAnnotationMeasurements('/path/to/export/' + getProjectEntry().getImageName() + "".txt""); ```; and I believe this works. I have reopened this issue until the dot bug is fixed, however if any other problems are found with the export then please report them here as well.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269953909
https://github.com/qupath/qupath/issues/25#issuecomment-269992633:69,Testability,log,logged,69,"Oops... there's a bug affecting only Windows :(; The command will be logged something like; ```groovy; saveAnnotationMeasurements('C:\path\to\export', ); ```; but Java/Groovy doesn't like the path with just single backslashes. Therefore you will need to change this to be; ```groovy; saveAnnotationMeasurements('C:\\path\\to\\export', ); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269992633
https://github.com/qupath/qupath/issues/25#issuecomment-518559177:154,Testability,log,logged,154,Closing this issue because of lack of activity and the backslash issue should be resolved in the latest milestone versions. GUI-related activity can't be logged in the workflow using the current design.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-518559177
https://github.com/qupath/qupath/issues/26#issuecomment-261924933:610,Deployability,update,update,610,"Hi Romain,. You should be able to double-click on the 'Min display' or 'Max display' labels and input values manually there. As you've likely seen, the values should persist when the image is closed/reopened within the same QuPath session, but not when QuPath is reopened. I'll give some thought to where this information could best be added to the ```.qpdata``` file, and how to set the values through scripting (similar to ImageJ's ```setMinAndMax(min, max, channels)```. If both of these can be done, then running such a script would be one way to use the same values across the whole project. I'll post an update here when I've made progress on this.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-261924933
https://github.com/qupath/qupath/issues/26#issuecomment-453632278:209,Deployability,update,updates,209,"> As you've likely seen, the values should persist when the image is closed/reopened within the same QuPath session, but not when QuPath is reopened. Hi! @petebankhead I was just wondering if there's been any updates to this thread? Is there a way to save the max/min values to be used once QuPath is reopened - for example to apply these settings to an entire project?. Thank you,. belliveau13",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453632278
https://github.com/qupath/qupath/issues/26#issuecomment-453637134:34,Availability,avail,available,34,"Yes and no... not in any publicly available way, and it remains on my todo list before the next release. This is taking longer than I'd hope as I find more and more to do, but some talks and workshops in March give me a pretty hard deadline.... However, amidst all the changes I'm making for the next release I've introduced an option to 'retain the display settings' when opening a new image. This means that if you have an image open with certain brightness/contrast settings (and color channels turned on/off), then if you open another image in the project it will (optionally) keep the settings constant:; https://github.com/petebankhead/qupath/commit/5750e42574cf34f9c868c9d2b133da3daaecf5e1. My hope is that it reduces the need to apply settings across all images in a project through a script, because the min/max settings (optionally) don't automatically change per image. How does that sounds to you?. Alongside that, I've added the ability to turn on/off multiple channels at once (by selecting them and right-clicking), and given a bit more control on what the 'Auto' button does when adjusting brightness/contrast per channel. I think these changes make the Brightness/Contrast dialog considerably easier to use; at least, I find it less annoying now than it previously was. (I still do need to revisit saving settings though, because it needs to be possible to set channel names if these are wrong or missing. And if it's possible to save channel names, it may as well be possible to save display settings per channel as well...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453637134
https://github.com/qupath/qupath/issues/26#issuecomment-453637134:96,Deployability,release,release,96,"Yes and no... not in any publicly available way, and it remains on my todo list before the next release. This is taking longer than I'd hope as I find more and more to do, but some talks and workshops in March give me a pretty hard deadline.... However, amidst all the changes I'm making for the next release I've introduced an option to 'retain the display settings' when opening a new image. This means that if you have an image open with certain brightness/contrast settings (and color channels turned on/off), then if you open another image in the project it will (optionally) keep the settings constant:; https://github.com/petebankhead/qupath/commit/5750e42574cf34f9c868c9d2b133da3daaecf5e1. My hope is that it reduces the need to apply settings across all images in a project through a script, because the min/max settings (optionally) don't automatically change per image. How does that sounds to you?. Alongside that, I've added the ability to turn on/off multiple channels at once (by selecting them and right-clicking), and given a bit more control on what the 'Auto' button does when adjusting brightness/contrast per channel. I think these changes make the Brightness/Contrast dialog considerably easier to use; at least, I find it less annoying now than it previously was. (I still do need to revisit saving settings though, because it needs to be possible to set channel names if these are wrong or missing. And if it's possible to save channel names, it may as well be possible to save display settings per channel as well...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453637134
https://github.com/qupath/qupath/issues/26#issuecomment-453637134:301,Deployability,release,release,301,"Yes and no... not in any publicly available way, and it remains on my todo list before the next release. This is taking longer than I'd hope as I find more and more to do, but some talks and workshops in March give me a pretty hard deadline.... However, amidst all the changes I'm making for the next release I've introduced an option to 'retain the display settings' when opening a new image. This means that if you have an image open with certain brightness/contrast settings (and color channels turned on/off), then if you open another image in the project it will (optionally) keep the settings constant:; https://github.com/petebankhead/qupath/commit/5750e42574cf34f9c868c9d2b133da3daaecf5e1. My hope is that it reduces the need to apply settings across all images in a project through a script, because the min/max settings (optionally) don't automatically change per image. How does that sounds to you?. Alongside that, I've added the ability to turn on/off multiple channels at once (by selecting them and right-clicking), and given a bit more control on what the 'Auto' button does when adjusting brightness/contrast per channel. I think these changes make the Brightness/Contrast dialog considerably easier to use; at least, I find it less annoying now than it previously was. (I still do need to revisit saving settings though, because it needs to be possible to set channel names if these are wrong or missing. And if it's possible to save channel names, it may as well be possible to save display settings per channel as well...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453637134
https://github.com/qupath/qupath/issues/26#issuecomment-453637134:717,Energy Efficiency,reduce,reduces,717,"Yes and no... not in any publicly available way, and it remains on my todo list before the next release. This is taking longer than I'd hope as I find more and more to do, but some talks and workshops in March give me a pretty hard deadline.... However, amidst all the changes I'm making for the next release I've introduced an option to 'retain the display settings' when opening a new image. This means that if you have an image open with certain brightness/contrast settings (and color channels turned on/off), then if you open another image in the project it will (optionally) keep the settings constant:; https://github.com/petebankhead/qupath/commit/5750e42574cf34f9c868c9d2b133da3daaecf5e1. My hope is that it reduces the need to apply settings across all images in a project through a script, because the min/max settings (optionally) don't automatically change per image. How does that sounds to you?. Alongside that, I've added the ability to turn on/off multiple channels at once (by selecting them and right-clicking), and given a bit more control on what the 'Auto' button does when adjusting brightness/contrast per channel. I think these changes make the Brightness/Contrast dialog considerably easier to use; at least, I find it less annoying now than it previously was. (I still do need to revisit saving settings though, because it needs to be possible to set channel names if these are wrong or missing. And if it's possible to save channel names, it may as well be possible to save display settings per channel as well...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453637134
https://github.com/qupath/qupath/issues/26#issuecomment-453955094:363,Deployability,update,update,363,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094
https://github.com/qupath/qupath/issues/26#issuecomment-453955094:370,Deployability,release,released,370,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094
https://github.com/qupath/qupath/issues/26#issuecomment-453955094:759,Deployability,release,release,759,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094
https://github.com/qupath/qupath/issues/26#issuecomment-453955094:209,Performance,Load,Load,209,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094
https://github.com/qupath/qupath/issues/26#issuecomment-453955094:681,Safety,risk,risk,681,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094
https://github.com/qupath/qupath/issues/26#issuecomment-632599816:502,Deployability,release,release,502,"Hi @petebankhead, . RGB may be the main target of QuPath and they have no such issue. But honestly the lack of ability to conveniently set B&C for all fluorescent images of the same kind is pretty annoying. We regularly have users with k.10's of multichannel images. The workaround with the retain option is okish but clearly not as convenient as a 'set B&C for all images of the same kind'. > So that remains a task for a future version... So why not letting the issue open and add a tag for a future release ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632599816
https://github.com/qupath/qupath/issues/26#issuecomment-632599816:318,Usability,clear,clearly,318,"Hi @petebankhead, . RGB may be the main target of QuPath and they have no such issue. But honestly the lack of ability to conveniently set B&C for all fluorescent images of the same kind is pretty annoying. We regularly have users with k.10's of multichannel images. The workaround with the retain option is okish but clearly not as convenient as a 'set B&C for all images of the same kind'. > So that remains a task for a future version... So why not letting the issue open and add a tag for a future release ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632599816
https://github.com/qupath/qupath/issues/26#issuecomment-632609335:140,Usability,clear,clear,140,"Hi @NicoKiaru, I closed this because it became fragmented and hard for follow, and there have been no comments for over a year. Without any clear feedback I couldn't know that it is pretty annoying for your users. In case you missed it, I already added scripting methods to help: https://github.com/petebankhead/qupath/pull/37#issuecomment-586469880",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632609335
https://github.com/qupath/qupath/issues/26#issuecomment-632609335:146,Usability,feedback,feedback,146,"Hi @NicoKiaru, I closed this because it became fragmented and hard for follow, and there have been no comments for over a year. Without any clear feedback I couldn't know that it is pretty annoying for your users. In case you missed it, I already added scripting methods to help: https://github.com/petebankhead/qupath/pull/37#issuecomment-586469880",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632609335
https://github.com/qupath/qupath/issues/26#issuecomment-632615374:364,Usability,simpl,simple,364,"@petebankhead the last comment before it became closed came from @romainGuiet from which we heard no comments from you. Admittedly we did not pursue this further as we had a workaround in our version. ; I would be curious to have your opinion on how we did it and whether you think that the approach we took could break anything. The commands we built were pretty simple and were not breaking anything. they were of course not polished to look pretty but the desired effect and user satisfaction were worth the effort we had put into it. ; You can find the commands here:; https://github.com/BIOP/qupath-biop-extensions/blob/master/src/main/java/ch/epfl/biop/qupath/commands/ApplyDisplaySettingsCommand.java. There are two other commands in that directory that do similar things, but that were not so used in the end. The one people really liked was the one linked above. These are not doing or hacking anything special in QuPath to make them work, and having them in the QuPath main code would remove the package private issues I had to deal with.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632615374
https://github.com/qupath/qupath/issues/26#issuecomment-632627020:241,Availability,mainten,maintenance,241,"As I mentioned (each time you brought this up :) ) the approach you have taken creates a dependency on `ImageDisplay` that I *really* do not want to be stuck with. It creates an awkward confusion between the GUI and core code that will be a maintenance headache, and would greatly complicate trying to implement a better design later. I added the alternative scripting methods that I linked to before precisely because you asked for it. Running that for a project is the solution I propose. It uses `ImageDisplay` internally (because it has to), but doesn't expose this publicly. Romain's comment wasn't a question, it seemed you had a solution you were satisfied with, and I received no reply to the changes I made for you except for 👍 so it remains very unclear to me what you want...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632627020
https://github.com/qupath/qupath/issues/26#issuecomment-632627020:89,Integrability,depend,dependency,89,"As I mentioned (each time you brought this up :) ) the approach you have taken creates a dependency on `ImageDisplay` that I *really* do not want to be stuck with. It creates an awkward confusion between the GUI and core code that will be a maintenance headache, and would greatly complicate trying to implement a better design later. I added the alternative scripting methods that I linked to before precisely because you asked for it. Running that for a project is the solution I propose. It uses `ImageDisplay` internally (because it has to), but doesn't expose this publicly. Romain's comment wasn't a question, it seemed you had a solution you were satisfied with, and I received no reply to the changes I made for you except for 👍 so it remains very unclear to me what you want...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632627020
https://github.com/qupath/qupath/issues/26#issuecomment-632627020:558,Security,expose,expose,558,"As I mentioned (each time you brought this up :) ) the approach you have taken creates a dependency on `ImageDisplay` that I *really* do not want to be stuck with. It creates an awkward confusion between the GUI and core code that will be a maintenance headache, and would greatly complicate trying to implement a better design later. I added the alternative scripting methods that I linked to before precisely because you asked for it. Running that for a project is the solution I propose. It uses `ImageDisplay` internally (because it has to), but doesn't expose this publicly. Romain's comment wasn't a question, it seemed you had a solution you were satisfied with, and I received no reply to the changes I made for you except for 👍 so it remains very unclear to me what you want...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632627020
https://github.com/qupath/qupath/issues/26#issuecomment-632635935:430,Deployability,update,updates,430,"Thank yo for the reply and your re-repeat :) of what you had already told me. I admit that I am really bad at understanding this part. This is what I think I understand:. The approach we used creates an issue with the way `ImageDisplay` is currently implemented because saving display settings to the .qpdata file is not good practice? ; But doing this via scripting is OK because it's less important if scripts break upon QuPath updates?. The risk is that if these are made public, other people could call upon these methods, and that would break something in the GUI whenever changes will be made to the code?. Currently there is no other way than to use `ImageDisplay` to set these properties for the channels (and save and recall them) which is bad because this will be revised in the future?. Let me know what I got wrong there if you have time. I think that in the meantime I will test a script to do what we used to be able to do, and dive into the wonderful world of Reflection for my sake.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632635935
https://github.com/qupath/qupath/issues/26#issuecomment-632635935:444,Safety,risk,risk,444,"Thank yo for the reply and your re-repeat :) of what you had already told me. I admit that I am really bad at understanding this part. This is what I think I understand:. The approach we used creates an issue with the way `ImageDisplay` is currently implemented because saving display settings to the .qpdata file is not good practice? ; But doing this via scripting is OK because it's less important if scripts break upon QuPath updates?. The risk is that if these are made public, other people could call upon these methods, and that would break something in the GUI whenever changes will be made to the code?. Currently there is no other way than to use `ImageDisplay` to set these properties for the channels (and save and recall them) which is bad because this will be revised in the future?. Let me know what I got wrong there if you have time. I think that in the meantime I will test a script to do what we used to be able to do, and dive into the wonderful world of Reflection for my sake.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632635935
https://github.com/qupath/qupath/issues/26#issuecomment-632635935:887,Testability,test,test,887,"Thank yo for the reply and your re-repeat :) of what you had already told me. I admit that I am really bad at understanding this part. This is what I think I understand:. The approach we used creates an issue with the way `ImageDisplay` is currently implemented because saving display settings to the .qpdata file is not good practice? ; But doing this via scripting is OK because it's less important if scripts break upon QuPath updates?. The risk is that if these are made public, other people could call upon these methods, and that would break something in the GUI whenever changes will be made to the code?. Currently there is no other way than to use `ImageDisplay` to set these properties for the channels (and save and recall them) which is bad because this will be revised in the future?. Let me know what I got wrong there if you have time. I think that in the meantime I will test a script to do what we used to be able to do, and dive into the wonderful world of Reflection for my sake.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632635935
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:1144,Availability,toler,tolerable,1144,"ath-gui-fx/src/main/java/qupath/lib/gui/scripting/QPEx.java#L336).... but no absolute promises that won't be broken in the future either :). Ok, I will explain some more and hope it will be sufficient. QuPath is divided into modules. This modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but it would also make updating this information for 10,000 images almost instantaneous. I have made some progress in parts of this, because I needed a way",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:3776,Availability,avail,available,3776,"ImageDisplay`. Eventually I think this kind of color transform approach should completely replace the (currently GUI-only) color transforms for better consistency and more maintainable code. More generally, I need to be thinking broadly about existing users as well as how the software will need to look a year from now, or two years from now, to meet a host of new applications. And I need to think about how much of those years will go into maintaining existing things where it is *already* clear they are not using the right approach. Often, there are lots of considerations that I haven't articulated anywhere (there just isn't time), but which are impacted by the choices. For example: finding a better approach to handle brightness/contrast perhaps could/should also support serializing the image histograms (since `ImageDisplay` uses them). Storing these histograms would make opening images a great deal faster as well. But then, having histograms separated from the GUI (and JavaFX) would also make intensity distribution information instantly available in general. This might open up new and faster processing and analysis options - including the use of automated thresholds based on such histograms. If something is not public, it can be freely changed without breaking other extensions (and also well-behaved scripts). If it is public, other extensions and scripts that use it will definitely break. Each breaking change costs a) user annoyance, and b) developer time. Making fewer things public reduces that. Time is incredibly precious... there are now (finally) two of us working on it, but there are quite some demands on us. And in academia, a lot of what we are judged on isn't software anyway. So I think it is important we follow our beliefs about what will protect our time and be better in the long run - trying to be helpful, but not caving to pressure :). So why the scripting approach?. In general, when something is used internally by QuPath, we have a much better idea of wh",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:5611,Deployability,release,release,5611,"eneral, when something is used internally by QuPath, we have a much better idea of what we might be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:6611,Deployability,release,releases,6611," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:1867,Energy Efficiency,efficient,efficient,1867," in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but it would also make updating this information for 10,000 images almost instantaneous. I have made some progress in parts of this, because I needed a way to have JSON-serializable color transforms separate from the GUI in order to support stain separation in the pixel classifier and thresholder.... which was needed [to make the sluggish and limited 'Positive pixel counter' unnecessary](https://qupath.readthedocs.io/en/latest/docs/tutorials/measuring_areas.html)... which was needed for my sanity so I'd have to stop answering questions about such a poorly-implemented command (that I had originally implemented). Doing this involved writing a completely separate way of representing the transforms than the one used by `ImageDisplay`. Eventually I think this kind of color transform approach should completely replace the (currently GUI-only) color transforms for better consistency and",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:4231,Energy Efficiency,reduce,reduces,4231,"hey are not using the right approach. Often, there are lots of considerations that I haven't articulated anywhere (there just isn't time), but which are impacted by the choices. For example: finding a better approach to handle brightness/contrast perhaps could/should also support serializing the image histograms (since `ImageDisplay` uses them). Storing these histograms would make opening images a great deal faster as well. But then, having histograms separated from the GUI (and JavaFX) would also make intensity distribution information instantly available in general. This might open up new and faster processing and analysis options - including the use of automated thresholds based on such histograms. If something is not public, it can be freely changed without breaking other extensions (and also well-behaved scripts). If it is public, other extensions and scripts that use it will definitely break. Each breaking change costs a) user annoyance, and b) developer time. Making fewer things public reduces that. Time is incredibly precious... there are now (finally) two of us working on it, but there are quite some demands on us. And in academia, a lot of what we are judged on isn't software anyway. So I think it is important we follow our beliefs about what will protect our time and be better in the long run - trying to be helpful, but not caving to pressure :). So why the scripting approach?. In general, when something is used internally by QuPath, we have a much better idea of what we might be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:6700,Energy Efficiency,sustainab,sustainable,6700," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:613,Integrability,depend,dependency,613,"Well, you can avoid both reflection and scripting if you go to [QPEx](https://github.com/qupath/qupath/blob/6ebd4a296e05b89bca3466a14a7d7cf79eb3fad4/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/QPEx.java#L336).... but no absolute promises that won't be broken in the future either :). Ok, I will explain some more and hope it will be sufficient. QuPath is divided into modules. This modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:773,Integrability,depend,dependent,773,"Well, you can avoid both reflection and scripting if you go to [QPEx](https://github.com/qupath/qupath/blob/6ebd4a296e05b89bca3466a14a7d7cf79eb3fad4/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/QPEx.java#L336).... but no absolute promises that won't be broken in the future either :). Ok, I will explain some more and hope it will be sufficient. QuPath is divided into modules. This modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:2895,Modifiability,maintainab,maintainable,2895,"e large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but it would also make updating this information for 10,000 images almost instantaneous. I have made some progress in parts of this, because I needed a way to have JSON-serializable color transforms separate from the GUI in order to support stain separation in the pixel classifier and thresholder.... which was needed [to make the sluggish and limited 'Positive pixel counter' unnecessary](https://qupath.readthedocs.io/en/latest/docs/tutorials/measuring_areas.html)... which was needed for my sanity so I'd have to stop answering questions about such a poorly-implemented command (that I had originally implemented). Doing this involved writing a completely separate way of representing the transforms than the one used by `ImageDisplay`. Eventually I think this kind of color transform approach should completely replace the (currently GUI-only) color transforms for better consistency and more maintainable code. More generally, I need to be thinking broadly about existing users as well as how the software will need to look a year from now, or two years from now, to meet a host of new applications. And I need to think about how much of those years will go into maintaining existing things where it is *already* clear they are not using the right approach. Often, there are lots of considerations that I haven't articulated anywhere (there just isn't time), but which are impacted by the choices. For example: finding a better approach to handle brightness/contrast perhaps could/should also support serializing the image histograms (since `ImageDisplay` uses them). Storing these histograms would make opening images a great deal faster as well. But then, having histograms separated from the GUI (and JavaFX) would also make intensity distribution information instantly available in general. This might open up new and ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:14,Safety,avoid,avoid,14,"Well, you can avoid both reflection and scripting if you go to [QPEx](https://github.com/qupath/qupath/blob/6ebd4a296e05b89bca3466a14a7d7cf79eb3fad4/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/QPEx.java#L336).... but no absolute promises that won't be broken in the future either :). Ok, I will explain some more and hope it will be sufficient. QuPath is divided into modules. This modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:5821,Safety,risk,risks,5821," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:1419,Security,access,access,1419,"s modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but it would also make updating this information for 10,000 images almost instantaneous. I have made some progress in parts of this, because I needed a way to have JSON-serializable color transforms separate from the GUI in order to support stain separation in the pixel classifier and thresholder.... which was needed [to make the sluggish and limited 'Positive pixel counter' unnecessary](ht",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:5887,Testability,log,logic,5887," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:3216,Usability,clear,clear,3216,"lor transforms separate from the GUI in order to support stain separation in the pixel classifier and thresholder.... which was needed [to make the sluggish and limited 'Positive pixel counter' unnecessary](https://qupath.readthedocs.io/en/latest/docs/tutorials/measuring_areas.html)... which was needed for my sanity so I'd have to stop answering questions about such a poorly-implemented command (that I had originally implemented). Doing this involved writing a completely separate way of representing the transforms than the one used by `ImageDisplay`. Eventually I think this kind of color transform approach should completely replace the (currently GUI-only) color transforms for better consistency and more maintainable code. More generally, I need to be thinking broadly about existing users as well as how the software will need to look a year from now, or two years from now, to meet a host of new applications. And I need to think about how much of those years will go into maintaining existing things where it is *already* clear they are not using the right approach. Often, there are lots of considerations that I haven't articulated anywhere (there just isn't time), but which are impacted by the choices. For example: finding a better approach to handle brightness/contrast perhaps could/should also support serializing the image histograms (since `ImageDisplay` uses them). Storing these histograms would make opening images a great deal faster as well. But then, having histograms separated from the GUI (and JavaFX) would also make intensity distribution information instantly available in general. This might open up new and faster processing and analysis options - including the use of automated thresholds based on such histograms. If something is not public, it can be freely changed without breaking other extensions (and also well-behaved scripts). If it is public, other extensions and scripts that use it will definitely break. Each breaking change costs a) user annoyance, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:5867,Usability,clear,clearly,5867," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632668731:6595,Usability,clear,clear,6595," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731
https://github.com/qupath/qupath/issues/26#issuecomment-632682362:172,Safety,risk,risk,172,"Pete, . Thank you deeply for the complete explanation and information regarding this. . I will now consider this as closed myself, but will most likely continue (at my own risk, as you say) working on this feature as I sincerely do believe it to be useful, and will find a way without changing anything in QuPath. I am aware it will break at one point or another but for the benefit of our users it will be worth to maintain. . Thank you for all the time and effort explaining this to me, and for the scripting alternatives you have provided which I am sure we will be making use of. 😃",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632682362
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:128,Availability,down,downloaded,128,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:359,Deployability,install,install,359,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:493,Deployability,install,installed,493,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:1163,Deployability,update,update,1163,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:1504,Integrability,wrap,wrap,1504,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:84,Testability,test,tested,84,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:1013,Testability,test,tested,1013,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:62,Usability,clear,clearest,62,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:864,Usability,simpl,simply,864,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262733775:1191,Usability,clear,clearer,1191,"Hi,. Looking back that the documentation, I see it wasn't the clearest... I've just tested the following on macOS Sierra with a downloaded QuPath and I was able to run the script in the docs after the following steps:. 1. If you don't already have a QuPath extensions directory, you can either set one under *Edit &rarr; Preferences* or follow the process to install any extension that takes your interest [here](https://github.com/qupath/qupath/wiki/Extensions). 2. Next, locate where JEP is installed and create a symbolic link in your QuPath extensions directory to its Jar file. For me, this was the command:; ```; ln -s /usr/local/lib/python2.7/site-packages/jep/jep-3.5.3.jar /Users/pete/QuPath/extensions/jep.jar; ```. 3. Alongside the Jar, there were also two native files ```jep.so``` and ```libjep.jnilib```. The easiest way to get QuPath to see them is simply to copy these into your QuPath directory containing ```QuPathApp.jar``` (there should already be other native libraries there too). I haven't tested this on Linux, but would be very interested to know if it works (or, indeed, if other things are working fine for you with Fedora). If so I'll update the docs to be a bit clearer. Note that I never took the use of JEP with QuPath far enough for it to be genuinely useful, since I didn't have a sufficient need for it myself until now. But I think the ability to run Python scripts could be really valuable, so I'd be happy to help with setting this up or coming up with a neat way to wrap or convert data structures. If you'd like to discuss more the kind of applications you see this being useful for (e.g. segmentation, classification, manipulating objects, statistical analysis...) just let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262733775
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:129,Availability,error,error,129,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:144,Availability,ERROR,ERROR,144,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:151,Availability,Error,Error,151,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:218,Availability,ERROR,ERROR,218,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:232,Availability,error,error,232,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:135,Integrability,message,message,135,"Hello,; Thanks for the detailed and rapid reply. I have made some progress following your instructions and am now at a different error message. ERROR: Error at line 17: Cannot invoke method getServer() on null object; ERROR: Script error. at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:2231,Integrability,wrap,wrapping,2231,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1511,Performance,concurren,concurrent,1511,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1587,Performance,concurren,concurrent,1587,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1648,Performance,concurren,concurrent,1648,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1732,Performance,concurren,concurrent,1732,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1377,Security,access,access,1377,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143
https://github.com/qupath/qupath/issues/27#issuecomment-262779794:296,Usability,simpl,simple,296,"Thanks for your reply - yes, jnilib should be an apple-only thing. Sounds good that it's getting through the imports now. Do you have an (RGB) image open when you run the script? The script assumes that you do. If you do have an image open, yet it still doesn't work, could you try the following simple script to check what QuPath is seeing:. ```groovy; print(""Current image data: "" + getCurrentImageData()); print(""Current image server: "" + getCurrentImageData().getServer()); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262779794
https://github.com/qupath/qupath/issues/27#issuecomment-262781834:14,Availability,error,error,14,"Hi, ah, silly error on my part. Thanks. . Ok, so now the imports seem to work, but something isn't connecting right for the jep section of the script. ```. INFO: Mean red (from Java): 86.81525; INFO: Mean green (from Java): 72.492275; INFO: Mean blue (from Java): 68.141675; INFO: java.lang.UnsatisfiedLinkError: no jep in java.library.path. ```. I tried the script you sent and received:; ```. INFO: Current image data: ImageData: Fluorescence, IMG_5_11_sq; INFO: Current image server: ImageJ server: /home/bl/Documents/IMG_5_11_sq.png (IMG_5_11_sq.png). ```. I should say that I think jep is installed ok, though I have only played with for a second this morning. But I can start jep, and do the basic test on the jep git Getting Started page (the python to java one).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262781834
https://github.com/qupath/qupath/issues/27#issuecomment-262781834:594,Deployability,install,installed,594,"Hi, ah, silly error on my part. Thanks. . Ok, so now the imports seem to work, but something isn't connecting right for the jep section of the script. ```. INFO: Mean red (from Java): 86.81525; INFO: Mean green (from Java): 72.492275; INFO: Mean blue (from Java): 68.141675; INFO: java.lang.UnsatisfiedLinkError: no jep in java.library.path. ```. I tried the script you sent and received:; ```. INFO: Current image data: ImageData: Fluorescence, IMG_5_11_sq; INFO: Current image server: ImageJ server: /home/bl/Documents/IMG_5_11_sq.png (IMG_5_11_sq.png). ```. I should say that I think jep is installed ok, though I have only played with for a second this morning. But I can start jep, and do the basic test on the jep git Getting Started page (the python to java one).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262781834
https://github.com/qupath/qupath/issues/27#issuecomment-262781834:205,Energy Efficiency,green,green,205,"Hi, ah, silly error on my part. Thanks. . Ok, so now the imports seem to work, but something isn't connecting right for the jep section of the script. ```. INFO: Mean red (from Java): 86.81525; INFO: Mean green (from Java): 72.492275; INFO: Mean blue (from Java): 68.141675; INFO: java.lang.UnsatisfiedLinkError: no jep in java.library.path. ```. I tried the script you sent and received:; ```. INFO: Current image data: ImageData: Fluorescence, IMG_5_11_sq; INFO: Current image server: ImageJ server: /home/bl/Documents/IMG_5_11_sq.png (IMG_5_11_sq.png). ```. I should say that I think jep is installed ok, though I have only played with for a second this morning. But I can start jep, and do the basic test on the jep git Getting Started page (the python to java one).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262781834
https://github.com/qupath/qupath/issues/27#issuecomment-262781834:704,Testability,test,test,704,"Hi, ah, silly error on my part. Thanks. . Ok, so now the imports seem to work, but something isn't connecting right for the jep section of the script. ```. INFO: Mean red (from Java): 86.81525; INFO: Mean green (from Java): 72.492275; INFO: Mean blue (from Java): 68.141675; INFO: java.lang.UnsatisfiedLinkError: no jep in java.library.path. ```. I tried the script you sent and received:; ```. INFO: Current image data: ImageData: Fluorescence, IMG_5_11_sq; INFO: Current image server: ImageJ server: /home/bl/Documents/IMG_5_11_sq.png (IMG_5_11_sq.png). ```. I should say that I think jep is installed ok, though I have only played with for a second this morning. But I can start jep, and do the basic test on the jep git Getting Started page (the python to java one).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262781834
https://github.com/qupath/qupath/issues/27#issuecomment-262791032:249,Availability,error,error,249,"I should say that I also did try setting the CLASSPATH to include the jep-3.6.1.jar and also the LD_LIBRARY_PATH to include the two .so library files. But so far, still stuck at the java.lang.UnsatisfiedLinkError. Actually, when I run it again, the error changes to:. INFO: java.lang.NoClassDefFoundError: Could not initialize class jep.Jep",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262791032
https://github.com/qupath/qupath/issues/27#issuecomment-262797014:304,Availability,error,errors,304,"It sounds like ```jep-3.6.1jar``` is not a problem any more, and it is instead related to the native libraries. I've just had a look on Ubuntu, and there's a ```jep.so``` and ```libjep.so```. Do you have both, and did you copy them both in?. When I do that in Ubuntu I don't get any library or class def errors. It still doesn't work though, due to an ```attr not found``` problem...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262797014
https://github.com/qupath/qupath/issues/27#issuecomment-262802247:93,Availability,error,error,93,"Hi,; Yes, I have both `jep`.so and `libjep.so` copied in the folder and am still getting the error message I reported. I didn't realize initially but `libjep.so` is just a symlink to `jep.so`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262802247
https://github.com/qupath/qupath/issues/27#issuecomment-262802247:99,Integrability,message,message,99,"Hi,; Yes, I have both `jep`.so and `libjep.so` copied in the folder and am still getting the error message I reported. I didn't realize initially but `libjep.so` is just a symlink to `jep.so`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262802247
https://github.com/qupath/qupath/issues/27#issuecomment-262835928:170,Availability,down,down,170,"Hi,. Strange... my quick attempt on Ubuntu also didn't work, but apparently for a different reason... An alternative method to add to your library path would be to track down the ```QuPath.cfg``` file within your QuPath installation, and amend it - something like the following:; ```; [JVMOptions]; -Djava.library.path=.:/usr/local/lib/python2.7/dist-packages/jep/; ```. With this, it shouldn't be necessary to copy the files. Does this help at all, or is it the same error?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262835928
https://github.com/qupath/qupath/issues/27#issuecomment-262835928:468,Availability,error,error,468,"Hi,. Strange... my quick attempt on Ubuntu also didn't work, but apparently for a different reason... An alternative method to add to your library path would be to track down the ```QuPath.cfg``` file within your QuPath installation, and amend it - something like the following:; ```; [JVMOptions]; -Djava.library.path=.:/usr/local/lib/python2.7/dist-packages/jep/; ```. With this, it shouldn't be necessary to copy the files. Does this help at all, or is it the same error?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262835928
https://github.com/qupath/qupath/issues/27#issuecomment-262835928:220,Deployability,install,installation,220,"Hi,. Strange... my quick attempt on Ubuntu also didn't work, but apparently for a different reason... An alternative method to add to your library path would be to track down the ```QuPath.cfg``` file within your QuPath installation, and amend it - something like the following:; ```; [JVMOptions]; -Djava.library.path=.:/usr/local/lib/python2.7/dist-packages/jep/; ```. With this, it shouldn't be necessary to copy the files. Does this help at all, or is it the same error?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262835928
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:224,Availability,error,error,224,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:346,Availability,error,error,346,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:377,Availability,down,down,377,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1292,Availability,ERROR,ERROR,1292," this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.jav",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3541,Availability,ERROR,ERROR,3541,"null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:9412,Availability,error,error,9412,"read] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with J",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:9975,Availability,error,error,9975,"ver: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with JEP by itself in order to see if I run into any similar issues.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:105,Deployability,install,installation,105,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:2008,Deployability,install,installExtension,2008,"h/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Th",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3182,Deployability,update,update,3182," 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(Ope",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3425,Deployability,release,release,3425,"atformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServe",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:9091,Energy Efficiency,green,green,9091,"Handler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you wo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:230,Integrability,message,message,230,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:352,Integrability,message,message,352,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:662,Performance,cache,cache,662,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:992,Performance,load,loaded,992,"Well, that definitely did something - I managed to crash QuPath. One thing - I am trying to run a 64 bit installation, perhaps that is causing some kind of conflict? I checked just to be sure and my python is 64 bit and the error message below discusses a 64-bit Open-JDK server, so this may not be the issue. I am going to paste the (very long) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1341,Performance,load,load,1341,"ong) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$l",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1566,Performance,load,load,1566,"34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.A",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1676,Performance,load,loadLibrary,1676,"39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$11",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1787,Performance,load,loadLibrary,1787,"p/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1852,Performance,load,loadNativeLibrary,1852,"ath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3171,Performance,Perform,Performing,3171," 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(Ope",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3597,Performance,load,load,3597,"doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3822,Performance,load,load,3822,"on._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	at qupath.lib.gui.commands.OpenCommand.run(OpenCommand.java:51); 	at qupath.lib.gui.QuPathGUI.lambda$43(QuPathGUI.java:2960); 	at org.controlsfx.control.action.Action.handle(Action.java:419); 	at org.controlsfx.control.action.Action.handle(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3932,Performance,load,loadLibrary,3932,"); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	at qupath.lib.gui.commands.OpenCommand.run(OpenCommand.java:51); 	at qupath.lib.gui.QuPathGUI.lambda$43(QuPathGUI.java:2960); 	at org.controlsfx.control.action.Action.handle(Action.java:419); 	at org.controlsfx.control.action.Action.handle(Action.java:64); 	at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:4043,Performance,load,loadLibrary,4043,"i.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	at qupath.lib.gui.commands.OpenCommand.run(OpenCommand.java:51); 	at qupath.lib.gui.QuPathGUI.lambda$43(QuPathGUI.java:2960); 	at org.controlsfx.control.action.Action.handle(Action.java:419); 	at org.controlsfx.control.action.Action.handle(Action.java:64); 	at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); 	at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:8835,Performance,Load,Loading,8835,"n.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write cor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:9427,Safety,detect,detected,9427,"read] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with J",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:10319,Safety,Abort,Aborted,10319,"ver: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with JEP by itself in order to see if I run into any similar issues.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:2571,Security,secur,security,2571,"ve Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServe",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:2580,Security,Access,AccessController,2580,"at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Co",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:7387,Security,access,access,7387,atcher.dispatchEvent(BasicEventDispatcher.java:58); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.j,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:7784,Security,secur,security,7784,"nt(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:7793,Security,Access,AccessController,7793,"Dispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:8878,Testability,Test,TestJep,8878,"n.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write cor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262870405:10070,Testability,log,log,10070,"ver: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with JEP by itself in order to see if I run into any similar issues.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405
https://github.com/qupath/qupath/issues/27#issuecomment-262912897:262,Usability,usab,usable,262,"I realise that doesn't look good, but I think it is progress... the failed import of ```numpy.core.multiarray``` is where I was also having problems with Ubuntu (albeit with a less catastrophic-looking exception). The fact that OpenCV and OpenSlide are also not usable is... disappointing, but not exactly surprising - I have mostly focussed on getting QuPath to work properly on Windows and Mac, and you are the first person I know of using it on Linux. Both OpenCV and OpenSlide have native library issues that might be easier to solve. If you happen to find a way to get them to work, the same solution may help make progress with JEP. I will look into this some more, but realistically it might take a few weeks before I can give it proper attention. (It may also be worth keeping [javabridge](http://pythonhosted.org/javabridge/) in mind, if you would like some variation...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262912897
https://github.com/qupath/qupath/issues/27#issuecomment-262925931:371,Integrability,rout,routines,371,"Hi,; Oh, no worries, I have definitely learned a bit about getting QuPath; and JEP up and running on Linux. I look forward to spending a little more; time with this later this weekend, but I will also probably end up putting; it on the back burner if I can't make much progress. I think being able to; call Python segmentation algorithms and also measurement/statistics; routines would be very cool. . Thanks for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262925931
https://github.com/qupath/qupath/issues/27#issuecomment-262925931:39,Usability,learn,learned,39,"Hi,; Oh, no worries, I have definitely learned a bit about getting QuPath; and JEP up and running on Linux. I look forward to spending a little more; time with this later this weekend, but I will also probably end up putting; it on the back burner if I can't make much progress. I think being able to; call Python segmentation algorithms and also measurement/statistics; routines would be very cool. . Thanks for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262925931
https://github.com/qupath/qupath/issues/27#issuecomment-263157993:92,Deployability,release,releases,92,"While not directly related to the Python problem, [v0.0.7](https://github.com/qupath/qupath/releases/tag/v0.0.7) will hopefully do away with the exceptions you were seeing related to OpenSlide and OpenCV (some info [here](https://github.com/qupath/qupath/issues/2)). At least, I was able to run the this release on a clean installation of Fedora (25) through VirtualBox without major trouble... albeit it still not quite as smoothly as under macOS, Windows or Ubuntu.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263157993
https://github.com/qupath/qupath/issues/27#issuecomment-263157993:304,Deployability,release,release,304,"While not directly related to the Python problem, [v0.0.7](https://github.com/qupath/qupath/releases/tag/v0.0.7) will hopefully do away with the exceptions you were seeing related to OpenSlide and OpenCV (some info [here](https://github.com/qupath/qupath/issues/2)). At least, I was able to run the this release on a clean installation of Fedora (25) through VirtualBox without major trouble... albeit it still not quite as smoothly as under macOS, Windows or Ubuntu.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263157993
https://github.com/qupath/qupath/issues/27#issuecomment-263157993:323,Deployability,install,installation,323,"While not directly related to the Python problem, [v0.0.7](https://github.com/qupath/qupath/releases/tag/v0.0.7) will hopefully do away with the exceptions you were seeing related to OpenSlide and OpenCV (some info [here](https://github.com/qupath/qupath/issues/2)). At least, I was able to run the this release on a clean installation of Fedora (25) through VirtualBox without major trouble... albeit it still not quite as smoothly as under macOS, Windows or Ubuntu.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263157993
https://github.com/qupath/qupath/issues/27#issuecomment-263166949:266,Deployability,release,releases,266,"That's really great. I will give it a spin and let you know if I come up; against any problems. On Mon, Nov 28, 2016 at 12:04 AM, Pete <notifications@github.com> wrote:. > While not directly related to the Python problem, v0.0.7; > <https://github.com/qupath/qupath/releases/tag/v0.0.7> will hopefully do; > away with the exceptions you were seeing related to OpenSlide and OpenCV; > (some info here <https://github.com/qupath/qupath/issues/2>).; >; > At least, I was able to run the this release on a clean installation of; > Fedora (25) through VirtualBox without major trouble... albeit it still not; > quite as smoothly as under macOS, Windows or Ubuntu.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-263157993>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEar0xe5TkOXBQe4CzEpPWcbxH0v5Nks5rChqhgaJpZM4K7UrB>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263166949
https://github.com/qupath/qupath/issues/27#issuecomment-263166949:489,Deployability,release,release,489,"That's really great. I will give it a spin and let you know if I come up; against any problems. On Mon, Nov 28, 2016 at 12:04 AM, Pete <notifications@github.com> wrote:. > While not directly related to the Python problem, v0.0.7; > <https://github.com/qupath/qupath/releases/tag/v0.0.7> will hopefully do; > away with the exceptions you were seeing related to OpenSlide and OpenCV; > (some info here <https://github.com/qupath/qupath/issues/2>).; >; > At least, I was able to run the this release on a clean installation of; > Fedora (25) through VirtualBox without major trouble... albeit it still not; > quite as smoothly as under macOS, Windows or Ubuntu.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-263157993>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEar0xe5TkOXBQe4CzEpPWcbxH0v5Nks5rChqhgaJpZM4K7UrB>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263166949
https://github.com/qupath/qupath/issues/27#issuecomment-263166949:508,Deployability,install,installation,508,"That's really great. I will give it a spin and let you know if I come up; against any problems. On Mon, Nov 28, 2016 at 12:04 AM, Pete <notifications@github.com> wrote:. > While not directly related to the Python problem, v0.0.7; > <https://github.com/qupath/qupath/releases/tag/v0.0.7> will hopefully do; > away with the exceptions you were seeing related to OpenSlide and OpenCV; > (some info here <https://github.com/qupath/qupath/issues/2>).; >; > At least, I was able to run the this release on a clean installation of; > Fedora (25) through VirtualBox without major trouble... albeit it still not; > quite as smoothly as under macOS, Windows or Ubuntu.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-263157993>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEar0xe5TkOXBQe4CzEpPWcbxH0v5Nks5rChqhgaJpZM4K7UrB>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-263166949
https://github.com/qupath/qupath/issues/27#issuecomment-264693922:766,Testability,test,test,766,"So I looked a bit more this morning, and the issue seems to go back to preloading... and it was documented all along in the JEP wiki at https://github.com/mrj0/jep/wiki/Linux#ld_preload. The way I got it to work was by copying the file identified by ; ```sh; which jep; ```; into the base QuPath directory (which contains the launcher) and then modifying it. You can see more about the original contents of this file [here](https://github.com/mrj0/jep/blob/master/src/scripts/jep). The end result is that I launched QuPath with the following:. ```sh; #!/bin/sh. VIRTUAL_ENV=; export VIRTUAL_ENV. LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD. if test ""x$VIRTUAL_ENV"" != ""x""; then; PATH=""$VIRTUAL_ENV/bin:$PATH""; export PATH; PYTHONHOME=""$VIRTUAL_ENV""; export PYTHONHOME; fi. cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""; if test ""x$CLASSPATH"" != ""x""; then; cp=""$cp"":""$CLASSPATH""; fi. jni_path=""/usr/local/lib/python2.7/dist-packages/jep"". DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )"". exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; ```. After doing this, the Groovy script for testing JEP worked without problems. One thing in particular to note is the use of ```-Xmx4G``` to set the maximum memory to 4GB on my (virtual) machine... it would be good to modify this as required, as the built-in method is modifying the maximum memory within QuPath won't work when it's launched in this way. I've only tested this in Ubuntu, but hopefully it works for you too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264693922
https://github.com/qupath/qupath/issues/27#issuecomment-264693922:961,Testability,test,test,961,"So I looked a bit more this morning, and the issue seems to go back to preloading... and it was documented all along in the JEP wiki at https://github.com/mrj0/jep/wiki/Linux#ld_preload. The way I got it to work was by copying the file identified by ; ```sh; which jep; ```; into the base QuPath directory (which contains the launcher) and then modifying it. You can see more about the original contents of this file [here](https://github.com/mrj0/jep/blob/master/src/scripts/jep). The end result is that I launched QuPath with the following:. ```sh; #!/bin/sh. VIRTUAL_ENV=; export VIRTUAL_ENV. LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD. if test ""x$VIRTUAL_ENV"" != ""x""; then; PATH=""$VIRTUAL_ENV/bin:$PATH""; export PATH; PYTHONHOME=""$VIRTUAL_ENV""; export PYTHONHOME; fi. cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""; if test ""x$CLASSPATH"" != ""x""; then; cp=""$cp"":""$CLASSPATH""; fi. jni_path=""/usr/local/lib/python2.7/dist-packages/jep"". DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )"". exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; ```. After doing this, the Groovy script for testing JEP worked without problems. One thing in particular to note is the use of ```-Xmx4G``` to set the maximum memory to 4GB on my (virtual) machine... it would be good to modify this as required, as the built-in method is modifying the maximum memory within QuPath won't work when it's launched in this way. I've only tested this in Ubuntu, but hopefully it works for you too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264693922
https://github.com/qupath/qupath/issues/27#issuecomment-264693922:1302,Testability,test,testing,1302,"So I looked a bit more this morning, and the issue seems to go back to preloading... and it was documented all along in the JEP wiki at https://github.com/mrj0/jep/wiki/Linux#ld_preload. The way I got it to work was by copying the file identified by ; ```sh; which jep; ```; into the base QuPath directory (which contains the launcher) and then modifying it. You can see more about the original contents of this file [here](https://github.com/mrj0/jep/blob/master/src/scripts/jep). The end result is that I launched QuPath with the following:. ```sh; #!/bin/sh. VIRTUAL_ENV=; export VIRTUAL_ENV. LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD. if test ""x$VIRTUAL_ENV"" != ""x""; then; PATH=""$VIRTUAL_ENV/bin:$PATH""; export PATH; PYTHONHOME=""$VIRTUAL_ENV""; export PYTHONHOME; fi. cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""; if test ""x$CLASSPATH"" != ""x""; then; cp=""$cp"":""$CLASSPATH""; fi. jni_path=""/usr/local/lib/python2.7/dist-packages/jep"". DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )"". exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; ```. After doing this, the Groovy script for testing JEP worked without problems. One thing in particular to note is the use of ```-Xmx4G``` to set the maximum memory to 4GB on my (virtual) machine... it would be good to modify this as required, as the built-in method is modifying the maximum memory within QuPath won't work when it's launched in this way. I've only tested this in Ubuntu, but hopefully it works for you too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264693922
https://github.com/qupath/qupath/issues/27#issuecomment-264693922:1625,Testability,test,tested,1625,"So I looked a bit more this morning, and the issue seems to go back to preloading... and it was documented all along in the JEP wiki at https://github.com/mrj0/jep/wiki/Linux#ld_preload. The way I got it to work was by copying the file identified by ; ```sh; which jep; ```; into the base QuPath directory (which contains the launcher) and then modifying it. You can see more about the original contents of this file [here](https://github.com/mrj0/jep/blob/master/src/scripts/jep). The end result is that I launched QuPath with the following:. ```sh; #!/bin/sh. VIRTUAL_ENV=; export VIRTUAL_ENV. LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD. if test ""x$VIRTUAL_ENV"" != ""x""; then; PATH=""$VIRTUAL_ENV/bin:$PATH""; export PATH; PYTHONHOME=""$VIRTUAL_ENV""; export PYTHONHOME; fi. cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""; if test ""x$CLASSPATH"" != ""x""; then; cp=""$cp"":""$CLASSPATH""; fi. jni_path=""/usr/local/lib/python2.7/dist-packages/jep"". DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )"". exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; ```. After doing this, the Groovy script for testing JEP worked without problems. One thing in particular to note is the use of ```-Xmx4G``` to set the maximum memory to 4GB on my (virtual) machine... it would be good to modify this as required, as the built-in method is modifying the maximum memory within QuPath won't work when it's launched in this way. I've only tested this in Ubuntu, but hopefully it works for you too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264693922
https://github.com/qupath/qupath/issues/27#issuecomment-264698049:1111,Testability,test,test,1111,"iki more carefully! Thanks for following this up.; Cheers,; Ben. On Sun, 4 Dec 2016 at 09:44, Pete <notifications@github.com> wrote:. > So I looked a bit more this morning, and the issue seems to go back to; > preloading... and it was documented all along in the JEP wiki at; > https://github.com/mrj0/jep/wiki/Linux#ld_preload; >; > The way I got it to work was by copying the file identified by; >; > which jep; >; > into the base QuPath directory (which contains the launcher) and then; > modifying it. You can see more about the original contents of this file; > here <https://github.com/mrj0/jep/blob/master/src/scripts/jep>.; >; > The end result is that I launched QuPath with the following:; >; > #!/bin/sh; >; > VIRTUAL_ENV=export VIRTUAL_ENV; >; > LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; > LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD; > if test ""x$VIRTUAL_ENV"" != ""x""; then; > PATH=""$VIRTUAL_ENV/bin:$PATH""; > export PATH; > PYTHONHOME=""$VIRTUAL_ENV""; > export PYTHONHOMEfi; >; > cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""if test ""x$CLASSPATH"" != ""x""; then; > cp=""$cp"":""$CLASSPATH""fi; >; > jni_path=""/usr/local/lib/python2.7/dist-packages/jep""; >; > DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""; > exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; >; > After doing this, the Groovy script for testing JEP worked without; > problems.; >; > One thing in particular to note is the use of -Xmx4G to set the maximum; > memory to 4GB on my (virtual) machine... it would be good to modify this as; > required, as the built-in method is modifying the maximum memory within; > QuPath won't work when it's launched in this way.; >; > I've only tested this in Ubuntu, but hopefully it works for you too.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264698049
https://github.com/qupath/qupath/issues/27#issuecomment-264698049:1315,Testability,test,test,1315," issue seems to go back to; > preloading... and it was documented all along in the JEP wiki at; > https://github.com/mrj0/jep/wiki/Linux#ld_preload; >; > The way I got it to work was by copying the file identified by; >; > which jep; >; > into the base QuPath directory (which contains the launcher) and then; > modifying it. You can see more about the original contents of this file; > here <https://github.com/mrj0/jep/blob/master/src/scripts/jep>.; >; > The end result is that I launched QuPath with the following:; >; > #!/bin/sh; >; > VIRTUAL_ENV=export VIRTUAL_ENV; >; > LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; > LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD; > if test ""x$VIRTUAL_ENV"" != ""x""; then; > PATH=""$VIRTUAL_ENV/bin:$PATH""; > export PATH; > PYTHONHOME=""$VIRTUAL_ENV""; > export PYTHONHOMEfi; >; > cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""if test ""x$CLASSPATH"" != ""x""; then; > cp=""$cp"":""$CLASSPATH""fi; >; > jni_path=""/usr/local/lib/python2.7/dist-packages/jep""; >; > DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""; > exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; >; > After doing this, the Groovy script for testing JEP worked without; > problems.; >; > One thing in particular to note is the use of -Xmx4G to set the maximum; > memory to 4GB on my (virtual) machine... it would be good to modify this as; > required, as the built-in method is modifying the maximum memory within; > QuPath won't work when it's launched in this way.; >; > I've only tested this in Ubuntu, but hopefully it works for you too.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-264693922>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEati9u5U4I6W4lEmcAFz8NqY",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264698049
https://github.com/qupath/qupath/issues/27#issuecomment-264698049:1668,Testability,test,testing,1668,"ading... and it was documented all along in the JEP wiki at; > https://github.com/mrj0/jep/wiki/Linux#ld_preload; >; > The way I got it to work was by copying the file identified by; >; > which jep; >; > into the base QuPath directory (which contains the launcher) and then; > modifying it. You can see more about the original contents of this file; > here <https://github.com/mrj0/jep/blob/master/src/scripts/jep>.; >; > The end result is that I launched QuPath with the following:; >; > #!/bin/sh; >; > VIRTUAL_ENV=export VIRTUAL_ENV; >; > LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; > LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD; > if test ""x$VIRTUAL_ENV"" != ""x""; then; > PATH=""$VIRTUAL_ENV/bin:$PATH""; > export PATH; > PYTHONHOME=""$VIRTUAL_ENV""; > export PYTHONHOMEfi; >; > cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""if test ""x$CLASSPATH"" != ""x""; then; > cp=""$cp"":""$CLASSPATH""fi; >; > jni_path=""/usr/local/lib/python2.7/dist-packages/jep""; >; > DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""; > exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; >; > After doing this, the Groovy script for testing JEP worked without; > problems.; >; > One thing in particular to note is the use of -Xmx4G to set the maximum; > memory to 4GB on my (virtual) machine... it would be good to modify this as; > required, as the built-in method is modifying the maximum memory within; > QuPath won't work when it's launched in this way.; >; > I've only tested this in Ubuntu, but hopefully it works for you too.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-264693922>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEati9u5U4I6W4lEmcAFz8NqYSzkVOks5rEot6gaJpZM4K7UrB>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264698049
https://github.com/qupath/qupath/issues/27#issuecomment-264698049:2009,Testability,test,tested,2009,"ading... and it was documented all along in the JEP wiki at; > https://github.com/mrj0/jep/wiki/Linux#ld_preload; >; > The way I got it to work was by copying the file identified by; >; > which jep; >; > into the base QuPath directory (which contains the launcher) and then; > modifying it. You can see more about the original contents of this file; > here <https://github.com/mrj0/jep/blob/master/src/scripts/jep>.; >; > The end result is that I launched QuPath with the following:; >; > #!/bin/sh; >; > VIRTUAL_ENV=export VIRTUAL_ENV; >; > LD_LIBRARY_PATH=""/usr/lib:/usr/local/lib/python2.7/dist-packages/""; export LD_LIBRARY_PATH; > LD_PRELOAD=""/usr/lib/x86_64-linux-gnu/libpython2.7.so""; export LD_PRELOAD; > if test ""x$VIRTUAL_ENV"" != ""x""; then; > PATH=""$VIRTUAL_ENV/bin:$PATH""; > export PATH; > PYTHONHOME=""$VIRTUAL_ENV""; > export PYTHONHOMEfi; >; > cp=""/usr/local/lib/python2.7/dist-packages/jep/jep-3.6.1.jar""if test ""x$CLASSPATH"" != ""x""; then; > cp=""$cp"":""$CLASSPATH""fi; >; > jni_path=""/usr/local/lib/python2.7/dist-packages/jep""; >; > DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""; > exec java -Xmx4G -classpath ""$cp:${DIR}/app/QuPathApp.jar"" -Djava.library.path=""$jni_path:${DIR}:${DIR}/app"" qupath.QuPath; >; > After doing this, the Groovy script for testing JEP worked without; > problems.; >; > One thing in particular to note is the use of -Xmx4G to set the maximum; > memory to 4GB on my (virtual) machine... it would be good to modify this as; > required, as the built-in method is modifying the maximum memory within; > QuPath won't work when it's launched in this way.; >; > I've only tested this in Ubuntu, but hopefully it works for you too.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/27#issuecomment-264693922>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APkEati9u5U4I6W4lEmcAFz8NqYSzkVOks5rEot6gaJpZM4K7UrB>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264698049
https://github.com/qupath/qupath/issues/27#issuecomment-264699698:95,Deployability,update,updated,95,"No worries, I looked at the Wiki multiple times as well and completely missed it :). I've also updated the [Working with Python](https://github.com/qupath/qupath/wiki/Working-with-Python) section of the Wiki and started adding a bit of info about [Paths & configuration](https://github.com/qupath/qupath/wiki/Paths-&-configuration) that might be useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264699698
https://github.com/qupath/qupath/issues/27#issuecomment-264699698:256,Deployability,configurat,configuration,256,"No worries, I looked at the Wiki multiple times as well and completely missed it :). I've also updated the [Working with Python](https://github.com/qupath/qupath/wiki/Working-with-Python) section of the Wiki and started adding a bit of info about [Paths & configuration](https://github.com/qupath/qupath/wiki/Paths-&-configuration) that might be useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264699698
https://github.com/qupath/qupath/issues/27#issuecomment-264699698:317,Deployability,configurat,configuration,317,"No worries, I looked at the Wiki multiple times as well and completely missed it :). I've also updated the [Working with Python](https://github.com/qupath/qupath/wiki/Working-with-Python) section of the Wiki and started adding a bit of info about [Paths & configuration](https://github.com/qupath/qupath/wiki/Paths-&-configuration) that might be useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264699698
https://github.com/qupath/qupath/issues/27#issuecomment-264699698:256,Modifiability,config,configuration,256,"No worries, I looked at the Wiki multiple times as well and completely missed it :). I've also updated the [Working with Python](https://github.com/qupath/qupath/wiki/Working-with-Python) section of the Wiki and started adding a bit of info about [Paths & configuration](https://github.com/qupath/qupath/wiki/Paths-&-configuration) that might be useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264699698
https://github.com/qupath/qupath/issues/27#issuecomment-264699698:317,Modifiability,config,configuration,317,"No worries, I looked at the Wiki multiple times as well and completely missed it :). I've also updated the [Working with Python](https://github.com/qupath/qupath/wiki/Working-with-Python) section of the Wiki and started adding a bit of info about [Paths & configuration](https://github.com/qupath/qupath/wiki/Paths-&-configuration) that might be useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264699698
https://github.com/qupath/qupath/issues/27#issuecomment-264866312:55,Deployability,update,updated,55,Easily done I guess! . I for one really appreciate the updated docs with the new example. Thats much more than I was expecting and I am looking forward to testing it out. Thanks again!,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264866312
https://github.com/qupath/qupath/issues/27#issuecomment-264866312:155,Testability,test,testing,155,Easily done I guess! . I for one really appreciate the updated docs with the new example. Thats much more than I was expecting and I am looking forward to testing it out. Thanks again!,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-264866312
https://github.com/qupath/qupath/issues/27#issuecomment-372239278:160,Performance,load,loaded,160,"Hi,. I'm using JEP at the moment and just wanted to let you know with regard to the Wiki page that the syntax of the method declaring the python packages to be loaded has changed (jep 3.7) is now . addSharedModules(""numpy"",""pandas"",...). otherwise I think is far more optimal compared to Jython although there are still some issues with pandas but as long as you stick to numpy and packages relying on numpy is fine.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-372239278
https://github.com/qupath/qupath/issues/32#issuecomment-265467061:277,Availability,error,errors,277,"Hi Mario,. Thanks for letting me know. I have tried several MRXS images on v0.1.1 using Mac and it seems to be working here, so it would be good to know a bit more about the problem you are seeing. * Are you running QuPath on Windows/Linux/Mac?; * When it doesn't work, do any errors appear - or do you see any errors logged under *View &rarr; Show log*?; * Do you know if v0.1.0 works?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265467061
https://github.com/qupath/qupath/issues/32#issuecomment-265467061:311,Availability,error,errors,311,"Hi Mario,. Thanks for letting me know. I have tried several MRXS images on v0.1.1 using Mac and it seems to be working here, so it would be good to know a bit more about the problem you are seeing. * Are you running QuPath on Windows/Linux/Mac?; * When it doesn't work, do any errors appear - or do you see any errors logged under *View &rarr; Show log*?; * Do you know if v0.1.0 works?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265467061
https://github.com/qupath/qupath/issues/32#issuecomment-265467061:318,Testability,log,logged,318,"Hi Mario,. Thanks for letting me know. I have tried several MRXS images on v0.1.1 using Mac and it seems to be working here, so it would be good to know a bit more about the problem you are seeing. * Are you running QuPath on Windows/Linux/Mac?; * When it doesn't work, do any errors appear - or do you see any errors logged under *View &rarr; Show log*?; * Do you know if v0.1.0 works?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265467061
https://github.com/qupath/qupath/issues/32#issuecomment-265467061:349,Testability,log,log,349,"Hi Mario,. Thanks for letting me know. I have tried several MRXS images on v0.1.1 using Mac and it seems to be working here, so it would be good to know a bit more about the problem you are seeing. * Are you running QuPath on Windows/Linux/Mac?; * When it doesn't work, do any errors appear - or do you see any errors logged under *View &rarr; Show log*?; * Do you know if v0.1.0 works?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265467061
https://github.com/qupath/qupath/issues/32#issuecomment-265471212:143,Availability,Error,Error,143,"Hi Pete,. I'm running QuPath under Mac. We replicated the issue on 2 machines. Version 1.0.0 works fine, too.; Server Type: OpenSlide. V1.0.1. Error in log is: Could not load OpenSlide native library (followed by a lot of Java errors); Server Type: ImageJ server. Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265471212
https://github.com/qupath/qupath/issues/32#issuecomment-265471212:227,Availability,error,errors,227,"Hi Pete,. I'm running QuPath under Mac. We replicated the issue on 2 machines. Version 1.0.0 works fine, too.; Server Type: OpenSlide. V1.0.1. Error in log is: Could not load OpenSlide native library (followed by a lot of Java errors); Server Type: ImageJ server. Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265471212
https://github.com/qupath/qupath/issues/32#issuecomment-265471212:170,Performance,load,load,170,"Hi Pete,. I'm running QuPath under Mac. We replicated the issue on 2 machines. Version 1.0.0 works fine, too.; Server Type: OpenSlide. V1.0.1. Error in log is: Could not load OpenSlide native library (followed by a lot of Java errors); Server Type: ImageJ server. Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265471212
https://github.com/qupath/qupath/issues/32#issuecomment-265471212:152,Testability,log,log,152,"Hi Pete,. I'm running QuPath under Mac. We replicated the issue on 2 machines. Version 1.0.0 works fine, too.; Server Type: OpenSlide. V1.0.1. Error in log is: Could not load OpenSlide native library (followed by a lot of Java errors); Server Type: ImageJ server. Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265471212
https://github.com/qupath/qupath/issues/32#issuecomment-265486923:42,Availability,down,downloaded,42,"Thanks, that's quite strange... I've just downloaded it again, and it is working here on two different Macs. Are you running macOS Sierra, or some other version?. If QuPath can't load OpenSlide, then I expect it can't load any other whole slide formats (unless you have the Bio-Formats extension installed). In that case, I would expect it to fall back to using ImageJ for MRXS images to read only the low-resolution data. If you right-click on QuPath.app and select 'Show package contents', you should be able to see something like what is shown below:. ![libopenslide](https://cloud.githubusercontent.com/assets/4690904/20973479/a23ad306-bc90-11e6-9863-e9281c2c9110.jpg). I suspect the issue may be connected to differences in the many ```lib*``` files. One way to test this is to copy all the ```lib.*``` files from a QuPath version that works (i.e. anything before v0.1.1?) and paste it into the QuPath that doesn't. This may cause v0.1.1 to function. If these instructions make any sense, could you try this?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265486923
https://github.com/qupath/qupath/issues/32#issuecomment-265486923:296,Deployability,install,installed,296,"Thanks, that's quite strange... I've just downloaded it again, and it is working here on two different Macs. Are you running macOS Sierra, or some other version?. If QuPath can't load OpenSlide, then I expect it can't load any other whole slide formats (unless you have the Bio-Formats extension installed). In that case, I would expect it to fall back to using ImageJ for MRXS images to read only the low-resolution data. If you right-click on QuPath.app and select 'Show package contents', you should be able to see something like what is shown below:. ![libopenslide](https://cloud.githubusercontent.com/assets/4690904/20973479/a23ad306-bc90-11e6-9863-e9281c2c9110.jpg). I suspect the issue may be connected to differences in the many ```lib*``` files. One way to test this is to copy all the ```lib.*``` files from a QuPath version that works (i.e. anything before v0.1.1?) and paste it into the QuPath that doesn't. This may cause v0.1.1 to function. If these instructions make any sense, could you try this?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265486923
https://github.com/qupath/qupath/issues/32#issuecomment-265486923:179,Performance,load,load,179,"Thanks, that's quite strange... I've just downloaded it again, and it is working here on two different Macs. Are you running macOS Sierra, or some other version?. If QuPath can't load OpenSlide, then I expect it can't load any other whole slide formats (unless you have the Bio-Formats extension installed). In that case, I would expect it to fall back to using ImageJ for MRXS images to read only the low-resolution data. If you right-click on QuPath.app and select 'Show package contents', you should be able to see something like what is shown below:. ![libopenslide](https://cloud.githubusercontent.com/assets/4690904/20973479/a23ad306-bc90-11e6-9863-e9281c2c9110.jpg). I suspect the issue may be connected to differences in the many ```lib*``` files. One way to test this is to copy all the ```lib.*``` files from a QuPath version that works (i.e. anything before v0.1.1?) and paste it into the QuPath that doesn't. This may cause v0.1.1 to function. If these instructions make any sense, could you try this?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265486923
https://github.com/qupath/qupath/issues/32#issuecomment-265486923:218,Performance,load,load,218,"Thanks, that's quite strange... I've just downloaded it again, and it is working here on two different Macs. Are you running macOS Sierra, or some other version?. If QuPath can't load OpenSlide, then I expect it can't load any other whole slide formats (unless you have the Bio-Formats extension installed). In that case, I would expect it to fall back to using ImageJ for MRXS images to read only the low-resolution data. If you right-click on QuPath.app and select 'Show package contents', you should be able to see something like what is shown below:. ![libopenslide](https://cloud.githubusercontent.com/assets/4690904/20973479/a23ad306-bc90-11e6-9863-e9281c2c9110.jpg). I suspect the issue may be connected to differences in the many ```lib*``` files. One way to test this is to copy all the ```lib.*``` files from a QuPath version that works (i.e. anything before v0.1.1?) and paste it into the QuPath that doesn't. This may cause v0.1.1 to function. If these instructions make any sense, could you try this?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265486923
https://github.com/qupath/qupath/issues/32#issuecomment-265486923:767,Testability,test,test,767,"Thanks, that's quite strange... I've just downloaded it again, and it is working here on two different Macs. Are you running macOS Sierra, or some other version?. If QuPath can't load OpenSlide, then I expect it can't load any other whole slide formats (unless you have the Bio-Formats extension installed). In that case, I would expect it to fall back to using ImageJ for MRXS images to read only the low-resolution data. If you right-click on QuPath.app and select 'Show package contents', you should be able to see something like what is shown below:. ![libopenslide](https://cloud.githubusercontent.com/assets/4690904/20973479/a23ad306-bc90-11e6-9863-e9281c2c9110.jpg). I suspect the issue may be connected to differences in the many ```lib*``` files. One way to test this is to copy all the ```lib.*``` files from a QuPath version that works (i.e. anything before v0.1.1?) and paste it into the QuPath that doesn't. This may cause v0.1.1 to function. If these instructions make any sense, could you try this?. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265486923
https://github.com/qupath/qupath/issues/32#issuecomment-265488012:64,Availability,error,error,64,"It would also be good if you could copy and paste the full long error message, in case that helps identify exactly which library is failing to load (OpenSlide links to several).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265488012
https://github.com/qupath/qupath/issues/32#issuecomment-265488012:70,Integrability,message,message,70,"It would also be good if you could copy and paste the full long error message, in case that helps identify exactly which library is failing to load (OpenSlide links to several).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265488012
https://github.com/qupath/qupath/issues/32#issuecomment-265488012:143,Performance,load,load,143,"It would also be good if you could copy and paste the full long error message, in case that helps identify exactly which library is failing to load (OpenSlide links to several).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265488012
https://github.com/qupath/qupath/issues/32#issuecomment-265496307:30,Availability,error,error,30,"Actually, no need to send the error... I was able to reproduce the problem on an older Mac here. It would still be good to know what version of the operating system you are running. It works for me on Sierra, but not on Mavericks - although I'm not sure if that's relevant. In any case, my awkward hack of copying the ```lib*``` files from a working version to v0.1.1 appears to work - so I will try to find which part is missing in v0.1.1, and recompile a version with everything that is required.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265496307
https://github.com/qupath/qupath/issues/32#issuecomment-265532855:43,Availability,error,error,43,Great to hear that you could reproduce the error.; we've tried under osx Sierra and osx el Capitan with the same results.; thanks again!,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265532855
https://github.com/qupath/qupath/issues/32#issuecomment-265556833:10,Deployability,update,updated,10,"I've just updated the Mac release [here](https://github.com/qupath/qupath/releases/tag/v0.1.1).; It works for me on all three computers now. Please let me know if it also solves things on your side. (Thanks again for reporting this - it appears to have been connected to libraries I have installed on my own computers but didn't include in the distribution, so I assume the Mac version was not working for anyone else... so it was a pretty big problem!)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265556833
https://github.com/qupath/qupath/issues/32#issuecomment-265556833:26,Deployability,release,release,26,"I've just updated the Mac release [here](https://github.com/qupath/qupath/releases/tag/v0.1.1).; It works for me on all three computers now. Please let me know if it also solves things on your side. (Thanks again for reporting this - it appears to have been connected to libraries I have installed on my own computers but didn't include in the distribution, so I assume the Mac version was not working for anyone else... so it was a pretty big problem!)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265556833
https://github.com/qupath/qupath/issues/32#issuecomment-265556833:74,Deployability,release,releases,74,"I've just updated the Mac release [here](https://github.com/qupath/qupath/releases/tag/v0.1.1).; It works for me on all three computers now. Please let me know if it also solves things on your side. (Thanks again for reporting this - it appears to have been connected to libraries I have installed on my own computers but didn't include in the distribution, so I assume the Mac version was not working for anyone else... so it was a pretty big problem!)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265556833
https://github.com/qupath/qupath/issues/32#issuecomment-265556833:288,Deployability,install,installed,288,"I've just updated the Mac release [here](https://github.com/qupath/qupath/releases/tag/v0.1.1).; It works for me on all three computers now. Please let me know if it also solves things on your side. (Thanks again for reporting this - it appears to have been connected to libraries I have installed on my own computers but didn't include in the distribution, so I assume the Mac version was not working for anyone else... so it was a pretty big problem!)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265556833
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:93,Availability,Error,Errors,93,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:103,Availability,ERROR,ERROR,103,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:134,Availability,avail,available,134,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:176,Availability,ERROR,ERROR,176,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:207,Availability,avail,available,207,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265674934:307,Testability,test,tested,307,"Working like a charm now! ; Just for the sake of completeness. Openslide still reports some ""Errors"":; ERROR: Openslide: Property not available: openslide.level[0].tile-width; ERROR: Openslide: Property not available: openslide.level[0].tile-height. But they are the same across all versions of QuPath I've tested and don't hinder ; image analysis on MRXS slides. Thank again for fixing this issue so fast! ; Have a great day,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265674934
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:49,Availability,error,errors,49,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:449,Availability,down,download,449,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:711,Availability,down,download,711,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:880,Availability,avail,available,880,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:758,Deployability,update,updates,758,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:816,Deployability,update,updates,816,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:425,Integrability,depend,dependencies,425,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:1021,Integrability,depend,dependencies,1021,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:563,Performance,cache,cached,563,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:953,Security,secur,security,953,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/32#issuecomment-265679401:1154,Usability,clear,clear,1154,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401
https://github.com/qupath/qupath/issues/34#issuecomment-266703994:45,Availability,down,download,45,"Hi Benjamin,. It should work already. If you download the [QuPath Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension), then so long as you add the latest Bio-Formats 5.3.0 then you should get CZI support immediately. I've tried it with a couple of images and it seems to work well. I have some plans to update the Bio-Formats extension to incorporate [memoization](https://www.openmicroscopy.org/site/support/bio-formats5.3/developers/matlab-dev.html#improving-reading-performance) to see if it improves performance... although it shouldn't be needed for CZI support in general. Please let me know if it works for you as well, or if you find any problems. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266703994
https://github.com/qupath/qupath/issues/34#issuecomment-266703994:329,Deployability,update,update,329,"Hi Benjamin,. It should work already. If you download the [QuPath Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension), then so long as you add the latest Bio-Formats 5.3.0 then you should get CZI support immediately. I've tried it with a couple of images and it seems to work well. I have some plans to update the Bio-Formats extension to incorporate [memoization](https://www.openmicroscopy.org/site/support/bio-formats5.3/developers/matlab-dev.html#improving-reading-performance) to see if it improves performance... although it shouldn't be needed for CZI support in general. Please let me know if it works for you as well, or if you find any problems. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266703994
https://github.com/qupath/qupath/issues/34#issuecomment-266703994:495,Performance,perform,performance,495,"Hi Benjamin,. It should work already. If you download the [QuPath Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension), then so long as you add the latest Bio-Formats 5.3.0 then you should get CZI support immediately. I've tried it with a couple of images and it seems to work well. I have some plans to update the Bio-Formats extension to incorporate [memoization](https://www.openmicroscopy.org/site/support/bio-formats5.3/developers/matlab-dev.html#improving-reading-performance) to see if it improves performance... although it shouldn't be needed for CZI support in general. Please let me know if it works for you as well, or if you find any problems. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266703994
https://github.com/qupath/qupath/issues/34#issuecomment-266703994:530,Performance,perform,performance,530,"Hi Benjamin,. It should work already. If you download the [QuPath Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension), then so long as you add the latest Bio-Formats 5.3.0 then you should get CZI support immediately. I've tried it with a couple of images and it seems to work well. I have some plans to update the Bio-Formats extension to incorporate [memoization](https://www.openmicroscopy.org/site/support/bio-formats5.3/developers/matlab-dev.html#improving-reading-performance) to see if it improves performance... although it shouldn't be needed for CZI support in general. Please let me know if it works for you as well, or if you find any problems. Thanks,. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266703994
https://github.com/qupath/qupath/issues/34#issuecomment-266705423:113,Deployability,install,installer,113,"Hi Pete,. Whaoou, indeed, it works perfectly, thanks a lot!; Why not to include this extension by default in the installer (or may be add an option to install it) ?; Thanks again!; Benjamin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266705423
https://github.com/qupath/qupath/issues/34#issuecomment-266705423:151,Deployability,install,install,151,"Hi Pete,. Whaoou, indeed, it works perfectly, thanks a lot!; Why not to include this extension by default in the installer (or may be add an option to install it) ?; Thanks again!; Benjamin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266705423
https://github.com/qupath/qupath/issues/34#issuecomment-266709923:491,Availability,down,download,491,"Hi Benjamin,. Great! Glad it works, thanks for letting me know. Regarding including the extension by default, that would definitely be handy. It should also be quite easy technically (thanks to Maven), but until now I've been a bit apprehensive about what requirements it would place on QuPath in terms of the GPL... i.e. providing source code, licenses for Bio-Formats and all its dependencies etc. So while I'm still learning about that side of things, I thought that requiring a separate download direct from the OME website makes things simpler in one way, even if it's a bit inconvenient. I'll give it a bit more thought though, and hopefully will be able to come up with a more streamlined way to install it at some point. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266709923
https://github.com/qupath/qupath/issues/34#issuecomment-266709923:703,Deployability,install,install,703,"Hi Benjamin,. Great! Glad it works, thanks for letting me know. Regarding including the extension by default, that would definitely be handy. It should also be quite easy technically (thanks to Maven), but until now I've been a bit apprehensive about what requirements it would place on QuPath in terms of the GPL... i.e. providing source code, licenses for Bio-Formats and all its dependencies etc. So while I'm still learning about that side of things, I thought that requiring a separate download direct from the OME website makes things simpler in one way, even if it's a bit inconvenient. I'll give it a bit more thought though, and hopefully will be able to come up with a more streamlined way to install it at some point. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266709923
https://github.com/qupath/qupath/issues/34#issuecomment-266709923:382,Integrability,depend,dependencies,382,"Hi Benjamin,. Great! Glad it works, thanks for letting me know. Regarding including the extension by default, that would definitely be handy. It should also be quite easy technically (thanks to Maven), but until now I've been a bit apprehensive about what requirements it would place on QuPath in terms of the GPL... i.e. providing source code, licenses for Bio-Formats and all its dependencies etc. So while I'm still learning about that side of things, I thought that requiring a separate download direct from the OME website makes things simpler in one way, even if it's a bit inconvenient. I'll give it a bit more thought though, and hopefully will be able to come up with a more streamlined way to install it at some point. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266709923
https://github.com/qupath/qupath/issues/34#issuecomment-266709923:419,Usability,learn,learning,419,"Hi Benjamin,. Great! Glad it works, thanks for letting me know. Regarding including the extension by default, that would definitely be handy. It should also be quite easy technically (thanks to Maven), but until now I've been a bit apprehensive about what requirements it would place on QuPath in terms of the GPL... i.e. providing source code, licenses for Bio-Formats and all its dependencies etc. So while I'm still learning about that side of things, I thought that requiring a separate download direct from the OME website makes things simpler in one way, even if it's a bit inconvenient. I'll give it a bit more thought though, and hopefully will be able to come up with a more streamlined way to install it at some point. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266709923
https://github.com/qupath/qupath/issues/34#issuecomment-266709923:541,Usability,simpl,simpler,541,"Hi Benjamin,. Great! Glad it works, thanks for letting me know. Regarding including the extension by default, that would definitely be handy. It should also be quite easy technically (thanks to Maven), but until now I've been a bit apprehensive about what requirements it would place on QuPath in terms of the GPL... i.e. providing source code, licenses for Bio-Formats and all its dependencies etc. So while I'm still learning about that side of things, I thought that requiring a separate download direct from the OME website makes things simpler in one way, even if it's a bit inconvenient. I'll give it a bit more thought though, and hopefully will be able to come up with a more streamlined way to install it at some point. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/34#issuecomment-266709923
https://github.com/qupath/qupath/issues/35#issuecomment-268206675:288,Deployability,install,installed,288,"Thanks for reporting this.; Am I right to understand that you have tried this on two Windows computers, and one works but the other does not?. I am not at a computer right now to explore more, but my first question is does the computer that fails to work have a 32-bit version of Windows installed?. From the log, there appears to be a problem loading the OpenSlide library (for which I think only 64-bit support is included). This should not prevent Bio-Formats from opening the image, but conceivably it could since QuPath tries out all the possible libraries that it has when opening a new image.... and if it fails badly enough with its OpenSlide attempt, perhaps it does not try Bio-Formats. You can prevent this if you find where QuPath is installed, and delete (or copy to another location) the OpenSlide component - probably called qupath-openslide-0.1.1.jar or similar. You can then restart QuPath and try again. Could you try this and see if it makes a difference? Thanks.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268206675
https://github.com/qupath/qupath/issues/35#issuecomment-268206675:746,Deployability,install,installed,746,"Thanks for reporting this.; Am I right to understand that you have tried this on two Windows computers, and one works but the other does not?. I am not at a computer right now to explore more, but my first question is does the computer that fails to work have a 32-bit version of Windows installed?. From the log, there appears to be a problem loading the OpenSlide library (for which I think only 64-bit support is included). This should not prevent Bio-Formats from opening the image, but conceivably it could since QuPath tries out all the possible libraries that it has when opening a new image.... and if it fails badly enough with its OpenSlide attempt, perhaps it does not try Bio-Formats. You can prevent this if you find where QuPath is installed, and delete (or copy to another location) the OpenSlide component - probably called qupath-openslide-0.1.1.jar or similar. You can then restart QuPath and try again. Could you try this and see if it makes a difference? Thanks.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268206675
https://github.com/qupath/qupath/issues/35#issuecomment-268206675:344,Performance,load,loading,344,"Thanks for reporting this.; Am I right to understand that you have tried this on two Windows computers, and one works but the other does not?. I am not at a computer right now to explore more, but my first question is does the computer that fails to work have a 32-bit version of Windows installed?. From the log, there appears to be a problem loading the OpenSlide library (for which I think only 64-bit support is included). This should not prevent Bio-Formats from opening the image, but conceivably it could since QuPath tries out all the possible libraries that it has when opening a new image.... and if it fails badly enough with its OpenSlide attempt, perhaps it does not try Bio-Formats. You can prevent this if you find where QuPath is installed, and delete (or copy to another location) the OpenSlide component - probably called qupath-openslide-0.1.1.jar or similar. You can then restart QuPath and try again. Could you try this and see if it makes a difference? Thanks.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268206675
https://github.com/qupath/qupath/issues/35#issuecomment-268206675:309,Testability,log,log,309,"Thanks for reporting this.; Am I right to understand that you have tried this on two Windows computers, and one works but the other does not?. I am not at a computer right now to explore more, but my first question is does the computer that fails to work have a 32-bit version of Windows installed?. From the log, there appears to be a problem loading the OpenSlide library (for which I think only 64-bit support is included). This should not prevent Bio-Formats from opening the image, but conceivably it could since QuPath tries out all the possible libraries that it has when opening a new image.... and if it fails badly enough with its OpenSlide attempt, perhaps it does not try Bio-Formats. You can prevent this if you find where QuPath is installed, and delete (or copy to another location) the OpenSlide component - probably called qupath-openslide-0.1.1.jar or similar. You can then restart QuPath and try again. Could you try this and see if it makes a difference? Thanks.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268206675
https://github.com/qupath/qupath/issues/35#issuecomment-268235442:223,Deployability,install,installed,223,"Thanks for your quick answer.; I renamed the file `C:\Program Files\QuPath\app\qupathqupath-extension-openslide-0.1.1.jar` to `qupath-extension-openslide-0.1.1.jar.TMP` as suggested and it solved the issue.; The program is installed with windows 10 64 bits on both computer, I don't know why on one openslide is not correctly loaded. Many thanks anyway!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268235442
https://github.com/qupath/qupath/issues/35#issuecomment-268235442:326,Performance,load,loaded,326,"Thanks for your quick answer.; I renamed the file `C:\Program Files\QuPath\app\qupathqupath-extension-openslide-0.1.1.jar` to `qupath-extension-openslide-0.1.1.jar.TMP` as suggested and it solved the issue.; The program is installed with windows 10 64 bits on both computer, I don't know why on one openslide is not correctly loaded. Many thanks anyway!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268235442
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:71,Availability,recover,recover,71,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:155,Availability,recover,recovered,155,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:265,Availability,error,error,265,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:13,Deployability,update,update,13,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:548,Deployability,install,installing,548,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:563,Deployability,update,update,563,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:132,Performance,load,loaded,132,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:71,Safety,recover,recover,71,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-268797552:155,Safety,recover,recovered,155,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552
https://github.com/qupath/qupath/issues/35#issuecomment-517719018:105,Availability,error,error,105,"@bpmed12 can you be more specific regarding what exactly you have tried, what does/does not work and any error messages you see?. Note that the 'image list' (under the 'Image' tab) does not exist in m3. So your issue may be different. Also not that the Bio-Formats extension must *not* be installed with m3 - it is included by default. You may still need to install the visual studio redistributable as specified at https://docs.openmicroscopy.org/bio-formats/6.1.1/formats/zeiss-czi.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-517719018
https://github.com/qupath/qupath/issues/35#issuecomment-517719018:289,Deployability,install,installed,289,"@bpmed12 can you be more specific regarding what exactly you have tried, what does/does not work and any error messages you see?. Note that the 'image list' (under the 'Image' tab) does not exist in m3. So your issue may be different. Also not that the Bio-Formats extension must *not* be installed with m3 - it is included by default. You may still need to install the visual studio redistributable as specified at https://docs.openmicroscopy.org/bio-formats/6.1.1/formats/zeiss-czi.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-517719018
https://github.com/qupath/qupath/issues/35#issuecomment-517719018:358,Deployability,install,install,358,"@bpmed12 can you be more specific regarding what exactly you have tried, what does/does not work and any error messages you see?. Note that the 'image list' (under the 'Image' tab) does not exist in m3. So your issue may be different. Also not that the Bio-Formats extension must *not* be installed with m3 - it is included by default. You may still need to install the visual studio redistributable as specified at https://docs.openmicroscopy.org/bio-formats/6.1.1/formats/zeiss-czi.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-517719018
https://github.com/qupath/qupath/issues/35#issuecomment-517719018:111,Integrability,message,messages,111,"@bpmed12 can you be more specific regarding what exactly you have tried, what does/does not work and any error messages you see?. Note that the 'image list' (under the 'Image' tab) does not exist in m3. So your issue may be different. Also not that the Bio-Formats extension must *not* be installed with m3 - it is included by default. You may still need to install the visual studio redistributable as specified at https://docs.openmicroscopy.org/bio-formats/6.1.1/formats/zeiss-czi.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-517719018
https://github.com/qupath/qupath/issues/36#issuecomment-268772402:348,Availability,avail,available,348,"Yes - if QuPath was able to read the label from the file, it can display it. To find it:. * Select the *Image* tab on the left.; * Below the image properties, click on *Associated images* (or, if there aren't any associated images, you could try *Image list*).; * All other images from the file should be listed there, including the label if it is available. You can double-click on any image to view it. ![qupath_label](https://cloud.githubusercontent.com/assets/4690904/21422884/fa411414-c831-11e6-93b5-f05b1a81d99c.jpg)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/36#issuecomment-268772402
https://github.com/qupath/qupath/issues/36#issuecomment-268778034:136,Security,access,access,136,"It wasn't, but it will be now. I have rarely looked at the label myself, but if it is useful then I will think some more about a way to access it more quickly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/36#issuecomment-268778034
https://github.com/qupath/qupath/issues/36#issuecomment-268792433:9,Deployability,release,release,9,"The next release of QuPath (v0.1.2, planned before the end of the year) will contain an option to show the label in a floating window under *View &rarr; Show slide label*. This is automatically updated any time a new image is opened, and the option should remain selected (or unselected) whenever QuPath is restarted. I also created a [FAQs section in the Wiki](https://github.com/qupath/qupath/wiki/FAQs) to link to this answer.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/36#issuecomment-268792433
https://github.com/qupath/qupath/issues/36#issuecomment-268792433:194,Deployability,update,updated,194,"The next release of QuPath (v0.1.2, planned before the end of the year) will contain an option to show the label in a floating window under *View &rarr; Show slide label*. This is automatically updated any time a new image is opened, and the option should remain selected (or unselected) whenever QuPath is restarted. I also created a [FAQs section in the Wiki](https://github.com/qupath/qupath/wiki/FAQs) to link to this answer.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/36#issuecomment-268792433
https://github.com/qupath/qupath/issues/40#issuecomment-622099365:97,Availability,avail,available,97,"Hi,. Congratulations for QuPath v2-mx series, amazing work!. Working with .ndpi files, ""No label available"". It would be useful to see the label in QuPath, e.g. when working with large collections of images from different experimental conditions, errors can easily occur when renaming the files after scanning, and being able to view the label would be valuable to detect possible errors, while at the same time adding an alternative to only relying on the file name for slide identification. Kind regards,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622099365
https://github.com/qupath/qupath/issues/40#issuecomment-622099365:247,Availability,error,errors,247,"Hi,. Congratulations for QuPath v2-mx series, amazing work!. Working with .ndpi files, ""No label available"". It would be useful to see the label in QuPath, e.g. when working with large collections of images from different experimental conditions, errors can easily occur when renaming the files after scanning, and being able to view the label would be valuable to detect possible errors, while at the same time adding an alternative to only relying on the file name for slide identification. Kind regards,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622099365
https://github.com/qupath/qupath/issues/40#issuecomment-622099365:381,Availability,error,errors,381,"Hi,. Congratulations for QuPath v2-mx series, amazing work!. Working with .ndpi files, ""No label available"". It would be useful to see the label in QuPath, e.g. when working with large collections of images from different experimental conditions, errors can easily occur when renaming the files after scanning, and being able to view the label would be valuable to detect possible errors, while at the same time adding an alternative to only relying on the file name for slide identification. Kind regards,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622099365
https://github.com/qupath/qupath/issues/40#issuecomment-622099365:365,Safety,detect,detect,365,"Hi,. Congratulations for QuPath v2-mx series, amazing work!. Working with .ndpi files, ""No label available"". It would be useful to see the label in QuPath, e.g. when working with large collections of images from different experimental conditions, errors can easily occur when renaming the files after scanning, and being able to view the label would be valuable to detect possible errors, while at the same time adding an alternative to only relying on the file name for slide identification. Kind regards,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622099365
https://github.com/qupath/qupath/issues/40#issuecomment-622246686:143,Availability,reliab,reliable,143,"Labels don't seem to be stored in a consistently identifiable away across scanners and file formats, and I'm afraid I don't think there is any reliable way for QuPath to identify automatically if a 'small image' within a larger file really is a slide label or something else. This would all be much easier if QuPath only needed to support a few scanners, and especially if it was written with file format specifications available, but unfortunately we don't have that much information :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622246686
https://github.com/qupath/qupath/issues/40#issuecomment-622246686:420,Availability,avail,available,420,"Labels don't seem to be stored in a consistently identifiable away across scanners and file formats, and I'm afraid I don't think there is any reliable way for QuPath to identify automatically if a 'small image' within a larger file really is a slide label or something else. This would all be much easier if QuPath only needed to support a few scanners, and especially if it was written with file format specifications available, but unfortunately we don't have that much information :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622246686
https://github.com/qupath/qupath/issues/42#issuecomment-473025090:20,Modifiability,enhance,enhancement,20,"I also support this enhancement as a simple way that QuPath could enhance the environment. . Another possibility would be the ability to rename annotations from the hierarchy view, which would be very helpful for many of my workflows.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-473025090
https://github.com/qupath/qupath/issues/42#issuecomment-473025090:66,Modifiability,enhance,enhance,66,"I also support this enhancement as a simple way that QuPath could enhance the environment. . Another possibility would be the ability to rename annotations from the hierarchy view, which would be very helpful for many of my workflows.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-473025090
https://github.com/qupath/qupath/issues/42#issuecomment-473025090:37,Usability,simpl,simple,37,"I also support this enhancement as a simple way that QuPath could enhance the environment. . Another possibility would be the ability to rename annotations from the hierarchy view, which would be very helpful for many of my workflows.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-473025090
https://github.com/qupath/qupath/issues/42#issuecomment-477945985:64,Modifiability,enhance,enhancement,64,"Hmmm, I opened this wondering who had originally asked for this enhancement and now I see it was me.... In v0.2.0 the annotation ordering should be less 'jumpy' than it previously was, even if the exact logic is not always easy to fathom. You can also rename annotations but selecting them in the viewer and pressing `Enter`. @murbano89 ; Is this sufficient, or would it still be helpful to be able to rename them from within the hierarchy view? If so, would you envisage it by right-clicking and choosing 'Set properties' (like in the Annotation tab) or some other way?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-477945985
https://github.com/qupath/qupath/issues/42#issuecomment-477945985:203,Testability,log,logic,203,"Hmmm, I opened this wondering who had originally asked for this enhancement and now I see it was me.... In v0.2.0 the annotation ordering should be less 'jumpy' than it previously was, even if the exact logic is not always easy to fathom. You can also rename annotations but selecting them in the viewer and pressing `Enter`. @murbano89 ; Is this sufficient, or would it still be helpful to be able to rename them from within the hierarchy view? If so, would you envisage it by right-clicking and choosing 'Set properties' (like in the Annotation tab) or some other way?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-477945985
https://github.com/qupath/qupath/issues/42#issuecomment-481330513:265,Safety,predict,predict,265,"Thanks for considering the request. I think it would still be nice to be able to re-name within the hierarchy view. The pattern could be homologous to as in the ""Annotations"" view where under the ""Hierarchy"" view (right-click --> set-properties), so that users can predict and expect the behavior that they have already learned in the ""Annotations"" view ~ just as you suggested above.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-481330513
https://github.com/qupath/qupath/issues/42#issuecomment-481330513:320,Usability,learn,learned,320,"Thanks for considering the request. I think it would still be nice to be able to re-name within the hierarchy view. The pattern could be homologous to as in the ""Annotations"" view where under the ""Hierarchy"" view (right-click --> set-properties), so that users can predict and expect the behavior that they have already learned in the ""Annotations"" view ~ just as you suggested above.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-481330513
https://github.com/qupath/qupath/issues/42#issuecomment-632222754:117,Security,access,access,117,"Closing this now... still not possible to rename in the *Hierarchy* view (sorry), but at least in v0.2.0 one can now access a consistent annotations menu by right-clicking on the viewer. This gives another way to set the properties, in addition to choosing from the *Annotations* tab or pressing `Enter`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-632222754
https://github.com/qupath/qupath/issues/43#issuecomment-272952005:686,Availability,error,errors,686,"Thanks Benjamin! That's really good to know, I had not realised that installing the redistributable was necessary. I have added the link to https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi. On the topic of CZI support, I have recently learned there may be some memory issues connected to reading CZI files that have been 'prestitched' using QuPath + Bio-Formats... is this something you have encountered / solved at all?. In the example I looked at, reading a single tile at the highest resolution would require preallocating an array that is the size of the entire full-resolution image whenever JPEG-XR compression was used... which would lead to out-of-memory errors in most cases. However I am not clear on the exact cause of this, and any insights would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/43#issuecomment-272952005
https://github.com/qupath/qupath/issues/43#issuecomment-272952005:69,Deployability,install,installing,69,"Thanks Benjamin! That's really good to know, I had not realised that installing the redistributable was necessary. I have added the link to https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi. On the topic of CZI support, I have recently learned there may be some memory issues connected to reading CZI files that have been 'prestitched' using QuPath + Bio-Formats... is this something you have encountered / solved at all?. In the example I looked at, reading a single tile at the highest resolution would require preallocating an array that is the size of the entire full-resolution image whenever JPEG-XR compression was used... which would lead to out-of-memory errors in most cases. However I am not clear on the exact cause of this, and any insights would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/43#issuecomment-272952005
https://github.com/qupath/qupath/issues/43#issuecomment-272952005:258,Usability,learn,learned,258,"Thanks Benjamin! That's really good to know, I had not realised that installing the redistributable was necessary. I have added the link to https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi. On the topic of CZI support, I have recently learned there may be some memory issues connected to reading CZI files that have been 'prestitched' using QuPath + Bio-Formats... is this something you have encountered / solved at all?. In the example I looked at, reading a single tile at the highest resolution would require preallocating an array that is the size of the entire full-resolution image whenever JPEG-XR compression was used... which would lead to out-of-memory errors in most cases. However I am not clear on the exact cause of this, and any insights would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/43#issuecomment-272952005
https://github.com/qupath/qupath/issues/43#issuecomment-272952005:725,Usability,clear,clear,725,"Thanks Benjamin! That's really good to know, I had not realised that installing the redistributable was necessary. I have added the link to https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi. On the topic of CZI support, I have recently learned there may be some memory issues connected to reading CZI files that have been 'prestitched' using QuPath + Bio-Formats... is this something you have encountered / solved at all?. In the example I looked at, reading a single tile at the highest resolution would require preallocating an array that is the size of the entire full-resolution image whenever JPEG-XR compression was used... which would lead to out-of-memory errors in most cases. However I am not clear on the exact cause of this, and any insights would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/43#issuecomment-272952005
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:227,Availability,down,downsampled,227,"Yes, there are a few ways to do that, depending on what exactly you want. https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d may help to give a starting point, since it shows how to do the export of a (very) downsampled version of the image as a single tile. But it still involves using a ```RegionRequest``` object to define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The follo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:370,Availability,down,downsampling,370,"Yes, there are a few ways to do that, depending on what exactly you want. https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d may help to give a starting point, since it shows how to do the export of a (very) downsampled version of the image as a single tile. But it still involves using a ```RegionRequest``` object to define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The follo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:1021,Availability,down,downsample,1021,"ctly you want. https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d may help to give a starting point, since it shows how to do the export of a (very) downsampled version of the image as a single tile. But it still involves using a ```RegionRequest``` object to define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ..",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:2474,Availability,down,downsample,2474," cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class). // Paint the overlay (except TMA grid); def img = imp.getProcessor().getBufferedImage(); def g2d = img.createGraphics(); g2d.scale(1.0/downsample, 1.0/downsample); g2d.translate(-request.getX(), -request.getY()); g2d.setClip((int)request.getX(), (int)request.getY(), (int)request.getWidth()+2, (int)request.getHeight()+4); hierarchyOverlay.paintOverlay(g2d, request, downsample, null, true); g2d.dispose(); imp.setProcessor(new ij.process.ColorProcessor(img)). // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```. Because the display settings are obtained from the current viewer, then settings applied there should be maintained (including the use of measurement maps to visualize cell features in context).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:2490,Availability,down,downsample,2490," cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class). // Paint the overlay (except TMA grid); def img = imp.getProcessor().getBufferedImage(); def g2d = img.createGraphics(); g2d.scale(1.0/downsample, 1.0/downsample); g2d.translate(-request.getX(), -request.getY()); g2d.setClip((int)request.getX(), (int)request.getY(), (int)request.getWidth()+2, (int)request.getHeight()+4); hierarchyOverlay.paintOverlay(g2d, request, downsample, null, true); g2d.dispose(); imp.setProcessor(new ij.process.ColorProcessor(img)). // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```. Because the display settings are obtained from the current viewer, then settings applied there should be maintained (including the use of measurement maps to visualize cell features in context).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:2706,Availability,down,downsample,2706," cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class). // Paint the overlay (except TMA grid); def img = imp.getProcessor().getBufferedImage(); def g2d = img.createGraphics(); g2d.scale(1.0/downsample, 1.0/downsample); g2d.translate(-request.getX(), -request.getY()); g2d.setClip((int)request.getX(), (int)request.getY(), (int)request.getWidth()+2, (int)request.getHeight()+4); hierarchyOverlay.paintOverlay(g2d, request, downsample, null, true); g2d.dispose(); imp.setProcessor(new ij.process.ColorProcessor(img)). // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```. Because the display settings are obtained from the current viewer, then settings applied there should be maintained (including the use of measurement maps to visualize cell features in context).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:2917,Availability,down,downsample,2917," cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class). // Paint the overlay (except TMA grid); def img = imp.getProcessor().getBufferedImage(); def g2d = img.createGraphics(); g2d.scale(1.0/downsample, 1.0/downsample); g2d.translate(-request.getX(), -request.getY()); g2d.setClip((int)request.getX(), (int)request.getY(), (int)request.getWidth()+2, (int)request.getHeight()+4); hierarchyOverlay.paintOverlay(g2d, request, downsample, null, true); g2d.dispose(); imp.setProcessor(new ij.process.ColorProcessor(img)). // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```. Because the display settings are obtained from the current viewer, then settings applied there should be maintained (including the use of measurement maps to visualize cell features in context).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:38,Integrability,depend,depending,38,"Yes, there are a few ways to do that, depending on what exactly you want. https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d may help to give a starting point, since it shows how to do the export of a (very) downsampled version of the image as a single tile. But it still involves using a ```RegionRequest``` object to define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The follo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273680833:1340,Safety,detect,detections,1340,"define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:211,Availability,avail,available,211,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:178,Integrability,interface,interface,178,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:558,Integrability,interface,interface,558,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:133,Security,access,access,133,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:288,Security,access,access,288,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-273939189:114,Usability,learn,learn,114,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:985,Energy Efficiency,power,powerful,985,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:996,Integrability,depend,depending,996,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:1746,Integrability,interface,interface,1746,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:863,Usability,learn,learning,863,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:968,Usability,simpl,simpler,968,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/44#issuecomment-274013607:1679,Usability,learn,learned,1679,"Hi Colin,. Thanks very much for your reply and positive comments. With regard to resources, I’m afraid the only ones I know of are the ones that I have written myself. These are mostly on the Wiki, however three other sources of scripts are:. * the Supplementary Material for the recent [bioRxiv preprint](http://biorxiv.org/content/early/2017/01/12/099796) - this also includes descriptions of how the scripts are used; * my own [Gists on GitHub](https://gist.github.com/petebankhead); * the built-in examples under *Automate &rarr; Open sample scripts*. Beyond that, I find [using IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) to be really essential. Its Groovy support is excellent, and it is full of tricks that help with finding the parts of code that are needed. I hadn’t used IntelliJ previously, so I am only gradually learning what it can do*. Scripting is something that I would like to revisit in the future to make both simpler and more powerful - depending upon what is needed most. Currently, I use scripting for working with projects, working with objects/classifications, working with pixels, and working with GUI components… but the classes and techniques involves are quite different, and some are easier than others. I’m not sure which of my uses are of general interest... or just useful to me. Therefore in the absence of more complete documentation, it’s probably best to ask specific questions here and I’ll try to answer. In the short term, I plan to add links to the most generally-useful questions in the [FAQ section](https://github.com/qupath/qupath/wiki/FAQs) to make them a bit easier to find. Pete. *-Just now I learned that ```Ctrl + h``` with the cursor on a relevant class or interface name (e.g. ```PathObject``` or ```ImageServer```) opens up a class hierarchy to help see related classes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-274013607
https://github.com/qupath/qupath/issues/45#issuecomment-274611030:366,Availability,down,down,366,"Thanks for reporting this. I have not been working with CZI images myself, but I recently received one example image with this problem. Unfortunately, I have not yet been able to identify the exact cause, beyond the fact that too much memory is used. Because the image is not being read by QuPath directly (but rather Bio-Formats) it is a bit harder for me to track down where exactly the problem lies. However, I will continue to investigate, and add an update here when I learn more. In the meantime, I have been told that the Zeiss ZEN software is able to export the different scenes as separate images, which can then be read into a [QuPath project](https://github.com/qupath/qupath/wiki/Projects). Therefore this may be a workaround that enables you to work with the images in QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274611030
https://github.com/qupath/qupath/issues/45#issuecomment-274611030:455,Deployability,update,update,455,"Thanks for reporting this. I have not been working with CZI images myself, but I recently received one example image with this problem. Unfortunately, I have not yet been able to identify the exact cause, beyond the fact that too much memory is used. Because the image is not being read by QuPath directly (but rather Bio-Formats) it is a bit harder for me to track down where exactly the problem lies. However, I will continue to investigate, and add an update here when I learn more. In the meantime, I have been told that the Zeiss ZEN software is able to export the different scenes as separate images, which can then be read into a [QuPath project](https://github.com/qupath/qupath/wiki/Projects). Therefore this may be a workaround that enables you to work with the images in QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274611030
https://github.com/qupath/qupath/issues/45#issuecomment-274611030:474,Usability,learn,learn,474,"Thanks for reporting this. I have not been working with CZI images myself, but I recently received one example image with this problem. Unfortunately, I have not yet been able to identify the exact cause, beyond the fact that too much memory is used. Because the image is not being read by QuPath directly (but rather Bio-Formats) it is a bit harder for me to track down where exactly the problem lies. However, I will continue to investigate, and add an update here when I learn more. In the meantime, I have been told that the Zeiss ZEN software is able to export the different scenes as separate images, which can then be read into a [QuPath project](https://github.com/qupath/qupath/wiki/Projects). Therefore this may be a workaround that enables you to work with the images in QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274611030
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:818,Availability,down,down,818,"Hi Pete,. thanks for your answer. I want to learn all functions of QuPath. I like ; your documentation a lot. Its well done work. Do you develop QuPath all alone by yourself?. Another question: is there a log file, QuPath is writing, that can help ; you to track and find the reason for bugs and system crashes?. We did that with our software in the past. It is very helpful. Best. David. Am 23/01/2017 um 21:44 schrieb Pete:; >; > Thanks for reporting this. I have not been working with CZI images ; > myself, but I recently received one example image with this problem. ; > Unfortunately, I have not yet been able to identify the exact cause, ; > beyond the fact that too much memory is used. Because the image is not ; > being read by QuPath directly (but rather Bio-Formats) it is a bit ; > harder for me to track down where exactly the problem lies. However, I ; > will continue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:2788,Availability,error,error,2788,"inue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:911,Deployability,update,update,911,"Hi Pete,. thanks for your answer. I want to learn all functions of QuPath. I like ; your documentation a lot. Its well done work. Do you develop QuPath all alone by yourself?. Another question: is there a log file, QuPath is writing, that can help ; you to track and find the reason for bugs and system crashes?. We did that with our software in the past. It is very helpful. Best. David. Am 23/01/2017 um 21:44 schrieb Pete:; >; > Thanks for reporting this. I have not been working with CZI images ; > myself, but I recently received one example image with this problem. ; > Unfortunately, I have not yet been able to identify the exact cause, ; > beyond the fact that too much memory is used. Because the image is not ; > being read by QuPath directly (but rather Bio-Formats) it is a bit ; > harder for me to track down where exactly the problem lies. However, I ; > will continue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:2559,Security,confidential,confidential,2559,"inue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:2826,Security,access,accessible,2826,"inue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:205,Testability,log,log,205,"Hi Pete,. thanks for your answer. I want to learn all functions of QuPath. I like ; your documentation a lot. Its well done work. Do you develop QuPath all alone by yourself?. Another question: is there a log file, QuPath is writing, that can help ; you to track and find the reason for bugs and system crashes?. We did that with our software in the past. It is very helpful. Best. David. Am 23/01/2017 um 21:44 schrieb Pete:; >; > Thanks for reporting this. I have not been working with CZI images ; > myself, but I recently received one example image with this problem. ; > Unfortunately, I have not yet been able to identify the exact cause, ; > beyond the fact that too much memory is used. Because the image is not ; > being read by QuPath directly (but rather Bio-Formats) it is a bit ; > harder for me to track down where exactly the problem lies. However, I ; > will continue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:44,Usability,learn,learn,44,"Hi Pete,. thanks for your answer. I want to learn all functions of QuPath. I like ; your documentation a lot. Its well done work. Do you develop QuPath all alone by yourself?. Another question: is there a log file, QuPath is writing, that can help ; you to track and find the reason for bugs and system crashes?. We did that with our software in the past. It is very helpful. Best. David. Am 23/01/2017 um 21:44 schrieb Pete:; >; > Thanks for reporting this. I have not been working with CZI images ; > myself, but I recently received one example image with this problem. ; > Unfortunately, I have not yet been able to identify the exact cause, ; > beyond the fact that too much memory is used. Because the image is not ; > being read by QuPath directly (but rather Bio-Formats) it is a bit ; > harder for me to track down where exactly the problem lies. However, I ; > will continue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-274930919:930,Usability,learn,learn,930,"Hi Pete,. thanks for your answer. I want to learn all functions of QuPath. I like ; your documentation a lot. Its well done work. Do you develop QuPath all alone by yourself?. Another question: is there a log file, QuPath is writing, that can help ; you to track and find the reason for bugs and system crashes?. We did that with our software in the past. It is very helpful. Best. David. Am 23/01/2017 um 21:44 schrieb Pete:; >; > Thanks for reporting this. I have not been working with CZI images ; > myself, but I recently received one example image with this problem. ; > Unfortunately, I have not yet been able to identify the exact cause, ; > beyond the fact that too much memory is used. Because the image is not ; > being read by QuPath directly (but rather Bio-Formats) it is a bit ; > harder for me to track down where exactly the problem lies. However, I ; > will continue to investigate, and add an update here when I learn more.; >; > In the meantime, I have been told that the Zeiss ZEN software is able ; > to export the different scenes as separate images, which can then be ; > read into a QuPath project ; > <https://github.com/qupath/qupath/wiki/Projects>. Therefore this may ; > be a workaround that enables you to work with the images in QuPath.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-274611030>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEV0UakHZI556HGXSHym-5fglXkHwks5rVREZgaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; G",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-274930919
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:294,Testability,test,test,294,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:420,Testability,log,log,420,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:706,Testability,log,logged,706,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:757,Testability,log,log,757,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:917,Testability,log,log,917,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275033701:318,Usability,feedback,feedback,318,"Hi David,. Thanks, I'm glad you like the documentation! It's always a difficult balance between writing documentation, developing new features and polishing/fixing/generalizing current ones... Although I developed the software at university, as it started to become more useful others began to test it and gave useful feedback, and I discussed its application often with pathologists. So never really alone. There is no log file written at the moment - mostly because I wasn't sure where to save it and didn't want to annoy a user with files appearing where they did not want them... although it would probably be worth adding an option for this. I will look into it. However, you can at least see what is logged for the current session under 'View -> Show log'. In many cases, this should automatically appear if QuPath suffers any serious disaster - but that is not guaranteed to happen, so it can help to open the log window early if you anticipate a crash may occur. Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275033701
https://github.com/qupath/qupath/issues/45#issuecomment-275047111:324,Integrability,message,message,324,"Hi David,; Since this is through GitHub, I don't have any your contact address to get in touch privately, and any email replies to this thread are shown [here](https://github.com/qupath/qupath/issues/45) (can also edit/delete through that link). However, if you'd like to follow up on this maybe you could send me a private message on ResearchGate?; Thanks,; Pete",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275047111
https://github.com/qupath/qupath/issues/45#issuecomment-275055657:2039,Availability,error,error,2039," > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657
https://github.com/qupath/qupath/issues/45#issuecomment-275055657:23,Integrability,message,message,23,"Hi Pete,. I sent you a message in ResearchGate and deleted the last comment. Best. David. Am 25/01/2017 um 09:26 schrieb Pete:; >; > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails inc",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657
https://github.com/qupath/qupath/issues/45#issuecomment-275055657:474,Integrability,message,message,474,"Hi Pete,. I sent you a message in ResearchGate and deleted the last comment. Best. David. Am 25/01/2017 um 09:26 schrieb Pete:; >; > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails inc",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657
https://github.com/qupath/qupath/issues/45#issuecomment-275055657:1810,Security,confidential,confidential,1810," > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657
https://github.com/qupath/qupath/issues/45#issuecomment-275055657:2077,Security,access,accessible,2077," > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:352,Integrability,depend,depending,352,"Most things are possible with a (possibly-complicated) script, but there is no easy way to do what you describe in QuPath. Detecting positive and negative cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:1845,Performance,perform,perform,1845,"tive cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for defined regions of interest... when you don't need to use the full cell information to train QuPath to distinguish between tumor and non-tumor cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:123,Safety,Detect,Detecting,123,"Most things are possible with a (possibly-complicated) script, but there is no easy way to do what you describe in QuPath. Detecting positive and negative cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:467,Safety,avoid,avoid,467,"Most things are possible with a (possibly-complicated) script, but there is no easy way to do what you describe in QuPath. Detecting positive and negative cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:540,Safety,detect,detection,540,"Most things are possible with a (possibly-complicated) script, but there is no easy way to do what you describe in QuPath. Detecting positive and negative cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:1816,Safety,detect,detection,1816,"tive cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for defined regions of interest... when you don't need to use the full cell information to train QuPath to distinguish between tumor and non-tumor cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-275932246:1955,Safety,detect,detecting,1955,"tive cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for defined regions of interest... when you don't need to use the full cell information to train QuPath to distinguish between tumor and non-tumor cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:2626,Availability,error,error,2626,"assify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:415,Safety,detect,detection,415,"Thank you Svidro,. Thank you for your answer. I will try your suggested way. I didnt find your answer in the github chat. I am not familiar with ; github yet - didnt know, it is possible to have a conversation that does ; not appear in the issue. how did u do that?. Best. David. Am 29/01/2017 um 21:04 schrieb Svidro:; >; > My usual method for this type of situation would be to use ; > Analyze>Cell Analysis>Cell detection with ""make measurements"" checked ; > (using Hematoxylin OD since that is giving you the best cell detection).; >; > Then run Classify>Classify By Specific Feature with whatever cutoff ; > you were using in the positive cell detection that gave you good ; > positive/negative separation.; > classify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetz",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:523,Safety,detect,detection,523,"Thank you Svidro,. Thank you for your answer. I will try your suggested way. I didnt find your answer in the github chat. I am not familiar with ; github yet - didnt know, it is possible to have a conversation that does ; not appear in the issue. how did u do that?. Best. David. Am 29/01/2017 um 21:04 schrieb Svidro:; >; > My usual method for this type of situation would be to use ; > Analyze>Cell Analysis>Cell detection with ""make measurements"" checked ; > (using Hematoxylin OD since that is giving you the best cell detection).; >; > Then run Classify>Classify By Specific Feature with whatever cutoff ; > you were using in the positive cell detection that gave you good ; > positive/negative separation.; > classify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetz",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:649,Safety,detect,detection,649,"Thank you Svidro,. Thank you for your answer. I will try your suggested way. I didnt find your answer in the github chat. I am not familiar with ; github yet - didnt know, it is possible to have a conversation that does ; not appear in the issue. how did u do that?. Best. David. Am 29/01/2017 um 21:04 schrieb Svidro:; >; > My usual method for this type of situation would be to use ; > Analyze>Cell Analysis>Cell detection with ""make measurements"" checked ; > (using Hematoxylin OD since that is giving you the best cell detection).; >; > Then run Classify>Classify By Specific Feature with whatever cutoff ; > you were using in the positive cell detection that gave you good ; > positive/negative separation.; > classify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetz",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:2397,Security,confidential,confidential,2397,"assify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276000050:2664,Security,access,accessible,2664,"assify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050
https://github.com/qupath/qupath/issues/46#issuecomment-276007341:137,Safety,detect,detecting,137,"Ah, sorry, I actually deleted it once I realized it wasn't actually answering your question correctly. I thought you were having trouble detecting positivity within your cells, not missing cells entirely! The only other thing I could think of for that was along the same lines as Pete's suggestion. . Sometimes with more complicated stains I ""cheat"" by creating my own stain vector as a mix of Hematoxylin and DAB, and save it over Hematoxylin. In a straight HDAB this shouldn't give very different results from full OD (and could easily be worse), though, but it may be worth a try if you are still having trouble.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276007341
https://github.com/qupath/qupath/issues/46#issuecomment-276200635:466,Safety,Detect,Detection,466,"So I just had this problem on a project today! I can't post the data, but what I did was roughly what I described above, but with a slight twist. We had a purple cytoplasmic stain along with hematoxylin for the nuclei, and finally a DAB stain that was also nuclear. . I changed the DAB vector to the purple stain (in Analyze>Estimate Stain vectors) and created a hybrid vector between the DAB and hematoxylin for the hematoxylin vector. . I then ran a standard Cell Detection using ; 1. Hematoxylin OD for nuclei ; 2. Exclude DAB checked (DAB now being all of the background purple) and ; 3. a Threshold of .05; and obtained quite good results.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276200635
https://github.com/qupath/qupath/issues/47#issuecomment-276386273:15,Performance,load,loaded,15,"if the file is loaded just als single file, not within a project, it also crashes QuPath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/47#issuecomment-276386273
https://github.com/qupath/qupath/issues/47#issuecomment-276485995:276,Testability,test,tested,276,"If you can send me the file somehow, then I can have a look. What I would do is to try opening the same image with [Fiji](http://www.fiji.sc), since Fiji can also use Bio-Formats to read files. The connection between Bio-Formats and Fiji is well-established, and is much more tested than that between Bio-Formats and QuPath. If Fiji can open all scenes within the file, then the problem may be within the QuPath extension. However if Fiji cannot open all the scenes, then it is more likely to be either an issue with the CZI file itself, or with Bio-Format's support for CZI. If this is the case, then perhaps the developers of Bio-Formats may be able to help further. There are several ways to contact them described at http://www.openmicroscopy.org/site/community",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/47#issuecomment-276485995
https://github.com/qupath/qupath/issues/47#issuecomment-358750045:59,Deployability,update,update,59,"Very good to know about the workaround, thanks. The latest update to the extension should improve CZI support, and hopefully there's no need to split the image any more. There are more details [here](https://groups.google.com/d/msg/qupath-users/78PpZuu2J1s/su6ZjY0mAgAJ).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/47#issuecomment-358750045
https://github.com/qupath/qupath/issues/48#issuecomment-276482533:536,Availability,toler,tolerance,536,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533
https://github.com/qupath/qupath/issues/48#issuecomment-276482533:611,Availability,toler,tolerance,611,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533
https://github.com/qupath/qupath/issues/48#issuecomment-276482533:1185,Availability,down,down,1185,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533
https://github.com/qupath/qupath/issues/48#issuecomment-276482533:42,Safety,detect,detect,42,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533
https://github.com/qupath/qupath/issues/48#issuecomment-276482533:1156,Testability,log,log,1156,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533
https://github.com/qupath/qupath/issues/49#issuecomment-278233145:622,Availability,down,downside,622,"Hi! I was just considering this problem, and I was wondering if you have tried splitting the image into two as a possible work-around?. There are multiple problems with this, but... one thing to try is:; 1. Get Pannoramic Viewer (Caseviewer does not do this) from 3DHISTECH.; 2. Export your image twice, and select only 3 of the 4 channels each time, with one different between the images.; 3. Import both images into QuPath, calculate your values, then recombine the images at the end. Since your DAPI channel should be the exact same, the cells generated should pair 1 to 1, and we even have XY coordinates now! Another downside though is that Pannoramic Viewer only exports .mrxs files in JPEG PNG and BMP, not JPEGXR, so you might lose some information there if you took the images in another format, or your files might end up being huge. Please let me know if this works for you! I may end up trying it some day...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/49#issuecomment-278233145
https://github.com/qupath/qupath/issues/49#issuecomment-278264549:249,Security,access,access,249,"Hi Svidro,; thank you for your suggestions. The problem is, that I need all the 4 channels to analyze co-expression of markers. Hence, exporting every image twice is not feasible (and too slow). ; Could you explain to me why is it so problematic to access more than 3 channels? . Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/49#issuecomment-278264549
https://github.com/qupath/qupath/issues/49#issuecomment-278268312:564,Safety,Detect,Detections,564,"I am afraid I do not know what the problem is with more than 3 channels, and I certainly do not have the programming experience to dive into it, unfortunately! I agree that it would be nice to be able to handle more fluorescence channels. I also understand the need to study co-expression of markers, however, which is very possible even after you split the channels into two images, provided each image still has DAPI in order for QuPath to generate the same exact cell population. Merging the data sets later gives you your co-expressors. For example, since the Detections output file is in the same cell by cell order, the first cell from image 1 might be positive for markers A and B, with the first cell in the second image positive or negative for marker C. Fluorescent channels are independent, anyway, though you would need an extra program such as R (or just Excel if your sample is small enough) to combine the data sets to see the co-expressing population cell by cell, and you would lack the visualization tools of QuPath, but you could get the data (percentage positive for each type, or per mm^2) with a fairly straightforward script!. As a side note, I think increasing the tile size to maximum dramatically decreases the export time in Pannoramic viewer. I have spent quite a while with it running on multiple computers though, so I understand it can be frustrating.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/49#issuecomment-278268312
https://github.com/qupath/qupath/issues/50#issuecomment-278506606:164,Availability,down,down,164,"Yes, it will try to select the object you already have created. If you want to draw within the annotation object (square) you have created, right click on it, drop down to Annotations, and select ""Lock."" Otherwise, it thinks you are trying to fill in the annotation you already have created. One way to see this is, with the annotation unlocked, hold down Alt and draw with the brush tool. You will see you are creating holes in your annotation now. One important thing to note when creating annotations within annotations, is that if your second brush tool annotation exits the first annotation, none of the detections within will be considered part of the brush tool annotation. This is probably most important when dealing with TMAs, because if the region you draw leaves the TMA circle, it is treated as being entirely outside!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-278506606
https://github.com/qupath/qupath/issues/50#issuecomment-278506606:351,Availability,down,down,351,"Yes, it will try to select the object you already have created. If you want to draw within the annotation object (square) you have created, right click on it, drop down to Annotations, and select ""Lock."" Otherwise, it thinks you are trying to fill in the annotation you already have created. One way to see this is, with the annotation unlocked, hold down Alt and draw with the brush tool. You will see you are creating holes in your annotation now. One important thing to note when creating annotations within annotations, is that if your second brush tool annotation exits the first annotation, none of the detections within will be considered part of the brush tool annotation. This is probably most important when dealing with TMAs, because if the region you draw leaves the TMA circle, it is treated as being entirely outside!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-278506606
https://github.com/qupath/qupath/issues/50#issuecomment-278506606:609,Safety,detect,detections,609,"Yes, it will try to select the object you already have created. If you want to draw within the annotation object (square) you have created, right click on it, drop down to Annotations, and select ""Lock."" Otherwise, it thinks you are trying to fill in the annotation you already have created. One way to see this is, with the annotation unlocked, hold down Alt and draw with the brush tool. You will see you are creating holes in your annotation now. One important thing to note when creating annotations within annotations, is that if your second brush tool annotation exits the first annotation, none of the detections within will be considered part of the brush tool annotation. This is probably most important when dealing with TMAs, because if the region you draw leaves the TMA circle, it is treated as being entirely outside!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-278506606
https://github.com/qupath/qupath/issues/50#issuecomment-280862813:610,Safety,detect,detection,610,"Thanks Svidro and ClnSchlssr - yes, it is mostly 'expected behavior'. You can also work around it slightly by drawing a polygon inside your annotation, and then switch to the brush tool to edit it (using the shortcuts 'p' and 'b' to switch tools). The polygon is able to create the new annotation, and when clicking inside the new polygon with the brush tool then it should be selected (rather than the original annotation). But I think locking annotations is the best solution, since this also prevents you from accidentally moving the annotation within which the tiles were created. Some commands (e.g. cell detection) automatically lock the annotations that they are run inside, but 'Create tiles' doesn't. It probably should. As Svidro mentions, the need for annotations to be completely inside other annotations to 'capture' further objects is really important... there is some explanation for it at https://github.com/qupath/qupath/wiki/Object-hierarchies",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-280862813
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:482,Availability,down,download,482,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:1010,Availability,recover,recover,1010,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:1055,Availability,down,downloading,1055,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:386,Deployability,install,installed,386,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:52,Integrability,depend,dependencies,52,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:766,Integrability,depend,depend,766,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:1416,Modifiability,variab,variable,1416,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:1010,Safety,recover,recover,1010,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280861844:235,Testability,test,tested,235,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844
https://github.com/qupath/qupath/issues/51#issuecomment-280864702:58,Deployability,install,installed,58,Thanks for your suggestions. I found another computer and installed 16.04. It ran without any issue.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280864702
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:778,Availability,down,downside,778,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:998,Availability,down,down,998,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:37,Integrability,depend,depending,37,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:1119,Modifiability,rewrite,rewrite,1119,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:163,Usability,clear,clear,163,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/52#issuecomment-281009359:1337,Usability,simpl,simple,1337,"I think you have a couple of options depending on how easy it is to determine stroma vs tumor in your samples, and positive vs negative. If the differentiation is clear, and easy for the classifier to make, I would start with using one of the built in classifiers to sort all of the cells in the TMA into Stroma and Tumor classes. ; Then, by right clicking on the right hand side of the annotation tab, I would ""Add Class"" and make ""Tumor CD3 Positive"" and ""Stroma CD3 Positive"" classes. After you have those made, use the Classify->Classify By Specific Feature. This will take two steps, but it will let you select first ""Stroma"" class cells as the input and ""Stroma CD3 Positive""/""Stroma"" classes as the outputs. A second pass lets you do the same for the ""Tumor"" cells.; The downside to this is the Classify by specific feature command does not show up in the workflow and can be annoying to use on multiple images since you have to type it out each time. There is also a script that I can hunt down, if you want, that lets you automate the process, I forget if Peter posted it somewhere on the Wiki. You do need to rewrite the script somewhat for what you specifically want, however. ; The other option , if you cannot use the classifier to determine Stroma vs Tumor, and want to draw annotations in each core by hand, you can use a simple script that is currently the most recently discussed topic on the Gitter page, seen here [https://gitter.im/qupath-users/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link](url); After you use the annotations to assign the initial classes, proceed the same way. Of course, I am sure there are other ways to do it as well, this is quite versatile software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/52#issuecomment-281009359
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:665,Availability,toler,tolerance,665,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:740,Availability,toler,tolerance,740,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:1303,Availability,down,down,1303,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:268,Safety,detect,detect,268,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:169,Testability,test,tested,169,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282308795:1275,Testability,log,log,1275,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1682,Energy Efficiency,adapt,adapted,1682,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:755,Integrability,depend,depend,755,"Adding to the above suggestions, I understand by the manual you mean the section on [TMA CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). You can see in the screenshots the kind of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1910,Integrability,depend,depending,1910,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1682,Modifiability,adapt,adapted,1682,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:358,Safety,detect,detection,358,"Adding to the above suggestions, I understand by the manual you mean the section on [TMA CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). You can see in the screenshots the kind of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:543,Safety,detect,detecting,543,"Adding to the above suggestions, I understand by the manual you mean the section on [TMA CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). You can see in the screenshots the kind of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1178,Safety,detect,detection,1178,"of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, p",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1499,Safety,detect,detection,1499,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1652,Safety,detect,detect,1652,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1852,Safety,detect,detection,1852,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1967,Safety,detect,detect,1967,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:2039,Safety,detect,detect,2039,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1164,Usability,Simpl,Simple,1164,"of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, p",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1321,Usability,simpl,simple,1321,"of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, p",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1838,Usability,Simpl,Simple,1838,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282469327:2032,Usability,simpl,simply,2032,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327
https://github.com/qupath/qupath/issues/53#issuecomment-282515393:56,Safety,detect,detection,56,"Ooh, that is good to know! I hadn't realized the tissue detection did not use the colors at all. That nixes the entire first paragraph of my first comment!. And to add on to Peter's last comment, I frequently calculate tissue area in R after the fact, using a sum of the cell areas in each core, or create a second set of cells temporarily with a larger cell expansion if the density is low (large enough that the fake cells fill in most of the tissue space) to get a fairly accurate measure of the tissue area in order to generate a positive cells/mm^2 value. And if the significant yellowing is the primary culprit, a difference just +/- 1 on the threshold could make a huge difference as long as the background is consistent.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282515393
https://github.com/qupath/qupath/issues/53#issuecomment-282548616:139,Safety,detect,detection,139,"Thank you very much, Svidro, DHaumannHSA and petebankhead for your quick and helpful answers! Very much appreciated! I did not know tissue detection did not use colors! Very interesting! ; By ""manual"" I was referring to the section on TMA CD3 analysis. I followed all these steps precisely (including estimation of stain vectors). The setting is also on Brightfield. The values given for the background/whitespace at the bottom of the Image tab on the left are around 223,215,213 in my case. By playing around with these numbers in my settings I eventually managed to get better results that are ok to work with. Thank you very much everybody once again.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282548616
https://github.com/qupath/qupath/issues/53#issuecomment-282609510:270,Deployability,update,updates,270,"Slightly off QuPath- I don't know what scanner you are using, but if you have access to it, I think most should have a brightfield compensation image adjustment setting (it takes a picture of a blank slide and adjusts). We had some yellowing in ours after some software updates, and that took care of the background.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282609510
https://github.com/qupath/qupath/issues/53#issuecomment-282609510:78,Security,access,access,78,"Slightly off QuPath- I don't know what scanner you are using, but if you have access to it, I think most should have a brightfield compensation image adjustment setting (it takes a picture of a blank slide and adjusts). We had some yellowing in ours after some software updates, and that took care of the background.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282609510
https://github.com/qupath/qupath/issues/53#issuecomment-475997405:91,Safety,detect,detect,91,"Hey all,. I'm having similar issues to those described here above. TMA dearrayer refuse to detect cores on two images from the project.. seems like the H&E stain is a bit weaker in these slides:; ![image](https://user-images.githubusercontent.com/9028967/54885257-ce938480-4e82-11e9-9566-6b54a5ce77b2.png). I've attempted to change the background colors & stain vectors, but that did not work. Adding rows or columns manually do not work since they are added outside the frame and so I could not relocate them. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-475997405
https://github.com/qupath/qupath/issues/53#issuecomment-476218275:139,Safety,detect,detected,139,Thanks! this indeed solve the issue. I guess it would be nice to have an option to force QuPath to draw the grid even if the cores are not detected in a similar manner to what the script does.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-476218275
https://github.com/qupath/qupath/issues/55#issuecomment-285858735:134,Availability,error,error,134,"4GB is fairly low, I had trouble running much with even 8GB on an older laptop, but if you can replicate and post more details on the error (a screenshot?) maybe Peter can help you.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/55#issuecomment-285858735
https://github.com/qupath/qupath/issues/55#issuecomment-285868226:23,Availability,error,error,23,"Hi, yes I'm afraid the error is related to memory and unfortunately 4GB is probably not enough to do much analysis with QuPath. For browsing and annotating images it should be ok. Nevertheless, you might be able to get further if you adjust the memory settings and then restart QuPath for them to take effect - there is some information [here](https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits). The above link also contains instructions for how to reduce the number of things QuPath does in parallel, which can reduce the amount of memory needed for processing (at the cost of things taking longer to run). In this situation, it would be best to run QuPath with as few other applications as possible open on your computer at the same time. For the specific example of getting the *Estimate stain vectors* command to work, you can also try selecting a smaller rectangle in your image, as described [here](https://github.com/qupath/qupath/wiki/Preprocessing#find-a-representative-region).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/55#issuecomment-285868226
https://github.com/qupath/qupath/issues/55#issuecomment-285868226:475,Energy Efficiency,reduce,reduce,475,"Hi, yes I'm afraid the error is related to memory and unfortunately 4GB is probably not enough to do much analysis with QuPath. For browsing and annotating images it should be ok. Nevertheless, you might be able to get further if you adjust the memory settings and then restart QuPath for them to take effect - there is some information [here](https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits). The above link also contains instructions for how to reduce the number of things QuPath does in parallel, which can reduce the amount of memory needed for processing (at the cost of things taking longer to run). In this situation, it would be best to run QuPath with as few other applications as possible open on your computer at the same time. For the specific example of getting the *Estimate stain vectors* command to work, you can also try selecting a smaller rectangle in your image, as described [here](https://github.com/qupath/qupath/wiki/Preprocessing#find-a-representative-region).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/55#issuecomment-285868226
https://github.com/qupath/qupath/issues/55#issuecomment-285868226:538,Energy Efficiency,reduce,reduce,538,"Hi, yes I'm afraid the error is related to memory and unfortunately 4GB is probably not enough to do much analysis with QuPath. For browsing and annotating images it should be ok. Nevertheless, you might be able to get further if you adjust the memory settings and then restart QuPath for them to take effect - there is some information [here](https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits). The above link also contains instructions for how to reduce the number of things QuPath does in parallel, which can reduce the amount of memory needed for processing (at the cost of things taking longer to run). In this situation, it would be best to run QuPath with as few other applications as possible open on your computer at the same time. For the specific example of getting the *Estimate stain vectors* command to work, you can also try selecting a smaller rectangle in your image, as described [here](https://github.com/qupath/qupath/wiki/Preprocessing#find-a-representative-region).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/55#issuecomment-285868226
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:424,Availability,mask,mask,424,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:36,Modifiability,plugin,plugin,36,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:399,Safety,detect,detection,399,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:440,Safety,detect,detect,440,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:784,Safety,detect,detections,784,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286257042:122,Testability,test,test,122,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042
https://github.com/qupath/qupath/issues/56#issuecomment-286447290:466,Deployability,integrat,integration,466,"Thanks for the dedtail answer.; What I wanted to do was more something similar to what Ilastik or the Trainable Weka segmentation plugin for ImageJ offer, meaning you select manually some areas (in my case, I could define 3 classes of pixels, adipocytes, background and others) and after having applied multiple filters (gaussian, hessian etc...), the classifier is generated from my selection and applied to the rest of the image's pixels. I first thought that the integration of Weka was doing that but I realized then that it is used to classify annotations based on intensity and shape features, which is a bit different. It would be interesting to perform this kind of analysis because sometime that which give the best result in term of segmentation.; The threshold based approach didn't give me similar result, especially because background and inside of adipocyte have similar intensity.; The main advantage to use it in qpath instead of ImageJ will be to run it on the max resolution to get more precise result. ![image](https://cloud.githubusercontent.com/assets/1775952/23906471/53031de0-08ce-11e7-88ce-d89736289278.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286447290
https://github.com/qupath/qupath/issues/56#issuecomment-286447290:466,Integrability,integrat,integration,466,"Thanks for the dedtail answer.; What I wanted to do was more something similar to what Ilastik or the Trainable Weka segmentation plugin for ImageJ offer, meaning you select manually some areas (in my case, I could define 3 classes of pixels, adipocytes, background and others) and after having applied multiple filters (gaussian, hessian etc...), the classifier is generated from my selection and applied to the rest of the image's pixels. I first thought that the integration of Weka was doing that but I realized then that it is used to classify annotations based on intensity and shape features, which is a bit different. It would be interesting to perform this kind of analysis because sometime that which give the best result in term of segmentation.; The threshold based approach didn't give me similar result, especially because background and inside of adipocyte have similar intensity.; The main advantage to use it in qpath instead of ImageJ will be to run it on the max resolution to get more precise result. ![image](https://cloud.githubusercontent.com/assets/1775952/23906471/53031de0-08ce-11e7-88ce-d89736289278.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286447290
https://github.com/qupath/qupath/issues/56#issuecomment-286447290:130,Modifiability,plugin,plugin,130,"Thanks for the dedtail answer.; What I wanted to do was more something similar to what Ilastik or the Trainable Weka segmentation plugin for ImageJ offer, meaning you select manually some areas (in my case, I could define 3 classes of pixels, adipocytes, background and others) and after having applied multiple filters (gaussian, hessian etc...), the classifier is generated from my selection and applied to the rest of the image's pixels. I first thought that the integration of Weka was doing that but I realized then that it is used to classify annotations based on intensity and shape features, which is a bit different. It would be interesting to perform this kind of analysis because sometime that which give the best result in term of segmentation.; The threshold based approach didn't give me similar result, especially because background and inside of adipocyte have similar intensity.; The main advantage to use it in qpath instead of ImageJ will be to run it on the max resolution to get more precise result. ![image](https://cloud.githubusercontent.com/assets/1775952/23906471/53031de0-08ce-11e7-88ce-d89736289278.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286447290
https://github.com/qupath/qupath/issues/56#issuecomment-286447290:653,Performance,perform,perform,653,"Thanks for the dedtail answer.; What I wanted to do was more something similar to what Ilastik or the Trainable Weka segmentation plugin for ImageJ offer, meaning you select manually some areas (in my case, I could define 3 classes of pixels, adipocytes, background and others) and after having applied multiple filters (gaussian, hessian etc...), the classifier is generated from my selection and applied to the rest of the image's pixels. I first thought that the integration of Weka was doing that but I realized then that it is used to classify annotations based on intensity and shape features, which is a bit different. It would be interesting to perform this kind of analysis because sometime that which give the best result in term of segmentation.; The threshold based approach didn't give me similar result, especially because background and inside of adipocyte have similar intensity.; The main advantage to use it in qpath instead of ImageJ will be to run it on the max resolution to get more precise result. ![image](https://cloud.githubusercontent.com/assets/1775952/23906471/53031de0-08ce-11e7-88ce-d89736289278.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286447290
https://github.com/qupath/qupath/issues/56#issuecomment-286453790:858,Availability,error,errors,858,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790
https://github.com/qupath/qupath/issues/56#issuecomment-286453790:755,Integrability,depend,depending,755,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790
https://github.com/qupath/qupath/issues/56#issuecomment-286453790:85,Safety,Detect,Detection,85,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790
https://github.com/qupath/qupath/issues/56#issuecomment-286453790:701,Safety,detect,detections,701,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790
https://github.com/qupath/qupath/issues/56#issuecomment-286453790:71,Usability,Simpl,Simple,71,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790
https://github.com/qupath/qupath/issues/56#issuecomment-286559987:110,Modifiability,plugin,plugins,110,"Actually, looking at Ilaskit, I would probably start with trying to run that through QuPath (point the ImageJ plugins directory to the correct place in Preferences). Some modules are not compatible, but if that one is, it would probably be the way to go for segmentation. If it works, just find the largest tiles ImageJ can handle at a time, assuming you can store your training set for QuPath to access on each call.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286559987
https://github.com/qupath/qupath/issues/56#issuecomment-286559987:397,Security,access,access,397,"Actually, looking at Ilaskit, I would probably start with trying to run that through QuPath (point the ImageJ plugins directory to the correct place in Preferences). Some modules are not compatible, but if that one is, it would probably be the way to go for segmentation. If it works, just find the largest tiles ImageJ can handle at a time, assuming you can store your training set for QuPath to access on each call.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286559987
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:704,Availability,Mask,Mask,704,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1634,Integrability,bridg,bridge,1634,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:110,Performance,perform,perform,110,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:491,Performance,perform,perform,491,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1562,Performance,perform,perform,1562,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1700,Performance,perform,perform,1700,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:127,Safety,Detect,Detect,127,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:186,Safety,Detect,Detection,186,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:858,Safety,detect,detection,858,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1389,Safety,avoid,avoid,1389,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1424,Safety,detect,detected,1424,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:2077,Testability,test,test,2077,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:172,Usability,Simpl,Simple,172,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:764,Usability,clear,clear,764,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286702227:818,Usability,Clear,Clear,818,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227
https://github.com/qupath/qupath/issues/56#issuecomment-286849866:696,Availability,Down,Downside,696,"Yes, I did run into some of the same problems with the external measurements since the ImageJ macro runner takes squares, not the actual annotation. The advantage here is QuPath's heriarchy system, where everything ""outside"" of the annotation will show up separately (not underneath in the tree), and can be selected and deleted. Probably easier to do this after you go to the annotations tab, CTRL-A (or whatever to select all) and then go to the Objects menu and ""Merge annotations."" Then you get only one annotation and all of the external detections in the Hierarchy tab. This makes it easy to once again select all, deselect your annotation, and delete all of the ""outside"" detection areas. Downside, merging all of the tiles does NOT actually do what you might hope, and mesh them all into one contiguous annotation. It does add them all together, however, which lets you use the show annotation measurements to see the sum totals of all of your annotation tiles. You will see better after you do it once.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286849866
https://github.com/qupath/qupath/issues/56#issuecomment-286849866:543,Safety,detect,detections,543,"Yes, I did run into some of the same problems with the external measurements since the ImageJ macro runner takes squares, not the actual annotation. The advantage here is QuPath's heriarchy system, where everything ""outside"" of the annotation will show up separately (not underneath in the tree), and can be selected and deleted. Probably easier to do this after you go to the annotations tab, CTRL-A (or whatever to select all) and then go to the Objects menu and ""Merge annotations."" Then you get only one annotation and all of the external detections in the Hierarchy tab. This makes it easy to once again select all, deselect your annotation, and delete all of the ""outside"" detection areas. Downside, merging all of the tiles does NOT actually do what you might hope, and mesh them all into one contiguous annotation. It does add them all together, however, which lets you use the show annotation measurements to see the sum totals of all of your annotation tiles. You will see better after you do it once.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286849866
https://github.com/qupath/qupath/issues/56#issuecomment-286849866:679,Safety,detect,detection,679,"Yes, I did run into some of the same problems with the external measurements since the ImageJ macro runner takes squares, not the actual annotation. The advantage here is QuPath's heriarchy system, where everything ""outside"" of the annotation will show up separately (not underneath in the tree), and can be selected and deleted. Probably easier to do this after you go to the annotations tab, CTRL-A (or whatever to select all) and then go to the Objects menu and ""Merge annotations."" Then you get only one annotation and all of the external detections in the Hierarchy tab. This makes it easy to once again select all, deselect your annotation, and delete all of the ""outside"" detection areas. Downside, merging all of the tiles does NOT actually do what you might hope, and mesh them all into one contiguous annotation. It does add them all together, however, which lets you use the show annotation measurements to see the sum totals of all of your annotation tiles. You will see better after you do it once.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286849866
https://github.com/qupath/qupath/issues/56#issuecomment-286897156:82,Safety,detect,detection,82,"Ooops, I misread part of your question. I do not know of any way to merge the two detection measurements from either side of a square, if you figure it out please let me know!. The best suggestion I can offer there is to make your tile sizes as large as ImageJ can handle on a per-tile basis.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286897156
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3021,Availability,down,downsample,3021,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:716,Deployability,install,installation,716,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:1015,Deployability,install,installation,1015,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3926,Energy Efficiency,efficient,efficient,3926,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:650,Integrability,depend,dependencies,650,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:1099,Integrability,depend,dependencies,1099,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2019,Integrability,depend,depending,2019,"of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2947,Integrability,depend,depends,2947,"t *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficie",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:460,Modifiability,plugin,plugins,460,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:561,Modifiability,plugin,plugins,561,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:631,Modifiability,plugin,plugin,631,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:687,Modifiability,plugin,plugins,687,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:975,Modifiability,plugin,plugins,975,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3096,Modifiability,plugin,plugin,3096,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3070,Performance,perform,performance,3070,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3940,Performance,optimiz,optimized,3940,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:124,Safety,detect,detect,124,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:191,Safety,detect,detection,191,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:1491,Safety,detect,detection,1491,".g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's ofte",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2154,Safety,Detect,Detections,2154,"eka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixel",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3650,Safety,avoid,avoid,3650,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2644,Testability,log,logic,2644," square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:177,Usability,Simpl,Simple,177,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:1477,Usability,Simpl,Simple,1477,".g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's ofte",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2693,Usability,clear,clear,2693,"arr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of sto",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2758,Usability,Undo,Undo,2758,"rms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects ra",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877
https://github.com/qupath/qupath/issues/56#issuecomment-288508331:50,Safety,avoid,avoid,50,"One other thing... I find that the easiest way to avoid detecting outside the annotation is to modify the ImageJ macro, rather than do post-processing in QuPath. You can take advantage of the fact that, for any non-rectangular region, QuPath sends the ROI to ImageJ as well. And so ImageJ's *Edit &rarr; Clear Outside* can help. (In practice, it can be a bit more tricky than that... you might need to complicate your macro with checks to see whether there is a ROI present in the first place, and you might need to use *Edit &rarr; Selection &rarr; Select None* and *Edit &rarr; Selection &rarr; Restore Selection* within your macro if you find that you need to do some processing prior to using *Clear Outside*.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288508331
https://github.com/qupath/qupath/issues/56#issuecomment-288508331:56,Safety,detect,detecting,56,"One other thing... I find that the easiest way to avoid detecting outside the annotation is to modify the ImageJ macro, rather than do post-processing in QuPath. You can take advantage of the fact that, for any non-rectangular region, QuPath sends the ROI to ImageJ as well. And so ImageJ's *Edit &rarr; Clear Outside* can help. (In practice, it can be a bit more tricky than that... you might need to complicate your macro with checks to see whether there is a ROI present in the first place, and you might need to use *Edit &rarr; Selection &rarr; Select None* and *Edit &rarr; Selection &rarr; Restore Selection* within your macro if you find that you need to do some processing prior to using *Clear Outside*.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288508331
https://github.com/qupath/qupath/issues/56#issuecomment-288508331:304,Usability,Clear,Clear,304,"One other thing... I find that the easiest way to avoid detecting outside the annotation is to modify the ImageJ macro, rather than do post-processing in QuPath. You can take advantage of the fact that, for any non-rectangular region, QuPath sends the ROI to ImageJ as well. And so ImageJ's *Edit &rarr; Clear Outside* can help. (In practice, it can be a bit more tricky than that... you might need to complicate your macro with checks to see whether there is a ROI present in the first place, and you might need to use *Edit &rarr; Selection &rarr; Select None* and *Edit &rarr; Selection &rarr; Restore Selection* within your macro if you find that you need to do some processing prior to using *Clear Outside*.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288508331
https://github.com/qupath/qupath/issues/56#issuecomment-288508331:698,Usability,Clear,Clear,698,"One other thing... I find that the easiest way to avoid detecting outside the annotation is to modify the ImageJ macro, rather than do post-processing in QuPath. You can take advantage of the fact that, for any non-rectangular region, QuPath sends the ROI to ImageJ as well. And so ImageJ's *Edit &rarr; Clear Outside* can help. (In practice, it can be a bit more tricky than that... you might need to complicate your macro with checks to see whether there is a ROI present in the first place, and you might need to use *Edit &rarr; Selection &rarr; Select None* and *Edit &rarr; Selection &rarr; Restore Selection* within your macro if you find that you need to do some processing prior to using *Clear Outside*.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288508331
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:430,Availability,down,down,430,"When you save the classifier, QuPath really just saves what it needs to apply the classification - but it doesn't store all the information about where exactly the training information came from. That's why you aren't able to load the classifier again and update it... not enough information has been saved in the ```.qpclassifier``` file to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:256,Deployability,update,update,256,"When you save the classifier, QuPath really just saves what it needs to apply the classification - but it doesn't store all the information about where exactly the training information came from. That's why you aren't able to load the classifier again and update it... not enough information has been saved in the ```.qpclassifier``` file to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:1730,Deployability,update,updated,1730,"ain it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information from the old slide that you are closing and also the new slide that you are opening) or not (i.e. discard all the training information from the slide that was previously open). Again, the ```More...``` button can be useful. You can use it to find out how many objects have been used for training for each image in the project (*Show training object counts*). You can also use this button to apply the current classifier to all images in the project (*Classify project images*). Probably, you would want to train a classifier that works reasonably across all your TMA cores and all your slides, and then apply this across all your slides at the end - to make sure they all have the same classifier applied the sa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:3077,Deployability,update,update,3077,"aining in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information from the old slide that you are closing and also the new slide that you are opening) or not (i.e. discard all the training information from the slide that was previously open). Again, the ```More...``` button can be useful. You can use it to find out how many objects have been used for training for each image in the project (*Show training object counts*). You can also use this button to apply the current classifier to all images in the project (*Classify project images*). Probably, you would want to train a classifier that works reasonably across all your TMA cores and all your slides, and then apply this across all your slides at the end - to make sure they all have the same classifier applied the same way. You can either do this with the *Classify project images* option under ```More...```, by opening each image in turn and loading/running the classifier, or by using a script to automate the process. I hope that helps explain things a bit. I admit that things get a bit more complicated whenever you need to train a classifier across multiple images, and then update it later... but sometimes I also find that it is necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:226,Performance,load,load,226,"When you save the classifier, QuPath really just saves what it needs to apply the classification - but it doesn't store all the information about where exactly the training information came from. That's why you aren't able to load the classifier again and update it... not enough information has been saved in the ```.qpclassifier``` file to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:2839,Performance,load,loading,2839,"aining in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information from the old slide that you are closing and also the new slide that you are opening) or not (i.e. discard all the training information from the slide that was previously open). Again, the ```More...``` button can be useful. You can use it to find out how many objects have been used for training for each image in the project (*Show training object counts*). You can also use this button to apply the current classifier to all images in the project (*Classify project images*). Probably, you would want to train a classifier that works reasonably across all your TMA cores and all your slides, and then apply this across all your slides at the end - to make sure they all have the same classifier applied the same way. You can either do this with the *Classify project images* option under ```More...```, by opening each image in turn and loading/running the classifier, or by using a script to automate the process. I hope that helps explain things a bit. I admit that things get a bit more complicated whenever you need to train a classifier across multiple images, and then update it later... but sometimes I also find that it is necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:672,Safety,detect,detection,672,"When you save the classifier, QuPath really just saves what it needs to apply the classification - but it doesn't store all the information about where exactly the training information came from. That's why you aren't able to load the classifier again and update it... not enough information has been saved in the ```.qpclassifier``` file to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288491139:1335,Safety,detect,detection,1335,"to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information from the old slide that you are closing and also the new slide that you are opening) or not (i.e. discard all the training information from the slide that was previously open). Again, the ```More...``` button can be useful. You can use it to find out how many objects have been used for training for each image in the project (*Show traini",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139
https://github.com/qupath/qupath/issues/57#issuecomment-288756351:983,Safety,detect,detections,983,"Dear Pete, ; Thank you so so much for your quick and detailed answer! I appreciate your help very much!! Too bad there is no direct way to continue training a classifier once it has been saved and closed. I am sure however that your suggested solutions will work fine in my case. Thank you! As for your answer concerning my second question I am unsure how to create a classifier that would work fine for all TMA cores in one slide as the immunecells in core A look very similar to the tumor cells in core B for example (so when I train the classifier it either works for well for core A or B). Also the tumor cells differ a lot in appearance from core to core. I understand that using the same classifier for the entire slide or better all slides in one project would be a more elegant solution but I don´t see how this should work in my case. I understand from your answer to my first question that even if I created a new classifier for each core it would automatically change the detections in another core on the same slide previously made using another classifier....Do you have any suggestions how to address this problem? I should also use this opportunity to point out how well quPath works in general! Great software!; Thank you so much for your help and support!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288756351
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:1468,Availability,avail,available,1468," solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that sho",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:1491,Availability,avail,available,1491," solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that sho",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:3576,Availability,Down,Downsample,3576,"a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally, I think Option 1 is the ‘cleanest’ solution, but may be very time-consuming. All the others would give some kind of data management headache - but maybe it is worth it. Of course, there may also be more creative solutions that I haven’t considered. I would be interested to know what you choose in the end. Good luck!. Pete. PS. Thanks for the positive feedback!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:1755,Deployability,toggle,toggle,1755,"ou could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you c",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:2082,Deployability,toggle,toggle,2082,"t is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:590,Integrability,depend,depend,590,"Hi Liese,. You might be able to directly continue retaining a classifier if you use the *Save training objects* option under the ```More``` button, and then *Load training objects* next time. At least that is what that option is intended for... although I can’t say I have used it very much, so it hasn’t had a lot of testing. Regarding the second question, I feared that this would be the problem when I wrote my reply... I suppose that in the absence of an elegant solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:158,Performance,Load,Load,158,"Hi Liese,. You might be able to directly continue retaining a classifier if you use the *Save training objects* option under the ```More``` button, and then *Load training objects* next time. At least that is what that option is intended for... although I can’t say I have used it very much, so it hasn’t had a lot of testing. Regarding the second question, I feared that this would be the problem when I wrote my reply... I suppose that in the absence of an elegant solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:807,Safety,detect,detect,807,"Hi Liese,. You might be able to directly continue retaining a classifier if you use the *Save training objects* option under the ```More``` button, and then *Load training objects* next time. At least that is what that option is intended for... although I can’t say I have used it very much, so it hasn’t had a lot of testing. Regarding the second question, I feared that this would be the problem when I wrote my reply... I suppose that in the absence of an elegant solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:2403,Safety,detect,detection,2403,"otations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help y",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:2498,Safety,avoid,avoid,2498," new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:3999,Safety,detect,detect,3999,"a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally, I think Option 1 is the ‘cleanest’ solution, but may be very time-consuming. All the others would give some kind of data management headache - but maybe it is worth it. Of course, there may also be more creative solutions that I haven’t considered. I would be interested to know what you choose in the end. Good luck!. Pete. PS. Thanks for the positive feedback!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:4121,Safety,detect,detect,4121,"a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally, I think Option 1 is the ‘cleanest’ solution, but may be very time-consuming. All the others would give some kind of data management headache - but maybe it is worth it. Of course, there may also be more creative solutions that I haven’t considered. I would be interested to know what you choose in the end. Good luck!. Pete. PS. Thanks for the positive feedback!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:318,Testability,test,testing,318,"Hi Liese,. You might be able to directly continue retaining a classifier if you use the *Save training objects* option under the ```More``` button, and then *Load training objects* next time. At least that is what that option is intended for... although I can’t say I have used it very much, so it hasn’t had a lot of testing. Regarding the second question, I feared that this would be the problem when I wrote my reply... I suppose that in the absence of an elegant solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:3065,Usability,simpl,simple,3065,"elected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-288818401:4506,Usability,feedback,feedback,4506,"a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally, I think Option 1 is the ‘cleanest’ solution, but may be very time-consuming. All the others would give some kind of data management headache - but maybe it is worth it. Of course, there may also be more creative solutions that I haven’t considered. I would be interested to know what you choose in the end. Good luck!. Pete. PS. Thanks for the positive feedback!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401
https://github.com/qupath/qupath/issues/57#issuecomment-289248209:4176,Deployability,update,update,4176,"ld2 = 0; // Check what base classifications we should be worried about; // It's possible to specify 'All', or select specific classes and exclude others; def doAll = includeClassesWithName.contains(""All""); def includeClasses = [null]; //def Stroma = PathClassFactory.getPathClass(""Stroma""); def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""); //def DualPos = PathClassFactory.getPathClass(""Dual Positive""); if (!doAll) {; for (String n : includeClassesWithName); includeClasses.add(PathClassFactory.getPathClass(n)); }. // Loop through all detections; for (def pathObject : QP.getDetectionObjects()) {. // Get the base classification; PathClass baseClass = pathObject.getPathClass(); if (baseClass != null); baseClass = baseClass.getBaseClass(); else if (PathClassFactory.isPositiveClass(baseClass) || PathClassFactory.isNegativeClass(baseClass)); // In the event that we have a positive or negative classification that lacks a base class,; // this implies that the base class should be null; baseClass = ""Tumor""; // Apply classification, if required; if (doAll || includeClasses.contains(baseClass)) {. // Check if we have a measurement - if not, assign the base class; double val = pathObject.getMeasurementList().getMeasurementValue(feature); if (Double.isNaN(val)) {; pathObject.setPathClass(baseClass); continue; }; double val2 = pathObject.getMeasurementList().getMeasurementValue(feature2); if (Double.isNaN(val2)) {; pathObject.setPathClass(baseClass); continue; }. // Set positive or negative class; if (val >= threshold ){; pathObject.setPathClass(Positive); }else pathObject.setPathClass(Negative). }. }. // Fire update event; QP.getCurrentHierarchy().fireHierarchyChangedEvent(this). // Make sure we know we're done; println(""Done!""); ```; With as many defined values, thresholds, and if statements as you want, you can basically create your own decision trees. Maybe I should have posted this on the Google group instead :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209
https://github.com/qupath/qupath/issues/57#issuecomment-289248209:269,Performance,perform,perform,269,"I was looking into this, and ways to classify multiple sets of cells within an image, and found one way that may or may not be useful here.; Massive disclaimer, this does not work for using the ""Create Detection Classifier,"" but does work for the script Peter wrote to perform classifications based on features. I'll add a copy in at the end. 1. Create an annotation around the cells you want to generate in a certain way (sometimes I want to create larger cells for muscles vs smaller for other tissues), then generate your cells for each annotation.; 2. This step could use a short script from Peter (select all cells within a certain annotation class), but if you select a given subset of cells by picking one annotation (usually easy enough by clicking on that annotation in the hierarchy and shift+clicking) you can then add a dummy measurement to those cells using settings in the Compute Intensity Features (or a script, probably) that you do not need for classification. In my case I chose Hue-Mean.; 3. Include Hue-Mean in your classification script as a measurement it checks for the presence of, and if not found, the classifier does not even try to classify those cells. I tested this by adding Hue-Mean, Saturation-Min, and Saturation-Max to three different sets of cells, and was able to run 3 different classifiers on all of my cells, and only have the correct cells (the ones with the dummy measurement) receive the results of the correct classification.; I'm sure this is somewhat complicated by the TMAs and dealing with multiple cores, and I haven't had a chance to figure out how to make that work since you can't draw an annotation to include multiple TMA cores, but maybe this could prove useful as a stepping stone for running multiple classifiers within a TMA. Here is the code for the dummy Hue-Mean classifier (specifically run at 0.50 µm). I have muddled around in the code here, and I think this is working because I never create a ""def"" for my ""baseClass"" of ""Tumor."" Ther",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209
https://github.com/qupath/qupath/issues/57#issuecomment-289248209:202,Safety,Detect,Detection,202,"I was looking into this, and ways to classify multiple sets of cells within an image, and found one way that may or may not be useful here.; Massive disclaimer, this does not work for using the ""Create Detection Classifier,"" but does work for the script Peter wrote to perform classifications based on features. I'll add a copy in at the end. 1. Create an annotation around the cells you want to generate in a certain way (sometimes I want to create larger cells for muscles vs smaller for other tissues), then generate your cells for each annotation.; 2. This step could use a short script from Peter (select all cells within a certain annotation class), but if you select a given subset of cells by picking one annotation (usually easy enough by clicking on that annotation in the hierarchy and shift+clicking) you can then add a dummy measurement to those cells using settings in the Compute Intensity Features (or a script, probably) that you do not need for classification. In my case I chose Hue-Mean.; 3. Include Hue-Mean in your classification script as a measurement it checks for the presence of, and if not found, the classifier does not even try to classify those cells. I tested this by adding Hue-Mean, Saturation-Min, and Saturation-Max to three different sets of cells, and was able to run 3 different classifiers on all of my cells, and only have the correct cells (the ones with the dummy measurement) receive the results of the correct classification.; I'm sure this is somewhat complicated by the TMAs and dealing with multiple cores, and I haven't had a chance to figure out how to make that work since you can't draw an annotation to include multiple TMA cores, but maybe this could prove useful as a stepping stone for running multiple classifiers within a TMA. Here is the code for the dummy Hue-Mean classifier (specifically run at 0.50 µm). I have muddled around in the code here, and I think this is working because I never create a ""def"" for my ""baseClass"" of ""Tumor."" Ther",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209
https://github.com/qupath/qupath/issues/57#issuecomment-289248209:3092,Safety,detect,detections,3092,"de until it does what I want. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory; import qupath.lib.scripting.QP. // Parameters to modify; List<String> includeClassesWithName = [""Tumor"", ""Stroma""] as List<String>; def feature = ""Nucleus: DAB OD mean""; def threshold = 0.1; def feature2 = ""ROI: 0.50 µm per pixel: Hue: Mean""; //def threshold2 = 0; // Check what base classifications we should be worried about; // It's possible to specify 'All', or select specific classes and exclude others; def doAll = includeClassesWithName.contains(""All""); def includeClasses = [null]; //def Stroma = PathClassFactory.getPathClass(""Stroma""); def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""); //def DualPos = PathClassFactory.getPathClass(""Dual Positive""); if (!doAll) {; for (String n : includeClassesWithName); includeClasses.add(PathClassFactory.getPathClass(n)); }. // Loop through all detections; for (def pathObject : QP.getDetectionObjects()) {. // Get the base classification; PathClass baseClass = pathObject.getPathClass(); if (baseClass != null); baseClass = baseClass.getBaseClass(); else if (PathClassFactory.isPositiveClass(baseClass) || PathClassFactory.isNegativeClass(baseClass)); // In the event that we have a positive or negative classification that lacks a base class,; // this implies that the base class should be null; baseClass = ""Tumor""; // Apply classification, if required; if (doAll || includeClasses.contains(baseClass)) {. // Check if we have a measurement - if not, assign the base class; double val = pathObject.getMeasurementList().getMeasurementValue(feature); if (Double.isNaN(val)) {; pathObject.setPathClass(baseClass); continue; }; double val2 = pathObject.getMeasurementList().getMeasurementValue(feature2); if (Double.isNaN(val2)) {; pathObject.setPathClass(baseClass); continue; }. // Set positive or negative class; if (val >= threshold ){; pathObject.set",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209
https://github.com/qupath/qupath/issues/57#issuecomment-289248209:1185,Testability,test,tested,1185,"y in at the end. 1. Create an annotation around the cells you want to generate in a certain way (sometimes I want to create larger cells for muscles vs smaller for other tissues), then generate your cells for each annotation.; 2. This step could use a short script from Peter (select all cells within a certain annotation class), but if you select a given subset of cells by picking one annotation (usually easy enough by clicking on that annotation in the hierarchy and shift+clicking) you can then add a dummy measurement to those cells using settings in the Compute Intensity Features (or a script, probably) that you do not need for classification. In my case I chose Hue-Mean.; 3. Include Hue-Mean in your classification script as a measurement it checks for the presence of, and if not found, the classifier does not even try to classify those cells. I tested this by adding Hue-Mean, Saturation-Min, and Saturation-Max to three different sets of cells, and was able to run 3 different classifiers on all of my cells, and only have the correct cells (the ones with the dummy measurement) receive the results of the correct classification.; I'm sure this is somewhat complicated by the TMAs and dealing with multiple cores, and I haven't had a chance to figure out how to make that work since you can't draw an annotation to include multiple TMA cores, but maybe this could prove useful as a stepping stone for running multiple classifiers within a TMA. Here is the code for the dummy Hue-Mean classifier (specifically run at 0.50 µm). I have muddled around in the code here, and I think this is working because I never create a ""def"" for my ""baseClass"" of ""Tumor."" There is almost certainly a more elegant way of doing this instead of my hacking and slashing at the code until it does what I want. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory; import qupath.lib.scripting.QP. // Parameters to modify; List<String> includeClassesWithName =",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209
https://github.com/qupath/qupath/issues/57#issuecomment-289249459:478,Availability,Down,Downside,478,"Another possibility for TMAs might be something like ; ```; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; fireHierarchyUpdate(); ```; in order to name all cells after their parent TMA core (assuming no other annotations have been drawn at this point). . At that point, there could be a list of TMA cores you wanted to apply that particular classifier to which the script checks before applying the current classification steps. ; Downside: you would have to create both the list and each classifier. ; Upside: you would have complete control over the classifier and once created it would be easy to apply across many TMAs. PS. It might be more streamlined to check the parent annotation name within the classifier script against the list, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289249459
https://github.com/qupath/qupath/issues/57#issuecomment-289249459:88,Safety,detect,detection,88,"Another possibility for TMAs might be something like ; ```; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; fireHierarchyUpdate(); ```; in order to name all cells after their parent TMA core (assuming no other annotations have been drawn at this point). . At that point, there could be a list of TMA cores you wanted to apply that particular classifier to which the script checks before applying the current classification steps. ; Downside: you would have to create both the list and each classifier. ; Upside: you would have complete control over the classifier and once created it would be easy to apply across many TMAs. PS. It might be more streamlined to check the parent annotation name within the classifier script against the list, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289249459
https://github.com/qupath/qupath/issues/57#issuecomment-289249459:101,Safety,detect,detection,101,"Another possibility for TMAs might be something like ; ```; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; fireHierarchyUpdate(); ```; in order to name all cells after their parent TMA core (assuming no other annotations have been drawn at this point). . At that point, there could be a list of TMA cores you wanted to apply that particular classifier to which the script checks before applying the current classification steps. ; Downside: you would have to create both the list and each classifier. ; Upside: you would have complete control over the classifier and once created it would be easy to apply across many TMAs. PS. It might be more streamlined to check the parent annotation name within the classifier script against the list, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289249459
https://github.com/qupath/qupath/issues/57#issuecomment-289249459:119,Safety,detect,detection,119,"Another possibility for TMAs might be something like ; ```; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; fireHierarchyUpdate(); ```; in order to name all cells after their parent TMA core (assuming no other annotations have been drawn at this point). . At that point, there could be a list of TMA cores you wanted to apply that particular classifier to which the script checks before applying the current classification steps. ; Downside: you would have to create both the list and each classifier. ; Upside: you would have complete control over the classifier and once created it would be easy to apply across many TMAs. PS. It might be more streamlined to check the parent annotation name within the classifier script against the list, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289249459
https://github.com/qupath/qupath/issues/57#issuecomment-1808333179:145,Safety,detect,detection,145,"Hello Dear Pete, . First of all, thanks for this great program. You must be genius. Second of all, does ""Click on Advanced options in the Create detection classifier window and select the More... button on the right. If you choose Rebuild training from project QuPath will then loop through all the images in the project and use any annotations it finds to train the new classifier."" still work? I couldn´t really find these create detection classifier window, more or advance selections.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-1808333179
https://github.com/qupath/qupath/issues/57#issuecomment-1808333179:432,Safety,detect,detection,432,"Hello Dear Pete, . First of all, thanks for this great program. You must be genius. Second of all, does ""Click on Advanced options in the Create detection classifier window and select the More... button on the right. If you choose Rebuild training from project QuPath will then loop through all the images in the project and use any annotations it finds to train the new classifier."" still work? I couldn´t really find these create detection classifier window, more or advance selections.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-1808333179
https://github.com/qupath/qupath/issues/58#issuecomment-289494801:719,Availability,error,error,719,"I'm afraid it looks like the ```.qpdata``` file is incomplete for some reason, effectively making the data corrupt/unreadable for QuPath. See [this thread](https://groups.google.com/forum/#!topic/qupath-users/sYzchFq-Y60) for some more information - and for some details about ```.backup``` files, which might (possibly) be able to help. This appears to happen very rarely, and I don't know why (since I don't recall the last time it happened to me). Do you happen to remember did anything strange happen / did QuPath crash when saving the data the first time around? Or can you figure out any way to reproduce the problem?. It's particularly hard to debug, since I presume that the problem happens when saving but the error log only shows what happens when trying to reload the data. I haven't found a way to reproduce it myself, so any insights you could have on what could have caused it would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/58#issuecomment-289494801
https://github.com/qupath/qupath/issues/58#issuecomment-289494801:725,Testability,log,log,725,"I'm afraid it looks like the ```.qpdata``` file is incomplete for some reason, effectively making the data corrupt/unreadable for QuPath. See [this thread](https://groups.google.com/forum/#!topic/qupath-users/sYzchFq-Y60) for some more information - and for some details about ```.backup``` files, which might (possibly) be able to help. This appears to happen very rarely, and I don't know why (since I don't recall the last time it happened to me). Do you happen to remember did anything strange happen / did QuPath crash when saving the data the first time around? Or can you figure out any way to reproduce the problem?. It's particularly hard to debug, since I presume that the problem happens when saving but the error log only shows what happens when trying to reload the data. I haven't found a way to reproduce it myself, so any insights you could have on what could have caused it would be very welcome.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/58#issuecomment-289494801
https://github.com/qupath/qupath/issues/59#issuecomment-289487421:100,Safety,detect,detections,100,"If you are referring to the core, that should be part of the ""Name"" column, or first column, in the detections measurements list (my first entry shows up as A-12 - Negative). If you want to apply the name of the TMA, you would have to do that when you import the other TMA patient data, I think.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289487421
https://github.com/qupath/qupath/issues/59#issuecomment-289505578:126,Safety,Detect,Detection,126,That is true for the TMA core export and my Tissue annotation but not for the txt output for all cells.; I'm referring to the Detection measurements for every core = single cells. Under the Name column it only says PathCellObject.; I've completed the cell analysis again and this is still the case.; Any suggestions appreciated.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289505578
https://github.com/qupath/qupath/issues/59#issuecomment-289508349:307,Safety,detect,detection,307,"Hmm, interesting. We are getting different behavior or choosing a different step order. I am not sure I could get it to do that. Are you using version 0.1.2? And what OS (I don't think it should matter, but maybe Peter will know better)?. After running the dearrayer then selecting a core/cores to run cell detection, I see the following for cell by cell data.; ![tma names](https://cloud.githubusercontent.com/assets/23145209/24367053/12f1cd4e-12d0-11e7-8fc0-dabcda42d2cd.JPG)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289508349
https://github.com/qupath/qupath/issues/59#issuecomment-289512650:12,Testability,log,logging,12,"Ah... I was logging on to give the same answer as above, but @Svidro beat me to it. But I see that the 'Name' column doesn't contain the TMA core if the cells are inside an annotation rather than directly inside the TMA core - which is the source of the problem, right?. I agree it would probably be useful to have the core always shown in the table, but in the absence of that you could use a simple script to repurpose the 'name' property for all your cells - setting it explicitly to be the same name as the core containing the cells. That way it still appears in the table. @Svidro already gave some of the code to do that [here](https://github.com/qupath/qupath/issues/57#issuecomment-289249459).; In your case, you might need to replace ```getParent()``` with ```getParent().getParent()```... to get the name of the object two levels up in the hierarchy rather than one - but the idea is the same. In the event that you might have annotations inside annotations, then doing it that way would get a bit complicated since sometimes you might need to go up three levels... or four levels.; In that case, a simpler script would involve looping through all the TMA cores, and naming the cells inside them. Does that sound like it would solve the problem, or have I misunderstood?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289512650
https://github.com/qupath/qupath/issues/59#issuecomment-289512650:394,Usability,simpl,simple,394,"Ah... I was logging on to give the same answer as above, but @Svidro beat me to it. But I see that the 'Name' column doesn't contain the TMA core if the cells are inside an annotation rather than directly inside the TMA core - which is the source of the problem, right?. I agree it would probably be useful to have the core always shown in the table, but in the absence of that you could use a simple script to repurpose the 'name' property for all your cells - setting it explicitly to be the same name as the core containing the cells. That way it still appears in the table. @Svidro already gave some of the code to do that [here](https://github.com/qupath/qupath/issues/57#issuecomment-289249459).; In your case, you might need to replace ```getParent()``` with ```getParent().getParent()```... to get the name of the object two levels up in the hierarchy rather than one - but the idea is the same. In the event that you might have annotations inside annotations, then doing it that way would get a bit complicated since sometimes you might need to go up three levels... or four levels.; In that case, a simpler script would involve looping through all the TMA cores, and naming the cells inside them. Does that sound like it would solve the problem, or have I misunderstood?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289512650
https://github.com/qupath/qupath/issues/59#issuecomment-289512650:1109,Usability,simpl,simpler,1109,"Ah... I was logging on to give the same answer as above, but @Svidro beat me to it. But I see that the 'Name' column doesn't contain the TMA core if the cells are inside an annotation rather than directly inside the TMA core - which is the source of the problem, right?. I agree it would probably be useful to have the core always shown in the table, but in the absence of that you could use a simple script to repurpose the 'name' property for all your cells - setting it explicitly to be the same name as the core containing the cells. That way it still appears in the table. @Svidro already gave some of the code to do that [here](https://github.com/qupath/qupath/issues/57#issuecomment-289249459).; In your case, you might need to replace ```getParent()``` with ```getParent().getParent()```... to get the name of the object two levels up in the hierarchy rather than one - but the idea is the same. In the event that you might have annotations inside annotations, then doing it that way would get a bit complicated since sometimes you might need to go up three levels... or four levels.; In that case, a simpler script would involve looping through all the TMA cores, and naming the cells inside them. Does that sound like it would solve the problem, or have I misunderstood?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289512650
https://github.com/qupath/qupath/issues/59#issuecomment-289513743:116,Availability,down,down,116,"Sounds like that could work. I will play with the script and will also try running the cell analysis only one level down. It appears that Qupath currently applies the TMA name one level down but maybe not two.; Within my TMA cores, I run the tissue identification and then run the cell and membrane analysis within the annotated areas. Under Name the core identifier is present for the annotated tissue but not for the cells inside the annotated tissue.; Thanks, I'll get back to you tomorrow.; H",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289513743
https://github.com/qupath/qupath/issues/59#issuecomment-289513743:186,Availability,down,down,186,"Sounds like that could work. I will play with the script and will also try running the cell analysis only one level down. It appears that Qupath currently applies the TMA name one level down but maybe not two.; Within my TMA cores, I run the tissue identification and then run the cell and membrane analysis within the annotated areas. Under Name the core identifier is present for the annotated tissue but not for the cells inside the annotated tissue.; Thanks, I'll get back to you tomorrow.; H",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289513743
https://github.com/qupath/qupath/issues/59#issuecomment-289537633:154,Safety,detect,detection,154,"Ah, I was just thinking that, but stuck in lab meeting!; Yes, I tend to calculate my tissue areas after the fact in R rather than using the simple tissue detection, so when I saw that line in your script, I figured that might be what was happening. Good luck!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289537633
https://github.com/qupath/qupath/issues/59#issuecomment-289537633:140,Usability,simpl,simple,140,"Ah, I was just thinking that, but stuck in lab meeting!; Yes, I tend to calculate my tissue areas after the fact in R rather than using the simple tissue detection, so when I saw that line in your script, I figured that might be what was happening. Good luck!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289537633
https://github.com/qupath/qupath/issues/59#issuecomment-289692872:280,Modifiability,enhance,enhancement,280,"Yes - If I run the cell detection within each core (instead of within the annotation) then the core name is in the txt export. Thanks.; There are a couple of reasons that I would want to know which single cells are within my annotations, so the hierarchy export would be a useful enhancement in the future. ; Overall, great work!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289692872
https://github.com/qupath/qupath/issues/59#issuecomment-289692872:24,Safety,detect,detection,24,"Yes - If I run the cell detection within each core (instead of within the annotation) then the core name is in the txt export. Thanks.; There are a couple of reasons that I would want to know which single cells are within my annotations, so the hierarchy export would be a useful enhancement in the future. ; Overall, great work!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289692872
https://github.com/qupath/qupath/issues/59#issuecomment-290309875:109,Safety,detect,detection,109,"I'm not sure what you mean by 'hierarchy export'?; I think it would probably be good to have a column in the detection table giving the name of the TMA core containing the detection. A column to add the immediate 'parent' object could also be helpful. I suspect that trying to put more information concerning the hierarchy into the table could be confusing (since some detections might be at lower levels in the hierarchy than others), but I'll give it some thought. I suspect @Svidro is much more familiar with R than I am, but if you are happy with R then I would suggest trying out some scripting in QuPath with Groovy. There is a bit of documentation in the Wiki (starting [here](https://github.com/qupath/qupath/wiki/Writing-custom-scripts)). It may take a little while to become familiar with QuPath's data structures, but I think Groovy has quite a nice syntax and [IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) can help considerably. With even a little bit of scripting, you are no longer limited by the tables QuPath gives, but you can export your data any way you like... for use in R or elsewhere.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290309875
https://github.com/qupath/qupath/issues/59#issuecomment-290309875:172,Safety,detect,detection,172,"I'm not sure what you mean by 'hierarchy export'?; I think it would probably be good to have a column in the detection table giving the name of the TMA core containing the detection. A column to add the immediate 'parent' object could also be helpful. I suspect that trying to put more information concerning the hierarchy into the table could be confusing (since some detections might be at lower levels in the hierarchy than others), but I'll give it some thought. I suspect @Svidro is much more familiar with R than I am, but if you are happy with R then I would suggest trying out some scripting in QuPath with Groovy. There is a bit of documentation in the Wiki (starting [here](https://github.com/qupath/qupath/wiki/Writing-custom-scripts)). It may take a little while to become familiar with QuPath's data structures, but I think Groovy has quite a nice syntax and [IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) can help considerably. With even a little bit of scripting, you are no longer limited by the tables QuPath gives, but you can export your data any way you like... for use in R or elsewhere.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290309875
https://github.com/qupath/qupath/issues/59#issuecomment-290309875:369,Safety,detect,detections,369,"I'm not sure what you mean by 'hierarchy export'?; I think it would probably be good to have a column in the detection table giving the name of the TMA core containing the detection. A column to add the immediate 'parent' object could also be helpful. I suspect that trying to put more information concerning the hierarchy into the table could be confusing (since some detections might be at lower levels in the hierarchy than others), but I'll give it some thought. I suspect @Svidro is much more familiar with R than I am, but if you are happy with R then I would suggest trying out some scripting in QuPath with Groovy. There is a bit of documentation in the Wiki (starting [here](https://github.com/qupath/qupath/wiki/Writing-custom-scripts)). It may take a little while to become familiar with QuPath's data structures, but I think Groovy has quite a nice syntax and [IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) can help considerably. With even a little bit of scripting, you are no longer limited by the tables QuPath gives, but you can export your data any way you like... for use in R or elsewhere.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290309875
https://github.com/qupath/qupath/issues/59#issuecomment-290314163:461,Safety,Detect,Detections,461,"Oops, I somehow missed the followup question. I don't use any particular packages just to calculate areas, it's pretty much just a use of the base sum function. I'm certain there are more elegant ways to do this using functions, but I only have basic programming experience so for loops it is!; ```; path = ""Your file path here""; setwd(path); outFile <-""test areas.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; file.names <- dir(path,pattern = "".txt""). #an empty frame to place data into; Areas <- data.frame(). #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(file.names)){; data.raw <- read_delim(file.names[i],""\t"", escape_double = FALSE, trim_ws = TRUE). #place the file names in the first column; Sample = tools::file_path_sans_ext(file.names[i]); Areas[i,1]<-Sample. #Sum of cell areas here. Add extra lines for mean of intensity/OD, etc; Areas[i,2]<-sum(data.raw$""Cell: Area""). }; Areas$""Area mm^2""<- Areas$V2/1000000. #set row names to F if you don't want a numbered list as the first column; write.csv(Areas, outFile, row.names=T); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290314163
https://github.com/qupath/qupath/issues/59#issuecomment-290314163:354,Testability,test,test,354,"Oops, I somehow missed the followup question. I don't use any particular packages just to calculate areas, it's pretty much just a use of the base sum function. I'm certain there are more elegant ways to do this using functions, but I only have basic programming experience so for loops it is!; ```; path = ""Your file path here""; setwd(path); outFile <-""test areas.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; file.names <- dir(path,pattern = "".txt""). #an empty frame to place data into; Areas <- data.frame(). #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(file.names)){; data.raw <- read_delim(file.names[i],""\t"", escape_double = FALSE, trim_ws = TRUE). #place the file names in the first column; Sample = tools::file_path_sans_ext(file.names[i]); Areas[i,1]<-Sample. #Sum of cell areas here. Add extra lines for mean of intensity/OD, etc; Areas[i,2]<-sum(data.raw$""Cell: Area""). }; Areas$""Area mm^2""<- Areas$V2/1000000. #set row names to F if you don't want a numbered list as the first column; write.csv(Areas, outFile, row.names=T); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290314163
https://github.com/qupath/qupath/issues/59#issuecomment-290314163:609,Usability,simpl,simple,609,"Oops, I somehow missed the followup question. I don't use any particular packages just to calculate areas, it's pretty much just a use of the base sum function. I'm certain there are more elegant ways to do this using functions, but I only have basic programming experience so for loops it is!; ```; path = ""Your file path here""; setwd(path); outFile <-""test areas.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; file.names <- dir(path,pattern = "".txt""). #an empty frame to place data into; Areas <- data.frame(). #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(file.names)){; data.raw <- read_delim(file.names[i],""\t"", escape_double = FALSE, trim_ws = TRUE). #place the file names in the first column; Sample = tools::file_path_sans_ext(file.names[i]); Areas[i,1]<-Sample. #Sum of cell areas here. Add extra lines for mean of intensity/OD, etc; Areas[i,2]<-sum(data.raw$""Cell: Area""). }; Areas$""Area mm^2""<- Areas$V2/1000000. #set row names to F if you don't want a numbered list as the first column; write.csv(Areas, outFile, row.names=T); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290314163
https://github.com/qupath/qupath/issues/59#issuecomment-518574610:36,Safety,detect,detection,36,The TMA core is now included in the detection table in QuPath v0.2.0-m3 (and likely earlier milestones...).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-518574610
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:80,Safety,detect,detection,80,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:292,Safety,predict,predictable,292,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:715,Safety,detect,detecting,715,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:953,Safety,detect,detections,953,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:1014,Safety,detect,detect,1014,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/60#issuecomment-290307913:651,Testability,test,test,651,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913
https://github.com/qupath/qupath/issues/61#issuecomment-290912225:2456,Availability,avail,available,2456,".com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/roi/PolygonROI.java) for polygons. The most useful constructor is:; ```groovy; public PolygonROI(float[] x, float[] y, int c, int z, int t); ```; For ```c```, ```z``` and ```t``` (channel, z-slide & time point) you can probably use ```-1```, ```0```, ```0``` by default. . After creating your polygon ROI, then create a [```PathAnnotationObject```](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java) with the ROI:; ```groovy; public PathAnnotationObject(ROI pathROI); ```. and finally you can add this annotation to the hierarchy simply with; ```groovy; addObject(annotation); ```. I have some memory of Aperio ImageScope having a concept of layers, and also 'negative' regions; I don't know if this would also be in your XML. If so, these may not have exact matches inside QuPath, but there are various tricks you could use if you find they are needed (e.g. combining or subtracting ROIs, adding them to the hierarchy in different ways, setting names, classifications or colors etc.). If you haven't already, I suggest checking out the Wiki for [Writing custom scripts](https://github.com/qupath/qupath/wiki/Writing-custom-scripts) and [Advanced scripting with IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ), which can help with writing the code and accessing the QuPath source. Finally, it may also be useful to know that, if you want to use any other Java libraries to help, then you can drag the required Jar file onto QuPath to copy it into QuPath's extensions directory. Even if the Jar isn't a 'real' QuPath extension, this means that it will still be available on QuPath's classpath when running the script. This could be useful if your XML parsing code is already contained in a Jar, or if you want to add another library (e.g. ```groovy-xml.jar```) to help with scripting the parsing. Hopefully that helps to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-290912225
https://github.com/qupath/qupath/issues/61#issuecomment-290912225:1504,Modifiability,layers,layers,1504,"ROIs is [here](https://github.com/qupath/qupath/tree/master/qupath-core/src/main/java/qupath/lib/roi) - so you could create rectangles, ellipses or lines if required, or just stick with [PolygonROI](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/roi/PolygonROI.java) for polygons. The most useful constructor is:; ```groovy; public PolygonROI(float[] x, float[] y, int c, int z, int t); ```; For ```c```, ```z``` and ```t``` (channel, z-slide & time point) you can probably use ```-1```, ```0```, ```0``` by default. . After creating your polygon ROI, then create a [```PathAnnotationObject```](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java) with the ROI:; ```groovy; public PathAnnotationObject(ROI pathROI); ```. and finally you can add this annotation to the hierarchy simply with; ```groovy; addObject(annotation); ```. I have some memory of Aperio ImageScope having a concept of layers, and also 'negative' regions; I don't know if this would also be in your XML. If so, these may not have exact matches inside QuPath, but there are various tricks you could use if you find they are needed (e.g. combining or subtracting ROIs, adding them to the hierarchy in different ways, setting names, classifications or colors etc.). If you haven't already, I suggest checking out the Wiki for [Writing custom scripts](https://github.com/qupath/qupath/wiki/Writing-custom-scripts) and [Advanced scripting with IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ), which can help with writing the code and accessing the QuPath source. Finally, it may also be useful to know that, if you want to use any other Java libraries to help, then you can drag the required Jar file onto QuPath to copy it into QuPath's extensions directory. Even if the Jar isn't a 'real' QuPath extension, this means that it will still be available on QuPath's classpath when running the script. Thi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-290912225
https://github.com/qupath/qupath/issues/61#issuecomment-290912225:2148,Security,access,accessing,2148,".com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/roi/PolygonROI.java) for polygons. The most useful constructor is:; ```groovy; public PolygonROI(float[] x, float[] y, int c, int z, int t); ```; For ```c```, ```z``` and ```t``` (channel, z-slide & time point) you can probably use ```-1```, ```0```, ```0``` by default. . After creating your polygon ROI, then create a [```PathAnnotationObject```](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java) with the ROI:; ```groovy; public PathAnnotationObject(ROI pathROI); ```. and finally you can add this annotation to the hierarchy simply with; ```groovy; addObject(annotation); ```. I have some memory of Aperio ImageScope having a concept of layers, and also 'negative' regions; I don't know if this would also be in your XML. If so, these may not have exact matches inside QuPath, but there are various tricks you could use if you find they are needed (e.g. combining or subtracting ROIs, adding them to the hierarchy in different ways, setting names, classifications or colors etc.). If you haven't already, I suggest checking out the Wiki for [Writing custom scripts](https://github.com/qupath/qupath/wiki/Writing-custom-scripts) and [Advanced scripting with IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ), which can help with writing the code and accessing the QuPath source. Finally, it may also be useful to know that, if you want to use any other Java libraries to help, then you can drag the required Jar file onto QuPath to copy it into QuPath's extensions directory. Even if the Jar isn't a 'real' QuPath extension, this means that it will still be available on QuPath's classpath when running the script. This could be useful if your XML parsing code is already contained in a Jar, or if you want to add another library (e.g. ```groovy-xml.jar```) to help with scripting the parsing. Hopefully that helps to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-290912225
https://github.com/qupath/qupath/issues/61#issuecomment-290912225:1392,Usability,simpl,simply,1392,"exported coordinates; * Create an annotation for the ROI; * Add the annotation to the object hierarchy. Most code for specific ROIs is [here](https://github.com/qupath/qupath/tree/master/qupath-core/src/main/java/qupath/lib/roi) - so you could create rectangles, ellipses or lines if required, or just stick with [PolygonROI](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/roi/PolygonROI.java) for polygons. The most useful constructor is:; ```groovy; public PolygonROI(float[] x, float[] y, int c, int z, int t); ```; For ```c```, ```z``` and ```t``` (channel, z-slide & time point) you can probably use ```-1```, ```0```, ```0``` by default. . After creating your polygon ROI, then create a [```PathAnnotationObject```](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java) with the ROI:; ```groovy; public PathAnnotationObject(ROI pathROI); ```. and finally you can add this annotation to the hierarchy simply with; ```groovy; addObject(annotation); ```. I have some memory of Aperio ImageScope having a concept of layers, and also 'negative' regions; I don't know if this would also be in your XML. If so, these may not have exact matches inside QuPath, but there are various tricks you could use if you find they are needed (e.g. combining or subtracting ROIs, adding them to the hierarchy in different ways, setting names, classifications or colors etc.). If you haven't already, I suggest checking out the Wiki for [Writing custom scripts](https://github.com/qupath/qupath/wiki/Writing-custom-scripts) and [Advanced scripting with IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ), which can help with writing the code and accessing the QuPath source. Finally, it may also be useful to know that, if you want to use any other Java libraries to help, then you can drag the required Jar file onto QuPath to copy it into QuPath's extensions directory. Even if the Jar",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-290912225
https://github.com/qupath/qupath/issues/61#issuecomment-1206076109:202,Modifiability,layers,layers,202,"> We have a lot of annotations previously done using Aperio ScanScope which generates the XML files. We already have code that can parse those files and eliminate the boundaries for the various objects/layers....; > ; > We'd like to be able to compare analysis results done using QuPath with those we previously did in ScanScope, without having to redraw the annotations ...; > ; > If we had the boundaries of the shapes (lets just assume polygons for general use case), would it be possible to somehow import them and create an annotation layer we could use for analysis?. Hey @dgutman can you share the code on how to parse those XML files for annotations, actually I have an XML file for the .scn digital histopathology image and one of those XML files has 4 vertices for a region while another XML file has 2 vertices for a region and I am baffled on how to work with them,; It would be of great help if you could please share the code for parsing the image scope anootation.xml file, they need to be converted into MS COCO .json format with bounding boxes, so if you have conversion code too, that would be super helpful.; Thanking you in advance,; Warm regards,; Harshit",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-1206076109
https://github.com/qupath/qupath/issues/62#issuecomment-293101449:218,Safety,detect,detections,218,"You should get null for any tiles or annotations with no class set, and Tumor, or whatever class is set for any annotations with a set class. If the tiles do not have a class, they will return null. . If the tiles are detections, and have a parent annotation with a class name, you should be able to use something like for all detections, p= detection.getParent() followed by p.getPathClass() being assigned to a value in order to find out what the parent annotation's class was. I am not sure this works if you have converted all of the tiles to annotations (maybe it does!).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293101449
https://github.com/qupath/qupath/issues/62#issuecomment-293101449:327,Safety,detect,detections,327,"You should get null for any tiles or annotations with no class set, and Tumor, or whatever class is set for any annotations with a set class. If the tiles do not have a class, they will return null. . If the tiles are detections, and have a parent annotation with a class name, you should be able to use something like for all detections, p= detection.getParent() followed by p.getPathClass() being assigned to a value in order to find out what the parent annotation's class was. I am not sure this works if you have converted all of the tiles to annotations (maybe it does!).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293101449
https://github.com/qupath/qupath/issues/62#issuecomment-293101449:342,Safety,detect,detection,342,"You should get null for any tiles or annotations with no class set, and Tumor, or whatever class is set for any annotations with a set class. If the tiles do not have a class, they will return null. . If the tiles are detections, and have a parent annotation with a class name, you should be able to use something like for all detections, p= detection.getParent() followed by p.getPathClass() being assigned to a value in order to find out what the parent annotation's class was. I am not sure this works if you have converted all of the tiles to annotations (maybe it does!).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293101449
https://github.com/qupath/qupath/issues/62#issuecomment-293105049:64,Deployability,update,update,64,"Thanks Svidro, the getParent() idea seems to be working. I will update this thread with the full script once I have tile export working.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293105049
https://github.com/qupath/qupath/issues/62#issuecomment-293124108:97,Safety,detect,detections,97,"It seems like the easiest way to resolve the minor issue would be swapping the for loop/tiles to detections, if that works with the imagewritertools.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293124108
https://github.com/qupath/qupath/issues/63#issuecomment-293362848:337,Safety,Detect,Detections,337,"It sounds like maybe you used *Create tiles* or one of the superpixel commands?. If so, these don't produce any features/measurements by default, as required by the classifier. You can add some by running *Analyze &rarr; Calculate features &rarr; Add intensity features*.; But be warned... you generally need to choose the *Process all: Detections* option after you press *Run*. Otherwise the features might be calculated for something else (e.g. the annotation containing your tiles/superpixels... but not the tiles/superpixels themselves).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293362848
https://github.com/qupath/qupath/issues/63#issuecomment-293362863:98,Integrability,message,message,98,Have you clicked on the Select... button or Use All to the right side of the no features selected message? You will need cells or some kinds of detections to already exist in that image in order to populate the list.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293362863
https://github.com/qupath/qupath/issues/63#issuecomment-293362863:144,Safety,detect,detections,144,Have you clicked on the Select... button or Use All to the right side of the no features selected message? You will need cells or some kinds of detections to already exist in that image in order to populate the list.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293362863
https://github.com/qupath/qupath/issues/63#issuecomment-293365471:67,Safety,detect,detection,67,"Ok, looks like by first applying ""Analyze -> Cell analysis -> Cell detection"" I was able to generate features for Classification. Using ""Analyze -> Calculate features -> Add intensity features (experimental)"" did not provide features. Thanks a lot!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293365471
https://github.com/qupath/qupath/issues/63#issuecomment-293368367:38,Integrability,depend,depending,38,"The latter will only provide features depending on what boxes are checked, and only for the detections you choose (cells, SLICS, whatever you happen to have selected, etc). I don't know that it will work if you just have large annotations, but if you choose annotations after running it, it will look ""inside"" all annotations for detections to apply the Calculate Features to. ; Edit: Whoops, nix that last part, finally got around to playing with it and reminding myself how it works. It will apply the measurements to the annotation, but if you are classifying detections, the measurements you created will not show up as they would only be part of the annotation itself, as Peter first said. You also need to have one or more ""Basic Features"" selected in order for it to generate something off of the Color Transforms you select.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293368367
https://github.com/qupath/qupath/issues/63#issuecomment-293368367:92,Safety,detect,detections,92,"The latter will only provide features depending on what boxes are checked, and only for the detections you choose (cells, SLICS, whatever you happen to have selected, etc). I don't know that it will work if you just have large annotations, but if you choose annotations after running it, it will look ""inside"" all annotations for detections to apply the Calculate Features to. ; Edit: Whoops, nix that last part, finally got around to playing with it and reminding myself how it works. It will apply the measurements to the annotation, but if you are classifying detections, the measurements you created will not show up as they would only be part of the annotation itself, as Peter first said. You also need to have one or more ""Basic Features"" selected in order for it to generate something off of the Color Transforms you select.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293368367
https://github.com/qupath/qupath/issues/63#issuecomment-293368367:330,Safety,detect,detections,330,"The latter will only provide features depending on what boxes are checked, and only for the detections you choose (cells, SLICS, whatever you happen to have selected, etc). I don't know that it will work if you just have large annotations, but if you choose annotations after running it, it will look ""inside"" all annotations for detections to apply the Calculate Features to. ; Edit: Whoops, nix that last part, finally got around to playing with it and reminding myself how it works. It will apply the measurements to the annotation, but if you are classifying detections, the measurements you created will not show up as they would only be part of the annotation itself, as Peter first said. You also need to have one or more ""Basic Features"" selected in order for it to generate something off of the Color Transforms you select.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293368367
https://github.com/qupath/qupath/issues/63#issuecomment-293368367:563,Safety,detect,detections,563,"The latter will only provide features depending on what boxes are checked, and only for the detections you choose (cells, SLICS, whatever you happen to have selected, etc). I don't know that it will work if you just have large annotations, but if you choose annotations after running it, it will look ""inside"" all annotations for detections to apply the Calculate Features to. ; Edit: Whoops, nix that last part, finally got around to playing with it and reminding myself how it works. It will apply the measurements to the annotation, but if you are classifying detections, the measurements you created will not show up as they would only be part of the annotation itself, as Peter first said. You also need to have one or more ""Basic Features"" selected in order for it to generate something off of the Color Transforms you select.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293368367
https://github.com/qupath/qupath/issues/63#issuecomment-531642422:76,Safety,detect,detection,76,Thanks for your reply Pete. . I have classified the cells before creating a detection classifier. Still its void classifier after wards.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-531642422
https://github.com/qupath/qupath/issues/64#issuecomment-293464289:14,Safety,detect,detection,14,"Positive cell detection only works on the first go. Other ways to do it involve using the Classify by specific feature option under the Classify menu and choosing your cutoff there, while choosing the cutoff for your specific measurement for the given cell type (IE choose tumor as the input, and then positive tumor or negative tumor as the output). You may have to create the extra classes. The other way involves a one line script that classifies as positive or negative by the value you input. . setCellIntensityClassifications(""Cytoplasm: DAB OD mean"", 0.15)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293464289
https://github.com/qupath/qupath/issues/64#issuecomment-293474681:321,Safety,detect,detection,321,"Thanks for the answer! I already tried this but I only could differ in; tumor cells between positive and negative. Is it possible to differ also; between positive and negative cells in the other classes I created in the; same step?. Le 12 avr. 2017 5:36 AM, ""Svidro"" <notifications@github.com> a écrit :. > Positive cell detection only works on the first go. Other ways to do it; > involve using the Classify by specific feature option under the Classify; > menu and choosing your cutoff there, while choosing the cutoff for your; > specific measurement for the given cell type (IE choose tumor as the input,; > and then positive tumor or negative tumor as the output). You may have to; > create the extra classes. The other way involves a one line script that; > classifies as positive or negative by the value you input.; >; > setCellIntensityClassifications(""Cytoplasm: DAB OD mean"", 0.15); >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/64#issuecomment-293464289>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AaDxoxUmBjQg_4-trBFaetrGH61sBP2-ks5rvEapgaJpZM4M641S>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293474681
https://github.com/qupath/qupath/issues/64#issuecomment-293778069:157,Deployability,update,update,157,"You would need to run the classifier first to distinguish (for example) tumor vs. stromal cells. Once you are happy with that, be sure to turn off the 'Auto-update' setting if you were using it... and then run ```setCellIntensityClassifications``` to further subclassify cells of each type according to their intensities. Note that you can use a single intensity threshold, to distinguish positive/negative cells only, e.g.; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2); ```; or 3 thresholds to get positive/negative, 1+, 2+, 3+ and H-scores; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); ```. It's true that the sliders that allow you to set intensity classifications when you create the classifier at the start will only result in tumor cells being classified. At the time I wrote that command, I was only interested in classifying tumor cells.... and it was much later that I realized that applying intensity classifications to other kinds of cell would be important too. There is no button/menu item for that yet, so the ```setCellIntensityClassifications``` script is the best way to do that currently.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293778069
https://github.com/qupath/qupath/issues/64#issuecomment-293894576:588,Deployability,update,update,588,"Thanks a lot for your help! Only one last question: Is it possible to use 3; thresholds for the tumor cells (e.g. by using the classifier first) and; distinguish afterwards only the stroma cells with help of; setcellintensityclassifications into positive/negative cells? If so what do; I have to put in the script?; I'm sorry for my bad skills in programming. 2017-04-13 6:32 GMT+02:00 Pete <notifications@github.com>:. > You would need to run the classifier first to distinguish (for example); > tumor vs. stromal cells.; >; > Once you are happy with that, be sure to turn off the 'Auto-update'; > setting if you were using it... and then run; > setCellIntensityClassifications to further subclassify cells of each type; > according to their intensities.; >; > Note that you can use a single intensity threshold, to distinguish; > positive/negative cells only, e.g.; >; > setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2); >; > or 3 thresholds to get positive/negative, 1+, 2+, 3+ and H-scores; >; > setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); >; > It's true that the sliders that allow you to set intensity classifications; > when you create the classifier at the start will only result in tumor cells; > being classified. At the time I wrote that command, I was only interested; > in classifying tumor cells.... and it was much later that I realized that; > applying intensity classifications to other kinds of cell would be; > important too. There is no button/menu item for that yet, so the; > setCellIntensityClassifications script is the best way to do that; > currently.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/64#issuecomment-293778069>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AaDxo7t3HoNaYO5n-YVuTD1ZdZj5Z1a-ks5rvaVhgaJpZM4M641S>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293894576
https://github.com/qupath/qupath/issues/65#issuecomment-296463668:675,Deployability,Install,Install,675,"It looks like OpenSlide may need to be recompiled (maybe with a different libtiff) to handle these files. In the meantime, it should be possible to get QuPath to use an alternative version of OpenSlide by removing the OpenSlide-related files from QuPath, and amending the ```java.library.path``` used when launching QuPath if needed. I do not have much experience of handling native libraries with Java on Linux, but Issue #27 may be of some use for reference. Basically you can launch QuPath from the command line and set ```-Djava.library.path``` or modify the ```QuPath.cfg``` file. If you would prefer to avoid this, as a shortcut do either of these two methods work?. * Install the Bio-Formats extension, as described [here](https://github.com/qupath/qupath-bioformats-extension), to use Bio-Formats as an alternative; * Copy ```libopenslide.so.0``` from your working OpenSlide distribution to replace the corresponding file in your QuPath installation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-296463668
https://github.com/qupath/qupath/issues/65#issuecomment-296463668:945,Deployability,install,installation,945,"It looks like OpenSlide may need to be recompiled (maybe with a different libtiff) to handle these files. In the meantime, it should be possible to get QuPath to use an alternative version of OpenSlide by removing the OpenSlide-related files from QuPath, and amending the ```java.library.path``` used when launching QuPath if needed. I do not have much experience of handling native libraries with Java on Linux, but Issue #27 may be of some use for reference. Basically you can launch QuPath from the command line and set ```-Djava.library.path``` or modify the ```QuPath.cfg``` file. If you would prefer to avoid this, as a shortcut do either of these two methods work?. * Install the Bio-Formats extension, as described [here](https://github.com/qupath/qupath-bioformats-extension), to use Bio-Formats as an alternative; * Copy ```libopenslide.so.0``` from your working OpenSlide distribution to replace the corresponding file in your QuPath installation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-296463668
https://github.com/qupath/qupath/issues/65#issuecomment-296463668:609,Safety,avoid,avoid,609,"It looks like OpenSlide may need to be recompiled (maybe with a different libtiff) to handle these files. In the meantime, it should be possible to get QuPath to use an alternative version of OpenSlide by removing the OpenSlide-related files from QuPath, and amending the ```java.library.path``` used when launching QuPath if needed. I do not have much experience of handling native libraries with Java on Linux, but Issue #27 may be of some use for reference. Basically you can launch QuPath from the command line and set ```-Djava.library.path``` or modify the ```QuPath.cfg``` file. If you would prefer to avoid this, as a shortcut do either of these two methods work?. * Install the Bio-Formats extension, as described [here](https://github.com/qupath/qupath-bioformats-extension), to use Bio-Formats as an alternative; * Copy ```libopenslide.so.0``` from your working OpenSlide distribution to replace the corresponding file in your QuPath installation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-296463668
https://github.com/qupath/qupath/issues/65#issuecomment-296876433:144,Usability,guid,guide,144,"@petebankhead thanks for pointers. I re-compiled openslide with openjpeg, to get it working. I would like to debug the code too. Can you please guide me as how to setup my local build using eclipse? I was able to import the source code into eclipse.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-296876433
https://github.com/qupath/qupath/issues/65#issuecomment-297603658:290,Deployability,configurat,configuration,290,"There is some information [here](https://github.com/qupath/qupath/blob/076fb69112b22a299e70819b5af31bd469e47e8a/src/main/resources/eclipse/README.md) about how to set things up in eclipse. You should be able to run in debug mode then. You will probably need to set ```-Xmx``` in your debug configuration, since the maximum memory settings chosen in the GUI won't take effect when run from within eclipse.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-297603658
https://github.com/qupath/qupath/issues/65#issuecomment-297603658:290,Modifiability,config,configuration,290,"There is some information [here](https://github.com/qupath/qupath/blob/076fb69112b22a299e70819b5af31bd469e47e8a/src/main/resources/eclipse/README.md) about how to set things up in eclipse. You should be able to run in debug mode then. You will probably need to set ```-Xmx``` in your debug configuration, since the maximum memory settings chosen in the GUI won't take effect when run from within eclipse.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-297603658
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:721,Availability,down,downsample,721,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:842,Availability,down,downsample,842,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:1232,Deployability,update,updated,1232,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:1060,Testability,log,logical,1060,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:1123,Testability,log,logical,1123,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297915004:172,Usability,simpl,simple,172,"I'm afraid that some of the commands flagged 'experimental' are more experimental than others... and that's one that is more experimental than most. It was added as a very simple counting method, but I only used it myself for some TMAs to have a quick comparison of the results against 'full' cell-by-cell analysis. It turns out to have some troubles that need to be fixed, especially when used in other contexts. The problem @Svidro mentions is that it requires at least one 'hematoxylin' pixel to be able to return anything.; Another strange feature is that, if you look at the hierarchy, the 'Positive' region is _inside_ the 'Negative' one.; And a third is that the 'Num pixels' value is a count of the pixels at the downsample level used. This isn't necessarily 'wrong', but it is not ideal because the measurement name doesn't say what downsample was used. It would be preferable to have a value converted to µm. > Some of these problems arose because the command was initially designed to generate 'Any staining' and 'DAB' regions; at that time, it was logical to return nothing if 'Any staining' was 0. It was also logical to put the 'DAB' region inside 'Any staining' in the hierarchy. Unfortunately, these aspects weren't updated when 'Any staining' was switched to become 'Hematoxylin'. Added to all that, the command doesn't handle fluorescence or other stain types. For all these reasons, I expect that this command will be replaced or substantially changed at some point. Therefore, while you could maybe work around the limitations of the positive pixel command, I'd suggest trying to use other commands for now if possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297915004
https://github.com/qupath/qupath/issues/67#issuecomment-297932408:222,Safety,detect,detection,222,"Hi @Svidro and @petebankhead . Thanks for getting back to me. I'm using positive pixel count to estimate the extent of pathology in defined annotations (TDP-43 in ALS motor cortex, H-DAB slides). I can't use positive cell detection because the pathology is varied in shape and structure and a sizeable proportion of it is extracellular. However, I'm finding that it is ok as long as each annotation is drawn, then counted, then another annotation drawn and so on. If you draw multiple annotations and try to run them simultaneously it doesn't like it. I'm recording my output as a ratio of positive pixels per µm2, so for me the number of negative pixels is irrelevant. . The software is already better and more user friendly than the ImageScope package we were using before, so thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297932408
https://github.com/qupath/qupath/issues/67#issuecomment-297934703:282,Integrability,Depend,Depending,282,"That does sound kind of like the memory limits I have run into. Even with 90GB of RAM committed to a single slide I sometimes have to split things up a bit. I hope to test out how a newer processor handles things soon with a lower RAM cap though! Just finished building a new pc :] Depending on how fine you want your measurements to be, you might also take a look at using a classifier on SLICs. I think the command is roughly in the same menu area. I like that it gives me a little more flexibility in automatically weeding out black bits or other things I am not interested in without having to hand draw every little bit.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297934703
https://github.com/qupath/qupath/issues/67#issuecomment-297934703:167,Testability,test,test,167,"That does sound kind of like the memory limits I have run into. Even with 90GB of RAM committed to a single slide I sometimes have to split things up a bit. I hope to test out how a newer processor handles things soon with a lower RAM cap though! Just finished building a new pc :] Depending on how fine you want your measurements to be, you might also take a look at using a classifier on SLICs. I think the command is roughly in the same menu area. I like that it gives me a little more flexibility in automatically weeding out black bits or other things I am not interested in without having to hand draw every little bit.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297934703
https://github.com/qupath/qupath/issues/67#issuecomment-391770756:258,Deployability,update,updates,258,"Thanks @pyushkevich :) I'm also curious as to whether this was solved. I'm chipping in to mention that the positive pixel count should be quite a bit better if you use the beta version described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html) (involves compiling it, but it's not really a painful process...). You might also see some benefits by [adjusting the stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing) - but the staining you mention is intriguingly new and different to me, and not something I've encountered before. (In the longer term, I plan that there will be much better alternatives to the pixel count - but realistically that is still some months away...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391770756
https://github.com/qupath/qupath/issues/67#issuecomment-391773235:75,Integrability,depend,depending,75,"An interesting variant of this (brace yourself Pete for more of my crazy), depending on what and how you are measuring things, can be converting your measurement area into a ""pathCellObject"" (whether it is hand drawn, tiles, etc) and then running Subcellular detection on it for a bit more control. The segmentation allows you to do things like add further color measurements to the objects created, which then allows further thresholding (remove objects that are too much of a color you are not looking for to get rid of black junk). Can go more into specifics if it is something that would be of interest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391773235
https://github.com/qupath/qupath/issues/67#issuecomment-391773235:259,Safety,detect,detection,259,"An interesting variant of this (brace yourself Pete for more of my crazy), depending on what and how you are measuring things, can be converting your measurement area into a ""pathCellObject"" (whether it is hand drawn, tiles, etc) and then running Subcellular detection on it for a bit more control. The segmentation allows you to do things like add further color measurements to the objects created, which then allows further thresholding (remove objects that are too much of a color you are not looking for to get rid of black junk). Can go more into specifics if it is something that would be of interest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391773235
https://github.com/qupath/qupath/issues/67#issuecomment-391804783:343,Safety,detect,detection,343,"Thanks for the beta suggestion, I will check it out! . I attached an example of the data - it does not seem too different from some of the examples online. . ![image](https://user-images.githubusercontent.com/1241691/40502889-50725814-5f5a-11e8-9ffb-3f662387fa64.png). Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik? I develop a 3D image segmentation tool ITK-SNAP (for MRIs, CTs) and we have been successful with using random forests for segmentation. User paints some examples and the software extrapolates to the rest of the image. Unlike Ilastik we don't have the user generate engineered features, but just train using neighboring intensity values and let the random forest figure out which features are important and which aren't. The random forest code (C++) is fairly self-contained in case it is of any interest:. https://sourceforge.net/p/c3d/git/ci/master/tree/itkextras/RandomForest/. Thanks again,; Paul",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391804783
https://github.com/qupath/qupath/issues/67#issuecomment-391804783:321,Usability,learn,learning-based,321,"Thanks for the beta suggestion, I will check it out! . I attached an example of the data - it does not seem too different from some of the examples online. . ![image](https://user-images.githubusercontent.com/1241691/40502889-50725814-5f5a-11e8-9ffb-3f662387fa64.png). Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik? I develop a 3D image segmentation tool ITK-SNAP (for MRIs, CTs) and we have been successful with using random forests for segmentation. User paints some examples and the software extrapolates to the rest of the image. Unlike Ilastik we don't have the user generate engineered features, but just train using neighboring intensity values and let the random forest figure out which features are important and which aren't. The random forest code (C++) is fairly self-contained in case it is of any interest:. https://sourceforge.net/p/c3d/git/ci/master/tree/itkextras/RandomForest/. Thanks again,; Paul",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391804783
https://github.com/qupath/qupath/issues/67#issuecomment-391819273:219,Safety,detect,detections,219,"Not sure if this is what you are interested in, and I only did a quick run at different types of measurements, but I:; 1. Converted the image to a tiff so that I could have pixel measurements (necessary for Subcellular detections); 2. Created a whole image annotation; 3. Converted that into a cell; 4. Fixed up my color vectors and ran a subcellular detection on DAB (did not really do a great job there); 5. Add Intensity Features-most of them; Found that the residual did a decent job of picking out what I think are the extraneous black dots. I imagine there are better color vector sets that you could use to identify those areas, and eliminate them from analysis. Not sure if this is what you are looking for though before I go too crazy with it.; ![image](https://user-images.githubusercontent.com/23145209/40504972-bc8c1fd4-5f47-11e8-8377-630411164e51.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391819273
https://github.com/qupath/qupath/issues/67#issuecomment-391819273:351,Safety,detect,detection,351,"Not sure if this is what you are interested in, and I only did a quick run at different types of measurements, but I:; 1. Converted the image to a tiff so that I could have pixel measurements (necessary for Subcellular detections); 2. Created a whole image annotation; 3. Converted that into a cell; 4. Fixed up my color vectors and ran a subcellular detection on DAB (did not really do a great job there); 5. Add Intensity Features-most of them; Found that the residual did a decent job of picking out what I think are the extraneous black dots. I imagine there are better color vector sets that you could use to identify those areas, and eliminate them from analysis. Not sure if this is what you are looking for though before I go too crazy with it.; ![image](https://user-images.githubusercontent.com/23145209/40504972-bc8c1fd4-5f47-11e8-8377-630411164e51.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391819273
https://github.com/qupath/qupath/issues/67#issuecomment-391834425:229,Integrability,rout,routinely,229,"In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Tau is normally more heterogenously shaped than pTDP-43, I don't use it routinely as I work on ALS. When using the positive pixel count tool I only quantified user-defined annotations, so I could choose where to place them and avoid any bits of crud on the slide. Tweaking the colour deconvolution for your DAB channel might help. If there's a lot of background I would try raising the primary Ab dilution. Regardless of the antibody, I find that incubating the primary overnight at 4'C pretty much always gives the best signal with minimal background. . Regarding the settings, I basically just played around with the parameters until I found settings that struck a balance between being specific enough and not taking too much time to complete after clicking run. I then copied the generated script and applied it to every section. Hope this helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391834425
https://github.com/qupath/qupath/issues/67#issuecomment-391834425:122,Safety,detect,detection,122,"In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Tau is normally more heterogenously shaped than pTDP-43, I don't use it routinely as I work on ALS. When using the positive pixel count tool I only quantified user-defined annotations, so I could choose where to place them and avoid any bits of crud on the slide. Tweaking the colour deconvolution for your DAB channel might help. If there's a lot of background I would try raising the primary Ab dilution. Regardless of the antibody, I find that incubating the primary overnight at 4'C pretty much always gives the best signal with minimal background. . Regarding the settings, I basically just played around with the parameters until I found settings that struck a balance between being specific enough and not taking too much time to complete after clicking run. I then copied the generated script and applied it to every section. Hope this helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391834425
https://github.com/qupath/qupath/issues/67#issuecomment-391834425:384,Safety,avoid,avoid,384,"In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Tau is normally more heterogenously shaped than pTDP-43, I don't use it routinely as I work on ALS. When using the positive pixel count tool I only quantified user-defined annotations, so I could choose where to place them and avoid any bits of crud on the slide. Tweaking the colour deconvolution for your DAB channel might help. If there's a lot of background I would try raising the primary Ab dilution. Regardless of the antibody, I find that incubating the primary overnight at 4'C pretty much always gives the best signal with minimal background. . Regarding the settings, I basically just played around with the parameters until I found settings that struck a balance between being specific enough and not taking too much time to complete after clicking run. I then copied the generated script and applied it to every section. Hope this helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391834425
https://github.com/qupath/qupath/issues/67#issuecomment-391979772:504,Integrability,message,message,504,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772
https://github.com/qupath/qupath/issues/67#issuecomment-391979772:91,Safety,detect,detection,91,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772
https://github.com/qupath/qupath/issues/67#issuecomment-391979772:855,Safety,detect,detection,855,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772
https://github.com/qupath/qupath/issues/67#issuecomment-391979772:69,Usability,learn,learning-based,69,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772
https://github.com/qupath/qupath/issues/67#issuecomment-391979772:454,Usability,clear,clearer,454,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772
https://github.com/qupath/qupath/issues/67#issuecomment-392065810:108,Usability,usab,usable,108,"Of course, I would be happy to discuss the ITK-SNAP experience, and I hope some of the code can be directly usable. Regarding your suggestion, how do I actually convert an annotation area to a cell?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-392065810
https://github.com/qupath/qupath/issues/67#issuecomment-392080198:709,Safety,detect,detection,709,"To clarify, since you know more coding than I do, you are replacing an ROI of the exact same coordinates with a pathCellObject.; Here is the code from somewhere on the forum: https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-change-annotations-into-cell-objects-groovy. That script is designed to target second ""level"" annotations as it was written to ignore the top level annotation and convert hand drawn annotations within into cells. You will probably want to change line 8:. `def targets = getObjects{return it.getLevel()!=1 && it.isAnnotation()}`. to use something like ""getAnnotationObjects()"" if you do not have any annotation hierarchy.; If your area is too large, the subcellular detection may fail (it will be obvious if it happens, you get no segmentation). I have had it work successfully over very large areas, but on a whole slide, I had to create subdivisions. I am not 100% sure what the limits are. If you run into that problem, you could also create your annotation area, tile it, and then convert the tiles into cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-392080198
https://github.com/qupath/qupath/issues/67#issuecomment-471152043:86,Deployability,release,release,86,"Closing this because of lack of activity, and it is addressed in the latest milestone release (especially through the pixel classifier).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-471152043
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:1014,Integrability,depend,depending,1014," not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get started, or see the ```Estimate_background_values.groovy``` script included as supplementary material with the [bioRxiv preprint](http://biorxiv.org/content/early/2017/03/06/099796).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:1313,Integrability,depend,dependencies,1313," not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get started, or see the ```Estimate_background_values.groovy``` script included as supplementary material with the [bioRxiv preprint](http://biorxiv.org/content/early/2017/03/06/099796).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:319,Modifiability,plugin,plugins,319,"Thanks Benjamin, and I'm glad the macro functionality is useful!. I thought I knew the reason for the issues you are seeing, but upon quickly looking at the code I realise that I do not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get st",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:615,Modifiability,plugin,plugins,615,"Thanks Benjamin, and I'm glad the macro functionality is useful!. I thought I knew the reason for the issues you are seeing, but upon quickly looking at the code I realise that I do not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get st",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:1951,Modifiability,plugin,plugins,1951," not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get started, or see the ```Estimate_background_values.groovy``` script included as supplementary material with the [bioRxiv preprint](http://biorxiv.org/content/early/2017/03/06/099796).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:1234,Performance,perform,performs,1234," not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get started, or see the ```Estimate_background_values.groovy``` script included as supplementary material with the [bioRxiv preprint](http://biorxiv.org/content/early/2017/03/06/099796).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:438,Safety,avoid,avoid,438,"Thanks Benjamin, and I'm glad the macro functionality is useful!. I thought I knew the reason for the issues you are seeing, but upon quickly looking at the code I realise that I do not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get st",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-297931966:1508,Usability,learn,learning,1508," not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get started, or see the ```Estimate_background_values.groovy``` script included as supplementary material with the [bioRxiv preprint](http://biorxiv.org/content/early/2017/03/06/099796).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966
https://github.com/qupath/qupath/issues/68#issuecomment-300088603:460,Deployability,continuous,continuous,460,"Possibly... Java should take care of any requests exceeding the ```Integer.MAX_VALUE```, but the maximum memory should probably be involved in the calculation somewhere. I faintly recall adding a limit because I kept accidentally crashing/hanging by requesting regions that were much too large, and the macro runner doesn't do any kind of smart breaking-a-large-region-into-tiles. So I wanted to protect me from myself. It's complicated by the fact that large continuous regions of memory need to be found for the arrays and QuPath has no idea how much memory the macro is going to require (i.e. how many image duplicates it will make). And maybe sometimes the macro will be run in parallel. I still tend towards having a fixed limit, just a much bigger one. And preferably one implemented as a static field somewhere. Then it could be modified by a script in an emergency - or possibly even within the macro runner dialog itself. I definitely would agree that hard-coding a relatively small limit in the middle of a method wasn't the optimal way...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-300088603
https://github.com/qupath/qupath/issues/68#issuecomment-1999765237:41,Deployability,update,updates,41,"Hello!. I wanted to ask if there are any updates on this potential ImageJ macro runner extension. I have a similar case as @bpavie and would be interested in finding a way to send a single channel (DAB) from QuPath to ImageJ. Also, @bpavie if you found a way to get this to work, I´d be very happy about any input. Thank you!. Best, ; Julia",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-1999765237
https://github.com/qupath/qupath/issues/69#issuecomment-298743270:225,Deployability,update,update,225,"This may well be because of the image format, or QuPath might be having trouble for some other reason (not enough memory?). If you choose *View &rarr; Show log* does anything informative appear?. It may also be beneficial to update your version of Bio-Formats, if you have not already done so. I see on the [changelog for version 5.4.0](http://www.openmicroscopy.org/site/support/bio-formats5.4/about/whats-new.html) there is a mention of improved performance of large, uncompressed CZI files. Is exporting as CZI an option?. Currently, QuPath works best for images that are small enough to handle directly, or large whole slide images stored in a tiled, pyramidal format of some kind.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/69#issuecomment-298743270
https://github.com/qupath/qupath/issues/69#issuecomment-298743270:448,Performance,perform,performance,448,"This may well be because of the image format, or QuPath might be having trouble for some other reason (not enough memory?). If you choose *View &rarr; Show log* does anything informative appear?. It may also be beneficial to update your version of Bio-Formats, if you have not already done so. I see on the [changelog for version 5.4.0](http://www.openmicroscopy.org/site/support/bio-formats5.4/about/whats-new.html) there is a mention of improved performance of large, uncompressed CZI files. Is exporting as CZI an option?. Currently, QuPath works best for images that are small enough to handle directly, or large whole slide images stored in a tiled, pyramidal format of some kind.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/69#issuecomment-298743270
https://github.com/qupath/qupath/issues/69#issuecomment-298743270:156,Testability,log,log,156,"This may well be because of the image format, or QuPath might be having trouble for some other reason (not enough memory?). If you choose *View &rarr; Show log* does anything informative appear?. It may also be beneficial to update your version of Bio-Formats, if you have not already done so. I see on the [changelog for version 5.4.0](http://www.openmicroscopy.org/site/support/bio-formats5.4/about/whats-new.html) there is a mention of improved performance of large, uncompressed CZI files. Is exporting as CZI an option?. Currently, QuPath works best for images that are small enough to handle directly, or large whole slide images stored in a tiled, pyramidal format of some kind.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/69#issuecomment-298743270
https://github.com/qupath/qupath/issues/70#issuecomment-298747073:475,Availability,down,downsampled,475,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073
https://github.com/qupath/qupath/issues/70#issuecomment-298747073:776,Modifiability,Plugin,Plugins,776,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073
https://github.com/qupath/qupath/issues/70#issuecomment-298747073:31,Safety,detect,detection,31,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073
https://github.com/qupath/qupath/issues/70#issuecomment-298747073:300,Safety,detect,detected,300,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073
https://github.com/qupath/qupath/issues/70#issuecomment-298747073:1014,Safety,detect,detections,1014,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073
https://github.com/qupath/qupath/issues/71#issuecomment-299514248:195,Integrability,depend,depending,195,"Amazing timing! I just ran into this now trying to estimate dermal thickness. Thanks for the find and the fix.; As for the question about adjusting the script, the quickest thing I can think of, depending on how many lines you have... you might be able to change getAnnotationObjects to getSelectedObjects. This is assuming you can easily select out the ones you want to change!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299514248
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:994,Availability,error,error,994,"adn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; roi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:745,Deployability,release,released,745,"I hadn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:879,Deployability,update,updated,879,"I hadn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:470,Performance,load,loaded,470,"I hadn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:159,Safety,predict,predictable,159,"I hadn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-299623260:1449,Safety,avoid,avoids,1449," background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; roi = it.getROI(); if (roi instanceof qupath.lib.roi.LineROI) {; roi.x2 += roi.x; roi.y2 += roi.y; }; }; fireHierarchyUpdate(); ```. This will fix the selected lines, and leave the others unchanged.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260
https://github.com/qupath/qupath/issues/71#issuecomment-374199736:195,Deployability,update,updates,195,At long last this issue should be resolved without need for an extra script if you use the version of QuPath described in [this blog post](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-374199736
https://github.com/qupath/qupath/issues/71#issuecomment-471151818:45,Deployability,release,release,45,This should be fixed in the latest milestone release https://github.com/qupath/qupath/commit/6be3e55afa7e36cb3543ee3c06df56209ee913d1,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-471151818
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:833,Availability,down,down,833,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:856,Availability,error,error,856,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:1114,Availability,down,down,1114,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:1048,Modifiability,plugin,plugin,1048,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:178,Testability,test,test,178,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:778,Testability,log,log,778,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/72#issuecomment-299391470:511,Usability,simpl,simply,511,"Thanks @franfcunha !. I recently opened a (very small, single-channel) .jp2 image in QuPath with the help of Bio-Formats, but I do not have a whole slide image in that format to test. JPEG2000 *does* currently appear on the [Bio-Formats list of supported formats](https://www.openmicroscopy.org/site/support/bio-formats5.4/supported-formats.html) with a tick in the 'pyramid' column... but I am not sure whether that should be interpreted as meaning pyramidal .jp2 whole slide images are supported, or if it is simply a comment on the capabilities of the format. I would suggest asking the OME team about this through their [mailing list](http://lists.openmicroscopy.org.uk/mailman/listinfo/ome-users/) - they are the experts. Apart from that, in QuPath under *View &rarr; Show log* you may get more useful information to help track down the source of any error. Where Bio-Formats is involved, I would also recommend trying to open a cropped/lower resolution part of any problematic image with [Fiji](http://fiji.sc) as well, since the Bio-Formats plugin for Fiji is much more established. This can helps to track down whether the problem is most likely to be with the file itself, the file reader, or the QuPath extension.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/72#issuecomment-299391470
https://github.com/qupath/qupath/issues/73#issuecomment-299649956:40,Safety,detect,detection,40,"Another (important!) one:; * With *Cell detection*, any third stain is not automatically measured in the nucleus/cytoplasm/full cell",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/73#issuecomment-299649956
https://github.com/qupath/qupath/issues/74#issuecomment-399181470:55,Deployability,release,release,55,Another workaround for this bug is to try out the [pre-release for v0.1.3](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html)...,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/74#issuecomment-399181470
https://github.com/qupath/qupath/issues/74#issuecomment-399181470:131,Deployability,update,updates,131,Another workaround for this bug is to try out the [pre-release for v0.1.3](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html)...,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/74#issuecomment-399181470
https://github.com/qupath/qupath/issues/74#issuecomment-514596506:73,Deployability,release,releases,73,This should be addressed in [v0.2.0-m3](https://github.com/qupath/qupath/releases/tag/v0.2.0-m3) (and earlier milestones).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/74#issuecomment-514596506
https://github.com/qupath/qupath/issues/75#issuecomment-300235539:72,Performance,perform,perform,72,"Ah, Peter just pointed this out to me, but you can try using Shift+E to perform a quick Undo, though I think it only goes back one step. It seems to work with the point tool as well, which is the three small circles in a triangle on the right-most side of the drawing tools. . Selection can be an issue, so far I have had to find work arounds with scripting in order to select multiple objects that are not nicely next to each other in the hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300235539
https://github.com/qupath/qupath/issues/75#issuecomment-300235539:88,Usability,Undo,Undo,88,"Ah, Peter just pointed this out to me, but you can try using Shift+E to perform a quick Undo, though I think it only goes back one step. It seems to work with the point tool as well, which is the three small circles in a triangle on the right-most side of the drawing tools. . Selection can be an issue, so far I have had to find work arounds with scripting in order to select multiple objects that are not nicely next to each other in the hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300235539
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:2438,Deployability,Update,Update,2438,"rly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key pressed; * You can use a script, such as the one below. ```groovy; guiscript=true; // Get the current selected object & hierarchy; selected = getSelectedObject(); hierarchy = getCurrentHierarchy(); // Get all the objects inside the current selection; objectsToSelect = hierarchy.getDescendantObjects(selected, null, null); if (objectsToSelect != null) {; // Remove the current selected object; hierarchy.removeObject(selected, true); // Update the selection; hierarchy.getSelectionModel().selectObjects(objectsToSelect); }; ```. This should enable you to draw around objects using any of the drawing tools, and then run the script to select everything inside. As it is written, the annotation that you draw will then be deleted. This has the advantage of making it possible to select objects by drawing any arbitrary shape, without needing to add an extra tool to the toolbar. If this were to become a standard command, with a shortcut, would it address the need? Or do you think a separate selection tool would still be preferable?. > 3. A point tool allow using points to mark an object. Some times, we would like just mark the key point of an object. It is possible to use a polygon but a point tool will be nice. There is indeed a *Point tool*, described [here](https://github.com/qupath/qupath/wiki/Counting-cells#manual-cell-counting).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:1142,Energy Efficiency,reduce,reduce,1142,"gs that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key pressed; * You can use a script, such as the one below. ```groovy; guiscript=true; // Get the current selected object & hierarchy; selected = getSelectedObject(); hierarchy = getCurrent",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:314,Performance,perform,performance,314,"Hi there,. > 1. Undo function. Sometimes I deleted an object by mistake, and it will be great if I can get it back. An undo option would be useful; unfortunately, there are so many things that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:16,Usability,Undo,Undo,16,"Hi there,. > 1. Undo function. Sometimes I deleted an object by mistake, and it will be great if I can get it back. An undo option would be useful; unfortunately, there are so many things that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:119,Usability,undo,undo,119,"Hi there,. > 1. Undo function. Sometimes I deleted an object by mistake, and it will be great if I can get it back. An undo option would be useful; unfortunately, there are so many things that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:279,Usability,undo,undo-able,279,"Hi there,. > 1. Undo function. Sometimes I deleted an object by mistake, and it will be great if I can get it back. An undo option would be useful; unfortunately, there are so many things that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300294512:605,Usability,undo,undo,605,"Hi there,. > 1. Undo function. Sometimes I deleted an object by mistake, and it will be great if I can get it back. An undo option would be useful; unfortunately, there are so many things that you might do with QuPath - especially if you include scripting - that are not easily 'undo-able' without badly impacting performance and increasing the potential for bugs. For example, there are lots of ways you might change the [object hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) and keeping track of them would require a lot of additional overhead. So for now... I'm afraid there's no undo. Nevertheless, there are a few things that can help:. * If you draw something by accident, press *backspace* to delete it; * If you delete something by accident, as @Svidro says, press ```Shift+E```. This corresponds to the *Restore Selection* command in ImageJ, and has the same shortcut, so as to help if you happen to know ImageJ already. (However, it only ever remembers the most recent object that it saw... so if you select any other object in the meantime, then it cannot restore the one that was deleted.); * If you want to reduce the chances of accidentally editing an annotation, right-click and choose *Annotations &rarr; Lock*. Note that the annotation can still be deleted - but not moved or otherwise edited.; * Regularly save (```Ctrl + S```) and then use *File &rarr; Revert* to go back (```Ctrl + R```). The last one is probably the approach I use most. > 2. A select tool by drawing a square like many other editing tools. This will make select multiple objects easy. I've also wanted this occasionally, but not often enough to do anything about it yet. However, there are a few options for selecting:. * Click on each object in either the *Annotations* or *Hierarchy* tab (with ```Ctrl``` or ```Shift``` pressed if needed); * If you have one object selected, and the *Move* tool is active, you can select other objects by clicking them in the image with the ```Alt``` key ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300294512
https://github.com/qupath/qupath/issues/75#issuecomment-300553027:73,Availability,down,down,73,"With the *Point* tool selected, click on an existing point while holding down the ```Alt``` key, as described under [Tips for more effective counting](https://github.com/qupath/qupath/wiki/Counting-cells#tips-for-more-effective-counting).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-300553027
https://github.com/qupath/qupath/issues/75#issuecomment-518580699:25,Availability,avail,available,25,"Some undo support is now available in v0.2.0-m1 (and beyond), and explained [on my blog](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html#new-limited-support-for-undo).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-518580699
https://github.com/qupath/qupath/issues/75#issuecomment-518580699:145,Deployability,update,updates,145,"Some undo support is now available in v0.2.0-m1 (and beyond), and explained [on my blog](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html#new-limited-support-for-undo).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-518580699
https://github.com/qupath/qupath/issues/75#issuecomment-518580699:5,Usability,undo,undo,5,"Some undo support is now available in v0.2.0-m1 (and beyond), and explained [on my blog](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html#new-limited-support-for-undo).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-518580699
https://github.com/qupath/qupath/issues/75#issuecomment-518580699:182,Usability,undo,undo,182,"Some undo support is now available in v0.2.0-m1 (and beyond), and explained [on my blog](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html#new-limited-support-for-undo).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/75#issuecomment-518580699
https://github.com/qupath/qupath/issues/76#issuecomment-300999633:809,Deployability,configurat,configuration,809,"Yes, it's possible to use 3rd party libraries without recompiling, although I'm not sure how easy it will be to set up in this case. Firstly, you need all the (Java) jar files visible to the classloader in QuPath; the easiest way to do that is to put them in the *extensions* folder - normally just by dragging them onto QuPath when it's running. You might need to restart QuPath to make sure they are picked up. Secondly, in this case, you need all the native libraries of dl4j to be visible as well; these might have been distributed in jar files, in which case they need to be extracted (as far as I know - unless dl4j is doing something different here). There is some more information about where to put them to get them on the ```java.library.path``` [here](https://github.com/qupath/qupath/wiki/Paths-&-configuration). That is probably the easiest approach... if it works. Alternatively, if you choose to use Eclipse instead, you don't necessarily need to fork QuPath since you shouldn't need to modify it, you just an Eclipse project to be set up with the source. You can then create an extension and set up everything specific to your project there. You could choose an existing extension as a base and then modify it, using Maven to manage all the dl4j dependencies, and then add it to the build path for the main QuPath project. I haven't tried this exact configuration myself. Since this requires some knowledge of Eclipse, Maven, library paths, QuPath and dl4j, I imagine it isn't the easiest thing to get working... but I think it should be doable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-300999633
https://github.com/qupath/qupath/issues/76#issuecomment-300999633:1366,Deployability,configurat,configuration,1366,"Yes, it's possible to use 3rd party libraries without recompiling, although I'm not sure how easy it will be to set up in this case. Firstly, you need all the (Java) jar files visible to the classloader in QuPath; the easiest way to do that is to put them in the *extensions* folder - normally just by dragging them onto QuPath when it's running. You might need to restart QuPath to make sure they are picked up. Secondly, in this case, you need all the native libraries of dl4j to be visible as well; these might have been distributed in jar files, in which case they need to be extracted (as far as I know - unless dl4j is doing something different here). There is some more information about where to put them to get them on the ```java.library.path``` [here](https://github.com/qupath/qupath/wiki/Paths-&-configuration). That is probably the easiest approach... if it works. Alternatively, if you choose to use Eclipse instead, you don't necessarily need to fork QuPath since you shouldn't need to modify it, you just an Eclipse project to be set up with the source. You can then create an extension and set up everything specific to your project there. You could choose an existing extension as a base and then modify it, using Maven to manage all the dl4j dependencies, and then add it to the build path for the main QuPath project. I haven't tried this exact configuration myself. Since this requires some knowledge of Eclipse, Maven, library paths, QuPath and dl4j, I imagine it isn't the easiest thing to get working... but I think it should be doable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-300999633
https://github.com/qupath/qupath/issues/76#issuecomment-300999633:1262,Integrability,depend,dependencies,1262,"Yes, it's possible to use 3rd party libraries without recompiling, although I'm not sure how easy it will be to set up in this case. Firstly, you need all the (Java) jar files visible to the classloader in QuPath; the easiest way to do that is to put them in the *extensions* folder - normally just by dragging them onto QuPath when it's running. You might need to restart QuPath to make sure they are picked up. Secondly, in this case, you need all the native libraries of dl4j to be visible as well; these might have been distributed in jar files, in which case they need to be extracted (as far as I know - unless dl4j is doing something different here). There is some more information about where to put them to get them on the ```java.library.path``` [here](https://github.com/qupath/qupath/wiki/Paths-&-configuration). That is probably the easiest approach... if it works. Alternatively, if you choose to use Eclipse instead, you don't necessarily need to fork QuPath since you shouldn't need to modify it, you just an Eclipse project to be set up with the source. You can then create an extension and set up everything specific to your project there. You could choose an existing extension as a base and then modify it, using Maven to manage all the dl4j dependencies, and then add it to the build path for the main QuPath project. I haven't tried this exact configuration myself. Since this requires some knowledge of Eclipse, Maven, library paths, QuPath and dl4j, I imagine it isn't the easiest thing to get working... but I think it should be doable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-300999633
https://github.com/qupath/qupath/issues/76#issuecomment-300999633:809,Modifiability,config,configuration,809,"Yes, it's possible to use 3rd party libraries without recompiling, although I'm not sure how easy it will be to set up in this case. Firstly, you need all the (Java) jar files visible to the classloader in QuPath; the easiest way to do that is to put them in the *extensions* folder - normally just by dragging them onto QuPath when it's running. You might need to restart QuPath to make sure they are picked up. Secondly, in this case, you need all the native libraries of dl4j to be visible as well; these might have been distributed in jar files, in which case they need to be extracted (as far as I know - unless dl4j is doing something different here). There is some more information about where to put them to get them on the ```java.library.path``` [here](https://github.com/qupath/qupath/wiki/Paths-&-configuration). That is probably the easiest approach... if it works. Alternatively, if you choose to use Eclipse instead, you don't necessarily need to fork QuPath since you shouldn't need to modify it, you just an Eclipse project to be set up with the source. You can then create an extension and set up everything specific to your project there. You could choose an existing extension as a base and then modify it, using Maven to manage all the dl4j dependencies, and then add it to the build path for the main QuPath project. I haven't tried this exact configuration myself. Since this requires some knowledge of Eclipse, Maven, library paths, QuPath and dl4j, I imagine it isn't the easiest thing to get working... but I think it should be doable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-300999633
https://github.com/qupath/qupath/issues/76#issuecomment-300999633:1366,Modifiability,config,configuration,1366,"Yes, it's possible to use 3rd party libraries without recompiling, although I'm not sure how easy it will be to set up in this case. Firstly, you need all the (Java) jar files visible to the classloader in QuPath; the easiest way to do that is to put them in the *extensions* folder - normally just by dragging them onto QuPath when it's running. You might need to restart QuPath to make sure they are picked up. Secondly, in this case, you need all the native libraries of dl4j to be visible as well; these might have been distributed in jar files, in which case they need to be extracted (as far as I know - unless dl4j is doing something different here). There is some more information about where to put them to get them on the ```java.library.path``` [here](https://github.com/qupath/qupath/wiki/Paths-&-configuration). That is probably the easiest approach... if it works. Alternatively, if you choose to use Eclipse instead, you don't necessarily need to fork QuPath since you shouldn't need to modify it, you just an Eclipse project to be set up with the source. You can then create an extension and set up everything specific to your project there. You could choose an existing extension as a base and then modify it, using Maven to manage all the dl4j dependencies, and then add it to the build path for the main QuPath project. I haven't tried this exact configuration myself. Since this requires some knowledge of Eclipse, Maven, library paths, QuPath and dl4j, I imagine it isn't the easiest thing to get working... but I think it should be doable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-300999633
https://github.com/qupath/qupath/issues/76#issuecomment-301125628:112,Availability,reliab,reliable,112,"Thanks Peter. Quick and clear as usual. ; I'm getting the feeling that the latter will be a bit longer but more reliable. I assume the same approach could be taken with IntelliJ, no? ; It might be a bit of work but I think this would be an interesting feature for QuPath to have, and there might be a way to get several different user groups to collaborate and contribute images for training.; Thanks again for the direction.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-301125628
https://github.com/qupath/qupath/issues/76#issuecomment-301125628:24,Usability,clear,clear,24,"Thanks Peter. Quick and clear as usual. ; I'm getting the feeling that the latter will be a bit longer but more reliable. I assume the same approach could be taken with IntelliJ, no? ; It might be a bit of work but I think this would be an interesting feature for QuPath to have, and there might be a way to get several different user groups to collaborate and contribute images for training.; Thanks again for the direction.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-301125628
https://github.com/qupath/qupath/issues/76#issuecomment-301229258:1086,Deployability,update,updated,1086,"I assume so as well, although I've never done it. I generally use Eclipse for working with the full QuPath source/extensions, and IntelliJ for most other things. I dabbled briefly with dl4j in IntelliJ, but never introduced it to QuPath and never took the time to figure out how to set up QuPath in IntelliJ. I wouldn't claim my Eclipse setup is particularly elegant, but there is some information [here](https://github.com/qupath/qupath/blob/076fb69112b22a299e70819b5af31bd469e47e8a/src/main/resources/eclipse/README.md). The ability to run in debug more, and even to change the code in a running application (within limits), is extremely useful. If you did want to keep the worlds separate, with QuPath in Eclipse (or as a standalone application) and dl4j in IntelliJ, then you might have some benefit in creating a symbolic link in your QuPath extensions folder to wherever your dl4j jars are located; if I remember correctly, QuPath should look into subdirectories (symbolically linked or otherwise) for dependencies. At least that may allow the jars to be managed by IntelliJ, and updated without needing to copy them over to QuPath again. Native libraries will still need to be handled, but this only involves setting the path to the directory containing them anyway.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-301229258
https://github.com/qupath/qupath/issues/76#issuecomment-301229258:1008,Integrability,depend,dependencies,1008,"I assume so as well, although I've never done it. I generally use Eclipse for working with the full QuPath source/extensions, and IntelliJ for most other things. I dabbled briefly with dl4j in IntelliJ, but never introduced it to QuPath and never took the time to figure out how to set up QuPath in IntelliJ. I wouldn't claim my Eclipse setup is particularly elegant, but there is some information [here](https://github.com/qupath/qupath/blob/076fb69112b22a299e70819b5af31bd469e47e8a/src/main/resources/eclipse/README.md). The ability to run in debug more, and even to change the code in a running application (within limits), is extremely useful. If you did want to keep the worlds separate, with QuPath in Eclipse (or as a standalone application) and dl4j in IntelliJ, then you might have some benefit in creating a symbolic link in your QuPath extensions folder to wherever your dl4j jars are located; if I remember correctly, QuPath should look into subdirectories (symbolically linked or otherwise) for dependencies. At least that may allow the jars to be managed by IntelliJ, and updated without needing to copy them over to QuPath again. Native libraries will still need to be handled, but this only involves setting the path to the directory containing them anyway.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/76#issuecomment-301229258
https://github.com/qupath/qupath/issues/77#issuecomment-301233047:543,Availability,down,down,543,"In a way. I think once you get the first TMA core, you can keep Adding Row and Adding Column until you get the correct number. I suppose if those commands show up in the workflow and/or are scriptable, you might be able to craft something through scripting. Pete also might know something more elegant. ; I tend to just cheat though. If you rename the file I attached (TMA.txt) to a .qpdata file, then give it the same name as your image, for example, MyImageName.qpdata, you get to start off with a fairly large TMA, which you can then shave down or add columns to as necessary. You may need to do a fair bit of re-aligning though. Plus if you are using a standard TMA size for all of your images, once you have your TMA the way you want it, just save the data file make a spare copy of it somewhere. You can then use that file and rename copies of it to YourNextTMA.qpdata as many times as you need. All of the .qpdata files should be in the ""data"" folder in your project directory. [TMA.txt](https://github.com/qupath/qupath/files/998431/TMA.txt)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-301233047
https://github.com/qupath/qupath/issues/77#issuecomment-301234930:394,Deployability,update,update,394,"I didn't have a more elegant solution - and I like @Svidro's approach of reusing (and renaming) an existing ```.qpdata``` file. If you do this, I'd suggest trying to create one from any similar image you have that works - since it will also do things like set the image type (brightfield, fluorescence, stain colors...), and it makes sense to use values from related images rather than have to update them later. I always planned vaguely to make it possible to create a manual TMA grid, but the automated dearrayer never failed catastrophically enough on any image that I encountered to make this necessary; I only ever added/removed rows as needed. Nevertheless, in the absence of a user-friendly way to do something, it's generally possible to resort to a script. If you draw a rectangle around where the grid should be, you could try running this:. ```groovy; import qupath.lib.objects.TMACoreObject; import qupath.lib.objects.hierarchy.DefaultTMAGrid. // Enter the number of horizontal & vertical cores here; int numHorizontal = 12; int numVertical = 9; // Enter the core diameter, in millimetres; double diameterMM = 1.2. // Convert diameter to pixels; double diameterPixels = (diameterMM * 1000) / getCurrentImageData().getServer().getAveragedPixelSizeMicrons(). // Get the current ROI; def roi = getSelectedROI(). // Create the cores; def cores = []; double xSpacing = roi.getBoundsWidth() / numHorizontal; double ySpacing = roi.getBoundsHeight() / numVertical; for (int i = 0; i < numVertical; i++) {; for (int j = 0; j < numHorizontal; j++) {; double x = roi.getBoundsX() + xSpacing / 2 + xSpacing * j; double y = roi.getBoundsY() + ySpacing / 2 + ySpacing * i; cores << new TMACoreObject(x, y, diameterPixels, false); }; }. // Create & set the grid; def tmaGrid = new DefaultTMAGrid(cores, numHorizontal); getCurrentHierarchy().setTMAGrid(tmaGrid); ```. Note that there are a few variables at the top that should be specified (i.e. the number of cores horizontally and vertically, and the an",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-301234930
https://github.com/qupath/qupath/issues/77#issuecomment-301234930:1890,Modifiability,variab,variables,1890,"se values from related images rather than have to update them later. I always planned vaguely to make it possible to create a manual TMA grid, but the automated dearrayer never failed catastrophically enough on any image that I encountered to make this necessary; I only ever added/removed rows as needed. Nevertheless, in the absence of a user-friendly way to do something, it's generally possible to resort to a script. If you draw a rectangle around where the grid should be, you could try running this:. ```groovy; import qupath.lib.objects.TMACoreObject; import qupath.lib.objects.hierarchy.DefaultTMAGrid. // Enter the number of horizontal & vertical cores here; int numHorizontal = 12; int numVertical = 9; // Enter the core diameter, in millimetres; double diameterMM = 1.2. // Convert diameter to pixels; double diameterPixels = (diameterMM * 1000) / getCurrentImageData().getServer().getAveragedPixelSizeMicrons(). // Get the current ROI; def roi = getSelectedROI(). // Create the cores; def cores = []; double xSpacing = roi.getBoundsWidth() / numHorizontal; double ySpacing = roi.getBoundsHeight() / numVertical; for (int i = 0; i < numVertical; i++) {; for (int j = 0; j < numHorizontal; j++) {; double x = roi.getBoundsX() + xSpacing / 2 + xSpacing * j; double y = roi.getBoundsY() + ySpacing / 2 + ySpacing * i; cores << new TMACoreObject(x, y, diameterPixels, false); }; }. // Create & set the grid; def tmaGrid = new DefaultTMAGrid(cores, numHorizontal); getCurrentHierarchy().setTMAGrid(tmaGrid); ```. Note that there are a few variables at the top that should be specified (i.e. the number of cores horizontally and vertically, and the anticipated diameter). The rectangle needs to be selected for this to work, but otherwise you can run it multiple times. Regrettably, this script doesn't do anything smart to try to align the cores with tissue in the image. Therefore the core locations will need to be manually corrected afterwards; still, it's hopefully enough to make progess.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-301234930
https://github.com/qupath/qupath/issues/77#issuecomment-301234930:684,Usability,user-friendly,user-friendly,684,"I didn't have a more elegant solution - and I like @Svidro's approach of reusing (and renaming) an existing ```.qpdata``` file. If you do this, I'd suggest trying to create one from any similar image you have that works - since it will also do things like set the image type (brightfield, fluorescence, stain colors...), and it makes sense to use values from related images rather than have to update them later. I always planned vaguely to make it possible to create a manual TMA grid, but the automated dearrayer never failed catastrophically enough on any image that I encountered to make this necessary; I only ever added/removed rows as needed. Nevertheless, in the absence of a user-friendly way to do something, it's generally possible to resort to a script. If you draw a rectangle around where the grid should be, you could try running this:. ```groovy; import qupath.lib.objects.TMACoreObject; import qupath.lib.objects.hierarchy.DefaultTMAGrid. // Enter the number of horizontal & vertical cores here; int numHorizontal = 12; int numVertical = 9; // Enter the core diameter, in millimetres; double diameterMM = 1.2. // Convert diameter to pixels; double diameterPixels = (diameterMM * 1000) / getCurrentImageData().getServer().getAveragedPixelSizeMicrons(). // Get the current ROI; def roi = getSelectedROI(). // Create the cores; def cores = []; double xSpacing = roi.getBoundsWidth() / numHorizontal; double ySpacing = roi.getBoundsHeight() / numVertical; for (int i = 0; i < numVertical; i++) {; for (int j = 0; j < numHorizontal; j++) {; double x = roi.getBoundsX() + xSpacing / 2 + xSpacing * j; double y = roi.getBoundsY() + ySpacing / 2 + ySpacing * i; cores << new TMACoreObject(x, y, diameterPixels, false); }; }. // Create & set the grid; def tmaGrid = new DefaultTMAGrid(cores, numHorizontal); getCurrentHierarchy().setTMAGrid(tmaGrid); ```. Note that there are a few variables at the top that should be specified (i.e. the number of cores horizontally and vertically, and the an",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-301234930
https://github.com/qupath/qupath/issues/77#issuecomment-411736289:32,Performance,load,loading,32,"So just to complete the story:; loading a pre-defined array map worked, but was a bit tedious. I eventually discovered taht the reason most maps were failing is bc the image was loading in hdab instead of h&e. once I switched to H&E it almost always was workable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-411736289
https://github.com/qupath/qupath/issues/77#issuecomment-411736289:178,Performance,load,loading,178,"So just to complete the story:; loading a pre-defined array map worked, but was a bit tedious. I eventually discovered taht the reason most maps were failing is bc the image was loading in hdab instead of h&e. once I switched to H&E it almost always was workable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-411736289
https://github.com/qupath/qupath/issues/77#issuecomment-411738253:15,Deployability,update,update,15,"Thanks for the update. I don't think that can be the explanation because (as best I recall, and from rechecking the code briefly) there is no difference in how the dearrayer handles H-DAB or H&E, although there is definitely a difference in how it handles fluorescence vs. everything else - and the initial size estimate for each core is critical. But good that it can be worked out one way or another.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/77#issuecomment-411738253
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:111,Availability,down,down,111,"I have seen the tiny rectangle appear whenever I use the brush tool in 'subtract' mode (with the ```Alt``` key down), and remove the entire area. However, in that case it is just a display thing - and the rectangle quickly disappears. But based on your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give thi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1658,Deployability,release,release,1658," - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful to create your own script/extension to handle your specific needs. To do this, I'd suggest looking into [PathROIToolsAwt.java](https://github.com/qupath/qupath/blob/a3e9246640f9819701d57c513bb21a0546cff130/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java) - specifically ```getArea(ROI roi)``` and ```getShapeROI(...)```. The first of these can convert a QuPath ROI into a [```java.awt.geom.Area```](https://docs.oracle.com/javase/8/docs/api/java/awt/geom",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:805,Safety,sanity check,sanity check,805,"I have seen the tiny rectangle appear whenever I use the brush tool in 'subtract' mode (with the ```Alt``` key down), and remove the entire area. However, in that case it is just a display thing - and the rectangle quickly disappears. But based on your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give thi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1104,Safety,sanity check,sanity check,1104," entire area. However, in that case it is just a display thing - and the rectangle quickly disappears. But based on your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that hav",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1277,Safety,sanity check,sanity check,1277," your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1583,Safety,predict,predictably,1583,". What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful to create your own script/extension to handle your specific needs. To do this, I'd suggest looking into [PathROIToolsAwt.java](https://github.com/qupath/qupath/blob/a3e9246640f9819701d57c513bb21a0546cff130/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java) ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1332,Usability,clear,clear,1332,"ns*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful to create your own script/extension to handle your specific needs. To do this, I'd sug",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-302926092:2139,Usability,clear,clearly,2139,"m/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful to create your own script/extension to handle your specific needs. To do this, I'd suggest looking into [PathROIToolsAwt.java](https://github.com/qupath/qupath/blob/a3e9246640f9819701d57c513bb21a0546cff130/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java) - specifically ```getArea(ROI roi)``` and ```getShapeROI(...)```. The first of these can convert a QuPath ROI into a [```java.awt.geom.Area```](https://docs.oracle.com/javase/8/docs/api/java/awt/geom/Area.html). An ```Area``` has methods to add/subtract/intersect with other ```Area``` objects. Then you can use ```getShapeROI(...)``` to convert the result back into a QuPath ROI and create a new annotation if needed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092
https://github.com/qupath/qupath/issues/78#issuecomment-303464822:332,Availability,reliab,reliable,332,"Thanks Pete,. For the time being I've dealt with the multiple subtractions simply by adding all of the areas that need to be subtracted first. When things are passed in the right order things seem to work OK. I haven't looked through the code enough to understand if it's spurious or not yet, but locking also seems to make it more reliable. If it becomes an issue I'll dive a little deeper as you suggest. Besides occasionally having to learn some java-specific construction, I seem to be meandering through the code OK. . Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-303464822
https://github.com/qupath/qupath/issues/78#issuecomment-303464822:75,Usability,simpl,simply,75,"Thanks Pete,. For the time being I've dealt with the multiple subtractions simply by adding all of the areas that need to be subtracted first. When things are passed in the right order things seem to work OK. I haven't looked through the code enough to understand if it's spurious or not yet, but locking also seems to make it more reliable. If it becomes an issue I'll dive a little deeper as you suggest. Besides occasionally having to learn some java-specific construction, I seem to be meandering through the code OK. . Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-303464822
https://github.com/qupath/qupath/issues/78#issuecomment-303464822:438,Usability,learn,learn,438,"Thanks Pete,. For the time being I've dealt with the multiple subtractions simply by adding all of the areas that need to be subtracted first. When things are passed in the right order things seem to work OK. I haven't looked through the code enough to understand if it's spurious or not yet, but locking also seems to make it more reliable. If it becomes an issue I'll dive a little deeper as you suggest. Besides occasionally having to learn some java-specific construction, I seem to be meandering through the code OK. . Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-303464822
https://github.com/qupath/qupath/issues/79#issuecomment-305082313:1285,Safety,Detect,Detections,1285," I can't find it now. Anyway, rough workflow for me:; `def string = ""G:\\MyProjectData\\Data""; saveDetectionMeasurements(string, ); saveTMAMeasurements(string, ); saveAnnotationMeasurements(string, )`; I first use that script and edit it for whatever project I want to export from, then ""Run for project"" and select all of the slides. I specifically need the double slashes because I am running Windows. Once all of the annotation files are in one place, I use the following R code to merge it all into one .csv file, which I finally open in Excel, edit for clarity, and save. You may find it easier to edit the file names before running the R script, I usually use a bulk file rename utility.; ```; library(dplyr); library(readr); #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the ; #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; # and all subsequent blank names are part of the first listed file.; path = ""G:/MyProjectData/Data""; setwd(path); outFile <-""Tumor Assay Annotation measurements.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; Annotationfiles <- dir(path,pattern = "".txt""). #an empty frame to place data into; Measurements <- data.frame(); #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(Annotationfiles)){; data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); ; #place the file names in the first column; Sample = tools::file_path_sans_ext(Annotationfiles[i]); data.raw[1,2]<-Sample; Measurements<-bind_rows(Measurements, data.raw); ; ; }. #set row names to F if you don't want a numbered list as the first column; write.csv(Measurements, outFile, row.names=T); ```. I am not an expert R coder, so I am sure there are more elegant ways to accomplish this, but it works for me!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305082313
https://github.com/qupath/qupath/issues/79#issuecomment-305082313:1445,Usability,simpl,simple,1445," I can't find it now. Anyway, rough workflow for me:; `def string = ""G:\\MyProjectData\\Data""; saveDetectionMeasurements(string, ); saveTMAMeasurements(string, ); saveAnnotationMeasurements(string, )`; I first use that script and edit it for whatever project I want to export from, then ""Run for project"" and select all of the slides. I specifically need the double slashes because I am running Windows. Once all of the annotation files are in one place, I use the following R code to merge it all into one .csv file, which I finally open in Excel, edit for clarity, and save. You may find it easier to edit the file names before running the R script, I usually use a bulk file rename utility.; ```; library(dplyr); library(readr); #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the ; #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; # and all subsequent blank names are part of the first listed file.; path = ""G:/MyProjectData/Data""; setwd(path); outFile <-""Tumor Assay Annotation measurements.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; Annotationfiles <- dir(path,pattern = "".txt""). #an empty frame to place data into; Measurements <- data.frame(); #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(Annotationfiles)){; data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); ; #place the file names in the first column; Sample = tools::file_path_sans_ext(Annotationfiles[i]); data.raw[1,2]<-Sample; Measurements<-bind_rows(Measurements, data.raw); ; ; }. #set row names to F if you don't want a numbered list as the first column; write.csv(Measurements, outFile, row.names=T); ```. I am not an expert R coder, so I am sure there are more elegant ways to accomplish this, but it works for me!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305082313
https://github.com/qupath/qupath/issues/79#issuecomment-305188668:1456,Safety,Detect,Detections,1456," select all of the slides. I specifically; > need the double slashes because I am running Windows.; >; > Once all of the annotation files are in one place, I use the following R; > code to merge it all into one .csv file, which I finally open in Excel,; > edit for clarity, and save. You may find it easier to edit the file names; > before running the R script, I usually use a bulk file rename utility.; >; > library(dplyr); > library(readr); > #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the; > #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; > # and all subsequent blank names are part of the first listed file.; > path = ""G:/MyProjectData/Data""; > setwd(path); > outFile <-""Tumor Assay Annotation measurements.csv""; >; > #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; > Annotationfiles <- dir(path,pattern = "".txt""); >; > #an empty frame to place data into; > Measurements <- data.frame(); > #simple for loop to read each file and keep a sum of the cell areas.; > for(i in 1:length(Annotationfiles)){; > data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); >; > #place the file names in the first column; > Sample = tools::file_path_sans_ext(Annotationfiles[i]); > data.raw[1,2]<-Sample; > Measurements<-bind_rows(Measurements, data.raw); >; >; > }; >; >; > #set row names to F if you don't want a numbered list as the first column; > write.csv(Measurements, outFile, row.names=T); >; > I am not an expert R coder, so I am sure there are more elegant ways to; > accomplish this, but it works for me!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/79#issuecomment-305082313>, or mute; > the thread; > <https://github.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305188668
https://github.com/qupath/qupath/issues/79#issuecomment-305188668:1627,Usability,simpl,simple,1627,".; >; > Once all of the annotation files are in one place, I use the following R; > code to merge it all into one .csv file, which I finally open in Excel,; > edit for clarity, and save. You may find it easier to edit the file names; > before running the R script, I usually use a bulk file rename utility.; >; > library(dplyr); > library(readr); > #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the; > #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; > # and all subsequent blank names are part of the first listed file.; > path = ""G:/MyProjectData/Data""; > setwd(path); > outFile <-""Tumor Assay Annotation measurements.csv""; >; > #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; > Annotationfiles <- dir(path,pattern = "".txt""); >; > #an empty frame to place data into; > Measurements <- data.frame(); > #simple for loop to read each file and keep a sum of the cell areas.; > for(i in 1:length(Annotationfiles)){; > data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); >; > #place the file names in the first column; > Sample = tools::file_path_sans_ext(Annotationfiles[i]); > data.raw[1,2]<-Sample; > Measurements<-bind_rows(Measurements, data.raw); >; >; > }; >; >; > #set row names to F if you don't want a numbered list as the first column; > write.csv(Measurements, outFile, row.names=T); >; > I am not an expert R coder, so I am sure there are more elegant ways to; > accomplish this, but it works for me!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/79#issuecomment-305082313>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AOahf43f2DYdFuBphZbwRo5-pV-cstbAks5r_PHQgaJpZM4Nqs8V>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305188668
https://github.com/qupath/qupath/issues/80#issuecomment-305264373:208,Safety,Detect,Detection,208,"Could you post your workflow script? Farthest tab on the right (Workflow) should have a ""Create Script"" at the bottom which you can copy and paste here. I suppose a more specific question would be which Cell Detection you were using to get this result. (Cell detection+membrane comes to mind as having some odd behavior on certain types of background).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305264373
https://github.com/qupath/qupath/issues/80#issuecomment-305264373:259,Safety,detect,detection,259,"Could you post your workflow script? Farthest tab on the right (Workflow) should have a ""Create Script"" at the bottom which you can copy and paste here. I suppose a more specific question would be which Cell Detection you were using to get this result. (Cell detection+membrane comes to mind as having some odd behavior on certain types of background).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305264373
https://github.com/qupath/qupath/issues/80#issuecomment-305265833:88,Modifiability,variab,variability,88,"This was the WatershedCellDetection, for some reason, I have gotten this type of tiling variability on ~10% of my files. . setImageType('UNSET');; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 235, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runClassifier('/Users/elijahedmondson/Desktop/Projects/MetH/classifiers/MetH.qpclassifier');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305265833
https://github.com/qupath/qupath/issues/80#issuecomment-305265833:428,Safety,detect,detect,428,"This was the WatershedCellDetection, for some reason, I have gotten this type of tiling variability on ~10% of my files. . setImageType('UNSET');; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 235, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runClassifier('/Users/elijahedmondson/Desktop/Projects/MetH/classifiers/MetH.qpclassifier');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305265833
https://github.com/qupath/qupath/issues/80#issuecomment-305265833:788,Safety,detect,detect,788,"This was the WatershedCellDetection, for some reason, I have gotten this type of tiling variability on ~10% of my files. . setImageType('UNSET');; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 235, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runClassifier('/Users/elijahedmondson/Desktop/Projects/MetH/classifiers/MetH.qpclassifier');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305265833
https://github.com/qupath/qupath/issues/80#issuecomment-305265833:830,Safety,detect,detectionImageBrightfield,830,"This was the WatershedCellDetection, for some reason, I have gotten this type of tiling variability on ~10% of my files. . setImageType('UNSET');; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 235, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runClassifier('/Users/elijahedmondson/Desktop/Projects/MetH/classifiers/MetH.qpclassifier');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305265833
https://github.com/qupath/qupath/issues/80#issuecomment-305266246:126,Availability,error,error,126,"I ramp the ""backgroundRadiusMicrons"" up to 50; this is much higher than the preset so I will play with this a bit more. . The error seems to only affect tiles that are along the periphery (i.e., tiles that are only partially complete).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305266246
https://github.com/qupath/qupath/issues/80#issuecomment-305385370:950,Integrability,Depend,Depending,950,"Yes, the trouble comes from the background estimate whenever a large region is broken up into tiles for processing. The technique QuPath is using to estimate the background is 'opening by reconstruction'; this starts out by estimating the background locally for every pixel, and then propagating this information throughout the tile. The propagation is helpful most of the time, since this handles cases where there may be quite a lot of texture in the background quite well; and usually it doesn't propagate very far. But it's not helpful all of the time... particularly where there are substantial differences in the amount of 'background' (or staining outside nuclei) within tiles and between neighboring tiles. So my suggestion would also be to either set the background radius very high, or set it to zero to turn off background estimation entirely. The second option is likely better if you can still find nucleus detection settings that work. Depending upon what you want to do next, you might also try the 'Fast cell counts' command. It is much simpler and does not provide nearly so much information, but it also does not handle background in the same way.... so gives an alternative.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305385370
https://github.com/qupath/qupath/issues/80#issuecomment-305385370:920,Safety,detect,detection,920,"Yes, the trouble comes from the background estimate whenever a large region is broken up into tiles for processing. The technique QuPath is using to estimate the background is 'opening by reconstruction'; this starts out by estimating the background locally for every pixel, and then propagating this information throughout the tile. The propagation is helpful most of the time, since this handles cases where there may be quite a lot of texture in the background quite well; and usually it doesn't propagate very far. But it's not helpful all of the time... particularly where there are substantial differences in the amount of 'background' (or staining outside nuclei) within tiles and between neighboring tiles. So my suggestion would also be to either set the background radius very high, or set it to zero to turn off background estimation entirely. The second option is likely better if you can still find nucleus detection settings that work. Depending upon what you want to do next, you might also try the 'Fast cell counts' command. It is much simpler and does not provide nearly so much information, but it also does not handle background in the same way.... so gives an alternative.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305385370
https://github.com/qupath/qupath/issues/80#issuecomment-305385370:1053,Usability,simpl,simpler,1053,"Yes, the trouble comes from the background estimate whenever a large region is broken up into tiles for processing. The technique QuPath is using to estimate the background is 'opening by reconstruction'; this starts out by estimating the background locally for every pixel, and then propagating this information throughout the tile. The propagation is helpful most of the time, since this handles cases where there may be quite a lot of texture in the background quite well; and usually it doesn't propagate very far. But it's not helpful all of the time... particularly where there are substantial differences in the amount of 'background' (or staining outside nuclei) within tiles and between neighboring tiles. So my suggestion would also be to either set the background radius very high, or set it to zero to turn off background estimation entirely. The second option is likely better if you can still find nucleus detection settings that work. Depending upon what you want to do next, you might also try the 'Fast cell counts' command. It is much simpler and does not provide nearly so much information, but it also does not handle background in the same way.... so gives an alternative.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305385370
https://github.com/qupath/qupath/issues/81#issuecomment-307854757:1490,Integrability,depend,dependencies,1490,"d complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to construct the ```PolygonROI```) from a String you might use this:. ```groovy; String inputString = ""1.0, 2.0, 3.0, 4.0, 50.0""; float[] x = inputString.tokenize(',') as float[]; print x; ```. Finally, I should mention that the coordinates should be in pixel units corresponding to the highest-resolution plane in your SVS file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757
https://github.com/qupath/qupath/issues/81#issuecomment-307854757:179,Security,access,accessible,179,"This is certainly possible, although will involve writing some Python and/or Groovy code. The basic process is:. 1. Get your contours (somehow) into arrays of x and y coordinates accessible to QuPath. 2. Create ```PolygonROI``` objects from each pair of coordinate arrays. If polygons are not sufficient, and you rather need complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to cons",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757
https://github.com/qupath/qupath/issues/81#issuecomment-307854757:1513,Security,access,accessible,1513,"d complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to construct the ```PolygonROI```) from a String you might use this:. ```groovy; String inputString = ""1.0, 2.0, 3.0, 4.0, 50.0""; float[] x = inputString.tokenize(',') as float[]; print x; ```. Finally, I should mention that the coordinates should be in pixel units corresponding to the highest-resolution plane in your SVS file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757
https://github.com/qupath/qupath/issues/81#issuecomment-307854757:1545,Usability,simpl,simple,1545,"d complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to construct the ```PolygonROI```) from a String you might use this:. ```groovy; String inputString = ""1.0, 2.0, 3.0, 4.0, 50.0""; float[] x = inputString.tokenize(',') as float[]; print x; ```. Finally, I should mention that the coordinates should be in pixel units corresponding to the highest-resolution plane in your SVS file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757
https://github.com/qupath/qupath/issues/81#issuecomment-307854757:1627,Usability,simpl,simple,1627,"d complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to construct the ```PolygonROI```) from a String you might use this:. ```groovy; String inputString = ""1.0, 2.0, 3.0, 4.0, 50.0""; float[] x = inputString.tokenize(',') as float[]; print x; ```. Finally, I should mention that the coordinates should be in pixel units corresponding to the highest-resolution plane in your SVS file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757
https://github.com/qupath/qupath/issues/81#issuecomment-356740194:256,Performance,perform,performance,256,"@ElEd2 Thank you for the scripts! I'll be using them once I figure out how to use the groovy code. Quick question: In my case, I have contours for the entire slide area. This means millions of vertices if I output everything naively. Do you experience any performance issues with loading or zooming in your case?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-356740194
https://github.com/qupath/qupath/issues/81#issuecomment-356740194:280,Performance,load,loading,280,"@ElEd2 Thank you for the scripts! I'll be using them once I figure out how to use the groovy code. Quick question: In my case, I have contours for the entire slide area. This means millions of vertices if I output everything naively. Do you experience any performance issues with loading or zooming in your case?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-356740194
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1438,Energy Efficiency,reduce,reduce,1438,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:68,Performance,perform,performance,68,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:855,Performance,perform,perform,855,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1009,Performance,perform,perform,1009,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1555,Performance,cache,cached,1555,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:2458,Performance,bottleneck,bottleneck,2458,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:358,Safety,detect,detections,358,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1293,Safety,detect,detection,1293,"'s a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeS",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1404,Safety,detect,detection,1404,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1745,Safety,detect,detection,1745,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1837,Safety,avoid,avoid,1837,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1043,Usability,clear,clearAllObjects,1043,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1424,Usability,simpl,simplified,1424,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1910,Usability,simpl,simplification,1910,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/81#issuecomment-357045269:2063,Usability,simpl,simplifyPolygon,2063,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269
https://github.com/qupath/qupath/issues/82#issuecomment-314169636:75,Energy Efficiency,reduce,reduce,75,This isn't a bug - by default annotations created this way are 'locked' to reduce the risk of editing them accidentally. There is some more information about locking [here](https://github.com/qupath/qupath/wiki/Working-with-objects#editing--locking-objects). You can right-click on the image and choose *Annotations &rarr; Unlock* if you need to be able to edit a locked annotation.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/82#issuecomment-314169636
https://github.com/qupath/qupath/issues/82#issuecomment-314169636:86,Safety,risk,risk,86,This isn't a bug - by default annotations created this way are 'locked' to reduce the risk of editing them accidentally. There is some more information about locking [here](https://github.com/qupath/qupath/wiki/Working-with-objects#editing--locking-objects). You can right-click on the image and choose *Annotations &rarr; Unlock* if you need to be able to edit a locked annotation.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/82#issuecomment-314169636
https://github.com/qupath/qupath/issues/83#issuecomment-314861290:104,Safety,detect,detection,104,"The other option, if the stain is overlapping the nucleus significantly, is to just use the subcellular detection tool (again with a smaller cell expansion), and set a threshold based on the amount of area that shows up ""pink.""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/83#issuecomment-314861290
https://github.com/qupath/qupath/issues/83#issuecomment-315138503:815,Usability,simpl,simple,815,"I completely understand, and don't really need more details beyond that snapshot, though I will have to make a few guesses without the Workflow script. You should be able to do that with just the red OD in a narrow cytoplasmic band around the nucleus, as mentioned before. I would definitely use the _Analyze -> preprocessing-> estimate stain vectors_ to get the best estimate of the red that you are looking for. Another way is to draw a very small box around some of the red you want to find (make sure you keep that box selected), and then double click on the stain vector you want to set in the Image tab on the left. You should get a popup, ""Set new stain vector from ROI?"". You will have to generate your cells again once you have the stain vectors set correctly, but once you do, you should be able to use a simple one step script to find positivity. . setCellIntensityClassifications(""Cytoplasm: DAB OD mean"", 0.15). Just place that in a script window and run it, but replace DAB with whatever the color vector is for your ""Red."" And you can just rename it red in the same Image tab from before. The 0.15 can be whatever cutoff you find works for your data, and I prefer to use the heatmaps from _Measure-> Show measurement maps_ for this purpose. Side note, you can use the _Positive cell detection_ for this purpose once you have determined what you want your cutoff to be, but you need to make sure you keep the color vector name as ""DAB.""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/83#issuecomment-315138503
https://github.com/qupath/qupath/issues/84#issuecomment-315304305:117,Deployability,update,update,117,Thank you for the tips. I'm using JIdea for the compilation but I will have a look at the Eclipse page above. I will update the thread once I get it working.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315304305
https://github.com/qupath/qupath/issues/84#issuecomment-315733313:76,Integrability,depend,dependencies,76,I'm still debugging but there seems to be at least on issue with one of the dependencies. org.slf4j. it's not among the sources and it is not described in the POM file for Maven neither.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315733313
https://github.com/qupath/qupath/issues/84#issuecomment-315890621:66,Deployability,install,installed,66,beside the library above there was also javax.script that was not installed properly. After adding two entries for the lib above with the last version of github I could run it in debug mode with JIdea and then create a single JAR including all jar files. . Somehow (maybe because of Intelli JIdea) the target version of interpreter and java compiler did not match. I had to change for all the different modules to 1.8. . The ant build did not work but finally the jar file is fine for our needs. Somehow it is also much smaller then the Windows install. It makes about 30MB instead of 300MB for the windows install but maybe there is some lib I didn't include. Anyway If something comes up will update the thread.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315890621
https://github.com/qupath/qupath/issues/84#issuecomment-315890621:545,Deployability,install,install,545,beside the library above there was also javax.script that was not installed properly. After adding two entries for the lib above with the last version of github I could run it in debug mode with JIdea and then create a single JAR including all jar files. . Somehow (maybe because of Intelli JIdea) the target version of interpreter and java compiler did not match. I had to change for all the different modules to 1.8. . The ant build did not work but finally the jar file is fine for our needs. Somehow it is also much smaller then the Windows install. It makes about 30MB instead of 300MB for the windows install but maybe there is some lib I didn't include. Anyway If something comes up will update the thread.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315890621
https://github.com/qupath/qupath/issues/84#issuecomment-315890621:607,Deployability,install,install,607,beside the library above there was also javax.script that was not installed properly. After adding two entries for the lib above with the last version of github I could run it in debug mode with JIdea and then create a single JAR including all jar files. . Somehow (maybe because of Intelli JIdea) the target version of interpreter and java compiler did not match. I had to change for all the different modules to 1.8. . The ant build did not work but finally the jar file is fine for our needs. Somehow it is also much smaller then the Windows install. It makes about 30MB instead of 300MB for the windows install but maybe there is some lib I didn't include. Anyway If something comes up will update the thread.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315890621
https://github.com/qupath/qupath/issues/84#issuecomment-315890621:695,Deployability,update,update,695,beside the library above there was also javax.script that was not installed properly. After adding two entries for the lib above with the last version of github I could run it in debug mode with JIdea and then create a single JAR including all jar files. . Somehow (maybe because of Intelli JIdea) the target version of interpreter and java compiler did not match. I had to change for all the different modules to 1.8. . The ant build did not work but finally the jar file is fine for our needs. Somehow it is also much smaller then the Windows install. It makes about 30MB instead of 300MB for the windows install but maybe there is some lib I didn't include. Anyway If something comes up will update the thread.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-315890621
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:2200,Availability,down,download,2200,"installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:2903,Availability,down,downloading,2903,"ath, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes it easier to use different IDEs. The combination of Java 8, JavaFX, Maven, Ant and native libraries makes it more difficult than a project using Java alone, and there wasn't previously a critical need. Still, the portability is something that I hope will be improved in the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:389,Deployability,update,updated,389,"I've only set up the entire project with Eclipse, using the approach briefly described at https://github.com/qupath/qupath/tree/v0.1.2/src/main/resources/eclipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1147,Deployability,install,installer,1147,"clipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you w",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1199,Deployability,install,installed,1199,"clipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you w",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:2302,Deployability,install,install,2302,"thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes it easier to use different IDEs. The combination of Java 8, JavaFX, Maven, Ant and native libraries makes it more difficult than a project using Java alone, and there wasn't previously a critical need. Still, the portability",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:2886,Deployability,install,installation,2886,"ath, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes it easier to use different IDEs. The combination of Java 8, JavaFX, Maven, Ant and native libraries makes it more difficult than a project using Java alone, and there wasn't previously a critical need. Still, the portability is something that I hope will be improved in the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:750,Integrability,depend,dependency,750,"I've only set up the entire project with Eclipse, using the approach briefly described at https://github.com/qupath/qupath/tree/v0.1.2/src/main/resources/eclipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:702,Modifiability,inherit,inherited,702,"I've only set up the entire project with Eclipse, using the approach briefly described at https://github.com/qupath/qupath/tree/v0.1.2/src/main/resources/eclipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1328,Modifiability,config,configuring,1328,". For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:3412,Modifiability,portab,portability,3412,"ath, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes it easier to use different IDEs. The combination of Java 8, JavaFX, Maven, Ant and native libraries makes it more difficult than a project using Java alone, and there wasn't previously a critical need. Still, the portability is something that I hope will be improved in the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1536,Security,access,access,1536,"cend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1799,Security,access,accessible,1799,"specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:2400,Security,access,accessing,2400,"thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as QuPath can find the Bio-Formats jar file. Still, you won't be able to use OpenSlide or any commands reliant on OpenCV (including the Wand tool). The easiest way to get the native libraries to work is generally to copy them to the directory from which you run the application in the first place. You should be able to find the libraries by looking within an existing QuPath installation, or downloading the binaries for Windows from the OpenSlide/OpenCV websites. But for running from within an IDE, I have only set this up with Eclipse to date and don't know the specifics of getting it to work elsewhere. Finally, I've no doubt that the project could be structured in a way that makes it easier to use different IDEs. The combination of Java 8, JavaFX, Maven, Ant and native libraries makes it more difficult than a project using Java alone, and there wasn't previously a critical need. Still, the portability",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:764,Testability,log,logback-classic,764,"I've only set up the entire project with Eclipse, using the approach briefly described at https://github.com/qupath/qupath/tree/v0.1.2/src/main/resources/eclipse - I'm afraid I don't know how to address the issues when using other IDE's.; (Incidentally, those instructions are a little old now, not all steps may be necessary. For example, from memory I think only the .project file needs updated, not the .classpath file.). However, here are some notes that might be helpful:. * Most of the POM files should descend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1497,Testability,test,test,1497,"cend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735
https://github.com/qupath/qupath/issues/85#issuecomment-315148256:262,Energy Efficiency,adapt,adapted,262,"I think the short answer is yes, but actually doing it might be a little more complicated. I will need to dig through some code to see if there is an easy way to do this, but the following can be used to export the entire image as TIFF files. I assume it can be adapted to just target TMA cores.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148256
https://github.com/qupath/qupath/issues/85#issuecomment-315148256:262,Modifiability,adapt,adapted,262,"I think the short answer is yes, but actually doing it might be a little more complicated. I will need to dig through some code to see if there is an easy way to do this, but the following can be used to export the entire image as TIFF files. I assume it can be adapted to just target TMA cores.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148256
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1037,Availability,down,downsample,1037," each tile as a separate image.; *; * Two things are notable about this script:; * - The location from which each tile was obtained (in terms of pixel values in the full-resolution image); * is encoded in the filename; * - ImageJ is used to write the output images; *; * The significance of using ImageJ to write TIFF images (rather than, say, ImageIO to write PNGs or JPEGs); * is that this enables the storage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeS",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1056,Availability,Down,Downsampling,1056," each tile as a separate image.; *; * Two things are notable about this script:; * - The location from which each tile was obtained (in terms of pixel values in the full-resolution image); * is encoded in the filename; * - ImageJ is used to write the output images; *; * The significance of using ImageJ to write TIFF images (rather than, say, ImageIO to write PNGs or JPEGs); * is that this enables the storage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeS",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1330,Availability,error,errors,1330,"the output images; *; * The significance of using ImageJ to write TIFF images (rather than, say, ImageIO to write PNGs or JPEGs); * is that this enables the storage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.ge",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1599,Availability,error,errors,1599,"rage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1831,Availability,error,error,1831,"mage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:2416,Availability,down,downsample,2416,"a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:2467,Availability,down,downsample,2467,"a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:2914,Availability,down,downsample,2914,"rentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:3323,Availability,down,downsample,3323,"serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceede",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:3421,Availability,down,downsample,3421,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:3894,Availability,down,downsample,3894,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:4225,Availability,error,errors,4225,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:4316,Availability,error,errors,4316,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1793,Modifiability,variab,variable,1793,".regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:2279,Modifiability,variab,variables,2279,"!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1343,Safety,avoid,avoid,1343,"rage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1514,Safety,avoid,avoid,1514,"rage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315148862:4334,Safety,abort,aborting,4334,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862
https://github.com/qupath/qupath/issues/85#issuecomment-315177285:92,Availability,down,down,92,"Actually, I was just reminded that there was another topic that handled this, if you scroll down to 4 in Peter's response. It has a macro you can run through the _Extensions -> ImageJ macro runner_ . That may be much more in line with what you are looking for.; https://github.com/qupath/qupath/issues/57",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315177285
https://github.com/qupath/qupath/issues/85#issuecomment-317354440:976,Availability,Down,Downsample,976,"I would definitely recommend doing the export with ImageJ if you can, using the [ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) and a very simple ImageJ macro like this one. ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```. You'll need to make sure that the export directory exists before running it. Still, if you do it this way then if you open the resulting TIFF within ImageJ you should find that the pixel sizes are preserved - and even the information regarding where in the image the region was taken (look under *Image &rarr; Properties* in ImageJ). This isn't stored if you export in any other format (e.g. PNG, JPEG). Even if you don't need it currently, this at least gives the possibility that you could relate any detected regions etc. that come from processing the TIFF back to where they came from in the original, whole slide image. You can also modify the export resolution by changing the 'Downsample factor' in the macro runner.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-317354440
https://github.com/qupath/qupath/issues/85#issuecomment-317354440:795,Safety,detect,detected,795,"I would definitely recommend doing the export with ImageJ if you can, using the [ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) and a very simple ImageJ macro like this one. ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```. You'll need to make sure that the export directory exists before running it. Still, if you do it this way then if you open the resulting TIFF within ImageJ you should find that the pixel sizes are preserved - and even the information regarding where in the image the region was taken (look under *Image &rarr; Properties* in ImageJ). This isn't stored if you export in any other format (e.g. PNG, JPEG). Even if you don't need it currently, this at least gives the possibility that you could relate any detected regions etc. that come from processing the TIFF back to where they came from in the original, whole slide image. You can also modify the export resolution by changing the 'Downsample factor' in the macro runner.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-317354440
https://github.com/qupath/qupath/issues/85#issuecomment-317354440:187,Usability,simpl,simple,187,"I would definitely recommend doing the export with ImageJ if you can, using the [ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) and a very simple ImageJ macro like this one. ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```. You'll need to make sure that the export directory exists before running it. Still, if you do it this way then if you open the resulting TIFF within ImageJ you should find that the pixel sizes are preserved - and even the information regarding where in the image the region was taken (look under *Image &rarr; Properties* in ImageJ). This isn't stored if you export in any other format (e.g. PNG, JPEG). Even if you don't need it currently, this at least gives the possibility that you could relate any detected regions etc. that come from processing the TIFF back to where they came from in the original, whole slide image. You can also modify the export resolution by changing the 'Downsample factor' in the macro runner.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-317354440
https://github.com/qupath/qupath/issues/86#issuecomment-316571471:144,Performance,load,load,144,"While I can't guarantee it isn't crashing, it also is likely that it only seems like it is crashing because the hierarchy is often VERY slow to load. If one CPU core is still chugging away, it might come back in a few hours. Some more information may be found here:; https://github.com/qupath/qupath/issues/41",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/86#issuecomment-316571471
https://github.com/qupath/qupath/issues/86#issuecomment-317358116:806,Performance,perform,performance,806,"I've flagged this as a duplicate, since it sounds the same as the issue linked to by @Svidro. I've given the details there, and potential direction for how it might be addressed in the long term. In this case, it might be possible to improve matters by ensuring that all entries in the 'hierarchy' tab are first closed - or that there are no child objects. Then the results in the annotation table can be sorted by area, and all the top entries (with low areas) selected in one go. In the longer term, the better way to handle this would be to write a script that finds all the annotations with an area below a specified threshold, and removes them directly from the object hierarchy. Using a script it is possible to avoid the need for selecting the annotations in the GUI entirely, and get *much* better performance. Clearly this is a bit more work to begin with, but I highly recommend working through the scripting parts on the Wiki if you haven't done so already - this is the kind of application where scripting can be invaluable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/86#issuecomment-317358116
https://github.com/qupath/qupath/issues/86#issuecomment-317358116:718,Safety,avoid,avoid,718,"I've flagged this as a duplicate, since it sounds the same as the issue linked to by @Svidro. I've given the details there, and potential direction for how it might be addressed in the long term. In this case, it might be possible to improve matters by ensuring that all entries in the 'hierarchy' tab are first closed - or that there are no child objects. Then the results in the annotation table can be sorted by area, and all the top entries (with low areas) selected in one go. In the longer term, the better way to handle this would be to write a script that finds all the annotations with an area below a specified threshold, and removes them directly from the object hierarchy. Using a script it is possible to avoid the need for selecting the annotations in the GUI entirely, and get *much* better performance. Clearly this is a bit more work to begin with, but I highly recommend working through the scripting parts on the Wiki if you haven't done so already - this is the kind of application where scripting can be invaluable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/86#issuecomment-317358116
https://github.com/qupath/qupath/issues/86#issuecomment-317358116:819,Usability,Clear,Clearly,819,"I've flagged this as a duplicate, since it sounds the same as the issue linked to by @Svidro. I've given the details there, and potential direction for how it might be addressed in the long term. In this case, it might be possible to improve matters by ensuring that all entries in the 'hierarchy' tab are first closed - or that there are no child objects. Then the results in the annotation table can be sorted by area, and all the top entries (with low areas) selected in one go. In the longer term, the better way to handle this would be to write a script that finds all the annotations with an area below a specified threshold, and removes them directly from the object hierarchy. Using a script it is possible to avoid the need for selecting the annotations in the GUI entirely, and get *much* better performance. Clearly this is a bit more work to begin with, but I highly recommend working through the scripting parts on the Wiki if you haven't done so already - this is the kind of application where scripting can be invaluable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/86#issuecomment-317358116
https://github.com/qupath/qupath/issues/87#issuecomment-316820068:252,Availability,error,error,252,Thanks for the reply. I think I actually figured out why it wasn't working before. The refresh method's accessibility was changed in javafx from Java 8u60 and onwards. I didn't realize but I was running an older JRE on Eclipse and thus the compilation error.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/87#issuecomment-316820068
https://github.com/qupath/qupath/issues/87#issuecomment-316820068:104,Security,access,accessibility,104,Thanks for the reply. I think I actually figured out why it wasn't working before. The refresh method's accessibility was changed in javafx from Java 8u60 and onwards. I didn't realize but I was running an older JRE on Eclipse and thus the compilation error.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/87#issuecomment-316820068
https://github.com/qupath/qupath/issues/88#issuecomment-318422764:9,Usability,clear,clear,9,"It's not clear that there is any bug here. Equally-spaced vertical lines can be common artefact of the scanning process. They may be sufficiently subtle not to be evident when looking at the image directly, but result in misclassifications - which then carry through when converting tiles to annotations. The solution is to spend more time training the classifier/provide additional features to the classifier. By playing around with the brightness/contrast to extreme levels you may see that the lines in your example correspond to lines in the original scanned slide. I will close this issue for now. If this explanation is wrong and you observe a problem with 'Tile classifications to annotations' that is not due to the tile classifications, please provide more detail - and ideally a way to replicate the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/88#issuecomment-318422764
https://github.com/qupath/qupath/issues/89#issuecomment-320290057:172,Integrability,Depend,Depending,172,"Aside from altering the code and recompiling, I don't think there is any easy way to change the tiling size, but you may be able to script merging the correct annotations. Depending on your sample, you might check annotations of the same class with centroids within a certain distance of each other, and select and merge them if they are close enough together. If you are going to merge all of the data later on, you can also just select all ""stroma"" (or whatever class) annotations and merge them with a two line script:; ```; selectObjects { p -> p.getPathClass() == getPathClass(""Stroma"") }; mergeSelectedAnnotations(); ```. Pete might have some better ideas, but that's the best I have got based on the description!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/89#issuecomment-320290057
https://github.com/qupath/qupath/issues/91#issuecomment-321321549:95,Modifiability,plugin,plugins,95,"Ah.... so am I. It seems to be a bug if the directory isn't set. However, you can also set the plugins directory through *Edit &rarr; Preferences...* - type ImageJ into the search box, and the option should appear. Double-click on the text entry box to be able to choose the directory. Once you do that, *Edit &rarr; ImageJ &rarr; Set ImageJ plugins directory* should work again. That appears to work for me, and avoids the bug.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/91#issuecomment-321321549
https://github.com/qupath/qupath/issues/91#issuecomment-321321549:342,Modifiability,plugin,plugins,342,"Ah.... so am I. It seems to be a bug if the directory isn't set. However, you can also set the plugins directory through *Edit &rarr; Preferences...* - type ImageJ into the search box, and the option should appear. Double-click on the text entry box to be able to choose the directory. Once you do that, *Edit &rarr; ImageJ &rarr; Set ImageJ plugins directory* should work again. That appears to work for me, and avoids the bug.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/91#issuecomment-321321549
https://github.com/qupath/qupath/issues/91#issuecomment-321321549:413,Safety,avoid,avoids,413,"Ah.... so am I. It seems to be a bug if the directory isn't set. However, you can also set the plugins directory through *Edit &rarr; Preferences...* - type ImageJ into the search box, and the option should appear. Double-click on the text entry box to be able to choose the directory. Once you do that, *Edit &rarr; ImageJ &rarr; Set ImageJ plugins directory* should work again. That appears to work for me, and avoids the bug.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/91#issuecomment-321321549
https://github.com/qupath/qupath/issues/92#issuecomment-322861341:341,Usability,undo,undo,341,"Does *File &rarr; Export snapshot... &rarr; Viewer snapshot* do what you need? This corresponds to *Edit &rarr; Copy view to clipboard*. If more control is needed, there's also an export script [here](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d) that may be useful as a starting point. With regard to (the lack of) undo, *File &rarr; Revert* is likely to be the best option to go back to the last saved version. With the help of shortcuts, you may press *Ctrl + S* to save regularly and then *Ctrl + R* to go back one step. The *backspace* key can also be used to quickly remove an accidentally-drawn annotation. *Objects &rarr; Transfer last annotation* (*Shift + E*) can also help sometimes in an emergency... although it only has a very short memory.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/92#issuecomment-322861341
https://github.com/qupath/qupath/pull/93#issuecomment-323493294:60,Availability,down,downsampling,60,"That sounds much easier, once integrated, than my method of downsampling the whole image to a size where I could submit it to ImageJ, greyscaling a merged image of the channels, and then sending back the annotation region! I haven't tested it yet, but can it work on multiple channels at once?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323493294
https://github.com/qupath/qupath/pull/93#issuecomment-323493294:30,Deployability,integrat,integrated,30,"That sounds much easier, once integrated, than my method of downsampling the whole image to a size where I could submit it to ImageJ, greyscaling a merged image of the channels, and then sending back the annotation region! I haven't tested it yet, but can it work on multiple channels at once?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323493294
https://github.com/qupath/qupath/pull/93#issuecomment-323493294:30,Integrability,integrat,integrated,30,"That sounds much easier, once integrated, than my method of downsampling the whole image to a size where I could submit it to ImageJ, greyscaling a merged image of the channels, and then sending back the annotation region! I haven't tested it yet, but can it work on multiple channels at once?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323493294
https://github.com/qupath/qupath/pull/93#issuecomment-323493294:233,Testability,test,tested,233,"That sounds much easier, once integrated, than my method of downsampling the whole image to a size where I could submit it to ImageJ, greyscaling a merged image of the channels, and then sending back the annotation region! I haven't tested it yet, but can it work on multiple channels at once?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323493294
https://github.com/qupath/qupath/pull/93#issuecomment-323671758:134,Availability,error,errors,134,"Hi again! I finally went and edited the changes into my code in Eclipse, and while the channel option shows up and does not cause any errors, I am not seeing the channel change have any effect on the result. Has anyone else tested this and had it work? I am not sure if I am doing something wrong or missed something. I tried it with a few files from the OpenSlide site, like Mirax2-Fluorescence-1.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323671758
https://github.com/qupath/qupath/pull/93#issuecomment-323671758:224,Testability,test,tested,224,"Hi again! I finally went and edited the changes into my code in Eclipse, and while the channel option shows up and does not cause any errors, I am not seeing the channel change have any effect on the result. Has anyone else tested this and had it work? I am not sure if I am doing something wrong or missed something. I tried it with a few files from the OpenSlide site, like Mirax2-Fluorescence-1.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323671758
https://github.com/qupath/qupath/pull/93#issuecomment-323689007:73,Usability,learn,learn,73,"Ah, apparently the channel swap doesn't apply to 8bit images! So much to learn.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323689007
https://github.com/qupath/qupath/pull/93#issuecomment-323765300:556,Modifiability,plugin,plugin,556,"Hi. the channel selection works by using the setC method on an ImagePlus, so it; would work whenever the image is recognized as a ""composite"" or a; ""hyperstack"". It should work with 8-bit, provided the image at that point; is seen as a composite or a hyperstack. The call to setC needs to be made; before the getByteProcessor call. In particular, it does not work with RGB; images, in the sense that RGB images are not composite/hyperstack by; default, so the setC would have no effect. The way around it is to precede; the call to setC with a call to ""ij.plugin.CompositeConverter.makeComposite; <https://imagej.nih.gov/ij/developer/api/ij/plugin/CompositeConverter.html>"",; to convert it to a Composite image. I can add a check and the call to; compositeconverter. Cheers; Thomas. On 21 August 2017 at 04:06, Svidro <notifications@github.com> wrote:. > Ah, apparently the channel swap doesn't apply to 8bit images! So much to; > learn.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/pull/93#issuecomment-323689007>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ADypF7vsElQOkcgKk7jpveApPbREBIRCks5saUiPgaJpZM4O8C04>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323765300
https://github.com/qupath/qupath/pull/93#issuecomment-323765300:641,Modifiability,plugin,plugin,641,"Hi. the channel selection works by using the setC method on an ImagePlus, so it; would work whenever the image is recognized as a ""composite"" or a; ""hyperstack"". It should work with 8-bit, provided the image at that point; is seen as a composite or a hyperstack. The call to setC needs to be made; before the getByteProcessor call. In particular, it does not work with RGB; images, in the sense that RGB images are not composite/hyperstack by; default, so the setC would have no effect. The way around it is to precede; the call to setC with a call to ""ij.plugin.CompositeConverter.makeComposite; <https://imagej.nih.gov/ij/developer/api/ij/plugin/CompositeConverter.html>"",; to convert it to a Composite image. I can add a check and the call to; compositeconverter. Cheers; Thomas. On 21 August 2017 at 04:06, Svidro <notifications@github.com> wrote:. > Ah, apparently the channel swap doesn't apply to 8bit images! So much to; > learn.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/pull/93#issuecomment-323689007>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ADypF7vsElQOkcgKk7jpveApPbREBIRCks5saUiPgaJpZM4O8C04>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323765300
https://github.com/qupath/qupath/pull/93#issuecomment-323765300:931,Usability,learn,learn,931,"Hi. the channel selection works by using the setC method on an ImagePlus, so it; would work whenever the image is recognized as a ""composite"" or a; ""hyperstack"". It should work with 8-bit, provided the image at that point; is seen as a composite or a hyperstack. The call to setC needs to be made; before the getByteProcessor call. In particular, it does not work with RGB; images, in the sense that RGB images are not composite/hyperstack by; default, so the setC would have no effect. The way around it is to precede; the call to setC with a call to ""ij.plugin.CompositeConverter.makeComposite; <https://imagej.nih.gov/ij/developer/api/ij/plugin/CompositeConverter.html>"",; to convert it to a Composite image. I can add a check and the call to; compositeconverter. Cheers; Thomas. On 21 August 2017 at 04:06, Svidro <notifications@github.com> wrote:. > Ah, apparently the channel swap doesn't apply to 8bit images! So much to; > learn.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/pull/93#issuecomment-323689007>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ADypF7vsElQOkcgKk7jpveApPbREBIRCks5saUiPgaJpZM4O8C04>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-323765300
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:1590,Deployability,integrat,integrate,1590,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:1620,Deployability,update,update,1620,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:1590,Integrability,integrat,integrate,1590,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:677,Safety,detect,detection,677,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:792,Safety,detect,detection,792,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:1682,Testability,test,test,1682,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:670,Usability,simpl,simple,670,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/pull/93#issuecomment-518571384:1115,Usability,simpl,simple,1115,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384
https://github.com/qupath/qupath/issues/95#issuecomment-324421783:104,Integrability,depend,depend,104,"This is certainly possible in a script, since the coordinates are stored at that level. But the details depend on the kind of regions you are drawing, and how you need them to be exported. For example, you can get the bounding box of any shape like this:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getBoundsX(), roi.getBoundsY(), roi.getBoundsWidth(), roi.getBoundsHeight()]); ```. That is really all you need to represent a rectangle or an ellipse. For a line, you could get the end points:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getX1(), roi.getY1(), roi.getX2(), roi.getY2()]); ```. Or, if you have a polygon then this will print the points:; ```groovy; def roi = getSelectedObject().getROI(); print roi.getPolygonPoints(); ```. As far as I recall, you can also use the final option for other shapes. But beware of complex 'areas', which could be composed of multiple polygons and include holes etc. Extracting and interpreting the coordinates for these is somewhat more difficult. If you need more than this, I would recommend looking at the scripting documentation on the wiki, and then exploring in more detail the code for each of the ROI (region of interest) classes to see how their points are stored and accessible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-324421783
https://github.com/qupath/qupath/issues/95#issuecomment-324421783:1258,Security,access,accessible,1258,"This is certainly possible in a script, since the coordinates are stored at that level. But the details depend on the kind of regions you are drawing, and how you need them to be exported. For example, you can get the bounding box of any shape like this:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getBoundsX(), roi.getBoundsY(), roi.getBoundsWidth(), roi.getBoundsHeight()]); ```. That is really all you need to represent a rectangle or an ellipse. For a line, you could get the end points:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getX1(), roi.getY1(), roi.getX2(), roi.getY2()]); ```. Or, if you have a polygon then this will print the points:; ```groovy; def roi = getSelectedObject().getROI(); print roi.getPolygonPoints(); ```. As far as I recall, you can also use the final option for other shapes. But beware of complex 'areas', which could be composed of multiple polygons and include holes etc. Extracting and interpreting the coordinates for these is somewhat more difficult. If you need more than this, I would recommend looking at the scripting documentation on the wiki, and then exploring in more detail the code for each of the ROI (region of interest) classes to see how their points are stored and accessible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-324421783
https://github.com/qupath/qupath/issues/95#issuecomment-388106470:419,Safety,avoid,avoid,419,"Hi Pete,. having basically the same problem, could you give me a hint on how to extract all the polygons that are made in the image at once? So far your suggested code works for one polygon. I believe it works when you have selected one prior running the script. I was trying to select all (=make them all yellow) and then running the script but it still gives me only the coordinates of one polygon. Is there a way to avoid this heavy time-consuming task of selecting all the polygons individually and exporting them?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388106470
https://github.com/qupath/qupath/issues/95#issuecomment-388110836:142,Integrability,depend,depending,142,"I should be able to get back to this a bit later, but in short you want to use something like getAnnotationObjects() or getDetectionObjects() depending on your targets of interest, and assign them to a variable. There are some good examples of looping on the google group forums, but you probably want something like:. annotations = getAnnotationObjects(); annotations.each{ println( it.getROI().getPolygonPoints()}",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388110836
https://github.com/qupath/qupath/issues/95#issuecomment-388110836:202,Modifiability,variab,variable,202,"I should be able to get back to this a bit later, but in short you want to use something like getAnnotationObjects() or getDetectionObjects() depending on your targets of interest, and assign them to a variable. There are some good examples of looping on the google group forums, but you probably want something like:. annotations = getAnnotationObjects(); annotations.each{ println( it.getROI().getPolygonPoints()}",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388110836
https://github.com/qupath/qupath/issues/95#issuecomment-388114844:1131,Safety,avoid,avoid,1131,"Here's a script that will loop through all objects (of any kind), and write out the polygon points to a text file inside the current project directory:; ```groovy; // Create an empty text file; def path = buildFilePath(PROJECT_BASE_DIR, 'polygons.txt'); def file = new File(path); file.text = ''. // Loop through all objects & write the points to the file; for (pathObject in getAllObjects()) {; // Check for interrupt (Run -> Kill running script); if (Thread.interrupted()); break; // Get the ROI; def roi = pathObject.getROI(); if (roi == null); continue; // Write the points; but beware areas, and also ellipses!; file << roi.getPolygonPoints() << System.lineSeparator(); }; print 'Done!'; ```; Be wary of any `Area` ROIs though (including `Area (AWT)`) - these can contain complex polygons with discontinuous regions, and you might well not get the expected output using this method. Any further help on this would require knowing exactly what the 'expected output' should be for these tricky cases. There are a few blog posts that describe other kinds of export, e.g. with raster images rather than vertices, which would help avoid the troublesome shapes. [This post](https://petebankhead.github.io/qupath/scripting/2018/03/14/script-export-labelled-images.html), for example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388114844
https://github.com/qupath/qupath/issues/95#issuecomment-388118309:389,Availability,avail,available,389,"Thanks @Svidro, I have lost track of which scripts I've written and where :); But yes, that would give a way to handle areas... and shows the trouble involved (separate list of external polygons and holes). It's also possible to get `java.awt.Shape` objects for any QuPath `ROI` and have the task of exporting them; still a job to do, but at least there is likely to be more documentation available. It would be worthwhile to have a general export function within QuPath; but my question is about which format should be used for export. Ideally it would be a standard, open format of general usefulness in the digital pathology community. Ideas welcome!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388118309
https://github.com/qupath/qupath/issues/95#issuecomment-388285040:132,Availability,mask,mask,132,"Thanks for the fast replies @all!. What I eventually want to do with the extracted polygon vertices, is to convert them to a binary mask, i.e. all the pixels inside the polygon will be marked as one class and the pixels of the polygon will be marked as another class. @andanis ; This approach isn't going to work out for drawing a binary mask, I think. The polygon vertices must be seperated, otherwise I will probably have all the stuff that is between each polygon also marked as the same class in the binary mask. @petebankhead ; Thanks for the code, Pete. But when I execute it, I get a blank text file. I changed `for (pathObject in getAllObjects())` to `for (pathObject in getAnnotationObjects())` which is giving the desired coordinates of all the polygons. Could you explain a little bit more about what you mean by complex polygons in discontinous regions? What do you mean by regions and when can they be discontinous?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388285040
https://github.com/qupath/qupath/issues/95#issuecomment-388285040:338,Availability,mask,mask,338,"Thanks for the fast replies @all!. What I eventually want to do with the extracted polygon vertices, is to convert them to a binary mask, i.e. all the pixels inside the polygon will be marked as one class and the pixels of the polygon will be marked as another class. @andanis ; This approach isn't going to work out for drawing a binary mask, I think. The polygon vertices must be seperated, otherwise I will probably have all the stuff that is between each polygon also marked as the same class in the binary mask. @petebankhead ; Thanks for the code, Pete. But when I execute it, I get a blank text file. I changed `for (pathObject in getAllObjects())` to `for (pathObject in getAnnotationObjects())` which is giving the desired coordinates of all the polygons. Could you explain a little bit more about what you mean by complex polygons in discontinous regions? What do you mean by regions and when can they be discontinous?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388285040
https://github.com/qupath/qupath/issues/95#issuecomment-388285040:511,Availability,mask,mask,511,"Thanks for the fast replies @all!. What I eventually want to do with the extracted polygon vertices, is to convert them to a binary mask, i.e. all the pixels inside the polygon will be marked as one class and the pixels of the polygon will be marked as another class. @andanis ; This approach isn't going to work out for drawing a binary mask, I think. The polygon vertices must be seperated, otherwise I will probably have all the stuff that is between each polygon also marked as the same class in the binary mask. @petebankhead ; Thanks for the code, Pete. But when I execute it, I get a blank text file. I changed `for (pathObject in getAllObjects())` to `for (pathObject in getAnnotationObjects())` which is giving the desired coordinates of all the polygons. Could you explain a little bit more about what you mean by complex polygons in discontinous regions? What do you mean by regions and when can they be discontinous?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388285040
https://github.com/qupath/qupath/issues/95#issuecomment-388286086:255,Availability,down,down,255,"I mean polygons that might have multiple separate regions and yet are still treated as the same shape, or contain holes inside them - and so can't be represented simply by a list of vertices. You can create such shapes using the brush or wand tool - hold down 'Alt' to turn on 'subtract mode', and this lets you remove areas from inside an existing shape. You can also hold down shift when using the brush to create multiple polygons but which are treated as the same object (which you can see by the fact they are all selected together... using the default colors this means all shown as yellow). Given that your plan is to create a binary mask, definitely check out the blog. It should be much easier to do this directly from within QuPath and not need to handle another way to handle the shapes. From memory, there are a few posts where I described this kind of thing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388286086
https://github.com/qupath/qupath/issues/95#issuecomment-388286086:374,Availability,down,down,374,"I mean polygons that might have multiple separate regions and yet are still treated as the same shape, or contain holes inside them - and so can't be represented simply by a list of vertices. You can create such shapes using the brush or wand tool - hold down 'Alt' to turn on 'subtract mode', and this lets you remove areas from inside an existing shape. You can also hold down shift when using the brush to create multiple polygons but which are treated as the same object (which you can see by the fact they are all selected together... using the default colors this means all shown as yellow). Given that your plan is to create a binary mask, definitely check out the blog. It should be much easier to do this directly from within QuPath and not need to handle another way to handle the shapes. From memory, there are a few posts where I described this kind of thing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388286086
https://github.com/qupath/qupath/issues/95#issuecomment-388286086:641,Availability,mask,mask,641,"I mean polygons that might have multiple separate regions and yet are still treated as the same shape, or contain holes inside them - and so can't be represented simply by a list of vertices. You can create such shapes using the brush or wand tool - hold down 'Alt' to turn on 'subtract mode', and this lets you remove areas from inside an existing shape. You can also hold down shift when using the brush to create multiple polygons but which are treated as the same object (which you can see by the fact they are all selected together... using the default colors this means all shown as yellow). Given that your plan is to create a binary mask, definitely check out the blog. It should be much easier to do this directly from within QuPath and not need to handle another way to handle the shapes. From memory, there are a few posts where I described this kind of thing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388286086
https://github.com/qupath/qupath/issues/95#issuecomment-388286086:162,Usability,simpl,simply,162,"I mean polygons that might have multiple separate regions and yet are still treated as the same shape, or contain holes inside them - and so can't be represented simply by a list of vertices. You can create such shapes using the brush or wand tool - hold down 'Alt' to turn on 'subtract mode', and this lets you remove areas from inside an existing shape. You can also hold down shift when using the brush to create multiple polygons but which are treated as the same object (which you can see by the fact they are all selected together... using the default colors this means all shown as yellow). Given that your plan is to create a binary mask, definitely check out the blog. It should be much easier to do this directly from within QuPath and not need to handle another way to handle the shapes. From memory, there are a few posts where I described this kind of thing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388286086
https://github.com/qupath/qupath/issues/95#issuecomment-388339764:69,Availability,mask,masks,69,"Hi Pete,. I tried your code from your blog regarding creating binary masks: https://gist.githubusercontent.com/petebankhead/0b14beef131312042686c01056104b85/raw/8223a934f10761a885ef6cab20d71f786029bb84/QuPath-Export%20binary%20masks.groovy. It works perfectly smooth and would save me lots of work. There's just one thing that gives me a bit of trouble: The binary masks are not embedded in the whole image, meaning if I read them in somewhere else, I just get the mask according to those squared little images but I don't know where exactly they are located in the whole image that I'm annotating (unless there's something I'm overlooking right now). Could you tell me how to modify your code from the blog in order to save the binary masks embedded in the whole image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388339764
https://github.com/qupath/qupath/issues/95#issuecomment-388339764:365,Availability,mask,masks,365,"Hi Pete,. I tried your code from your blog regarding creating binary masks: https://gist.githubusercontent.com/petebankhead/0b14beef131312042686c01056104b85/raw/8223a934f10761a885ef6cab20d71f786029bb84/QuPath-Export%20binary%20masks.groovy. It works perfectly smooth and would save me lots of work. There's just one thing that gives me a bit of trouble: The binary masks are not embedded in the whole image, meaning if I read them in somewhere else, I just get the mask according to those squared little images but I don't know where exactly they are located in the whole image that I'm annotating (unless there's something I'm overlooking right now). Could you tell me how to modify your code from the blog in order to save the binary masks embedded in the whole image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388339764
https://github.com/qupath/qupath/issues/95#issuecomment-388339764:465,Availability,mask,mask,465,"Hi Pete,. I tried your code from your blog regarding creating binary masks: https://gist.githubusercontent.com/petebankhead/0b14beef131312042686c01056104b85/raw/8223a934f10761a885ef6cab20d71f786029bb84/QuPath-Export%20binary%20masks.groovy. It works perfectly smooth and would save me lots of work. There's just one thing that gives me a bit of trouble: The binary masks are not embedded in the whole image, meaning if I read them in somewhere else, I just get the mask according to those squared little images but I don't know where exactly they are located in the whole image that I'm annotating (unless there's something I'm overlooking right now). Could you tell me how to modify your code from the blog in order to save the binary masks embedded in the whole image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388339764
https://github.com/qupath/qupath/issues/95#issuecomment-388339764:736,Availability,mask,masks,736,"Hi Pete,. I tried your code from your blog regarding creating binary masks: https://gist.githubusercontent.com/petebankhead/0b14beef131312042686c01056104b85/raw/8223a934f10761a885ef6cab20d71f786029bb84/QuPath-Export%20binary%20masks.groovy. It works perfectly smooth and would save me lots of work. There's just one thing that gives me a bit of trouble: The binary masks are not embedded in the whole image, meaning if I read them in somewhere else, I just get the mask according to those squared little images but I don't know where exactly they are located in the whole image that I'm annotating (unless there's something I'm overlooking right now). Could you tell me how to modify your code from the blog in order to save the binary masks embedded in the whole image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388339764
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:102,Availability,mask,mask,102,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:124,Availability,down,downsample,124,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:498,Availability,mask,mask,498,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:560,Availability,down,downsample,560,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:729,Availability,mask,mask,729,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:861,Availability,mask,mask,861,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388386859:947,Modifiability,plugin,plugin,947,"I don't think QuPath directly modifies any of the images. You can create new files with a ""burned in"" mask at whatever size/downsample as long as they are within the allowable size for that file type, but modifying pyramidal files might be rough. Similar question here perhaps: https://github.com/qupath/qupath/issues/166. Side note, the square images should have XY coordinates as part of their name so that they can be reconstructed from the file names. You may also be able to create the binary mask as Pete posted above, but as a single image with a known downsample, then expand it back to normal size within the program you are using to merge it into your (I assume) tiff. If you want essentially an extra channel with the mask in it, I think you want a file of a size that FIJI/ImageJ can handle, and merge the extra channel in there after exporting the mask from QuPath. That still leaves stitching all of the files together using another plugin or program, if you exported as many tiles. https://imagej.net/Stitch_and_Align_a_sequence_of_grid_images_Tutorial",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388386859
https://github.com/qupath/qupath/issues/95#issuecomment-388535578:520,Availability,mask,masks,520,"As @Svidro says, QuPath doesn't modify the whole slide images - and nor can it write a whole slide image itself (unless you were to do all the low-level stuff in a script yourself - just about anything should be possible then). Personally, I've never needed this functionality; or, more accurately, I've always found a way around it that was much easier than solving the problem of writing an entirely new whole slide image. These include:; * Exporting the original pixels along with the binary image (e.g. if using the masks to define training regions to create a new algorithm); * Exporting the binary image at a low resolution, and either exporting the scaling factor (downsample) or approximating this later based on the width & height compared to the original; * Exporting cropped regions, and including the bounding box and scale information in the file name; * Exporting cropped regions as ImageJ TIFFs, where QuPath is able to set the key information in the image properties to facilitate reading the regions back later. QuPath requests pixels using `RegionRequest` objects. To generate a string containing the key information from a `RegionRequest` you might use the following:; ```groovy; String name = String.format('%s_(%.2f,%d,%d,%d,%d)',; server.getShortServerName(),; request.getDownsample(),; request.getX(),; request.getY(),; request.getWidth(),; request.getHeight(); ); ```; The script [here](https://petebankhead.github.io/qupath/scripting/2018/03/14/script-export-labelled-images.html) uses this when exporting to include this information in the file name. If none of these methods seem like they would work for you, it would help if you describe a bit more what you need the final output for and what software you would be using next to read the images.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388535578
https://github.com/qupath/qupath/issues/95#issuecomment-388535578:672,Availability,down,downsample,672,"As @Svidro says, QuPath doesn't modify the whole slide images - and nor can it write a whole slide image itself (unless you were to do all the low-level stuff in a script yourself - just about anything should be possible then). Personally, I've never needed this functionality; or, more accurately, I've always found a way around it that was much easier than solving the problem of writing an entirely new whole slide image. These include:; * Exporting the original pixels along with the binary image (e.g. if using the masks to define training regions to create a new algorithm); * Exporting the binary image at a low resolution, and either exporting the scaling factor (downsample) or approximating this later based on the width & height compared to the original; * Exporting cropped regions, and including the bounding box and scale information in the file name; * Exporting cropped regions as ImageJ TIFFs, where QuPath is able to set the key information in the image properties to facilitate reading the regions back later. QuPath requests pixels using `RegionRequest` objects. To generate a string containing the key information from a `RegionRequest` you might use the following:; ```groovy; String name = String.format('%s_(%.2f,%d,%d,%d,%d)',; server.getShortServerName(),; request.getDownsample(),; request.getX(),; request.getY(),; request.getWidth(),; request.getHeight(); ); ```; The script [here](https://petebankhead.github.io/qupath/scripting/2018/03/14/script-export-labelled-images.html) uses this when exporting to include this information in the file name. If none of these methods seem like they would work for you, it would help if you describe a bit more what you need the final output for and what software you would be using next to read the images.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388535578
https://github.com/qupath/qupath/issues/95#issuecomment-388643336:462,Availability,mask,mask,462,"Hi,. thanks all for your responses. I'm not sure if I can follow what you actually mean but I think we talking about two different things. Anyways, I think, I'm good to go with the information that is included in the file name. I didn't notice at first that the coordinates given in the file name was '0,0'-coordinate of the respective small image. I believe that I just can generate an array with filled zeros in the size of the RoI and then fill in the binary mask at the coordinates in the file name,. Thanks a lot to you guys for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388643336
https://github.com/qupath/qupath/issues/95#issuecomment-395886486:316,Testability,test,tested,316,"Hello All,; I am working on something similar for exporting annotation objects from QUpath as shapefiles .shp/.dbf/.shx for later import into definiens. ; I would say I am 80% through.; Currently I have a python script that (given polygon vertices) dumps out the shapefiles that definiens is able to ingest. Not yet tested with complex shapes like holes within polygons though!; Also I have a groovy script along the lines mentioned above by Peter that dumps out vertices from QUpath annotations.; Ideally I would like to have a single python script that does both (using Jython within QUpath maybe). Not sure if anyone has tried Jython in QUpath before?; In case Peter is thinking of developing this functionality for exporting annotations objects from QUpath, I would say shapefiles is one such format that is widely used (and has third party libraries for handing the read/write).; cheers!; rawat.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395886486
https://github.com/qupath/qupath/issues/95#issuecomment-395945546:490,Availability,down,download,490,"I should probably admit that I didn't know anything about shapefiles - I'll look out for them from now on! If you happen to know of other pathology software that can export/import them (can Definiens do both?) that would be very good to know. I actually made a half-hearted attempt to incorporate Jython support in the early days, before I went all-in for Groovy because trying to be multilingual took extra effort that (at the time) didn't seem worth it. _However_, this means that if you download the Jython standalone jar and drag it onto QuPath then a new 'Jython' option will appear as an available scripting language. Now the half-hearted bit: there's a tiny error in the default import statement for Jython in v0.1.2 - so until that's fixed you'll need to *uncheck* the option *Run &rarr; Include default bindings*. This means that the normal [`QPEx` things](https://github.com/qupath/qupath/wiki/Writing-custom-scripts#default-methods--imports) will not be available in the script, and you'll need to import these separately... and possibly remember to turn the default imports back on if your Groovy scripts require them. The following works for me, after installing the jar and setting the script language to `Jython`:; ```python; from qupath.lib.scripting.QPEx import *; annotations = getAnnotationObjects(); print annotations; ```. The fix to address this in the code appears trivial (switching `+` to `,` in the code), so potentially this won't be necessary in later versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945546
https://github.com/qupath/qupath/issues/95#issuecomment-395945546:594,Availability,avail,available,594,"I should probably admit that I didn't know anything about shapefiles - I'll look out for them from now on! If you happen to know of other pathology software that can export/import them (can Definiens do both?) that would be very good to know. I actually made a half-hearted attempt to incorporate Jython support in the early days, before I went all-in for Groovy because trying to be multilingual took extra effort that (at the time) didn't seem worth it. _However_, this means that if you download the Jython standalone jar and drag it onto QuPath then a new 'Jython' option will appear as an available scripting language. Now the half-hearted bit: there's a tiny error in the default import statement for Jython in v0.1.2 - so until that's fixed you'll need to *uncheck* the option *Run &rarr; Include default bindings*. This means that the normal [`QPEx` things](https://github.com/qupath/qupath/wiki/Writing-custom-scripts#default-methods--imports) will not be available in the script, and you'll need to import these separately... and possibly remember to turn the default imports back on if your Groovy scripts require them. The following works for me, after installing the jar and setting the script language to `Jython`:; ```python; from qupath.lib.scripting.QPEx import *; annotations = getAnnotationObjects(); print annotations; ```. The fix to address this in the code appears trivial (switching `+` to `,` in the code), so potentially this won't be necessary in later versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945546
https://github.com/qupath/qupath/issues/95#issuecomment-395945546:665,Availability,error,error,665,"I should probably admit that I didn't know anything about shapefiles - I'll look out for them from now on! If you happen to know of other pathology software that can export/import them (can Definiens do both?) that would be very good to know. I actually made a half-hearted attempt to incorporate Jython support in the early days, before I went all-in for Groovy because trying to be multilingual took extra effort that (at the time) didn't seem worth it. _However_, this means that if you download the Jython standalone jar and drag it onto QuPath then a new 'Jython' option will appear as an available scripting language. Now the half-hearted bit: there's a tiny error in the default import statement for Jython in v0.1.2 - so until that's fixed you'll need to *uncheck* the option *Run &rarr; Include default bindings*. This means that the normal [`QPEx` things](https://github.com/qupath/qupath/wiki/Writing-custom-scripts#default-methods--imports) will not be available in the script, and you'll need to import these separately... and possibly remember to turn the default imports back on if your Groovy scripts require them. The following works for me, after installing the jar and setting the script language to `Jython`:; ```python; from qupath.lib.scripting.QPEx import *; annotations = getAnnotationObjects(); print annotations; ```. The fix to address this in the code appears trivial (switching `+` to `,` in the code), so potentially this won't be necessary in later versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945546
https://github.com/qupath/qupath/issues/95#issuecomment-395945546:965,Availability,avail,available,965,"I should probably admit that I didn't know anything about shapefiles - I'll look out for them from now on! If you happen to know of other pathology software that can export/import them (can Definiens do both?) that would be very good to know. I actually made a half-hearted attempt to incorporate Jython support in the early days, before I went all-in for Groovy because trying to be multilingual took extra effort that (at the time) didn't seem worth it. _However_, this means that if you download the Jython standalone jar and drag it onto QuPath then a new 'Jython' option will appear as an available scripting language. Now the half-hearted bit: there's a tiny error in the default import statement for Jython in v0.1.2 - so until that's fixed you'll need to *uncheck* the option *Run &rarr; Include default bindings*. This means that the normal [`QPEx` things](https://github.com/qupath/qupath/wiki/Writing-custom-scripts#default-methods--imports) will not be available in the script, and you'll need to import these separately... and possibly remember to turn the default imports back on if your Groovy scripts require them. The following works for me, after installing the jar and setting the script language to `Jython`:; ```python; from qupath.lib.scripting.QPEx import *; annotations = getAnnotationObjects(); print annotations; ```. The fix to address this in the code appears trivial (switching `+` to `,` in the code), so potentially this won't be necessary in later versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945546
https://github.com/qupath/qupath/issues/95#issuecomment-395945546:1165,Deployability,install,installing,1165,"I should probably admit that I didn't know anything about shapefiles - I'll look out for them from now on! If you happen to know of other pathology software that can export/import them (can Definiens do both?) that would be very good to know. I actually made a half-hearted attempt to incorporate Jython support in the early days, before I went all-in for Groovy because trying to be multilingual took extra effort that (at the time) didn't seem worth it. _However_, this means that if you download the Jython standalone jar and drag it onto QuPath then a new 'Jython' option will appear as an available scripting language. Now the half-hearted bit: there's a tiny error in the default import statement for Jython in v0.1.2 - so until that's fixed you'll need to *uncheck* the option *Run &rarr; Include default bindings*. This means that the normal [`QPEx` things](https://github.com/qupath/qupath/wiki/Writing-custom-scripts#default-methods--imports) will not be available in the script, and you'll need to import these separately... and possibly remember to turn the default imports back on if your Groovy scripts require them. The following works for me, after installing the jar and setting the script language to `Jython`:; ```python; from qupath.lib.scripting.QPEx import *; annotations = getAnnotationObjects(); print annotations; ```. The fix to address this in the code appears trivial (switching `+` to `,` in the code), so potentially this won't be necessary in later versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945546
https://github.com/qupath/qupath/issues/95#issuecomment-395945892:102,Deployability,update,updates,102,The import issue should be fixed [on my fork](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-395945892
https://github.com/qupath/qupath/issues/95#issuecomment-396428574:1046,Integrability,depend,dependency,1046,"You can convert any existing QuPath ROI into a [`java.awt.Shape`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) with [`PathROIToolsAwt`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java#L204). While it doesn't solve the shapefile problem, at least it gets the ROIs into a more QuPath-independent format, from with you can request vertices in a standard way (with a [PathIterator](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html)) that is fairly well documented. Using [`java.awt.geom.Area`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) is also an option for anything other than a `LineROI`. You _might_ then be able to find a library that converts a Java `Shape` into a more shapefile-friendly format (if you find a suitable library as a `.jar` file, you can just drag it onto QuPath to copy it to the extensions directory and then it should be accessible in your scripts - and potentially add it as a dependency in IntelliJ for easier scripting). Otherwise I guess I'd look for whatever way your shapefile-writing library represents complex shapes, and with the help of the `PathIterator` try to export from QuPath in the closest way I could. In general, I think QuPath needs better support for shapes and things that may be done with shapes, and every now and then I look towards [Java Topology Suite](https://github.com/locationtech/jts). I've written a couple of scripts with it, and am tentatively thinking of creating converters for all QuPath ROIs to a JTS representation... I just haven't had a big enough need for it yet. As far as I can see, JTS has support for reading shapefiles, but I don't see any for writing them. Although it may write GeoJSON - which is another candidate for a format. I've seen it used for pathology in [QuIP](https://sbu-bmi.github.io/quip_distro/), but I haven't noticed any other examples yet. I guess your main task is",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-396428574
https://github.com/qupath/qupath/issues/95#issuecomment-396428574:989,Security,access,accessible,989,"You can convert any existing QuPath ROI into a [`java.awt.Shape`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) with [`PathROIToolsAwt`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java#L204). While it doesn't solve the shapefile problem, at least it gets the ROIs into a more QuPath-independent format, from with you can request vertices in a standard way (with a [PathIterator](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html)) that is fairly well documented. Using [`java.awt.geom.Area`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) is also an option for anything other than a `LineROI`. You _might_ then be able to find a library that converts a Java `Shape` into a more shapefile-friendly format (if you find a suitable library as a `.jar` file, you can just drag it onto QuPath to copy it to the extensions directory and then it should be accessible in your scripts - and potentially add it as a dependency in IntelliJ for easier scripting). Otherwise I guess I'd look for whatever way your shapefile-writing library represents complex shapes, and with the help of the `PathIterator` try to export from QuPath in the closest way I could. In general, I think QuPath needs better support for shapes and things that may be done with shapes, and every now and then I look towards [Java Topology Suite](https://github.com/locationtech/jts). I've written a couple of scripts with it, and am tentatively thinking of creating converters for all QuPath ROIs to a JTS representation... I just haven't had a big enough need for it yet. As far as I can see, JTS has support for reading shapefiles, but I don't see any for writing them. Although it may write GeoJSON - which is another candidate for a format. I've seen it used for pathology in [QuIP](https://sbu-bmi.github.io/quip_distro/), but I haven't noticed any other examples yet. I guess your main task is",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-396428574
https://github.com/qupath/qupath/issues/95#issuecomment-690897795:276,Deployability,update,update,276,"Hi, it looks like in your script the coordinates of the points will be export in pixel units. The annotations (in the second export) will be export in µm (probably) or pixel units depending upon the image - but the column heading should tell you which. (I edited your post to update the code formatting to make it more readable)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-690897795
https://github.com/qupath/qupath/issues/95#issuecomment-690897795:180,Integrability,depend,depending,180,"Hi, it looks like in your script the coordinates of the points will be export in pixel units. The annotations (in the second export) will be export in µm (probably) or pixel units depending upon the image - but the column heading should tell you which. (I edited your post to update the code formatting to make it more readable)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-690897795
https://github.com/qupath/qupath/issues/96#issuecomment-326020294:14,Security,access,access,14,"I do not have access to a TMA at the moment but are those cores set to ""missing"" (they would have a lighter core outline)?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326020294
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:810,Availability,error,errors,810,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:784,Energy Efficiency,reduce,reduce,784,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:1056,Integrability,interface,interface,1056,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:20,Performance,load,loaded,20,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:338,Performance,load,loaded,338,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:747,Performance,cache,cache,747,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:1033,Performance,cache,cache,1033,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:1212,Performance,cache,cache,1212,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:75,Safety,timeout,timeout,75,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:266,Safety,timeout,timeout,266,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:795,Safety,risk,risk,795,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-326105429:507,Security,access,access,507,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429
https://github.com/qupath/qupath/issues/96#issuecomment-644847539:5,Deployability,update,updated,5,I've updated these limits in v0.2.1. Hopefully that is enough to avoid this issue resurfacing.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-644847539
https://github.com/qupath/qupath/issues/96#issuecomment-644847539:65,Safety,avoid,avoid,65,I've updated these limits in v0.2.1. Hopefully that is enough to avoid this issue resurfacing.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-644847539
https://github.com/qupath/qupath/issues/97#issuecomment-326506002:160,Availability,down,downsample,160,"There are a few options, depending upon what exactly you want / how much effort can be involved. Under *Edit &rarr; Preferences* you can change the *TMA export downsample factor* to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/io/PathAwtIO.java#L326) and it doesn't give a place to specify a different format. If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at [#85](https://github.com/qupath/qupath/issues/85#issuecomment-317354440). You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be *extremely* big (while the PNGs will probably just be 'big'). It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326506002
https://github.com/qupath/qupath/issues/97#issuecomment-326506002:25,Integrability,depend,depending,25,"There are a few options, depending upon what exactly you want / how much effort can be involved. Under *Edit &rarr; Preferences* you can change the *TMA export downsample factor* to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/io/PathAwtIO.java#L326) and it doesn't give a place to specify a different format. If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at [#85](https://github.com/qupath/qupath/issues/85#issuecomment-317354440). You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be *extremely* big (while the PNGs will probably just be 'big'). It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326506002
https://github.com/qupath/qupath/issues/97#issuecomment-326631504:136,Availability,error,error,136,"Thanks for the replies. The easiest method seemed to be exporting to imagej however when I try to use the macro in batch mode, I get an error if I try to export the full size core (without downsampling). Images over 5000x5000 px don't seem to export well to imagej. Workarounds?. Thanks. Sent from my iPhone. > On Sep 1, 2017, at 00:01, Pete <notifications@github.com> wrote:; > ; > There are a few options, depending upon what exactly you want / how much effort can be involved.; > ; > Under Edit → Preferences you can change the TMA export downsample factor to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is here and it doesn't give a place to specify a different format.; > ; > If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at #85. You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be extremely big (while the PNGs will probably just be 'big').; > ; > It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326631504
https://github.com/qupath/qupath/issues/97#issuecomment-326631504:189,Availability,down,downsampling,189,"Thanks for the replies. The easiest method seemed to be exporting to imagej however when I try to use the macro in batch mode, I get an error if I try to export the full size core (without downsampling). Images over 5000x5000 px don't seem to export well to imagej. Workarounds?. Thanks. Sent from my iPhone. > On Sep 1, 2017, at 00:01, Pete <notifications@github.com> wrote:; > ; > There are a few options, depending upon what exactly you want / how much effort can be involved.; > ; > Under Edit → Preferences you can change the TMA export downsample factor to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is here and it doesn't give a place to specify a different format.; > ; > If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at #85. You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be extremely big (while the PNGs will probably just be 'big').; > ; > It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326631504
https://github.com/qupath/qupath/issues/97#issuecomment-326631504:542,Availability,down,downsample,542,"Thanks for the replies. The easiest method seemed to be exporting to imagej however when I try to use the macro in batch mode, I get an error if I try to export the full size core (without downsampling). Images over 5000x5000 px don't seem to export well to imagej. Workarounds?. Thanks. Sent from my iPhone. > On Sep 1, 2017, at 00:01, Pete <notifications@github.com> wrote:; > ; > There are a few options, depending upon what exactly you want / how much effort can be involved.; > ; > Under Edit → Preferences you can change the TMA export downsample factor to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is here and it doesn't give a place to specify a different format.; > ; > If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at #85. You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be extremely big (while the PNGs will probably just be 'big').; > ; > It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326631504
https://github.com/qupath/qupath/issues/97#issuecomment-326631504:408,Integrability,depend,depending,408,"Thanks for the replies. The easiest method seemed to be exporting to imagej however when I try to use the macro in batch mode, I get an error if I try to export the full size core (without downsampling). Images over 5000x5000 px don't seem to export well to imagej. Workarounds?. Thanks. Sent from my iPhone. > On Sep 1, 2017, at 00:01, Pete <notifications@github.com> wrote:; > ; > There are a few options, depending upon what exactly you want / how much effort can be involved.; > ; > Under Edit → Preferences you can change the TMA export downsample factor to be 1 to get the highest resolution. However, this will still write JPEGs. There isn't an easy way to change that; the relevant part of the code is here and it doesn't give a place to specify a different format.; > ; > If it is the image of the TMA core only that you need, then I would suggest the one-line ImageJ macro at #85. You should be able to modify this to export PNGs. The main reason for (possibly) preferring to export as TIFF instead is that this would include the pixel size information in microns, in a way that ImageJ can understand; this might be useful if you want to do some analysis on the exported cores. The main disadvantage is that the TIFF files are likely to be extremely big (while the PNGs will probably just be 'big').; > ; > It is also possible to do the QuPath export in a Groovy script. In this case, you could also export the overlay (showing the QuPath objects) as well. But this would take a bit more effort and I'm not sure if this is something you need or not.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-326631504
https://github.com/qupath/qupath/issues/97#issuecomment-327534509:168,Availability,down,downsample,168,"This is one way to do the export:; ```groovy; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(PROJECT_BASE_DIR, 'cores'); mkdirs(dirOutput). // Write the cores; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (core in getTMACoreList()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, core.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, core.getName() + '.png')); }; print('Done!'); ```. This won't give any existing overlay, but I assume this isn't needed. Perhaps more importantly, it can be rather slow - and the resulting files may be large (often > 50 MB per PNG in my test). Exporting to JPEG would give much smaller manageable file sizes (~2 MB).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-327534509
https://github.com/qupath/qupath/issues/97#issuecomment-327534509:629,Availability,down,downsample,629,"This is one way to do the export:; ```groovy; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(PROJECT_BASE_DIR, 'cores'); mkdirs(dirOutput). // Write the cores; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (core in getTMACoreList()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, core.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, core.getName() + '.png')); }; print('Done!'); ```. This won't give any existing overlay, but I assume this isn't needed. Perhaps more importantly, it can be rather slow - and the resulting files may be large (often > 50 MB per PNG in my test). Exporting to JPEG would give much smaller manageable file sizes (~2 MB).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-327534509
https://github.com/qupath/qupath/issues/97#issuecomment-327534509:941,Testability,test,test,941,"This is one way to do the export:; ```groovy; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(PROJECT_BASE_DIR, 'cores'); mkdirs(dirOutput). // Write the cores; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (core in getTMACoreList()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, core.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, core.getName() + '.png')); }; print('Done!'); ```. This won't give any existing overlay, but I assume this isn't needed. Perhaps more importantly, it can be rather slow - and the resulting files may be large (often > 50 MB per PNG in my test). Exporting to JPEG would give much smaller manageable file sizes (~2 MB).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-327534509
https://github.com/qupath/qupath/issues/97#issuecomment-327535268:206,Availability,down,downsample,206,"As a bonus, here's how to write cores in parallel - this time as JPEGs:; ```groovy; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(PROJECT_BASE_DIR, 'cores'); mkdirs(dirOutput). // Write the cores; def server = getCurrentImageData().getServer(); def path = server.getPath(); getTMACoreList().parallelStream().forEach({core ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, core.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, core.getName() + '.jpg')); }); print('Done!'); ```. This should give a bit of a speedup. Hopefully some combination of this or the other script will help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-327535268
https://github.com/qupath/qupath/issues/97#issuecomment-327535268:563,Availability,down,downsample,563,"As a bonus, here's how to write cores in parallel - this time as JPEGs:; ```groovy; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(PROJECT_BASE_DIR, 'cores'); mkdirs(dirOutput). // Write the cores; def server = getCurrentImageData().getServer(); def path = server.getPath(); getTMACoreList().parallelStream().forEach({core ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, core.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, core.getName() + '.jpg')); }); print('Done!'); ```. This should give a bit of a speedup. Hopefully some combination of this or the other script will help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-327535268
https://github.com/qupath/qupath/issues/97#issuecomment-747453397:106,Availability,down,downsampling,106,"Hi @petebankhead, do you know how to modify the script to export every file in a project to a jpeg with a downsampling factor of 10?; Thanks",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-747453397
https://github.com/qupath/qupath/issues/97#issuecomment-747467234:395,Availability,down,downsampled,395,"Hi @kaizen89 ,. Git issues are really for bugs, please use the forum to ask questions/help with QuPath: https://forum.image.sc/tag/qupath (plus you'll get more visibility there and more chances to get loads of answers to your questions). I'll answer here for future visitors that are looking for a similar help anyway. ; You can _Run for project_ this little script, which will save a factor-10 downsampled `tif` image of the currently opened image:. ```; // Get current server; def server = getCurrentServer(). // Write the full image downsampled by a factor of 10; def requestFull = RegionRequest.createInstance(server, 10). // Create dir and image file; def imageName = getProjectEntry().getImageName(); def path = buildFilePath(PROJECT_BASE_DIR, ""downsampled_images""); if (!new File(path).exists()); mkdirs(path). // Write image region; writeImageRegion(server, requestFull, buildFilePath(path, GeneralTools.getNameWithoutExtension(getProjectEntry().getImageName()) + "".tif"")). print ""Done!""; ```. For more info about this, check out the official docs [here](https://qupath.readthedocs.io/en/latest/docs/advanced/exporting_images.html). It's full of answers (partly including this one) and good tips.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-747467234
https://github.com/qupath/qupath/issues/97#issuecomment-747467234:536,Availability,down,downsampled,536,"Hi @kaizen89 ,. Git issues are really for bugs, please use the forum to ask questions/help with QuPath: https://forum.image.sc/tag/qupath (plus you'll get more visibility there and more chances to get loads of answers to your questions). I'll answer here for future visitors that are looking for a similar help anyway. ; You can _Run for project_ this little script, which will save a factor-10 downsampled `tif` image of the currently opened image:. ```; // Get current server; def server = getCurrentServer(). // Write the full image downsampled by a factor of 10; def requestFull = RegionRequest.createInstance(server, 10). // Create dir and image file; def imageName = getProjectEntry().getImageName(); def path = buildFilePath(PROJECT_BASE_DIR, ""downsampled_images""); if (!new File(path).exists()); mkdirs(path). // Write image region; writeImageRegion(server, requestFull, buildFilePath(path, GeneralTools.getNameWithoutExtension(getProjectEntry().getImageName()) + "".tif"")). print ""Done!""; ```. For more info about this, check out the official docs [here](https://qupath.readthedocs.io/en/latest/docs/advanced/exporting_images.html). It's full of answers (partly including this one) and good tips.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-747467234
https://github.com/qupath/qupath/issues/97#issuecomment-747467234:201,Performance,load,loads,201,"Hi @kaizen89 ,. Git issues are really for bugs, please use the forum to ask questions/help with QuPath: https://forum.image.sc/tag/qupath (plus you'll get more visibility there and more chances to get loads of answers to your questions). I'll answer here for future visitors that are looking for a similar help anyway. ; You can _Run for project_ this little script, which will save a factor-10 downsampled `tif` image of the currently opened image:. ```; // Get current server; def server = getCurrentServer(). // Write the full image downsampled by a factor of 10; def requestFull = RegionRequest.createInstance(server, 10). // Create dir and image file; def imageName = getProjectEntry().getImageName(); def path = buildFilePath(PROJECT_BASE_DIR, ""downsampled_images""); if (!new File(path).exists()); mkdirs(path). // Write image region; writeImageRegion(server, requestFull, buildFilePath(path, GeneralTools.getNameWithoutExtension(getProjectEntry().getImageName()) + "".tif"")). print ""Done!""; ```. For more info about this, check out the official docs [here](https://qupath.readthedocs.io/en/latest/docs/advanced/exporting_images.html). It's full of answers (partly including this one) and good tips.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/97#issuecomment-747467234
https://github.com/qupath/qupath/issues/98#issuecomment-327718940:320,Integrability,depend,depend,320,"It's not totally clear to me whether this is something best approached using QuPath or Fiji. Factors to consider would be:. * Is there a DAPI channel? If so, QuPath's cell detection could give a head start.; * Is 'detecting peaks in each color channel' a suitable way to determine whether a cell is positive? This would depend on whether the staining is localized in each cell (e.g. in the nucleus, or dispersed elsewhere).; * Are you using (part of) a whole slide image?. Apart from that, [this ImageJ forum post](http://forum.imagej.net/t/counting-double-labeled-cells-in-fiji/3832/2?u=petebankhead) might help to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327718940
https://github.com/qupath/qupath/issues/98#issuecomment-327718940:172,Safety,detect,detection,172,"It's not totally clear to me whether this is something best approached using QuPath or Fiji. Factors to consider would be:. * Is there a DAPI channel? If so, QuPath's cell detection could give a head start.; * Is 'detecting peaks in each color channel' a suitable way to determine whether a cell is positive? This would depend on whether the staining is localized in each cell (e.g. in the nucleus, or dispersed elsewhere).; * Are you using (part of) a whole slide image?. Apart from that, [this ImageJ forum post](http://forum.imagej.net/t/counting-double-labeled-cells-in-fiji/3832/2?u=petebankhead) might help to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327718940
https://github.com/qupath/qupath/issues/98#issuecomment-327718940:214,Safety,detect,detecting,214,"It's not totally clear to me whether this is something best approached using QuPath or Fiji. Factors to consider would be:. * Is there a DAPI channel? If so, QuPath's cell detection could give a head start.; * Is 'detecting peaks in each color channel' a suitable way to determine whether a cell is positive? This would depend on whether the staining is localized in each cell (e.g. in the nucleus, or dispersed elsewhere).; * Are you using (part of) a whole slide image?. Apart from that, [this ImageJ forum post](http://forum.imagej.net/t/counting-double-labeled-cells-in-fiji/3832/2?u=petebankhead) might help to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327718940
https://github.com/qupath/qupath/issues/98#issuecomment-327718940:17,Usability,clear,clear,17,"It's not totally clear to me whether this is something best approached using QuPath or Fiji. Factors to consider would be:. * Is there a DAPI channel? If so, QuPath's cell detection could give a head start.; * Is 'detecting peaks in each color channel' a suitable way to determine whether a cell is positive? This would depend on whether the staining is localized in each cell (e.g. in the nucleus, or dispersed elsewhere).; * Are you using (part of) a whole slide image?. Apart from that, [this ImageJ forum post](http://forum.imagej.net/t/counting-double-labeled-cells-in-fiji/3832/2?u=petebankhead) might help to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327718940
https://github.com/qupath/qupath/issues/98#issuecomment-327913357:227,Performance,load,loaded,227,"In what format is your image? How does it appear in Fiji? Can you switch between 4 channels in either Fiji or QuPath? In the case of QuPath that would be under the 'Brightness/Contrast' option. It's possible the image is being loaded as a 3-channel RGB... either because of the way it is being opened, or the way in which it was previously saved. But we would need more information, or an example image, to be able to help further. It should be possible to work with 4-channel images in both Fiji or QuPath, if they have been saved in a suitable file format. I have written a bit about different kinds of multichannel images [here](https://petebankhead.gitbooks.io/imagej-intro/content/chapters/colors/colors.html).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327913357
https://github.com/qupath/qupath/issues/99#issuecomment-328360122:1748,Performance,Perform,Perform,1748,"Create separation lines using the brush tool with the 'Alt' key pressed (to put it into eraser mode). This won't entirely solve the problem, because the resulting split region will still be treated as one 'object' - giving one set of measurements, and taking one classification… but it’s a start. * Split the multi-part (area) annotation into separate polygons. The following script should do this (be sure to save your data before trying it, in case it doesn’t give the result that you want). ```groovy; import static qupath.lib.roi.PathROIToolsAwt.splitAreaToPolygons; import qupath.lib.roi.AreaROI; import qupath.lib.objects.PathAnnotationObject. // Get all the annotations; def annotations = getAnnotationObjects(). // Prepare to add/remove annotations in batch; def toAdd = []; def toRemove = []. // Loop through the annotations, preparing to make changes; for (annotation in annotations) {; def roi = annotation.getROI(); // If we have an area, prepare to remove it - ; // and add the separated polygons; if (roi instanceof AreaROI) {; toRemove << annotation; for (p in splitAreaToPolygons(roi)[1]) {; toAdd << new PathAnnotationObject(p, annotation.getPathClass()); }; }; }. // Perform the changes; removeObjects(toRemove, true); addObjects(toAdd); ```. * Set a classification for each new polygon, to help identify it later. * If you do not need/want to do a cell analysis, try *Analyze &rarr; Region identification &rarr; Positive pixel count (experimental)*. You will probably need to try different parameters. The useful measurement should be *Positive pixel %*. * View/export the results with the help of *Measure &rarr; Show annotation measurements*. Some extra work might be needed to combine the results across images, see #79 for more discussion on this. It would be possible to create a script or command to do this more easily with the help of the line drawing tool, but it would be quite a bit more complicated… this is the best I can come up with using the existing functionality.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328360122
https://github.com/qupath/qupath/issues/99#issuecomment-328360122:339,Safety,detect,detection,339,"It's definitely not too basic a question... I haven't personally needed anything quite like this, and unfortunately can't think of any really elegant way to do it currently. However, I think it should be possible in an inelegant way. This is how I would suggest:. * First unlock you annotation (it’s locked by default during simple tissue detection). Either select it, right click and choose *Annotations &rarr; Unlock*, or else run the following script to unlock all annotations in the image. ```groovy; getAnnotationObjects().each {it.setLocked(false)}; ```. * Create separation lines using the brush tool with the 'Alt' key pressed (to put it into eraser mode). This won't entirely solve the problem, because the resulting split region will still be treated as one 'object' - giving one set of measurements, and taking one classification… but it’s a start. * Split the multi-part (area) annotation into separate polygons. The following script should do this (be sure to save your data before trying it, in case it doesn’t give the result that you want). ```groovy; import static qupath.lib.roi.PathROIToolsAwt.splitAreaToPolygons; import qupath.lib.roi.AreaROI; import qupath.lib.objects.PathAnnotationObject. // Get all the annotations; def annotations = getAnnotationObjects(). // Prepare to add/remove annotations in batch; def toAdd = []; def toRemove = []. // Loop through the annotations, preparing to make changes; for (annotation in annotations) {; def roi = annotation.getROI(); // If we have an area, prepare to remove it - ; // and add the separated polygons; if (roi instanceof AreaROI) {; toRemove << annotation; for (p in splitAreaToPolygons(roi)[1]) {; toAdd << new PathAnnotationObject(p, annotation.getPathClass()); }; }; }. // Perform the changes; removeObjects(toRemove, true); addObjects(toAdd); ```. * Set a classification for each new polygon, to help identify it later. * If you do not need/want to do a cell analysis, try *Analyze &rarr; Region identification &rarr; Positiv",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328360122
https://github.com/qupath/qupath/issues/99#issuecomment-328360122:325,Usability,simpl,simple,325,"It's definitely not too basic a question... I haven't personally needed anything quite like this, and unfortunately can't think of any really elegant way to do it currently. However, I think it should be possible in an inelegant way. This is how I would suggest:. * First unlock you annotation (it’s locked by default during simple tissue detection). Either select it, right click and choose *Annotations &rarr; Unlock*, or else run the following script to unlock all annotations in the image. ```groovy; getAnnotationObjects().each {it.setLocked(false)}; ```. * Create separation lines using the brush tool with the 'Alt' key pressed (to put it into eraser mode). This won't entirely solve the problem, because the resulting split region will still be treated as one 'object' - giving one set of measurements, and taking one classification… but it’s a start. * Split the multi-part (area) annotation into separate polygons. The following script should do this (be sure to save your data before trying it, in case it doesn’t give the result that you want). ```groovy; import static qupath.lib.roi.PathROIToolsAwt.splitAreaToPolygons; import qupath.lib.roi.AreaROI; import qupath.lib.objects.PathAnnotationObject. // Get all the annotations; def annotations = getAnnotationObjects(). // Prepare to add/remove annotations in batch; def toAdd = []; def toRemove = []. // Loop through the annotations, preparing to make changes; for (annotation in annotations) {; def roi = annotation.getROI(); // If we have an area, prepare to remove it - ; // and add the separated polygons; if (roi instanceof AreaROI) {; toRemove << annotation; for (p in splitAreaToPolygons(roi)[1]) {; toAdd << new PathAnnotationObject(p, annotation.getPathClass()); }; }; }. // Perform the changes; removeObjects(toRemove, true); addObjects(toAdd); ```. * Set a classification for each new polygon, to help identify it later. * If you do not need/want to do a cell analysis, try *Analyze &rarr; Region identification &rarr; Positiv",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328360122
https://github.com/qupath/qupath/issues/99#issuecomment-328362033:285,Safety,detect,detection,285,"Oooh, that script would have been useful a few times! I have wanted the ability to split ROIs, though I don't recall why at the moment. If the tissue regions are visually distinct, this forum thread might also give you a way to automatically create the regions from your simple tissue detection, though it will never be perfect! Also, the more features you use, the larger sample size you will need, and I don't know how well that will work with your data set. Image quality/lighting also needs to be similar throughout :). https://groups.google.com/forum/#!topic/qupath-users/gm0YYJxSriA. edit: woah, I triggered some kind of title effect with the formatting.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328362033
https://github.com/qupath/qupath/issues/99#issuecomment-328362033:271,Usability,simpl,simple,271,"Oooh, that script would have been useful a few times! I have wanted the ability to split ROIs, though I don't recall why at the moment. If the tissue regions are visually distinct, this forum thread might also give you a way to automatically create the regions from your simple tissue detection, though it will never be perfect! Also, the more features you use, the larger sample size you will need, and I don't know how well that will work with your data set. Image quality/lighting also needs to be similar throughout :). https://groups.google.com/forum/#!topic/qupath-users/gm0YYJxSriA. edit: woah, I triggered some kind of title effect with the formatting.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328362033
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:1222,Integrability,depend,depending,1222,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:354,Safety,Safe,Safest,354,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:272,Security,access,access,272,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:665,Security,access,access,665,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:844,Security,access,access,844,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:1126,Security,access,accessing,1126,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:1174,Security,access,access,1174,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/100#issuecomment-328936155:1265,Security,access,accessing,1265,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155
https://github.com/qupath/qupath/issues/102#issuecomment-332441466:358,Availability,avail,available,358,"Good! To answer your question:. ```QP``` is inside the 'core' modules, which means it doesn't know anything about the GUI. ```QPEx``` is a subclass of ```QP``` that lives inside the GUI module - which has access to all the core modules too. Therefore ```QPEx``` adds extra GUI-related methods (e.g. to request the QuPathGUI instance, or viewers) that aren't available within ```QP```. *Potentially*, if you only rely on ```QP```, you could run a script headlessly, and completely independent of the QuPath GUI. If instead you run your scripts from QuPath directly, then you may as well use ```QPEx```. It should do the same, but also give you access to more stuff if you need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332441466
https://github.com/qupath/qupath/issues/102#issuecomment-332441466:205,Security,access,access,205,"Good! To answer your question:. ```QP``` is inside the 'core' modules, which means it doesn't know anything about the GUI. ```QPEx``` is a subclass of ```QP``` that lives inside the GUI module - which has access to all the core modules too. Therefore ```QPEx``` adds extra GUI-related methods (e.g. to request the QuPathGUI instance, or viewers) that aren't available within ```QP```. *Potentially*, if you only rely on ```QP```, you could run a script headlessly, and completely independent of the QuPath GUI. If instead you run your scripts from QuPath directly, then you may as well use ```QPEx```. It should do the same, but also give you access to more stuff if you need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332441466
https://github.com/qupath/qupath/issues/102#issuecomment-332441466:643,Security,access,access,643,"Good! To answer your question:. ```QP``` is inside the 'core' modules, which means it doesn't know anything about the GUI. ```QPEx``` is a subclass of ```QP``` that lives inside the GUI module - which has access to all the core modules too. Therefore ```QPEx``` adds extra GUI-related methods (e.g. to request the QuPathGUI instance, or viewers) that aren't available within ```QP```. *Potentially*, if you only rely on ```QP```, you could run a script headlessly, and completely independent of the QuPath GUI. If instead you run your scripts from QuPath directly, then you may as well use ```QPEx```. It should do the same, but also give you access to more stuff if you need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332441466
https://github.com/qupath/qupath/issues/102#issuecomment-332442980:176,Deployability,release,release,176,"Thanks for your fast answer Pete! We started to train people to use QuPath in our institute for a research purpose, so far I've got really go feedback! Thanks again for having release this great software and in opensource!; Could we find somewhere the API like the ImageJ project did ( https://imagej.nih.gov/ij/developer/api/index.html ) ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332442980
https://github.com/qupath/qupath/issues/102#issuecomment-332442980:142,Usability,feedback,feedback,142,"Thanks for your fast answer Pete! We started to train people to use QuPath in our institute for a research purpose, so far I've got really go feedback! Thanks again for having release this great software and in opensource!; Could we find somewhere the API like the ImageJ project did ( https://imagej.nih.gov/ij/developer/api/index.html ) ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332442980
https://github.com/qupath/qupath/issues/102#issuecomment-332629803:1210,Availability,avail,available,1210,"Great, thanks!. The API documentation would be good... although I'm not entirely sure where/how to arrange to get it hosted. I guess you may already have things set up with IntelliJ as described on the Wiki (if not, you probably should!), and through that there may be a way to generate javadocs... or at least browse the code directly. In moments of desperation when I'm relying only on QuPath's editor, I use Java reflection to get a list of methods. Here, for example, is a script to generate a list of all the methods in QPEx, with a little bit of cleanup to reduce redundancy:. ```groovy; import qupath.lib.scripting.QPEx. def objectMethods = Object.getMethods() as Set. def replacements = [; 'qupath.lib.scripting.QPEx.' : '',; 'qupath.lib.scripting.QP.' : '',; 'public static ' : '',; 'java.lang.': '',; 'java.io.File': 'File',; 'java.util.List': 'List',; ',': ', '; ]. def sb = new StringBuilder('Methods:\n'); for (m in QPEx.getMethods()) {; if (m in objectMethods); continue; def method = m.toString(); for (entry in replacements.entrySet()); method = method.replaceAll(entry.getKey(), entry.getValue()); sb << method; sb << '\n'; }; ; print sb; ```. One day I hope to get this documented better and available on the Wiki (like ImageJ's macro reference)...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332629803
https://github.com/qupath/qupath/issues/102#issuecomment-332629803:563,Energy Efficiency,reduce,reduce,563,"Great, thanks!. The API documentation would be good... although I'm not entirely sure where/how to arrange to get it hosted. I guess you may already have things set up with IntelliJ as described on the Wiki (if not, you probably should!), and through that there may be a way to generate javadocs... or at least browse the code directly. In moments of desperation when I'm relying only on QuPath's editor, I use Java reflection to get a list of methods. Here, for example, is a script to generate a list of all the methods in QPEx, with a little bit of cleanup to reduce redundancy:. ```groovy; import qupath.lib.scripting.QPEx. def objectMethods = Object.getMethods() as Set. def replacements = [; 'qupath.lib.scripting.QPEx.' : '',; 'qupath.lib.scripting.QP.' : '',; 'public static ' : '',; 'java.lang.': '',; 'java.io.File': 'File',; 'java.util.List': 'List',; ',': ', '; ]. def sb = new StringBuilder('Methods:\n'); for (m in QPEx.getMethods()) {; if (m in objectMethods); continue; def method = m.toString(); for (entry in replacements.entrySet()); method = method.replaceAll(entry.getKey(), entry.getValue()); sb << method; sb << '\n'; }; ; print sb; ```. One day I hope to get this documented better and available on the Wiki (like ImageJ's macro reference)...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332629803
https://github.com/qupath/qupath/issues/102#issuecomment-332629803:570,Safety,redund,redundancy,570,"Great, thanks!. The API documentation would be good... although I'm not entirely sure where/how to arrange to get it hosted. I guess you may already have things set up with IntelliJ as described on the Wiki (if not, you probably should!), and through that there may be a way to generate javadocs... or at least browse the code directly. In moments of desperation when I'm relying only on QuPath's editor, I use Java reflection to get a list of methods. Here, for example, is a script to generate a list of all the methods in QPEx, with a little bit of cleanup to reduce redundancy:. ```groovy; import qupath.lib.scripting.QPEx. def objectMethods = Object.getMethods() as Set. def replacements = [; 'qupath.lib.scripting.QPEx.' : '',; 'qupath.lib.scripting.QP.' : '',; 'public static ' : '',; 'java.lang.': '',; 'java.io.File': 'File',; 'java.util.List': 'List',; ',': ', '; ]. def sb = new StringBuilder('Methods:\n'); for (m in QPEx.getMethods()) {; if (m in objectMethods); continue; def method = m.toString(); for (entry in replacements.entrySet()); method = method.replaceAll(entry.getKey(), entry.getValue()); sb << method; sb << '\n'; }; ; print sb; ```. One day I hope to get this documented better and available on the Wiki (like ImageJ's macro reference)...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332629803
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:959,Deployability,update,update,959,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:1488,Deployability,update,update,1488,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:1202,Safety,safe,safer,1202,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:599,Security,access,accessing,599,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:1085,Testability,log,logic,1085,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332598953:150,Usability,simpl,simply,150,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:75,Availability,error,error,75,"Thanks Pete, it works, although it generate a multiple times the following error message:. `; ERROR: QuPath exception; at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236); at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423); at javafx.scene.Parent$2.onProposedChange(Parent.java:367); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108); at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575); at com.sun.javafx.scene.control.skin.TreeCellSkin.updateChildren(TreeCellSkin.java:197); at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204); at com.sun.javafx.scene.control.skin.TreeCellSkin.handleControlPropertyChanged(TreeCellSkin.java:125); at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:94,Availability,ERROR,ERROR,94,"Thanks Pete, it works, although it generate a multiple times the following error message:. `; ERROR: QuPath exception; at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236); at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423); at javafx.scene.Parent$2.onProposedChange(Parent.java:367); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108); at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575); at com.sun.javafx.scene.control.skin.TreeCellSkin.updateChildren(TreeCellSkin.java:197); at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204); at com.sun.javafx.scene.control.skin.TreeCellSkin.handleControlPropertyChanged(TreeCellSkin.java:125); at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:570,Deployability,update,updateChildren,570,"Thanks Pete, it works, although it generate a multiple times the following error message:. `; ERROR: QuPath exception; at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236); at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423); at javafx.scene.Parent$2.onProposedChange(Parent.java:367); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108); at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575); at com.sun.javafx.scene.control.skin.TreeCellSkin.updateChildren(TreeCellSkin.java:197); at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204); at com.sun.javafx.scene.control.skin.TreeCellSkin.handleControlPropertyChanged(TreeCellSkin.java:125); at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:662,Deployability,update,updateChildren,662,"Thanks Pete, it works, although it generate a multiple times the following error message:. `; ERROR: QuPath exception; at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236); at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423); at javafx.scene.Parent$2.onProposedChange(Parent.java:367); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108); at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575); at com.sun.javafx.scene.control.skin.TreeCellSkin.updateChildren(TreeCellSkin.java:197); at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204); at com.sun.javafx.scene.control.skin.TreeCellSkin.handleControlPropertyChanged(TreeCellSkin.java:125); at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:1957,Deployability,update,updateItem,1957,bda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at javafx.scene.control.TreeCell.updateItem(TreeCell.java:526); at javafx.scene.control.TreeCell.lambda$new$256(TreeCell.java:173); at javafx.beans.WeakInvalidationListener.invalidated(WeakInvalidationListener.java:83); at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:349); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.C,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:2027,Deployability,update,updateItem,2027,n.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at javafx.scene.control.TreeCell.updateItem(TreeCell.java:526); at javafx.scene.control.TreeCell.lambda$new$256(TreeCell.java:173); at javafx.beans.WeakInvalidationListener.invalidated(WeakInvalidationListener.java:83); at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:349); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.gr,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:81,Integrability,message,message,81,"Thanks Pete, it works, although it generate a multiple times the following error message:. `; ERROR: QuPath exception; at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236); at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423); at javafx.scene.Parent$2.onProposedChange(Parent.java:367); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113); at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108); at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575); at com.sun.javafx.scene.control.skin.TreeCellSkin.updateChildren(TreeCellSkin.java:197); at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204); at com.sun.javafx.scene.control.skin.TreeCellSkin.handleControlPropertyChanged(TreeCellSkin.java:125); at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197); at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55); at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89); at com.sun.javafx.binding.ExpressionHelper$SingleChange.fireValueChangedEvent(ExpressionHelper.java:182); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81); at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103); at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:144); at javafx.beans.property.StringPropertyBase.set(StringPropertyBase.java:49); at javafx.beans.property.StringProperty.setValue(StringProperty.java:65); at javafx.scene.control.Labeled.setText(Labeled.java:145); at qupath.lib.gui.panels.ProjectBrowser$ImageEntryCell.updateItem(ProjectBrowser.java:813); at java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:3967,Performance,concurren,concurrent,3967,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:4031,Performance,concurren,concurrent,4031,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:4092,Performance,concurren,concurrent,4092,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:4168,Performance,concurren,concurrent,4168,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:4229,Performance,concurren,concurrent,4229,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:4313,Performance,concurren,concurrent,4313,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332808179:3729,Security,access,access,3729,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179
https://github.com/qupath/qupath/issues/103#issuecomment-332887649:389,Availability,error,errors,389,"Hi Benjamin, the; ```groovy; guiscript=true; ```; line has to be the *very first line* in the script. Nothing else (even a comment) is allowed above it. This is a rather hackish, QuPath-specific trick to ensure that the script is run on the one JavaFX thread that is allowed to interact with the GUI. Otherwise, any attempt to do anything affecting the GUI directly results in the kind of errors you're seeing. There's an example of its use [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee). Without the guiscript trick, you'd need to wrap the contents of the script in something like this; ```groovy; javafx.application.Platform.runLater {; // Everything else here...; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332887649
https://github.com/qupath/qupath/issues/103#issuecomment-332887649:563,Integrability,wrap,wrap,563,"Hi Benjamin, the; ```groovy; guiscript=true; ```; line has to be the *very first line* in the script. Nothing else (even a comment) is allowed above it. This is a rather hackish, QuPath-specific trick to ensure that the script is run on the one JavaFX thread that is allowed to interact with the GUI. Otherwise, any attempt to do anything affecting the GUI directly results in the kind of errors you're seeing. There's an example of its use [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee). Without the guiscript trick, you'd need to wrap the contents of the script in something like this; ```groovy; javafx.application.Platform.runLater {; // Everything else here...; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332887649
https://github.com/qupath/qupath/issues/104#issuecomment-332890329:765,Usability,undo,undocumented,765,"Thanks Andrew, I'm very glad you like it - and extensions would be welcome!. I think what you're seeing is intended design. A few things that might help:; * Spaces are used (strictly) as the delimiter when you manually input a stain vector - in the example that doesn't work, commas were given instead; * All the numbers adjust when you change any one of them, because QuPath will automatically normalize them to become a unit vector; * It is actually possible to give a sample of each color... although I'm not entirely sure if/where this is documented. Just draw a small rectangle in the area you want, then double-click on the stain you want to change. It should ask if you want to set the values from the ROI - instead of typing them manually. Another possibly-undocumented thing is that if you use 'Estimate stain vectors', you can actually grab the end of one of the stain vectors and move it around by dragging. Although figuring out the appropriate moves to reposition a vector in 3D based on three separate 2D plots isn't entirely easy...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/104#issuecomment-332890329
https://github.com/qupath/qupath/issues/105#issuecomment-333905568:280,Availability,avail,available,280,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568
https://github.com/qupath/qupath/issues/105#issuecomment-333905568:730,Safety,detect,detect,730,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568
https://github.com/qupath/qupath/issues/105#issuecomment-333905568:771,Safety,detect,detectionImageBrightfield,771,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568
https://github.com/qupath/qupath/issues/105#issuecomment-333905568:26,Usability,simpl,simple,26,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568
https://github.com/qupath/qupath/issues/105#issuecomment-333905568:491,Usability,simpl,simply,491,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568
https://github.com/qupath/qupath/issues/106#issuecomment-333917237:726,Availability,avail,available,726,"I'm afraid I don't know of any way to open at 16-bit .mrxs files within QuPath... and I don't know of any current developments that will change that situation. Basically, there are two libraries that can be used to read whole slide images into QuPath: OpenSlide and Bio-Formats. However, OpenSlide only supports a subset of 8-bit RGB .mrxs files (16-bit multichannel would require a very substantial redesign), and is [not officially supported](https://lists.andrew.cmu.edu/pipermail/openslide-users/2012-July/000377.html).; [This blog post](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/) explains why there is no support for .mrxs files within Bio-Formats. If another library became freely available that could read .mrxs files, then potentially this could be used to add support within QuPath. But I'm not personally aware of any such library, and the blog post above suggests that creation one would be a difficult task. I've tagged this post as 'help wanted', in case anyone sees a possibility to help by creating such a library/integration.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-333917237
https://github.com/qupath/qupath/issues/106#issuecomment-333917237:1068,Deployability,integrat,integration,1068,"I'm afraid I don't know of any way to open at 16-bit .mrxs files within QuPath... and I don't know of any current developments that will change that situation. Basically, there are two libraries that can be used to read whole slide images into QuPath: OpenSlide and Bio-Formats. However, OpenSlide only supports a subset of 8-bit RGB .mrxs files (16-bit multichannel would require a very substantial redesign), and is [not officially supported](https://lists.andrew.cmu.edu/pipermail/openslide-users/2012-July/000377.html).; [This blog post](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/) explains why there is no support for .mrxs files within Bio-Formats. If another library became freely available that could read .mrxs files, then potentially this could be used to add support within QuPath. But I'm not personally aware of any such library, and the blog post above suggests that creation one would be a difficult task. I've tagged this post as 'help wanted', in case anyone sees a possibility to help by creating such a library/integration.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-333917237
https://github.com/qupath/qupath/issues/106#issuecomment-333917237:1068,Integrability,integrat,integration,1068,"I'm afraid I don't know of any way to open at 16-bit .mrxs files within QuPath... and I don't know of any current developments that will change that situation. Basically, there are two libraries that can be used to read whole slide images into QuPath: OpenSlide and Bio-Formats. However, OpenSlide only supports a subset of 8-bit RGB .mrxs files (16-bit multichannel would require a very substantial redesign), and is [not officially supported](https://lists.andrew.cmu.edu/pipermail/openslide-users/2012-July/000377.html).; [This blog post](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/) explains why there is no support for .mrxs files within Bio-Formats. If another library became freely available that could read .mrxs files, then potentially this could be used to add support within QuPath. But I'm not personally aware of any such library, and the blog post above suggests that creation one would be a difficult task. I've tagged this post as 'help wanted', in case anyone sees a possibility to help by creating such a library/integration.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-333917237
https://github.com/qupath/qupath/issues/106#issuecomment-333959855:211,Availability,down,downloads,211,"If you do not want to or are not able to rescan those images, one option is using the free Pannoramic Viewer from 3DHISTECH to export the images in 8bit format. It can be obtained at: ; http://www.3dhistech.com/downloads. I recommend maximizing the tile size for speed and your own sanity :) Especially as you would need some kind of external Python script or something in order to convert the images, as Pannoramic viewer only handles one at a time, manually. I recommend multiple logins on a server, or multiple computers!. Last I checked, the newer CaseViewer did not have as many options for exporting and could not be used for this purpose.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-333959855
https://github.com/qupath/qupath/issues/106#issuecomment-333959855:482,Testability,log,logins,482,"If you do not want to or are not able to rescan those images, one option is using the free Pannoramic Viewer from 3DHISTECH to export the images in 8bit format. It can be obtained at: ; http://www.3dhistech.com/downloads. I recommend maximizing the tile size for speed and your own sanity :) Especially as you would need some kind of external Python script or something in order to convert the images, as Pannoramic viewer only handles one at a time, manually. I recommend multiple logins on a server, or multiple computers!. Last I checked, the newer CaseViewer did not have as many options for exporting and could not be used for this purpose.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-333959855
https://github.com/qupath/qupath/issues/106#issuecomment-340702105:54,Deployability,update,update,54,"Hi everyone,. I hope I'm not too late but I wanted to update the feed based on my own experience with the .mrxs format from 3DHISTECH. . It's a problematic format and we have found at least 2 issues related to interoperability with both OpenSlide and Bio-Format. 1) Bio-Format: When scanning in high throughput the software piloting the scanner sometime saves as a snapshot for the current slide the snapshot of the previous slide. Bio-Format by default loads the snapshot so you have to be carefull if you're planing to do some analysis at very low resolution. 2) OpenSlide: Because of the issue above we started to use OpenSlide and grab the low-res from the stack but this also is problematic. For some slides the lowres is larger (in terms of area on the slide) then the actual scanned area on the consecutive higher resolution stack representations. We do not know why it happens only on a few slides of the batch. the converter is an option but this means you have to duplicate the data and when you have a lot slides it is such a pain when you think about the amount of actual data generated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-340702105
https://github.com/qupath/qupath/issues/106#issuecomment-340702105:210,Integrability,interoperab,interoperability,210,"Hi everyone,. I hope I'm not too late but I wanted to update the feed based on my own experience with the .mrxs format from 3DHISTECH. . It's a problematic format and we have found at least 2 issues related to interoperability with both OpenSlide and Bio-Format. 1) Bio-Format: When scanning in high throughput the software piloting the scanner sometime saves as a snapshot for the current slide the snapshot of the previous slide. Bio-Format by default loads the snapshot so you have to be carefull if you're planing to do some analysis at very low resolution. 2) OpenSlide: Because of the issue above we started to use OpenSlide and grab the low-res from the stack but this also is problematic. For some slides the lowres is larger (in terms of area on the slide) then the actual scanned area on the consecutive higher resolution stack representations. We do not know why it happens only on a few slides of the batch. the converter is an option but this means you have to duplicate the data and when you have a lot slides it is such a pain when you think about the amount of actual data generated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-340702105
https://github.com/qupath/qupath/issues/106#issuecomment-340702105:300,Performance,throughput,throughput,300,"Hi everyone,. I hope I'm not too late but I wanted to update the feed based on my own experience with the .mrxs format from 3DHISTECH. . It's a problematic format and we have found at least 2 issues related to interoperability with both OpenSlide and Bio-Format. 1) Bio-Format: When scanning in high throughput the software piloting the scanner sometime saves as a snapshot for the current slide the snapshot of the previous slide. Bio-Format by default loads the snapshot so you have to be carefull if you're planing to do some analysis at very low resolution. 2) OpenSlide: Because of the issue above we started to use OpenSlide and grab the low-res from the stack but this also is problematic. For some slides the lowres is larger (in terms of area on the slide) then the actual scanned area on the consecutive higher resolution stack representations. We do not know why it happens only on a few slides of the batch. the converter is an option but this means you have to duplicate the data and when you have a lot slides it is such a pain when you think about the amount of actual data generated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-340702105
https://github.com/qupath/qupath/issues/106#issuecomment-340702105:454,Performance,load,loads,454,"Hi everyone,. I hope I'm not too late but I wanted to update the feed based on my own experience with the .mrxs format from 3DHISTECH. . It's a problematic format and we have found at least 2 issues related to interoperability with both OpenSlide and Bio-Format. 1) Bio-Format: When scanning in high throughput the software piloting the scanner sometime saves as a snapshot for the current slide the snapshot of the previous slide. Bio-Format by default loads the snapshot so you have to be carefull if you're planing to do some analysis at very low resolution. 2) OpenSlide: Because of the issue above we started to use OpenSlide and grab the low-res from the stack but this also is problematic. For some slides the lowres is larger (in terms of area on the slide) then the actual scanned area on the consecutive higher resolution stack representations. We do not know why it happens only on a few slides of the batch. the converter is an option but this means you have to duplicate the data and when you have a lot slides it is such a pain when you think about the amount of actual data generated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-340702105
https://github.com/qupath/qupath/issues/106#issuecomment-341029135:16,Deployability,update,update,16,"Thanks for your update!. Please let me know if you ever find any improved solution, or possibly a library/SDK that could be used. In the last few days I've seen there is now an open source C++ library for Zeiss czi images [here](https://github.com/zeiss-microscopy/libCZI). It's something I plan to explore a bit more, but I don't know of anything similar for .mrxs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/106#issuecomment-341029135
https://github.com/qupath/qupath/issues/108#issuecomment-335856403:207,Usability,simpl,simplest,207,"Would it work for your analysis to export all of the information you need on the stromal cells (and whatever else you are studying) first, and then delete everything that is not pathClass Tumor? That is the simplest way I can think of to prevent the other overlays from being sent to ImageJ.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/108#issuecomment-335856403
https://github.com/qupath/qupath/issues/108#issuecomment-335863365:227,Availability,down,down,227,"Another way would be to change the opacity of the stromal (etc) colors to 1%. It refuses to allow 0% for full transparency, but if you double click on the color in the annotation tab, select Custom Color, you can manually turn down the opacity to 1%, which may be good enough. I am not sure how to do this in a script, however.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/108#issuecomment-335863365
https://github.com/qupath/qupath/issues/109#issuecomment-335994491:18,Testability,log,log,18,[hs_err_pid159313.log](https://github.com/qupath/qupath/files/1377702/hs_err_pid159313.log),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-335994491
https://github.com/qupath/qupath/issues/109#issuecomment-335994491:87,Testability,log,log,87,[hs_err_pid159313.log](https://github.com/qupath/qupath/files/1377702/hs_err_pid159313.log),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-335994491
https://github.com/qupath/qupath/issues/109#issuecomment-336031954:147,Availability,error,errors,147,"Hmmm... I've never tried this kind of setup, and have no idea if it can work. It would be very interesting if you can find a way... Those dramatic errors tend to involve native libraries (rather that code within Java). From the log, it appears to go wrong at the the earliest stage - so I'd try to launch it from ```QuPathApp.jar``` directly. There might be some clues in [Issue 27](https://github.com/qupath/qupath/issues/27#issuecomment-264693922). Otherwise, would it be of any benefit if you could run scripts on the server - having developed the scripts locally, on the less powerful machine? There are some links regarding that at #94 . Even if this isn't what you want to do, it might be worth trying to run such a script from the command line just to see if it works, or if the same error occurs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-336031954
https://github.com/qupath/qupath/issues/109#issuecomment-336031954:791,Availability,error,error,791,"Hmmm... I've never tried this kind of setup, and have no idea if it can work. It would be very interesting if you can find a way... Those dramatic errors tend to involve native libraries (rather that code within Java). From the log, it appears to go wrong at the the earliest stage - so I'd try to launch it from ```QuPathApp.jar``` directly. There might be some clues in [Issue 27](https://github.com/qupath/qupath/issues/27#issuecomment-264693922). Otherwise, would it be of any benefit if you could run scripts on the server - having developed the scripts locally, on the less powerful machine? There are some links regarding that at #94 . Even if this isn't what you want to do, it might be worth trying to run such a script from the command line just to see if it works, or if the same error occurs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-336031954
https://github.com/qupath/qupath/issues/109#issuecomment-336031954:580,Energy Efficiency,power,powerful,580,"Hmmm... I've never tried this kind of setup, and have no idea if it can work. It would be very interesting if you can find a way... Those dramatic errors tend to involve native libraries (rather that code within Java). From the log, it appears to go wrong at the the earliest stage - so I'd try to launch it from ```QuPathApp.jar``` directly. There might be some clues in [Issue 27](https://github.com/qupath/qupath/issues/27#issuecomment-264693922). Otherwise, would it be of any benefit if you could run scripts on the server - having developed the scripts locally, on the less powerful machine? There are some links regarding that at #94 . Even if this isn't what you want to do, it might be worth trying to run such a script from the command line just to see if it works, or if the same error occurs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-336031954
https://github.com/qupath/qupath/issues/109#issuecomment-336031954:228,Testability,log,log,228,"Hmmm... I've never tried this kind of setup, and have no idea if it can work. It would be very interesting if you can find a way... Those dramatic errors tend to involve native libraries (rather that code within Java). From the log, it appears to go wrong at the the earliest stage - so I'd try to launch it from ```QuPathApp.jar``` directly. There might be some clues in [Issue 27](https://github.com/qupath/qupath/issues/27#issuecomment-264693922). Otherwise, would it be of any benefit if you could run scripts on the server - having developed the scripts locally, on the less powerful machine? There are some links regarding that at #94 . Even if this isn't what you want to do, it might be worth trying to run such a script from the command line just to see if it works, or if the same error occurs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-336031954
https://github.com/qupath/qupath/issues/109#issuecomment-360180072:288,Security,access,access,288,"I guess that is some GLX problem. X11 forwarding with GL has its own set of quirks. This might be of interest:; askubuntu.com/questions/745135/how-to-enable-indirect-glx-contexts-iglx-in-ubuntu-14-04-lts-with-nvidia-gfx. BTW, we are running a similar setup but use xrdp to provide remote access to Windows and Linux machines via RDP. It works with qupath (but graphic output is not accelerated, of course).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-360180072
https://github.com/qupath/qupath/issues/110#issuecomment-336955291:669,Deployability,update,update,669,"Hi, this looks to be the same issue as #74 . It should only affect images that are being read with ImageJ, because of the way in which a cropped region is extracted (when you're unlucky, a second thread might call ```setRoi``` at an inopportune moment). One potential quick fix in the code could be to make [this method](https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L175) synchronized, although this could be refined a bit further. To the best of my knowledge, images accessed any other way (including all whole slide images) should be unaffected. This should be fixed in the next QuPath update. In the meantime, restricting the number of threads should work too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-336955291
https://github.com/qupath/qupath/issues/110#issuecomment-336955291:453,Integrability,synchroniz,synchronized,453,"Hi, this looks to be the same issue as #74 . It should only affect images that are being read with ImageJ, because of the way in which a cropped region is extracted (when you're unlucky, a second thread might call ```setRoi``` at an inopportune moment). One potential quick fix in the code could be to make [this method](https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L175) synchronized, although this could be refined a bit further. To the best of my knowledge, images accessed any other way (including all whole slide images) should be unaffected. This should be fixed in the next QuPath update. In the meantime, restricting the number of threads should work too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-336955291
https://github.com/qupath/qupath/issues/110#issuecomment-336955291:549,Security,access,accessed,549,"Hi, this looks to be the same issue as #74 . It should only affect images that are being read with ImageJ, because of the way in which a cropped region is extracted (when you're unlucky, a second thread might call ```setRoi``` at an inopportune moment). One potential quick fix in the code could be to make [this method](https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L175) synchronized, although this could be refined a bit further. To the best of my knowledge, images accessed any other way (including all whole slide images) should be unaffected. This should be fixed in the next QuPath update. In the meantime, restricting the number of threads should work too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-336955291
https://github.com/qupath/qupath/issues/110#issuecomment-337002695:1724,Availability,avail,availableProcessors,1724,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695
https://github.com/qupath/qupath/issues/110#issuecomment-337002695:244,Safety,detect,detect,244,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695
https://github.com/qupath/qupath/issues/110#issuecomment-337002695:285,Safety,detect,detectionImageBrightfield,285,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695
https://github.com/qupath/qupath/issues/110#issuecomment-337002695:1068,Safety,detect,detect,1068,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695
https://github.com/qupath/qupath/issues/110#issuecomment-337002695:1109,Safety,detect,detectionImageBrightfield,1109,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695
https://github.com/qupath/qupath/issues/110#issuecomment-514596348:71,Deployability,release,releases,71,This should be address in [v0.2.0-m3](https://github.com/qupath/qupath/releases/tag/v0.2.0-m3) (and earlier milestones).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-514596348
https://github.com/qupath/qupath/issues/111#issuecomment-342659964:39,Availability,error,error,39,"I suspect it is running into a similar error as https://github.com/qupath/qupath/issues/67; Try setting your hematoxylin threshold lower, or adjusting your color vector.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/111#issuecomment-342659964
https://github.com/qupath/qupath/issues/111#issuecomment-342661285:104,Energy Efficiency,reduce,reduced,104,Yes Svidro. Thanks. Positive Pixel count needs at least one hematoxylin pixel to work within a ROI. ; I reduced the threshold for H - now each ROI has a result. ; Acutally I did not need H. But it does not matter. . Thank you.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/111#issuecomment-342661285
https://github.com/qupath/qupath/issues/112#issuecomment-342841570:210,Availability,error,error,210,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570
https://github.com/qupath/qupath/issues/112#issuecomment-342841570:363,Safety,detect,detections,363,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570
https://github.com/qupath/qupath/issues/112#issuecomment-342841570:422,Safety,detect,detection,422,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570
https://github.com/qupath/qupath/issues/112#issuecomment-342841570:525,Safety,detect,detection,525,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570
https://github.com/qupath/qupath/issues/112#issuecomment-342841570:604,Safety,detect,detection,604,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:178,Availability,error,errors,178,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:616,Availability,error,error,616,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:185,Integrability,message,messages,185,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:622,Integrability,message,messages,622,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:397,Performance,perform,performed,397,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342939465:603,Testability,log,log,603,"Sorry for your frustrations. I am also unclear on what exact process you used. To help, I would need exact steps that I can use to reproduce the problems you are seeing, and any errors messages you see. I would also suggest:. * Make sure you are working with images in a project.; * Save regularly, and use *File &rarr; Revert* (Ctrl + R) to return to the last saved version.; * Whenever you have performed any lengthy manual steps consider duplicating your entire project folder (or creating a zip file of it) so that you may return to it later.; * If something goes wrong, check out *View &rarr; Show log* for any error messages, and post them here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342939465
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:1895,Availability,recover,recover,1895,"st intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this relationship. This is potentially a bug... or at least unintuitive behavior that may well change in a future release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:2426,Deployability,release,release,2426,"st intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this relationship. This is potentially a bug... or at least unintuitive behavior that may well change in a future release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:79,Safety,detect,detection,79,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:257,Safety,detect,detection,257,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:388,Safety,detect,detected,388,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:539,Safety,detect,detection,539,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:1272,Safety,detect,detections,1272,"ects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this rel",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:1895,Safety,recover,recover,1895,"st intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this relationship. This is potentially a bug... or at least unintuitive behavior that may well change in a future release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:437,Usability,intuit,intuitive,437,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-342941759:784,Usability,clear,clear,784,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:482,Availability,error,error,482,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:535,Availability,avail,available,535,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:828,Availability,error,error,828,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:1477,Availability,failure,failure,1477,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:443,Performance,optimiz,optimization,443,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:275,Safety,detect,detection,275,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:808,Testability,log,log,808,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343227944:351,Usability,undo,undo,351,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:1025,Availability,error,error,1025,"you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful in what I'll do.; > Unfortunately, there",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:1081,Availability,avail,available,1081,"you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful in what I'll do.; > Unfortunately, there",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:1386,Availability,error,error,1386,"er each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful in what I'll do.; > Unfortunately, there was also no backup file in the folder after the; > failure of saving.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/112#issuecomment-343227944>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:2094,Availability,failure,failure,2094,"om> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful in what I'll do.; > Unfortunately, there was also no backup file in the folder after the; > failure of saving.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/112#issuecomment-343227944>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-ZA0lAraRRrf3AumFsqB5fJAaSl1ks5s0zUngaJpZM4QWPEm>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:980,Performance,optimiz,optimization,980,"The backup will only show up, I think, if you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:800,Safety,detect,detection,800,"The backup will only show up, I think, if you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:184,Testability,test,testing,184,"The backup will only show up, I think, if you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:1363,Testability,log,log,1363,"er each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful in what I'll do.; > Unfortunately, there was also no backup file in the folder after the; > failure of saving.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/112#issuecomment-343227944>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343229740:879,Usability,undo,undo,879,"The backup will only show up, I think, if you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740
https://github.com/qupath/qupath/issues/112#issuecomment-343309138:1067,Availability,error,error,1067,"I'd say 3.3 GB is a perfectly respectable amount of RAM for QuPath (I assume your computer has 8 GB or 12 GB...?). Personally, I have never had a powerful enough computer to be able to give anywhere close to 64 GB when either developing or using QuPath... and I don't think I ever needed 16 GB either. Maybe my needs have been modest than @Svidro's but I think that it's not typical to need such huge amounts of memory for most people :). However, I note that you are using a CZI image. There are still some lingering issues around QuPath's ability to handle CZI images; depending on the type of image (e.g. TMA/non-TMA, stitched...), I've heard that sometimes it works very well and sometimes there are problems. It's on my to-do list to investigate why this happens... currently it is a little mysterious for me, and it's not clear if it's something I can resolve within QuPath or which requires more outside help. Anyway, I don't know if that is the source of your memory woes, but it could be. Out of curiosity,; * is your image brightfield or fluorescence? (the error suggests brightfield); * is it a 2D whole slide scan, or an image from a microscope?; * is it a TMA image, large tissue section, or something else?; * does QuPath operate reasonably smoothly, or horribly slowly before the crash? If you need a comparison, there are some [links on the wiki](https://github.com/qupath/qupath/wiki/Counting-cells) to test data that you might use for comparison.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343309138
https://github.com/qupath/qupath/issues/112#issuecomment-343309138:146,Energy Efficiency,power,powerful,146,"I'd say 3.3 GB is a perfectly respectable amount of RAM for QuPath (I assume your computer has 8 GB or 12 GB...?). Personally, I have never had a powerful enough computer to be able to give anywhere close to 64 GB when either developing or using QuPath... and I don't think I ever needed 16 GB either. Maybe my needs have been modest than @Svidro's but I think that it's not typical to need such huge amounts of memory for most people :). However, I note that you are using a CZI image. There are still some lingering issues around QuPath's ability to handle CZI images; depending on the type of image (e.g. TMA/non-TMA, stitched...), I've heard that sometimes it works very well and sometimes there are problems. It's on my to-do list to investigate why this happens... currently it is a little mysterious for me, and it's not clear if it's something I can resolve within QuPath or which requires more outside help. Anyway, I don't know if that is the source of your memory woes, but it could be. Out of curiosity,; * is your image brightfield or fluorescence? (the error suggests brightfield); * is it a 2D whole slide scan, or an image from a microscope?; * is it a TMA image, large tissue section, or something else?; * does QuPath operate reasonably smoothly, or horribly slowly before the crash? If you need a comparison, there are some [links on the wiki](https://github.com/qupath/qupath/wiki/Counting-cells) to test data that you might use for comparison.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343309138
https://github.com/qupath/qupath/issues/112#issuecomment-343309138:571,Integrability,depend,depending,571,"I'd say 3.3 GB is a perfectly respectable amount of RAM for QuPath (I assume your computer has 8 GB or 12 GB...?). Personally, I have never had a powerful enough computer to be able to give anywhere close to 64 GB when either developing or using QuPath... and I don't think I ever needed 16 GB either. Maybe my needs have been modest than @Svidro's but I think that it's not typical to need such huge amounts of memory for most people :). However, I note that you are using a CZI image. There are still some lingering issues around QuPath's ability to handle CZI images; depending on the type of image (e.g. TMA/non-TMA, stitched...), I've heard that sometimes it works very well and sometimes there are problems. It's on my to-do list to investigate why this happens... currently it is a little mysterious for me, and it's not clear if it's something I can resolve within QuPath or which requires more outside help. Anyway, I don't know if that is the source of your memory woes, but it could be. Out of curiosity,; * is your image brightfield or fluorescence? (the error suggests brightfield); * is it a 2D whole slide scan, or an image from a microscope?; * is it a TMA image, large tissue section, or something else?; * does QuPath operate reasonably smoothly, or horribly slowly before the crash? If you need a comparison, there are some [links on the wiki](https://github.com/qupath/qupath/wiki/Counting-cells) to test data that you might use for comparison.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343309138
https://github.com/qupath/qupath/issues/112#issuecomment-343309138:1420,Testability,test,test,1420,"I'd say 3.3 GB is a perfectly respectable amount of RAM for QuPath (I assume your computer has 8 GB or 12 GB...?). Personally, I have never had a powerful enough computer to be able to give anywhere close to 64 GB when either developing or using QuPath... and I don't think I ever needed 16 GB either. Maybe my needs have been modest than @Svidro's but I think that it's not typical to need such huge amounts of memory for most people :). However, I note that you are using a CZI image. There are still some lingering issues around QuPath's ability to handle CZI images; depending on the type of image (e.g. TMA/non-TMA, stitched...), I've heard that sometimes it works very well and sometimes there are problems. It's on my to-do list to investigate why this happens... currently it is a little mysterious for me, and it's not clear if it's something I can resolve within QuPath or which requires more outside help. Anyway, I don't know if that is the source of your memory woes, but it could be. Out of curiosity,; * is your image brightfield or fluorescence? (the error suggests brightfield); * is it a 2D whole slide scan, or an image from a microscope?; * is it a TMA image, large tissue section, or something else?; * does QuPath operate reasonably smoothly, or horribly slowly before the crash? If you need a comparison, there are some [links on the wiki](https://github.com/qupath/qupath/wiki/Counting-cells) to test data that you might use for comparison.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343309138
https://github.com/qupath/qupath/issues/112#issuecomment-343309138:828,Usability,clear,clear,828,"I'd say 3.3 GB is a perfectly respectable amount of RAM for QuPath (I assume your computer has 8 GB or 12 GB...?). Personally, I have never had a powerful enough computer to be able to give anywhere close to 64 GB when either developing or using QuPath... and I don't think I ever needed 16 GB either. Maybe my needs have been modest than @Svidro's but I think that it's not typical to need such huge amounts of memory for most people :). However, I note that you are using a CZI image. There are still some lingering issues around QuPath's ability to handle CZI images; depending on the type of image (e.g. TMA/non-TMA, stitched...), I've heard that sometimes it works very well and sometimes there are problems. It's on my to-do list to investigate why this happens... currently it is a little mysterious for me, and it's not clear if it's something I can resolve within QuPath or which requires more outside help. Anyway, I don't know if that is the source of your memory woes, but it could be. Out of curiosity,; * is your image brightfield or fluorescence? (the error suggests brightfield); * is it a 2D whole slide scan, or an image from a microscope?; * is it a TMA image, large tissue section, or something else?; * does QuPath operate reasonably smoothly, or horribly slowly before the crash? If you need a comparison, there are some [links on the wiki](https://github.com/qupath/qupath/wiki/Counting-cells) to test data that you might use for comparison.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343309138
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:349,Availability,avail,available,349,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:510,Availability,down,down,510,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:849,Availability,avail,available,849,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:900,Availability,error,errors,900,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1089,Availability,error,errors,1089,"iling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeq",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1271,Availability,error,error,1271,"dy noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1320,Availability,ERROR,ERROR,1320,"d cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""d",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1327,Availability,Error,Error,1327,"d cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""d",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2223,Availability,error,error,2223,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2742,Availability,ERROR,ERROR,2742,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2749,Availability,Error,Error,2749,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2015,Energy Efficiency,allocate,allocateElements,2015,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1341,Modifiability,plugin,plugin,1341,"d cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""d",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1533,Modifiability,plugin,plugins,1533,"ge image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"":",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1624,Modifiability,plugin,plugins,1624,"l up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1708,Modifiability,plugin,plugins,1708,"Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": tru",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1716,Modifiability,Plugin,PluginRunnerFX,1716,"omparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeas",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1740,Modifiability,Plugin,PluginRunnerFX,1740,"mage (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; E",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1779,Modifiability,plugin,plugins,1779," once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loc",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1852,Modifiability,plugin,plugins,1852,"le memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IF",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1407,Performance,concurren,concurrent,1407,"s. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1471,Performance,concurren,concurrent,1471,"em, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:59,Safety,detect,detection,59,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:101,Safety,detect,detections,101,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:395,Safety,detect,detection,395,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:701,Safety,detect,detection,701,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2296,Safety,detect,detect,2296,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2335,Safety,detect,detectionImageBrightfield,2335,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1134,Usability,simpl,simply,1134,"obably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be mo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:418,Availability,avail,available,418,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:744,Availability,avail,available,744,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:1300,Deployability,patch,patchy,1300,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:301,Safety,avoid,avoid,301,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:503,Safety,detect,detection,503,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:531,Safety,detect,detection,531,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:1137,Safety,detect,detection,1137,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343393030:610,Usability,simpl,simply,610,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030
https://github.com/qupath/qupath/issues/112#issuecomment-343607120:174,Safety,detect,detection,174,"If you are still running into problems, I would be interested in whether they also show up with a freshly opened QuPath instance (create ROIs, save and close, open, run cell detection). The tests in my last post showed that I could run a fairly large cell detection (570k cells) with only 2GB of RAM allowed, as long as it was the first thing I did after opening QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343607120
https://github.com/qupath/qupath/issues/112#issuecomment-343607120:256,Safety,detect,detection,256,"If you are still running into problems, I would be interested in whether they also show up with a freshly opened QuPath instance (create ROIs, save and close, open, run cell detection). The tests in my last post showed that I could run a fairly large cell detection (570k cells) with only 2GB of RAM allowed, as long as it was the first thing I did after opening QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343607120
https://github.com/qupath/qupath/issues/112#issuecomment-343607120:190,Testability,test,tests,190,"If you are still running into problems, I would be interested in whether they also show up with a freshly opened QuPath instance (create ROIs, save and close, open, run cell detection). The tests in my last post showed that I could run a fairly large cell detection (570k cells) with only 2GB of RAM allowed, as long as it was the first thing I did after opening QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343607120
https://github.com/qupath/qupath/issues/112#issuecomment-344193230:68,Safety,detect,detection,68,"I'm still busy with optimising the parameters for the positive cell detection such as nucleaus DAB mean/max or cytoplasm or cell. After a serie of runs on single ROI, Qupath fails again with the same 'problem' out of memory. Which is likely to be false 'cause I still have 3.5 gb RAM free and its the only program open. When I close the program and open it, it works a gain, but after a ten-fold runs it 'crashes' again.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344193230
https://github.com/qupath/qupath/issues/112#issuecomment-344249262:115,Testability,log,log,115,"Qupath did it again, deleting an annotation after running a positive cell analysis.; Don't know what happened, the log doesn't show anything. Luckily, I now now the ctrl+R button; ![2017-11-14](https://user-images.githubusercontent.com/33484227/32780738-aa5d356e-c942-11e7-8f5d-780bf2340640.png). ![image](https://user-images.githubusercontent.com/33484227/32780681-78758d44-c942-11e7-9b4c-fa130dcbfe5f.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344249262
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:598,Availability,avail,available,598,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1164,Availability,down,download,1164,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1374,Performance,optimiz,optimizing,1374,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1439,Safety,detect,detection,1439,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:965,Testability,test,test,965,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1183,Testability,test,testdata,1183,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:72,Usability,clear,clear,72,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1037,Usability,simpl,simple,1037,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051
https://github.com/qupath/qupath/issues/112#issuecomment-359880979:104,Deployability,update,update,104,"Closing this issue as it has gone quiet - feel free to reopen if there is more information. The recent [update to the Bio-Formats extension](https://groups.google.com/d/msg/qupath-users/78PpZuu2J1s/su6ZjY0mAgAJ) addresses numerous memory & performance issues, and should help with CZI images.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-359880979
https://github.com/qupath/qupath/issues/112#issuecomment-359880979:240,Performance,perform,performance,240,"Closing this issue as it has gone quiet - feel free to reopen if there is more information. The recent [update to the Bio-Formats extension](https://groups.google.com/d/msg/qupath-users/78PpZuu2J1s/su6ZjY0mAgAJ) addresses numerous memory & performance issues, and should help with CZI images.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-359880979
https://github.com/qupath/qupath/issues/113#issuecomment-342859723:306,Integrability,depend,depending,306,"Pete's suggestion in #114 might be useful here if you wanted to do a little; image reshuffling. 1. Have all of the aligned ndpi files named the same exact thing, but with; the images in different folders called DAPI, TRITC etc. 2. Use multiple project files, each pointing to one of those channel; folders depending on which channel you want to work in (DAPI.qpproj etc.).; Then you never need to move or edit the qpdata files, just do some renaming; at the start and open the project file for the channel you want to work in; later. On Nov 8, 2017 7:18 AM, ""shadyamigo"" <notifications@github.com> wrote:. > Reopened #113 <https://github.com/qupath/qupath/issues/113>.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/113#event-1332054127>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-f4ZmcVLyW_Q2tGpbFj8Z4JIVC2lks5s0cY_gaJpZM4QWZzE>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/113#issuecomment-342859723
https://github.com/qupath/qupath/issues/113#issuecomment-342861124:438,Testability,log,logged,438,"@Svidro beat me to it with the link to #114 ; The multiple projects could help. It could be scripted as well, if you don't mind going a bit more deeply into the QuPath code, but probably best see if the workaround... works. (Incidentally, I didn't know about ndpis until a couple of weeks ago... but I think this is the third time I've heard of the problem now. Certainly I will look into a longer term solution, and it's good to have it logged here as an issue now.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/113#issuecomment-342861124
https://github.com/qupath/qupath/issues/113#issuecomment-343225491:139,Availability,down,downloaded,139,Sorry Peter. I missed your reply-I will give the multiple projects a try. But I am also keen to script it. I have a c# background but have downloaded the java source to see if I can get my head around it. I can supply the ndpis files if you would like to do any testing. Basically it's just a text file that links multiple ndpi files that came from the same scan run (i.e. different filter per ndpi file),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/113#issuecomment-343225491
https://github.com/qupath/qupath/issues/113#issuecomment-343225491:262,Testability,test,testing,262,Sorry Peter. I missed your reply-I will give the multiple projects a try. But I am also keen to script it. I have a c# background but have downloaded the java source to see if I can get my head around it. I can supply the ndpis files if you would like to do any testing. Basically it's just a text file that links multiple ndpi files that came from the same scan run (i.e. different filter per ndpi file),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/113#issuecomment-343225491
https://github.com/qupath/qupath/issues/113#issuecomment-358744976:112,Performance,perform,performance,112,"Hopefully this is fixed now. At least it works for the one the ndpis example I've got, although with many other performance improvements. There's more info [here](https://groups.google.com/d/msg/qupath-users/78PpZuu2J1s/su6ZjY0mAgAJ).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/113#issuecomment-358744976
https://github.com/qupath/qupath/issues/114#issuecomment-342855367:736,Security,access,access,736,"You can also open the `project.qpproj` file directly in a text editor, and then use 'Find & Replace' to change the paths. That is probably easier and faster than reimporting. You could even duplicate the project file and keep the duplicates in the same directory, each with the paths including a drive letter you might need. So you might have `projectD.qpproj`, `projectE.qppro`j, `projectF.qpproj`... each containing the different paths that you might need. Ultimately the data for each image is stored inside the 'data' subdirectory inside the project folder, with a filename based only on the name of the image (not its full path). Therefore just open the project file that contains the correct paths, and it should immediately have access to the same data. There is a little bit of information about how projects are structured at https://github.com/qupath/qupath/wiki/Project-structure; It's usually best to leave QuPath to take care of the files in the project directory... but it is intentionally quite simple so that, if you know more or less what it is doing, you can certainly hack it a bit to behave the way you need.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-342855367
https://github.com/qupath/qupath/issues/114#issuecomment-342855367:1010,Usability,simpl,simple,1010,"You can also open the `project.qpproj` file directly in a text editor, and then use 'Find & Replace' to change the paths. That is probably easier and faster than reimporting. You could even duplicate the project file and keep the duplicates in the same directory, each with the paths including a drive letter you might need. So you might have `projectD.qpproj`, `projectE.qppro`j, `projectF.qpproj`... each containing the different paths that you might need. Ultimately the data for each image is stored inside the 'data' subdirectory inside the project folder, with a filename based only on the name of the image (not its full path). Therefore just open the project file that contains the correct paths, and it should immediately have access to the same data. There is a little bit of information about how projects are structured at https://github.com/qupath/qupath/wiki/Project-structure; It's usually best to leave QuPath to take care of the files in the project directory... but it is intentionally quite simple so that, if you know more or less what it is doing, you can certainly hack it a bit to behave the way you need.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-342855367
https://github.com/qupath/qupath/issues/114#issuecomment-343150195:37,Testability,test,tested,37,"Thanks a million for your answers! I tested both ways, and for my purpose the one @petebankhead proposed works the best, as it's very fast to do and I have over a hundred slides in several projects. Cheers! 🥇",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-343150195
https://github.com/qupath/qupath/issues/114#issuecomment-487867515:383,Security,password,password,383,"Hi, had similar issues as we have multiple backups of our files on different external hardrives. It is possible however to reassign the letter of each hardrive by going into administrative tools, see below. Open the Start menu, and type ""Administrative Tools"" in the search box. Click it in the list that appears and then double-click ""Computer Management."" Enter your administrator password if Windows asks for it. Click the ""Disk Management"" link, and then click your external hard drive's assigned disk. Right-click the disk and click ""Change Drive Letters and Paths."". Click the ""Change"" button and click ""Assign the Following Drive Letter."" Click the new letter to assign to your external hard drive and click ""OK"" to save your change. This way as long as the files and folder structures within the hardrive remain the same all that you need to change is the letter of the hardrive so that it is the same as the original that it was stored on.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-487867515
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:151,Safety,detect,detection,151,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:361,Safety,Detect,Detection,361,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:24,Testability,log,log,24,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:46,Testability,log,log,46,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:271,Testability,test,test,271,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/115#issuecomment-343274362:347,Usability,Simpl,Simple,347,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362
https://github.com/qupath/qupath/issues/117#issuecomment-343394860:512,Security,access,accessing,512,"Thanks!. For the TMA data viewer troubles, to be honest I entirely forgot that the *Import from current project (experimental)* option is there... it probably isn't a very good idea. I'd suggest doing the following instead:; * Use *File &rarr; Export TMA data* for each of your images, using the same output directory (it's also scriptable); * Drag the export directory into the TMA data viewer. That way, the data viewer doesn't need to bother with QuPath objects (potentially hundreds of MB per TMA), nor with accessing the whole slide scans. Rather, it will work with small, exported JPEGs and parsed text files, and hopefully behave much better.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/117#issuecomment-343394860
https://github.com/qupath/qupath/issues/118#issuecomment-345720827:687,Safety,detect,detection,687,"Aside, have you tried the _Subcellular detection_ command or ImageJ macro runner for identifying the spot counts in QuPath? In case you were exporting the images for the FISH analysis. Otherwise, there are some decent options for scripts picking out objects and exporting them as individual files found at https://github.com/qupath/qupath/issues/97 although that is mostly if you want an image of the bounding box area. If you want the nuclei and no other image data, I am less certain, although there is probably a way to do so using the ImageJ macro runner and saving them via ImageJ using the commands there to remove the area outside of the nucleus ROI.; Edit:; More info about spot detection here: https://github.com/qupath/qupath/wiki/Spot-detection",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345720827
https://github.com/qupath/qupath/issues/118#issuecomment-345720827:746,Safety,detect,detection,746,"Aside, have you tried the _Subcellular detection_ command or ImageJ macro runner for identifying the spot counts in QuPath? In case you were exporting the images for the FISH analysis. Otherwise, there are some decent options for scripts picking out objects and exporting them as individual files found at https://github.com/qupath/qupath/issues/97 although that is mostly if you want an image of the bounding box area. If you want the nuclei and no other image data, I am less certain, although there is probably a way to do so using the ImageJ macro runner and saving them via ImageJ using the commands there to remove the area outside of the nucleus ROI.; Edit:; More info about spot detection here: https://github.com/qupath/qupath/wiki/Spot-detection",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345720827
https://github.com/qupath/qupath/issues/118#issuecomment-345747414:104,Safety,detect,detecting,104,"Thanks for your answer. . For segmentation I use **DoG superpixel creator** which gives nice results on detecting individual nuclei. . Afterwards I try to use the one line macro as proposed in #85 : ; `saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle())`; to save the detected nuclei as separate image file. One exampel is shown in the follwoing screenshot (2 nuclei of interest):. ![01](https://user-images.githubusercontent.com/20478730/33028565-92f4738c-ce16-11e7-8fe5-88f1325027d2.PNG). However, the macro does only save annotations and segmented nculei are not classified as annotations (as objects/detections). . Is there a way to transfer the type/class of segmented nuclei to annotation type/class? This would make the macro work (I guess).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345747414
https://github.com/qupath/qupath/issues/118#issuecomment-345747414:275,Safety,detect,detected,275,"Thanks for your answer. . For segmentation I use **DoG superpixel creator** which gives nice results on detecting individual nuclei. . Afterwards I try to use the one line macro as proposed in #85 : ; `saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle())`; to save the detected nuclei as separate image file. One exampel is shown in the follwoing screenshot (2 nuclei of interest):. ![01](https://user-images.githubusercontent.com/20478730/33028565-92f4738c-ce16-11e7-8fe5-88f1325027d2.PNG). However, the macro does only save annotations and segmented nculei are not classified as annotations (as objects/detections). . Is there a way to transfer the type/class of segmented nuclei to annotation type/class? This would make the macro work (I guess).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345747414
https://github.com/qupath/qupath/issues/118#issuecomment-345747414:611,Safety,detect,detections,611,"Thanks for your answer. . For segmentation I use **DoG superpixel creator** which gives nice results on detecting individual nuclei. . Afterwards I try to use the one line macro as proposed in #85 : ; `saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle())`; to save the detected nuclei as separate image file. One exampel is shown in the follwoing screenshot (2 nuclei of interest):. ![01](https://user-images.githubusercontent.com/20478730/33028565-92f4738c-ce16-11e7-8fe5-88f1325027d2.PNG). However, the macro does only save annotations and segmented nculei are not classified as annotations (as objects/detections). . Is there a way to transfer the type/class of segmented nuclei to annotation type/class? This would make the macro work (I guess).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345747414
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:342,Availability,down,downsample,342,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:800,Availability,down,downsample,800,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:1091,Availability,error,error,1091,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:1097,Integrability,message,message,1097,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:1065,Safety,detect,detections,1065,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346617281:442,Testability,TEST,TESTFOLDER,442,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281
https://github.com/qupath/qupath/issues/118#issuecomment-346643029:101,Safety,detect,detections,101,"Glad you made it that far! I have not played with exporting images much, but for cycling through the detections I think you want getDetectionObjects(). I do not think selecting them returns them, so your script is not actually running through anything. You can test it by putting a print statement inside the loop too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346643029
https://github.com/qupath/qupath/issues/118#issuecomment-346643029:261,Testability,test,test,261,"Glad you made it that far! I have not played with exporting images much, but for cycling through the detections I think you want getDetectionObjects(). I do not think selecting them returns them, so your script is not actually running through anything. You can test it by putting a print statement inside the loop too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346643029
https://github.com/qupath/qupath/issues/118#issuecomment-346793633:176,Availability,down,downsample,176,"Thanks! Now it partially works using this code:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest; // Define resolution - 1.0 means full size; double downsample = 1.0; // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput); // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); print('Done!'); ```. **However it only saves one Polygon** (more or less randomly, out of ca. 20). I guess its because the Polygons do not have unique names. . Is there a way to include a command in the above mentioned script that gives each Polygon an unique name?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346793633
https://github.com/qupath/qupath/issues/118#issuecomment-346793633:523,Availability,down,downsample,523,"Thanks! Now it partially works using this code:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest; // Define resolution - 1.0 means full size; double downsample = 1.0; // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput); // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); print('Done!'); ```. **However it only saves one Polygon** (more or less randomly, out of ca. 20). I guess its because the Polygons do not have unique names. . Is there a way to include a command in the above mentioned script that gives each Polygon an unique name?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346793633
https://github.com/qupath/qupath/issues/118#issuecomment-346830301:279,Availability,down,downsample,279,"I think I got it. The point was to give each Polygon an individual name so that each Polygon can be saved as individual image file. This works for me:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in getDetectionObjects()){; roi = Polygon.getROI(); print(roi); area = roi.getArea(); print(area); name = (""Polygon_"" + area); print(name); // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); }; print('Done!'). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346830301
https://github.com/qupath/qupath/issues/118#issuecomment-346830301:842,Availability,down,downsample,842,"I think I got it. The point was to give each Polygon an individual name so that each Polygon can be saved as individual image file. This works for me:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in getDetectionObjects()){; roi = Polygon.getROI(); print(roi); area = roi.getArea(); print(area); name = (""Polygon_"" + area); print(name); // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); }; print('Done!'). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346830301
https://github.com/qupath/qupath/issues/118#issuecomment-346839298:286,Integrability,depend,depend,286,"That will work as long as you never have two with the exact same area. I would recommend using the X Y coordinates, or creating a dummy variable where i = i+1 each time through the for loop with i going into the image name instead of area. I suppose the chances of that being important depend on how many nuclei you are studying per image.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346839298
https://github.com/qupath/qupath/issues/118#issuecomment-346839298:136,Modifiability,variab,variable,136,"That will work as long as you never have two with the exact same area. I would recommend using the X Y coordinates, or creating a dummy variable where i = i+1 each time through the for loop with i going into the image name instead of area. I suppose the chances of that being important depend on how many nuclei you are studying per image.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346839298
https://github.com/qupath/qupath/issues/118#issuecomment-346840724:286,Integrability,depend,depend,286,"That will work as long as you never have two with the exact same area. I would recommend using the X Y coordinates, or creating a dummy variable where i = i+1 each time through the for loop with i going into the image name instead of area. I suppose the chances of that being important depend on how many nuclei you are studying per image.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346840724
https://github.com/qupath/qupath/issues/118#issuecomment-346840724:136,Modifiability,variab,variable,136,"That will work as long as you never have two with the exact same area. I would recommend using the X Y coordinates, or creating a dummy variable where i = i+1 each time through the for loop with i going into the image name instead of area. I suppose the chances of that being important depend on how many nuclei you are studying per image.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346840724
https://github.com/qupath/qupath/issues/118#issuecomment-346842870:149,Availability,down,downsample,149,"Yes, the i - method:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); i = 0; for (Polygon in getDetectionObjects()){; roi = Polygon.getROI(); print(roi); area = roi.getArea(); print(area); CentroidX = roi.getCentroidX(); print(CentroidX); name = (""Polygon_"" + i); print(name); // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); i = i + 1; }; print('Done!'); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346842870
https://github.com/qupath/qupath/issues/118#issuecomment-346842870:766,Availability,down,downsample,766,"Yes, the i - method:. ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); i = 0; for (Polygon in getDetectionObjects()){; roi = Polygon.getROI(); print(roi); area = roi.getArea(); print(area); CentroidX = roi.getCentroidX(); print(CentroidX); name = (""Polygon_"" + i); print(name); // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); i = i + 1; }; print('Done!'); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346842870
https://github.com/qupath/qupath/issues/118#issuecomment-346934805:213,Availability,down,downsample,213,"Hi, joining a bit late.... part of one of the suggestions above contained:; ```groovy; getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); ```. If you want to keep that kind of concise way of looping, `eachWithIndex` might help. The corresponding part might look something like this:; ```groovy; getDetectionObjects().eachWithIndex {pathObject, index ->; def img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, pathObject.getROI())); def name = pathObject.getDisplayedName() + '_' + index + '.jpg'; ImageIO.write(img, 'JPEG', new File(dirOutput, name)); }; ```. I also used `getDisplayedName()`; if no name has been set, this will try to come up with something else useful for that object (e.g. the classification). And I added `def`, which you don't really need but it keeps the variables local (otherwise you could likely access them after the loop).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346934805
https://github.com/qupath/qupath/issues/118#issuecomment-346934805:612,Availability,down,downsample,612,"Hi, joining a bit late.... part of one of the suggestions above contained:; ```groovy; getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); ```. If you want to keep that kind of concise way of looping, `eachWithIndex` might help. The corresponding part might look something like this:; ```groovy; getDetectionObjects().eachWithIndex {pathObject, index ->; def img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, pathObject.getROI())); def name = pathObject.getDisplayedName() + '_' + index + '.jpg'; ImageIO.write(img, 'JPEG', new File(dirOutput, name)); }; ```. I also used `getDisplayedName()`; if no name has been set, this will try to come up with something else useful for that object (e.g. the classification). And I added `def`, which you don't really need but it keeps the variables local (otherwise you could likely access them after the loop).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346934805
https://github.com/qupath/qupath/issues/118#issuecomment-346934805:993,Modifiability,variab,variables,993,"Hi, joining a bit late.... part of one of the suggestions above contained:; ```groovy; getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); ```. If you want to keep that kind of concise way of looping, `eachWithIndex` might help. The corresponding part might look something like this:; ```groovy; getDetectionObjects().eachWithIndex {pathObject, index ->; def img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, pathObject.getROI())); def name = pathObject.getDisplayedName() + '_' + index + '.jpg'; ImageIO.write(img, 'JPEG', new File(dirOutput, name)); }; ```. I also used `getDisplayedName()`; if no name has been set, this will try to come up with something else useful for that object (e.g. the classification). And I added `def`, which you don't really need but it keeps the variables local (otherwise you could likely access them after the loop).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346934805
https://github.com/qupath/qupath/issues/118#issuecomment-346934805:1037,Security,access,access,1037,"Hi, joining a bit late.... part of one of the suggestions above contained:; ```groovy; getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); ```. If you want to keep that kind of concise way of looping, `eachWithIndex` might help. The corresponding part might look something like this:; ```groovy; getDetectionObjects().eachWithIndex {pathObject, index ->; def img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, pathObject.getROI())); def name = pathObject.getDisplayedName() + '_' + index + '.jpg'; ImageIO.write(img, 'JPEG', new File(dirOutput, name)); }; ```. I also used `getDisplayedName()`; if no name has been set, this will try to come up with something else useful for that object (e.g. the classification). And I added `def`, which you don't really need but it keeps the variables local (otherwise you could likely access them after the loop).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346934805
https://github.com/qupath/qupath/issues/119#issuecomment-346389148:4,Integrability,interface,interface,4,"The interface will generally use the second color vector as its detection channel for the subcellular detection, so make sure that color vector is set to your fast red. If you need to do 2 color, I recommend setting the image type to Brightfield Other, though that has its own dangers! You are not locked into using DAB. I think changing the name of the color vector also changes the description in the subcellular detection dialog.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346389148
https://github.com/qupath/qupath/issues/119#issuecomment-346389148:64,Safety,detect,detection,64,"The interface will generally use the second color vector as its detection channel for the subcellular detection, so make sure that color vector is set to your fast red. If you need to do 2 color, I recommend setting the image type to Brightfield Other, though that has its own dangers! You are not locked into using DAB. I think changing the name of the color vector also changes the description in the subcellular detection dialog.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346389148
https://github.com/qupath/qupath/issues/119#issuecomment-346389148:102,Safety,detect,detection,102,"The interface will generally use the second color vector as its detection channel for the subcellular detection, so make sure that color vector is set to your fast red. If you need to do 2 color, I recommend setting the image type to Brightfield Other, though that has its own dangers! You are not locked into using DAB. I think changing the name of the color vector also changes the description in the subcellular detection dialog.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346389148
https://github.com/qupath/qupath/issues/119#issuecomment-346389148:415,Safety,detect,detection,415,"The interface will generally use the second color vector as its detection channel for the subcellular detection, so make sure that color vector is set to your fast red. If you need to do 2 color, I recommend setting the image type to Brightfield Other, though that has its own dangers! You are not locked into using DAB. I think changing the name of the color vector also changes the description in the subcellular detection dialog.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346389148
https://github.com/qupath/qupath/issues/119#issuecomment-346583086:216,Safety,detect,detection,216,"Thanks! Changing this solved it. I'm now trying to quantify the number of dots as a ratio of nuclear:cytoplasmic location. I'm using the script at the bottom of this page:. https://github.com/qupath/qupath/wiki/Spot-detection. This tells me the location of the spot when it is selected. However, I want to know the number of nuclear vs cytoplasmic dots when the cell is selected. I guess the nearest measure of this (using the above script) is just the Nuclear DAB OD mean vs Cytoplasmic DAB mean, but I'd like to know the actual number of dots as a nuclear:cytoplasmic ratio if possible?. Apologies if this is a simple question!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346583086
https://github.com/qupath/qupath/issues/119#issuecomment-346583086:613,Usability,simpl,simple,613,"Thanks! Changing this solved it. I'm now trying to quantify the number of dots as a ratio of nuclear:cytoplasmic location. I'm using the script at the bottom of this page:. https://github.com/qupath/qupath/wiki/Spot-detection. This tells me the location of the spot when it is selected. However, I want to know the number of nuclear vs cytoplasmic dots when the cell is selected. I guess the nearest measure of this (using the above script) is just the Nuclear DAB OD mean vs Cytoplasmic DAB mean, but I'd like to know the actual number of dots as a nuclear:cytoplasmic ratio if possible?. Apologies if this is a simple question!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346583086
https://github.com/qupath/qupath/issues/119#issuecomment-346644631:462,Modifiability,extend,extended,462,"I think you want something like the top script on https://github.com/qupath/qupath/wiki/Scripting-examples. You cycle through all cells, and then using measurements from each cell, you add another measurement. I do not have good ISH images handy to test it out, but I hope the example is easy enough to modify. One warning is to be very careful about the amount of whitespace in the measurement names, as it can vary by a space or two between different parts of extended measurement names. ; edit:phone typing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346644631
https://github.com/qupath/qupath/issues/119#issuecomment-346644631:249,Testability,test,test,249,"I think you want something like the top script on https://github.com/qupath/qupath/wiki/Scripting-examples. You cycle through all cells, and then using measurements from each cell, you add another measurement. I do not have good ISH images handy to test it out, but I hope the example is easy enough to modify. One warning is to be very careful about the amount of whitespace in the measurement names, as it can vary by a space or two between different parts of extended measurement names. ; edit:phone typing",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346644631
https://github.com/qupath/qupath/issues/119#issuecomment-347189540:678,Usability,simpl,simple,678,"Thanks. I've used this and come up with a measurement that is an expression of the Cell DAB OD mean:Nucleus DAB OD mean. This is an alright proxy, but doesn't account for variances in the OD of the dots themselves. . Ideally I would have a measurement of the absolute number of dots within the nucleus vs cytoplasm for every cell I click on. However I can't work out how to write a script for this as these measurements aren't visible when a cell is selected, only when a dot is selected. How do I add these measurements (number of dots in the nucleus and number of dots in the cytoplasm) so that I can combine them using the script you mentioned?. Apologies again if this is a simple question. Thanks for your help",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347189540
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:207,Deployability,update,update,207,"Ah, no, you are absolutely correct. I normally would handle this by exporting the detections file and processing it in R. But if you want to visualize the ratio (with view measurements etc) you will need to update the cell measurements once you have determined the nuclear/cytoplasmic localization. Roughly speaking, you need to either cycle through all cells, and sum/average their stats for that cell, or cycle through all subcellular detections, and update the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:453,Deployability,update,update,453,"Ah, no, you are absolutely correct. I normally would handle this by exporting the detections file and processing it in R. But if you want to visualize the ratio (with view measurements etc) you will need to update the cell measurements once you have determined the nuclear/cytoplasmic localization. Roughly speaking, you need to either cycle through all cells, and sum/average their stats for that cell, or cycle through all subcellular detections, and update the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:82,Safety,detect,detections,82,"Ah, no, you are absolutely correct. I normally would handle this by exporting the detections file and processing it in R. But if you want to visualize the ratio (with view measurements etc) you will need to update the cell measurements once you have determined the nuclear/cytoplasmic localization. Roughly speaking, you need to either cycle through all cells, and sum/average their stats for that cell, or cycle through all subcellular detections, and update the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:437,Safety,detect,detections,437,"Ah, no, you are absolutely correct. I normally would handle this by exporting the detections file and processing it in R. But if you want to visualize the ratio (with view measurements etc) you will need to update the cell measurements once you have determined the nuclear/cytoplasmic localization. Roughly speaking, you need to either cycle through all cells, and sum/average their stats for that cell, or cycle through all subcellular detections, and update the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1455,Safety,detect,detect,1455,"e the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getM",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1585,Safety,detect,detection,1585,"lls from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.clo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1807,Safety,detect,detection,1807,"lusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.closeList(); }; ; } ; println(""Done summarizing""). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1926,Safety,detect,detection,1926,"lusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.closeList(); }; ; } ; println(""Done summarizing""). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:2046,Safety,detect,detection,2046,"lusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.closeList(); }; ; } ; println(""Done summarizing""). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/119#issuecomment-347208202:2109,Safety,detect,detection,2109,"lusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.closeList(); }; ; } ; println(""Done summarizing""). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202
https://github.com/qupath/qupath/issues/121#issuecomment-349092952:652,Safety,detect,detections,652,"Hi Ieva, ; That shall defenitely be possible. You can generate regions of interest for each spheroid. That works via superpixel approach: Analyse > Region identification > Tiles & Superpixels > SLIC or DoG. You generate superpixels: ; ![grafik](https://user-images.githubusercontent.com/16352785/33573958-c45aa460-d937-11e7-8d4f-1d13d89a5e61.png). Change the image type in the image tab into ""Brightfield H&E"". ; Then feed it with statistics. ; Analyse > Calculate features > add intensity features. Use these checkboxes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574028-0b866eb4-d938-11e7-820d-3629d339a516.png). and run it for detections. . Next step is to train a classifier to detect the spheroids: First create a class ""Spheroid"" in the annotation tab by rightclick onto the list of classes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574089-3396762e-d938-11e7-8665-d2eef84ae60b.png). Then use the polygon and draw a circle around spheroids can set class of the polygon to ""Spheproid""; and paint polygon in the whitespace and set class to other or whitespace: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574170-7e522f3c-d938-11e7-9a84-d75add61bf04.png). Now go to menue ""Classify"" > ""create detection classifier"". ; Press advanced options and then ""use all"". Then build and apply. ; ![grafik](https://user-images.githubusercontent.com/16352785/33574202-9c0ac8a4-d938-11e7-822b-a9706b8cf600.png). The first result looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574227-a943d70e-d938-11e7-84a0-f4aef4baa9b1.png). after enough training you can convert the spheroid reagions into real regions of interest and afterwards for example count cells: . That is done by: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574256-c49afc1c-d938-11e7-8dfc-f03f1967c133.png). choose only spheroids to be converted to roi: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574300-e2e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349092952
https://github.com/qupath/qupath/issues/121#issuecomment-349092952:704,Safety,detect,detect,704,"Hi Ieva, ; That shall defenitely be possible. You can generate regions of interest for each spheroid. That works via superpixel approach: Analyse > Region identification > Tiles & Superpixels > SLIC or DoG. You generate superpixels: ; ![grafik](https://user-images.githubusercontent.com/16352785/33573958-c45aa460-d937-11e7-8d4f-1d13d89a5e61.png). Change the image type in the image tab into ""Brightfield H&E"". ; Then feed it with statistics. ; Analyse > Calculate features > add intensity features. Use these checkboxes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574028-0b866eb4-d938-11e7-820d-3629d339a516.png). and run it for detections. . Next step is to train a classifier to detect the spheroids: First create a class ""Spheroid"" in the annotation tab by rightclick onto the list of classes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574089-3396762e-d938-11e7-8665-d2eef84ae60b.png). Then use the polygon and draw a circle around spheroids can set class of the polygon to ""Spheproid""; and paint polygon in the whitespace and set class to other or whitespace: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574170-7e522f3c-d938-11e7-9a84-d75add61bf04.png). Now go to menue ""Classify"" > ""create detection classifier"". ; Press advanced options and then ""use all"". Then build and apply. ; ![grafik](https://user-images.githubusercontent.com/16352785/33574202-9c0ac8a4-d938-11e7-822b-a9706b8cf600.png). The first result looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574227-a943d70e-d938-11e7-84a0-f4aef4baa9b1.png). after enough training you can convert the spheroid reagions into real regions of interest and afterwards for example count cells: . That is done by: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574256-c49afc1c-d938-11e7-8dfc-f03f1967c133.png). choose only spheroids to be converted to roi: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574300-e2e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349092952
https://github.com/qupath/qupath/issues/121#issuecomment-349092952:1262,Safety,detect,detection,1262,"ser-images.githubusercontent.com/16352785/33573958-c45aa460-d937-11e7-8d4f-1d13d89a5e61.png). Change the image type in the image tab into ""Brightfield H&E"". ; Then feed it with statistics. ; Analyse > Calculate features > add intensity features. Use these checkboxes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574028-0b866eb4-d938-11e7-820d-3629d339a516.png). and run it for detections. . Next step is to train a classifier to detect the spheroids: First create a class ""Spheroid"" in the annotation tab by rightclick onto the list of classes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574089-3396762e-d938-11e7-8665-d2eef84ae60b.png). Then use the polygon and draw a circle around spheroids can set class of the polygon to ""Spheproid""; and paint polygon in the whitespace and set class to other or whitespace: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574170-7e522f3c-d938-11e7-9a84-d75add61bf04.png). Now go to menue ""Classify"" > ""create detection classifier"". ; Press advanced options and then ""use all"". Then build and apply. ; ![grafik](https://user-images.githubusercontent.com/16352785/33574202-9c0ac8a4-d938-11e7-822b-a9706b8cf600.png). The first result looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574227-a943d70e-d938-11e7-84a0-f4aef4baa9b1.png). after enough training you can convert the spheroid reagions into real regions of interest and afterwards for example count cells: . That is done by: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574256-c49afc1c-d938-11e7-8dfc-f03f1967c133.png). choose only spheroids to be converted to roi: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574300-e2ee9d72-d938-11e7-9130-871b14ac3036.png). The image looks like that now: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574325-f333fc72-d938-11e7-961f-0bafbeda1595.png). the brown areas are the speroid ROIs. ; You can now rund celldetect",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349092952
https://github.com/qupath/qupath/issues/121#issuecomment-349094523:53,Safety,Detect,Detection,53,"That looks like the sort of thing that Simple Tissue Detection might work for with the correct settings. Something around 220 threshold maybe, with a medium requested pixel size and minimum area (keep setting these lower until you are picking up all of what you want). Also you will probably want to uncheck Single annotation. The requested pixel size is probably the most important measurement to play around with if you use this method. David beat me to it! His method is also probably better in the long run, though this gives another, slightly simpler method. I would also be careful about using too many features in your classifier, or at least make sure your training set is significantly larger than the number of features you use!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349094523
https://github.com/qupath/qupath/issues/121#issuecomment-349094523:39,Usability,Simpl,Simple,39,"That looks like the sort of thing that Simple Tissue Detection might work for with the correct settings. Something around 220 threshold maybe, with a medium requested pixel size and minimum area (keep setting these lower until you are picking up all of what you want). Also you will probably want to uncheck Single annotation. The requested pixel size is probably the most important measurement to play around with if you use this method. David beat me to it! His method is also probably better in the long run, though this gives another, slightly simpler method. I would also be careful about using too many features in your classifier, or at least make sure your training set is significantly larger than the number of features you use!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349094523
https://github.com/qupath/qupath/issues/121#issuecomment-349094523:548,Usability,simpl,simpler,548,"That looks like the sort of thing that Simple Tissue Detection might work for with the correct settings. Something around 220 threshold maybe, with a medium requested pixel size and minimum area (keep setting these lower until you are picking up all of what you want). Also you will probably want to uncheck Single annotation. The requested pixel size is probably the most important measurement to play around with if you use this method. David beat me to it! His method is also probably better in the long run, though this gives another, slightly simpler method. I would also be careful about using too many features in your classifier, or at least make sure your training set is significantly larger than the number of features you use!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349094523
https://github.com/qupath/qupath/issues/121#issuecomment-349097979:32,Safety,detect,detection,32,"ah right, Svidro! simple tissue detection is the much faster and more convenient way to do it! I was thinking to complicated ^-^",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349097979
https://github.com/qupath/qupath/issues/121#issuecomment-349097979:18,Usability,simpl,simple,18,"ah right, Svidro! simple tissue detection is the much faster and more convenient way to do it! I was thinking to complicated ^-^",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349097979
https://github.com/qupath/qupath/issues/121#issuecomment-349101867:123,Availability,robust,robust,123,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867
https://github.com/qupath/qupath/issues/121#issuecomment-349101867:441,Integrability,depend,depending,441,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867
https://github.com/qupath/qupath/issues/121#issuecomment-349101867:297,Safety,detect,detection,297,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867
https://github.com/qupath/qupath/issues/121#issuecomment-349101867:283,Usability,simpl,simple,283,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867
https://github.com/qupath/qupath/issues/121#issuecomment-349101867:312,Usability,simpl,simply,312,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867
https://github.com/qupath/qupath/issues/121#issuecomment-349293402:72,Availability,robust,robust,72,"Hi,. Thank you both very much for your comments, I've gone for the more robust longer method. That seems to work better for these samples as I can adjust the selection better. It works really well, thank you for the quick responses!. Ieva",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349293402
https://github.com/qupath/qupath/issues/122#issuecomment-349589480:138,Deployability,update,updated,138,I was also wondering how to do this. Looking into the doc how it could be programatically accessed for read/write operations. I will keep updated if I find something,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-349589480
https://github.com/qupath/qupath/issues/122#issuecomment-349589480:90,Security,access,accessed,90,I was also wondering how to do this. Looking into the doc how it could be programatically accessed for read/write operations. I will keep updated if I find something,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-349589480
https://github.com/qupath/qupath/issues/122#issuecomment-349721017:122,Integrability,bridg,bridge,122,"The `.qpdata` files use Java serialization, so it probably isn't very feasible to read them in Python unless some kind of bridge to Java is involved. The easiest approach is likely to be to export the annotations in a Python-friendly form using a QuPath script (written in Groovy). Then you can choose your representation, e.g. JSON, binary images, something else. There are relevant pieces of Groovy code on GitHub or Google Groups already to export annotations, but if you would like to describe in more detail what exactly you want to be able to bring into Python then I can give some more detailed suggestions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-349721017
https://github.com/qupath/qupath/issues/122#issuecomment-350202064:405,Deployability,pipeline,pipelines,405,"@erexhepa good that the conversion is working!. Regarding CellProfiler, is interaction between it and QuPath something you'd need/want? If so, it would be good to add a new feature request here to draw attention to it, and maybe try to spark some discussion on how it should look. I personally never managed to get Javabridge set up successfully, and I didn't have any sufficiently important CellProfiler pipelines to work further on the integration myself. But it should be manageable in a few ways. The easiest might be to write out temporary image files (with Groovy) and then launch CellProfiler from the command line, before reading back in the results. However, early next year I plan to work more on streamlining the interaction between QuPath and Python, in which case the use of [CellProfiler as a Python package](https://github.com/CellProfiler/CellProfiler/wiki/CellProfiler-as-a-Python-package) could be helpful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350202064
https://github.com/qupath/qupath/issues/122#issuecomment-350202064:438,Deployability,integrat,integration,438,"@erexhepa good that the conversion is working!. Regarding CellProfiler, is interaction between it and QuPath something you'd need/want? If so, it would be good to add a new feature request here to draw attention to it, and maybe try to spark some discussion on how it should look. I personally never managed to get Javabridge set up successfully, and I didn't have any sufficiently important CellProfiler pipelines to work further on the integration myself. But it should be manageable in a few ways. The easiest might be to write out temporary image files (with Groovy) and then launch CellProfiler from the command line, before reading back in the results. However, early next year I plan to work more on streamlining the interaction between QuPath and Python, in which case the use of [CellProfiler as a Python package](https://github.com/CellProfiler/CellProfiler/wiki/CellProfiler-as-a-Python-package) could be helpful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350202064
https://github.com/qupath/qupath/issues/122#issuecomment-350202064:438,Integrability,integrat,integration,438,"@erexhepa good that the conversion is working!. Regarding CellProfiler, is interaction between it and QuPath something you'd need/want? If so, it would be good to add a new feature request here to draw attention to it, and maybe try to spark some discussion on how it should look. I personally never managed to get Javabridge set up successfully, and I didn't have any sufficiently important CellProfiler pipelines to work further on the integration myself. But it should be manageable in a few ways. The easiest might be to write out temporary image files (with Groovy) and then launch CellProfiler from the command line, before reading back in the results. However, early next year I plan to work more on streamlining the interaction between QuPath and Python, in which case the use of [CellProfiler as a Python package](https://github.com/CellProfiler/CellProfiler/wiki/CellProfiler-as-a-Python-package) could be helpful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350202064
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:808,Availability,down,down,808,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:119,Deployability,pipeline,pipelines,119,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:425,Deployability,deploy,deploy,425,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:712,Energy Efficiency,consumption,consumption,712,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:762,Energy Efficiency,efficient,efficient,762,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:938,Energy Efficiency,consumption,consumption,938,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:1251,Integrability,interface,interface,1251,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/122#issuecomment-350242806:109,Security,validat,validated,109,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806
https://github.com/qupath/qupath/issues/123#issuecomment-350436680:129,Deployability,integrat,integrated,129,Thanks for opening the feature request. Your suggestion it is a good starting point to see how cell profiler and QuPath could be integrated together and see for potential computational benefits of doing so. I will post some scripts I'm using with my local installation. I will be glad to help with anyway I can do so.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-350436680
https://github.com/qupath/qupath/issues/123#issuecomment-350436680:256,Deployability,install,installation,256,Thanks for opening the feature request. Your suggestion it is a good starting point to see how cell profiler and QuPath could be integrated together and see for potential computational benefits of doing so. I will post some scripts I'm using with my local installation. I will be glad to help with anyway I can do so.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-350436680
https://github.com/qupath/qupath/issues/123#issuecomment-350436680:129,Integrability,integrat,integrated,129,Thanks for opening the feature request. Your suggestion it is a good starting point to see how cell profiler and QuPath could be integrated together and see for potential computational benefits of doing so. I will post some scripts I'm using with my local installation. I will be glad to help with anyway I can do so.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-350436680
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:351,Deployability,pipeline,pipeline,351,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:400,Integrability,interface,interface,400,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:377,Modifiability,plugin,plugin,377,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:465,Modifiability,plugin,plugin,465,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:528,Modifiability,plugin,plugin,528,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:286,Performance,perform,perform,286,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/123#issuecomment-595983646:664,Performance,perform,perform,664,"Putting this here for future reference. ""Note: CellProfiler has limited capability with handling large, high-resolution images. We recommend using a field of view limited to a maximum number of two gigapixels in (x,y) to count cells and punctate dots present within cell boundaries. To perform whole slide image (WSI) analysis using your CellProfiler pipeline, Glencoe sells a plugin to allow you to interface CellProfiler with the open source platform QuPath. The plugin works through the OMERO + platform. Information on this plugin can be found by contacting Glencoe through their webpage: https://www.glencoesoftware.com/contact/. Other open source options to perform whole slide image (WSI) analysis include QuPath, Orbit, and SlideToolkit.""; https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjqguGA7IboAhXPtp4KHbgJBp0QFjAAegQIARAC&url=https%3A%2F%2Facdbio.com%2Fsystem%2Ffiles_force%2FTechNote_CellProfiler_20190920.pdf%3Fdownload%3D1&usg=AOvVaw2e7VjKojkOHZMrtc4Ibedg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/123#issuecomment-595983646
https://github.com/qupath/qupath/issues/124#issuecomment-350551044:101,Integrability,depend,depending,101,"Hi,. It could be due to the thresholds you're using to segment the tissue area that are too low/high depending on what color space or channel you're doing the threshold. . Normally if all you want to do is segment tissue from background you should have enough room to find a suitable threshold that can work well in different samples but it depends on the tissue sample too and difficult to say without looking at the tissue image. Anyway I think there is an option to not consider ROIs touching the border, so you can filter them automatically.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350551044
https://github.com/qupath/qupath/issues/124#issuecomment-350551044:341,Integrability,depend,depends,341,"Hi,. It could be due to the thresholds you're using to segment the tissue area that are too low/high depending on what color space or channel you're doing the threshold. . Normally if all you want to do is segment tissue from background you should have enough room to find a suitable threshold that can work well in different samples but it depends on the tissue sample too and difficult to say without looking at the tissue image. Anyway I think there is an option to not consider ROIs touching the border, so you can filter them automatically.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350551044
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:145,Energy Efficiency,adapt,adapted,145,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:313,Energy Efficiency,reduce,reduced,313,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:145,Modifiability,adapt,adapted,145,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:66,Safety,detect,detection,66,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:655,Safety,detect,detection,655,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-350561039:52,Usability,simpl,simple,52,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:28,Safety,detect,detection,28,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:417,Safety,detect,detection,417,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:839,Safety,detect,detection,839,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:14,Usability,Simpl,Simple,14,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:403,Usability,Simpl,Simple,403,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352167834:444,Usability,simpl,simple,444,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:825,Deployability,install,installation,825,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:866,Deployability,integrat,integration,866,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:734,Integrability,interface,interface,734,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:866,Integrability,integrat,integration,866,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:795,Modifiability,plugin,plugin,795,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/124#issuecomment-352399785:30,Usability,clear,clear,30,"@DavidMHaumann Sorry I wasn't clear on the colour deconv subject. I was generally speaking on the color space, RGB, HSV, LUV but I was also thinking about standart HE and immunostains. Your case might be difficult. . I was sure SimpleTissueDetection2 was not using ColourDeconv but after looking at #93 I know a bit more what is using. For me it is working fine but I'm working with very standard stains. . However, I'm working also on some special stains where deconvolution is necessary and of added value, especially with regard to the cell-object segmentation that would follow. The link to ImageJ is very useful because you can send the region to ImageJ , deconvolve, normalize, analyse and return the objects ROI back to qupath interface for further visual inspection/analysis. There is a plugin on the embedded ImageJ installation with QuPath that allows the integration of regions from ImageJ to QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352399785
https://github.com/qupath/qupath/issues/125#issuecomment-350847426:216,Energy Efficiency,adapt,adapted,216,"and another thing: ; Is it possible to dynamicly create the target folder for the results?; If QuPath loads an old script into a new project, the pathway for the ""Save results"" part in the script need to be manually adapted to the place/folder of the new project. . It would be nice, the script creates automatically a new folder ""results"" and saves the annotations results inside the new results folder in the new project. . To create a new folder works like that: ; import qupath.lib.scripting.QPEx; // Create the output directory, if required; def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""meise""); QPEx.mkdirs(path). But I dont know enought code yet to direct the new annotation results into the new folder.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/125#issuecomment-350847426
https://github.com/qupath/qupath/issues/125#issuecomment-350847426:216,Modifiability,adapt,adapted,216,"and another thing: ; Is it possible to dynamicly create the target folder for the results?; If QuPath loads an old script into a new project, the pathway for the ""Save results"" part in the script need to be manually adapted to the place/folder of the new project. . It would be nice, the script creates automatically a new folder ""results"" and saves the annotations results inside the new results folder in the new project. . To create a new folder works like that: ; import qupath.lib.scripting.QPEx; // Create the output directory, if required; def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""meise""); QPEx.mkdirs(path). But I dont know enought code yet to direct the new annotation results into the new folder.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/125#issuecomment-350847426
https://github.com/qupath/qupath/issues/125#issuecomment-350847426:102,Performance,load,loads,102,"and another thing: ; Is it possible to dynamicly create the target folder for the results?; If QuPath loads an old script into a new project, the pathway for the ""Save results"" part in the script need to be manually adapted to the place/folder of the new project. . It would be nice, the script creates automatically a new folder ""results"" and saves the annotations results inside the new results folder in the new project. . To create a new folder works like that: ; import qupath.lib.scripting.QPEx; // Create the output directory, if required; def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""meise""); QPEx.mkdirs(path). But I dont know enought code yet to direct the new annotation results into the new folder.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/125#issuecomment-350847426
https://github.com/qupath/qupath/issues/125#issuecomment-350869587:616,Usability,learn,learning,616,"I am fairly certain that the Windows slash issue is listed as one of the things to fix already in another posting already, so might get done in a later version of QuPath. If you are using the same location each time, you can just create a separate script and copy and paste the command in whenever you need it. If this is for different projects and different directories... then yes, I think, for Windows, that is the only way to do it. You can call a Python script on the folder where the file is placed to fix all of the .txt files, use a program like Bulk Rename Utility (I made quite a lot of use of that before learning any Python) or when you are already editing the path string, you could manually entire the file name as well. If it is for a batch run, you will need to get the name of the image from something like:. ```; outputFolder = ""D:\\Results\\""; String imageLocation = getCurrentImageData().getServer().getPath(); fileNameWithNoExtension = imageLocation.split(""[^A-Za-z0-9_ ]"")[-2]; saveAnnotationMeasurements(outputFolder+fileNameWithNoExtension+"".txt"", ); ```. I may be missing a few useful characters in the split string there, but I suspect you get the idea!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/125#issuecomment-350869587
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:100,Availability,down,downsampled,100,"Generating the tissue annotation can be a little tricky, for fluorescent images I started sending a downsampled image to ImageJ and using blur+thresholding tools there to generate the initial annotation. It worked well as long as the staining/nuclear density was great enough. For the rest, QuPath should be easy as long as you have a multichannel image. What format are you using?; Depending on the sensitivity you need, QuPath automatically includes your red and green channel mean intensities, so as long as you expand the cytoplasm out far enough, you will get a measure of how much stain is within that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:1377,Availability,down,down,1377,". What format are you using?; Depending on the sensitivity you need, QuPath automatically includes your red and green channel mean intensities, so as long as you expand the cytoplasm out far enough, you will get a measure of how much stain is within that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu classification system.; ```. import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""). //I honestly forget the exact text for the given fluorescence features; //but feature would be one of those; d",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:1576,Availability,down,down,1576,"in that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu classification system.; ```. import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""). //I honestly forget the exact text for the given fluorescence features; //but feature would be one of those; def feature = ""Channel 2: Mean intensity""; def threshold = 0.1; def threshold2 = 1.5. // Loop through all detections *** Change this to getCellObjects() or getTileObjects() if you have a mix of both and only want to classify one type; resetDetection",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:465,Energy Efficiency,green,green,465,"Generating the tissue annotation can be a little tricky, for fluorescent images I started sending a downsampled image to ImageJ and using blur+thresholding tools there to generate the initial annotation. It worked well as long as the staining/nuclear density was great enough. For the rest, QuPath should be easy as long as you have a multichannel image. What format are you using?; Depending on the sensitivity you need, QuPath automatically includes your red and green channel mean intensities, so as long as you expand the cytoplasm out far enough, you will get a measure of how much stain is within that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:383,Integrability,Depend,Depending,383,"Generating the tissue annotation can be a little tricky, for fluorescent images I started sending a downsampled image to ImageJ and using blur+thresholding tools there to generate the initial annotation. It worked well as long as the staining/nuclear density was great enough. For the rest, QuPath should be easy as long as you have a multichannel image. What format are you using?; Depending on the sensitivity you need, QuPath automatically includes your red and green channel mean intensities, so as long as you expand the cytoplasm out far enough, you will get a measure of how much stain is within that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:2458,Safety,detect,detections,2458,"er with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu classification system.; ```. import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""). //I honestly forget the exact text for the given fluorescence features; //but feature would be one of those; def feature = ""Channel 2: Mean intensity""; def threshold = 0.1; def threshold2 = 1.5. // Loop through all detections *** Change this to getCellObjects() or getTileObjects() if you have a mix of both and only want to classify one type; resetDetectionClassifications(); for (def pathObject : getDetectionObjects()) {. // Get the measurement value(s); double val = pathObject.getMeasurementList().getMeasurementValue(feature). // Set positive or negative class; if (val < threshold || val > threshold2){; pathObject.setPathClass(Positive); }else pathObject.setPathClass(Negative); }; ```; Hopefully that gets you started, let me know if you need anything else!; Edit: Oh, and _Measure->Show annotation measurements_ should get you the data you need",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/126#issuecomment-351212559:1060,Usability,simpl,simple,1060,"ing a downsampled image to ImageJ and using blur+thresholding tools there to generate the initial annotation. It worked well as long as the staining/nuclear density was great enough. For the rest, QuPath should be easy as long as you have a multichannel image. What format are you using?; Depending on the sensitivity you need, QuPath automatically includes your red and green channel mean intensities, so as long as you expand the cytoplasm out far enough, you will get a measure of how much stain is within that space. For the kind of staining I see in your image, I would also recommend the _Analyze->Cell analysis->Subcellular detection_ command, as it can generate a much more exact value for the ""amount of stain above a threshold"" within a given cell, without being diluted by empty space. This command will only work, though, if your image has Pixel width and height included in the metadata. Once you have the data you need on a cell to cell basis, it's as simple as creating a classifier, either with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu classification system.; ```. import qupath.lib.objects.classes.PathClass; import qupath.lib.o",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:827,Availability,down,downsample,827,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:891,Availability,down,downsample,891,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1033,Availability,down,downsample,1033,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1235,Availability,down,downsample,1235,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1299,Availability,down,downsample,1299,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1387,Availability,down,downsample,1387,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:845,Integrability,depend,depending,845,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1253,Integrability,depend,depending,1253,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1802,Integrability,interface,interface,1802,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-354475050:1702,Modifiability,enhance,enhancement,1702,"So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently. One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger. Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; ```groovy; // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20; ...; // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); ```. You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; ```groovy; // Calculate downsample factor depending on the requested pixel size; double downsample = 1.0; def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); ```. Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch. > Note: I've tagged this as *enhancement* because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-354475050
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:857,Availability,down,downsample,857,"> So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently.; > ; > One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:923,Availability,down,downsample,923,"> So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently.; > ; > One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1067,Availability,down,downsample,1067,"gle image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently.; > ; > One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1285,Availability,down,downsample,1285,"ger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1351,Availability,down,downsample,1351,"ger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1441,Availability,down,downsample,1441,"t. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your answer here adjust the script and it gave me sort of a blank image with some lines in it(I was doing regular image before just starting to deal with bioimage recently). Can you give me some instructions about how to export the whole image as jpg, png, or regular ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:2050,Availability,down,downloaded,2050,"tps://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your answer here adjust the script and it gave me sort of a blank image with some lines in it(I was doing regular image before just starting to deal with bioimage recently). Can you give me some instructions about how to export the whole image as jpg, png, or regular tif, so I can convert them to ndarray. Thank you in advance!!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:2192,Availability,down,downsampled,2192,"tps://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your answer here adjust the script and it gave me sort of a blank image with some lines in it(I was doing regular image before just starting to deal with bioimage recently). Can you give me some instructions about how to export the whole image as jpg, png, or regular tif, so I can convert them to ndarray. Thank you in advance!!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:875,Integrability,depend,depending,875,"> So long as 'arbitrarily large' is still small enough to work as a single image (not a pyramidal whole slide image), then it should certainly be possible. Image pyramids can't be written with QuPath currently.; > ; > One way to get a larger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1303,Integrability,depend,depending,1303,"ger image may be via [Send region to ImageJ](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#sending-image-regions-to-imagej) - from memory I think there's still a size limitation, but it should be bigger.; > ; > Otherwise, it is necessary to run a script. The closest matching script I can think of is [this one](https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/127#issuecomment-853621895:1871,Integrability,interface,interface,1871,"tps://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d). By default, it will export the entire image at a very low resolution because of these lines; > ; > ```groovy; > // Aim for an output resolution of approx 20 µm/pixel; > double requestedPixelSize = 20; > ...; > // Calculate downsample factor depending on the requested pixel size; > double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()); > ```; > ; > You can switch it to export only the region corresponding to the selected object, at full resolution, as follows:; > ; > ```groovy; > // Calculate downsample factor depending on the requested pixel size; > double downsample = 1.0; > def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, getSelectedROI()); > ```; > ; > Let me know if that doesn't do what you need, and hopefully some other script change could help. Personally, I'd use the ImageJ method for exporting isolated regions occasionally, and a script if I wanted to export lots of regions in a single batch.; > ; > > Note: I've tagged this as _enhancement_ because I think it would make sense to increase the export size limit through the user interface to make this easier. I had forgotten the existing limit was so small... I have almost the same need as @nathan. I have some .tiff WSI want to convert them to ndarray. I downloaded the 0.1.2 version( 0.2.3 wouldn't work with the script above) and run the script. The script ""QuPath_export_images.groovy"" gave me downsampled image as it should. I followed your answer here adjust the script and it gave me sort of a blank image with some lines in it(I was doing regular image before just starting to deal with bioimage recently). Can you give me some instructions about how to export the whole image as jpg, png, or regular tif, so I can convert them to ndarray. Thank you in advance!!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/127#issuecomment-853621895
https://github.com/qupath/qupath/issues/128#issuecomment-354846706:291,Usability,guid,guide,291,"I don't have much for this but... You may have already found it, but: https://github.com/qupath/qupath/issues/61; There was also a thread about using JSON objects to handle object exports on the Google forum; I'm not sure if that would come in handy as it might be reversible or useful as a guide.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/128#issuecomment-354846706
https://github.com/qupath/qupath/issues/128#issuecomment-354851520:566,Availability,avail,available,566,"Hi, if an extension is written in Java (not Javascript) then it would be possible to make it work like it's a built-in part of the software, e.g. with menu items to import/export the annotations. Then it could potentially be included in QuPath as well. I agree it would be useful, although I do have two hesitations...; * The kinds of annotations supported by ImageScope and QuPath don't quite match, and not all regions that could be drawn in ImageScope could be shown in QuPath, and vice versa (although rectangles should be fine); * I'm not aware of any publicly available specification for the XML used with ImageScope. The second one is maybe more important. I'm apprehensive about trying to add built-in support for these kinds of annotations without a specification.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/128#issuecomment-354851520
https://github.com/qupath/qupath/issues/128#issuecomment-356114669:275,Testability,test,test,275,"Here you can look at the different types of ROI you can draw (just in case). https://github.com/qupath/qupath/tree/master/qupath-core/src/main/java/qupath/lib/roi. The script below should work for rectangles (I was using for circles but quickly modified it for rectangles so test it). It looks for a txt file (one line for each rectangle specifying the top left corner coordinatex X,Y as well as Width and Height) having the same name as the digital slide and then iterates through all the lines. Try it. It should work. ```; import qupath.lib.scripting.QPEx; import qupath.lib.objects.*; import qupath.lib.roi.*. def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); def radiusCirc = 9055. String path = server.getPath(); //print path; def strfname = path[path.lastIndexOf('\\')+1..-1]; def strfnameTrim = strfname[0.. strfname.lastIndexOf('.')-1] ; def strpnameTrim = path[0..path.lastIndexOf('\\')]; def coordFname = strpnameTrim+strfnameTrim + "".txt"". print coordFname. def file = new File(coordFname); def lines = file.readLines(). num_rois = lines.size; print num_rois. for (i = 0; i <num_rois; i++) {; float[] x1 = lines[i].tokenize(',') as float[]; ; print x1[0]; print x1[1]; print x1[2]; print x1[3]; ; // Create object; def roiIter = new RectangleROI((x1[0] as double), (x1[1] as double),x1[2] as double, x1[3] as double); //def pathObject = new PathDetectionObject(roi); def pathObject3 = new PathAnnotationObject(roiIter); // Add object to hierarchy; addObject(pathObject3); }. print(""Numero de regions""); print num_rois; print strfnameTrim + "".txt""; print strpnameTrim3; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/128#issuecomment-356114669
https://github.com/qupath/qupath/issues/129#issuecomment-354845609:38,Usability,clear,clears,38,"Hypothesis: I don't think the program clears what is ""selected"" after the merge, so trying to create a new selection fails. Note that if you only have one object selected, and choose to merge, the selectObjects command will work, maybe because no changes have been made to the hierarchy. Fix: Add resetSelection() after the merge to clear the currently selected object set.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354845609
https://github.com/qupath/qupath/issues/129#issuecomment-354845609:333,Usability,clear,clear,333,"Hypothesis: I don't think the program clears what is ""selected"" after the merge, so trying to create a new selection fails. Note that if you only have one object selected, and choose to merge, the selectObjects command will work, maybe because no changes have been made to the hierarchy. Fix: Add resetSelection() after the merge to clear the currently selected object set.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354845609
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:569,Availability,error,error,569,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:727,Availability,ERROR,ERROR,727,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:734,Availability,Error,Error,734,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:758,Availability,ERROR,ERROR,758,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:772,Availability,error,error,772,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:75,Modifiability,plugin,plugin,75,"Hi Pete, . I have annotations that are created by the tiles to annotations plugin. So I have 3 different classes and a lot of annotations of the same class. ; Then i select annotations by class 1 first, merge them and then i want to go on by selecting all annotations with class 2. ; That is the point when it fails. Running all steps within one run does not work. . Yes, I use windows. ; And no, the above script with rectangles and ellipse does not work on my laptop. It has Windows 10. . Svidros recommendation (thank you Svidro) did also not help. . I get a script error: Line 27 is my second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2258,Performance,concurren,concurrent,2258,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2334,Performance,concurren,concurrent,2334,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2395,Performance,concurren,concurrent,2395,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2479,Performance,concurren,concurrent,2479,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2121,Security,access,access,2121,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398
https://github.com/qupath/qupath/issues/129#issuecomment-354857454:44,Integrability,depend,depending,44,"Ok, that does work for me. It seems to vary depending on a few more factors! And Windows for me. It looks like the problem may be with the it.getPathClass() == null after merging the previous annotations.; Running just the line:; `selectObjects {it.isAnnotation() && it.getPathClass() == null};; `; Always seems to work on its own.; While after a merge, it returns a warning:; ```; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'};; mergeSelectedAnnotations(); //resetSelection(); selectObjects {it.isAnnotation() && it.getPathClass() == null};; ```. > WARN: Cannot assign class unambiguously - 0 classes represented in selection. Edit: Could we see a little more of the script? I suspect things are working differently in our little stand alone scripts than in what you are working on. Though Pete's example did work for me.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857454
https://github.com/qupath/qupath/issues/129#issuecomment-354860945:259,Availability,down,down,259,"Oops, I take that back, Pete's script does not work for me when I use the Ellipse, I was selecting something else at the time, but now I have closed it and forgot what I was playing with. . The following does not work on Windows however, reducing the problem down a little.; ```; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); selectAnnotations(); ```; It still gives the same warning as above.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354860945
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:475,Availability,error,error,475,"The warning; ```; WARN: Cannot assign class unambiguously - 0 classes represented in selection; ```; should be ok - QuPath is checking if there is one and only one classification that it can use to assign to the merged annotation. Unfortunately it's not smart enough to recognize that no classifications is fine as well, and doesn't really require a warning. But the latest script from @Svidro lets me experience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:481,Integrability,message,message,481,"The warning; ```; WARN: Cannot assign class unambiguously - 0 classes represented in selection; ```; should be ok - QuPath is checking if there is one and only one classification that it can use to assign to the merged annotation. Unfortunately it's not smart enough to recognize that no classifications is fine as well, and doesn't really require a warning. But the latest script from @Svidro lets me experience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:821,Integrability,interface,interface,821,"The warning; ```; WARN: Cannot assign class unambiguously - 0 classes represented in selection; ```; should be ok - QuPath is checking if there is one and only one classification that it can use to assign to the merged annotation. Unfortunately it's not smart enough to recognize that no classifications is fine as well, and doesn't really require a warning. But the latest script from @Svidro lets me experience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1135,Integrability,interface,interface,1135,"sign class unambiguously - 0 classes represented in selection; ```; should be ok - QuPath is checking if there is one and only one classification that it can use to assign to the merged annotation. Unfortunately it's not smart enough to recognize that no classifications is fine as well, and doesn't really require a warning. But the latest script from @Svidro lets me experience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the comm",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1773,Integrability,depend,depending,1773,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1838,Integrability,depend,depending,1838,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1767,Safety,Avoid,Avoid,1767,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1832,Safety,avoid,avoid,1832,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1965,Safety,detect,detection,1965,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1384,Usability,Pause,Pause,1384,"ro lets me experience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1427,Usability,pause,pauses,1427,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354864318:2390,Usability,simpl,simple,2390,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318
https://github.com/qupath/qupath/issues/129#issuecomment-354865710:82,Safety,avoid,avoid,82,"Oooh, mergeAnnotations looks great. I was going to say that I have been trying to avoid selecting, but didn't realize there was an easy workaround for the merge in this case!; Edit: The first two worked for me as well.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354865710
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:212,Availability,error,erroring,212,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:167,Safety,detect,detection,167,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:341,Safety,detect,detection,341,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:655,Safety,detect,detection,655,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:991,Safety,detect,detection,991,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:1016,Safety,detect,detection,1016,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:871,Security,access,accessing,871,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:20,Testability,log,log,20,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:706,Testability,log,logs,706,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355477217:641,Usability,Simpl,Simple,641,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1106,Availability,down,down,1106,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:618,Performance,cache,cache,618,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:706,Performance,cache,cache,706,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1148,Performance,cache,cache,1148,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1410,Performance,cache,cache,1410,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1462,Safety,detect,detection,1462,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:914,Security,access,access,914,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:81,Testability,log,log,81,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:712,Usability,clear,clear,712,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1131,Usability,clear,clearing,1131,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:188,Availability,error,error,188,"Hi Pete,; I really appreciate your fast reply and your support.; As a non-code-speaking researcher I have found qupath relatively easy to navigate, although there is a degree of trial-and-error involved.; I have implemented your suggestions and it seems to have got around the problem. My main issue is that I need more memory on my computer for the processing that I am doing (4GB RAM is not enough).; Thanks again,; Chris. From: Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally b",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1816,Availability,down,down,1816,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1333,Performance,cache,cache,1333,"is that I need more memory on my computer for the processing that I am doing (4GB RAM is not enough).; Thanks again,; Chris. From: Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1421,Performance,cache,cache,1421," From: Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qu",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1858,Performance,cache,cache,1858,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:2120,Performance,cache,cache,2120,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:2172,Safety,detect,detection,2172,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1624,Security,access,access,1624,"hub.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:807,Testability,log,log,807,"Hi Pete,; I really appreciate your fast reply and your support.; As a non-code-speaking researcher I have found qupath relatively easy to navigate, although there is a degree of trial-and-error involved.; I have implemented your suggestions and it seems to have got around the problem. My main issue is that I need more memory on my computer for the processing that I am doing (4GB RAM is not enough).; Thanks again,; Chris. From: Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally b",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1427,Usability,clear,clear,1427,"Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qu",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1841,Usability,clear,clearing,1841,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016
https://github.com/qupath/qupath/issues/131#issuecomment-355842721:323,Energy Efficiency,green,green,323,"I disovered that the redout of the absolute pixel vallues experiences a very unrealistic value far beyond the theoretically maximum of 255: . ![grafik](https://user-images.githubusercontent.com/16352785/34652724-629261ee-f3e2-11e7-8503-88f92f71fd82.png). Probably the problem is connected with that?. Next screenshot shows green channel after restart of QuPath: ; ![grafik](https://user-images.githubusercontent.com/16352785/34652762-f5caea94-f3e2-11e7-9422-c233b31d08b4.png). Instead of a max pix value above 400, you see something above 4. Factor 100 changed!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355842721
https://github.com/qupath/qupath/issues/131#issuecomment-355843462:313,Performance,cache,cache,313,"I'm not able to reproduce it - could you generate a script (under the 'Workflow' tab) and send the relevant lines? Just the `setColorDeconvolutionStains` and `setImageType` parts should matter. Did I understand correctly that the bug only occurs after opening the Brightness/Contrast window? It does generate and cache a histogram, and it will only regenerate that histogram when QuPath is restarted. So I guess that it somehow creates an evil histogram and won't let go of it... but I'm not sure yet why that happens.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843462
https://github.com/qupath/qupath/issues/131#issuecomment-355843907:145,Performance,cache,cachedHistogramMaps,145,"You could try running the script below to brutally reset the histograms:; ```groovy; def display = getCurrentViewer().getImageDisplay(); display.cachedHistogramMaps.clear(); display.histogramMap.clear(); ```; It might help you avoid a restart, but I'm not sure...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843907
https://github.com/qupath/qupath/issues/131#issuecomment-355843907:227,Safety,avoid,avoid,227,"You could try running the script below to brutally reset the histograms:; ```groovy; def display = getCurrentViewer().getImageDisplay(); display.cachedHistogramMaps.clear(); display.histogramMap.clear(); ```; It might help you avoid a restart, but I'm not sure...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843907
https://github.com/qupath/qupath/issues/131#issuecomment-355843907:165,Usability,clear,clear,165,"You could try running the script below to brutally reset the histograms:; ```groovy; def display = getCurrentViewer().getImageDisplay(); display.cachedHistogramMaps.clear(); display.histogramMap.clear(); ```; It might help you avoid a restart, but I'm not sure...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843907
https://github.com/qupath/qupath/issues/131#issuecomment-355843907:195,Usability,clear,clear,195,"You could try running the script below to brutally reset the histograms:; ```groovy; def display = getCurrentViewer().getImageDisplay(); display.cachedHistogramMaps.clear(); display.histogramMap.clear(); ```; It might help you avoid a restart, but I'm not sure...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843907
https://github.com/qupath/qupath/issues/132#issuecomment-356053505:161,Safety,avoid,avoid,161,"From the script editor, you can choose *Run &rarr; Run for project* and then select all the images. You just need to be careful what your export file name is to avoid overwriting it for each image. Something like the following will include the name for the current image in the project in the export:; ```groovy; pathExport = buildFilePath(PROJECT_BASE_DIR, 'exported', getProjectEntry().getImageName() + '.txt'); print pathExport; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/132#issuecomment-356053505
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:97,Availability,error,errors,97,"I definitely agree that the current limit is bad. But the fix could result in more out-of-memory errors. I think it would be good to good to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:196,Availability,error,error,196,"I definitely agree that the current limit is bad. But the fix could result in more out-of-memory errors. I think it would be good to good to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:515,Availability,avail,available,515,"I definitely agree that the current limit is bad. But the fix could result in more out-of-memory errors. I think it would be good to good to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:601,Availability,avail,available,601,"I definitely agree that the current limit is bad. But the fix could result in more out-of-memory errors. I think it would be good to good to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:1036,Availability,error,error,1036,"bad. But the fix could result in more out-of-memory errors. I think it would be good to good to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` to create an annotation representing the full ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356714438:1420,Energy Efficiency,allocate,allocated,1420,"ood to give some protection from these (or a more informative error if they occur), and aim for a more substantial fix. Two changes could help:; * Choose a pixel count threshold based upon both the maximum pixel count that ImageJ could conceivably support, i.e. 2<sup>31</sup>-1 (or a little more than 1) *and* also a memory threshold based on estimating the image size and memory available; * Add a scaling factor as a static field to control what proportion of the available memory is permitted for use. It could be something like this:; ```java; static double MEMORY_THRESHOLD = 0.5;; ...; long remainingMemory = ... // With the help of Runtime.getRuntime(), after request for garbage collection; long approxMemory = ... // Calculation based on pixel count, bit-depth & number of channels; if (approxPixelCount > 2147480000L || approxMemory > remainingMemory * MEMORY_THRESHOLD) {; // Show the size error; } else {; // Have a go at extracting the region; }; ```; By making the scaling factor a static field, there is at least the option of overriding it in a Groovy script if absolutely necessary. The details around the pixel count get a bit fiddly, considering that ImageJ1 will use a packed int array in a `ColorProcessor` for RGB images, while in other cases a new array will be allocated for every channel. Furthermore, it might be prudent to take parallelization into account, and the result returned by `PathPrefs.getNumCommandThreads()`. I'm dubious about sending the whole image if no selection exists, because it's really easy to accidentally run the command without an area selected... and then everything can grind to a halt while QuPath tries (and possibly fails) to extract a massive region. Currently you can use *Objects &rarr; Create full image annotation*, its shortcut `Ctrl + Shift + A` or the scripting command `createSelectAllObject(true);` to create an annotation representing the full image, where the `true` indicates that this annotation should be selected automatically.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356714438
https://github.com/qupath/qupath/pull/134#issuecomment-356863236:641,Availability,error,error,641,"Hi Peter, . Thank for the very complete message! I'll go and implement this now and submit it to see if it's to your liking. Right now I have placed my version of the ImageJMacroRunner in our QuPath, so that I could process the images I am receiving. > Furthermore, it might be prudent to take parallelization into account, and the result returned by PathPrefs.getNumCommandThreads(). I am not sure how you want to address this, each command thread might take an image of a different size, and these threads to not talk to each other. In a case like this, it would make more sense to find a way to gracefully show some sort of out of memory error in case this happens. > Currently you can use Objects → Create full image annotation. Perfect, then you're right, no need to send the whole image by default if it's just one command! I was making a RectangleROI with the dimensions of the image server in my script...; [EDIT] Hmm.. Actually I just tested that last one and preferred my way, as I do not need to add the annotation to the hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356863236
https://github.com/qupath/qupath/pull/134#issuecomment-356863236:40,Integrability,message,message,40,"Hi Peter, . Thank for the very complete message! I'll go and implement this now and submit it to see if it's to your liking. Right now I have placed my version of the ImageJMacroRunner in our QuPath, so that I could process the images I am receiving. > Furthermore, it might be prudent to take parallelization into account, and the result returned by PathPrefs.getNumCommandThreads(). I am not sure how you want to address this, each command thread might take an image of a different size, and these threads to not talk to each other. In a case like this, it would make more sense to find a way to gracefully show some sort of out of memory error in case this happens. > Currently you can use Objects → Create full image annotation. Perfect, then you're right, no need to send the whole image by default if it's just one command! I was making a RectangleROI with the dimensions of the image server in my script...; [EDIT] Hmm.. Actually I just tested that last one and preferred my way, as I do not need to add the annotation to the hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356863236
https://github.com/qupath/qupath/pull/134#issuecomment-356863236:944,Testability,test,tested,944,"Hi Peter, . Thank for the very complete message! I'll go and implement this now and submit it to see if it's to your liking. Right now I have placed my version of the ImageJMacroRunner in our QuPath, so that I could process the images I am receiving. > Furthermore, it might be prudent to take parallelization into account, and the result returned by PathPrefs.getNumCommandThreads(). I am not sure how you want to address this, each command thread might take an image of a different size, and these threads to not talk to each other. In a case like this, it would make more sense to find a way to gracefully show some sort of out of memory error in case this happens. > Currently you can use Objects → Create full image annotation. Perfect, then you're right, no need to send the whole image by default if it's just one command! I was making a RectangleROI with the dimensions of the image server in my script...; [EDIT] Hmm.. Actually I just tested that last one and preferred my way, as I do not need to add the annotation to the hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-356863236
https://github.com/qupath/qupath/pull/134#issuecomment-357533150:948,Availability,error,error,948,"Looks good! I won't get a chance to try the code for a few days, but I will soon - sorry for the delay... Since you mention adding it to the preferences, this is how it works:; ```java; import javafx.beans.property.DoubleProperty;; import qupath.lib.gui.QuPathGUI;; import qupath.lib.gui.prefs.PathPrefs;. DoubleProperty preference = PathPrefs.createPersistentPreference(""ijFreeMemory"", 0.5);; QuPathGUI.getInstance().getPreferencePanel().addPropertyPreference(; preference, Double.class, ""Extract region memory limit"", ""ImageJ"",; ""The proportion free memory that ImageJ is allowed to use when extracting regions (set > 1 to use as much memory as possible)"");; ```. And your reference to using it elsewhere reminds me of the command to extract regions [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupath/imagej/gui/commands/ExtractRegionCommand.java#L120). Looking back at that code, it seems to contain an error in using totalMemory rather than the proper combination of max/total/free that you used. That is probably another candidate for improvement, and for calling your new method...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-357533150
https://github.com/qupath/qupath/pull/134#issuecomment-357533416:319,Performance,throttle,throttle,319,"Actually, on reflection, there isn't really anything ImageJ-specific in your method, making it a good candidate to go into one of the 'core' modules. I could see it being useful in other places - potentially with different memory proportion limits - such as when extracting images to write to disk, or possibly even to throttle parallelization when running a detection command.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-357533416
https://github.com/qupath/qupath/pull/134#issuecomment-357533416:359,Safety,detect,detection,359,"Actually, on reflection, there isn't really anything ImageJ-specific in your method, making it a good candidate to go into one of the 'core' modules. I could see it being useful in other places - potentially with different memory proportion limits - such as when extracting images to write to disk, or possibly even to throttle parallelization when running a detection command.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-357533416
https://github.com/qupath/qupath/pull/134#issuecomment-358236558:196,Modifiability,refactor,refactored,196,"Well, I decided to put it there based on your discussion that ImageJ used packed int arrays for RGB images, so that perhaps wasn't relevant to other parts of your code. But if you think it can be refactored elsewhere, that's fine by me.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-358236558
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:597,Availability,error,error,597,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:612,Availability,error,error,612,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:694,Availability,error,error,694,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:722,Availability,error,error,722,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:59,Deployability,install,install,59,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-356998068:471,Deployability,install,install,471,"It has been a while, but I do not think you should have to install anything for Bioformats. All you need is the JAR file off of their website, and the JAR file from Pete, both at: https://github.com/qupath/qupath-bioformats-extension; And as it says, just drag them into the open QuPath window to add them to QuPath. I am not sure why you are having issues with a visual C++ redistributable; I am not entirely sure if that is related. At least, I do not recall having to install anything else when adding bioformats to QuPath, even when it was one of the first things I put on my computer. Is the error a QuPath error? It would probably be best to include a picture or at least the text of the error, and exactly when the error pops up (when you drag the bioformats extension into the QuPath window? when you try to open the CZI file?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-356998068
https://github.com/qupath/qupath/issues/135#issuecomment-357022776:26,Deployability,install,install,26,"There is indeed a need to install the redistributables on Windows, as far as I know - it's mentioned [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi). But the Mac trouble suggests it's something else. I know that the support for CZI in QuPath using the Bio-Formats is pretty varied. Sometimes it works, but I've learned of cases recently where it doesn't. I think TMAs (with lots of scenes?) are especially troublesome. I have spotted a few ways to fix the QuPath Bio-Formats extension that I believe will help, and I hope to have these changes made by the middle/end of next week, and I'll write another update here. Hopefully they will fix the issue with your files, but if not then I will investigate further.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357022776
https://github.com/qupath/qupath/issues/135#issuecomment-357022776:636,Deployability,update,update,636,"There is indeed a need to install the redistributables on Windows, as far as I know - it's mentioned [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi). But the Mac trouble suggests it's something else. I know that the support for CZI in QuPath using the Bio-Formats is pretty varied. Sometimes it works, but I've learned of cases recently where it doesn't. I think TMAs (with lots of scenes?) are especially troublesome. I have spotted a few ways to fix the QuPath Bio-Formats extension that I believe will help, and I hope to have these changes made by the middle/end of next week, and I'll write another update here. Hopefully they will fix the issue with your files, but if not then I will investigate further.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357022776
https://github.com/qupath/qupath/issues/135#issuecomment-357022776:343,Usability,learn,learned,343,"There is indeed a need to install the redistributables on Windows, as far as I know - it's mentioned [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi). But the Mac trouble suggests it's something else. I know that the support for CZI in QuPath using the Bio-Formats is pretty varied. Sometimes it works, but I've learned of cases recently where it doesn't. I think TMAs (with lots of scenes?) are especially troublesome. I have spotted a few ways to fix the QuPath Bio-Formats extension that I believe will help, and I hope to have these changes made by the middle/end of next week, and I'll write another update here. Hopefully they will fix the issue with your files, but if not then I will investigate further.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357022776
https://github.com/qupath/qupath/issues/135#issuecomment-357053806:436,Availability,down,download,436,"Thank you both for your response. I would preferably like to run the software on the mac but have access to PC too if this is more suitable . The original files I wanted to work with were TMAs with multiple scenes but I cannot even open a jpg file. I am at home now and I am on my mac and it is still not opening the jpg files. . Thank you for looking into addressing the qupath bio-formats extension. In the meantime, should I need to download any extensions to run the software on the mac? I know in your tutorial for start ups you suggest you do but I have had no joy with this . Thank you again",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357053806
https://github.com/qupath/qupath/issues/135#issuecomment-357053806:98,Security,access,access,98,"Thank you both for your response. I would preferably like to run the software on the mac but have access to PC too if this is more suitable . The original files I wanted to work with were TMAs with multiple scenes but I cannot even open a jpg file. I am at home now and I am on my mac and it is still not opening the jpg files. . Thank you for looking into addressing the qupath bio-formats extension. In the meantime, should I need to download any extensions to run the software on the mac? I know in your tutorial for start ups you suggest you do but I have had no joy with this . Thank you again",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357053806
https://github.com/qupath/qupath/issues/135#issuecomment-357055699:606,Availability,error,error,606,"Oh dear, that sounds worse - I am using a Mac, and no extra extensions should be needed. Does the software start ok? I have seen a problem on some older Macs where it wasn't possible to start QuPath because of an incompatibility with OpenCV... but if the window opens at all then that shouldn't be the issue. You should be able to open a JPEG just by dragging it onto the main QuPath window. Could you try with the image *CMU-1.svs* that is suggested at https://github.com/qupath/qupath/wiki/First-steps ?; If there are problems, could you also choose *View &rarr; Show log* and report back if you see any error messages?. The CZI problem sounds like the one I met before, and will try to resolve next week.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357055699
https://github.com/qupath/qupath/issues/135#issuecomment-357055699:612,Integrability,message,messages,612,"Oh dear, that sounds worse - I am using a Mac, and no extra extensions should be needed. Does the software start ok? I have seen a problem on some older Macs where it wasn't possible to start QuPath because of an incompatibility with OpenCV... but if the window opens at all then that shouldn't be the issue. You should be able to open a JPEG just by dragging it onto the main QuPath window. Could you try with the image *CMU-1.svs* that is suggested at https://github.com/qupath/qupath/wiki/First-steps ?; If there are problems, could you also choose *View &rarr; Show log* and report back if you see any error messages?. The CZI problem sounds like the one I met before, and will try to resolve next week.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357055699
https://github.com/qupath/qupath/issues/135#issuecomment-357055699:570,Testability,log,log,570,"Oh dear, that sounds worse - I am using a Mac, and no extra extensions should be needed. Does the software start ok? I have seen a problem on some older Macs where it wasn't possible to start QuPath because of an incompatibility with OpenCV... but if the window opens at all then that shouldn't be the issue. You should be able to open a JPEG just by dragging it onto the main QuPath window. Could you try with the image *CMU-1.svs* that is suggested at https://github.com/qupath/qupath/wiki/First-steps ?; If there are problems, could you also choose *View &rarr; Show log* and report back if you see any error messages?. The CZI problem sounds like the one I met before, and will try to resolve next week.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357055699
https://github.com/qupath/qupath/issues/135#issuecomment-357061650:9,Availability,down,downloaded,9,Ive just downloaded and re-installed on my mac and its working now! What a pallava! I think I was tried to add extensions on the mac where they weren't needed and it seems to be working now. Ive just had a look at some tissue detections and it seems to be functional! I will continue using the software and would you mind if I checked in again if I continue having problems?. Thank you again,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357061650
https://github.com/qupath/qupath/issues/135#issuecomment-357061650:27,Deployability,install,installed,27,Ive just downloaded and re-installed on my mac and its working now! What a pallava! I think I was tried to add extensions on the mac where they weren't needed and it seems to be working now. Ive just had a look at some tissue detections and it seems to be functional! I will continue using the software and would you mind if I checked in again if I continue having problems?. Thank you again,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357061650
https://github.com/qupath/qupath/issues/135#issuecomment-357061650:226,Safety,detect,detections,226,Ive just downloaded and re-installed on my mac and its working now! What a pallava! I think I was tried to add extensions on the mac where they weren't needed and it seems to be working now. Ive just had a look at some tissue detections and it seems to be functional! I will continue using the software and would you mind if I checked in again if I continue having problems?. Thank you again,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357061650
https://github.com/qupath/qupath/issues/135#issuecomment-358722518:101,Deployability,release,releases,101,There's a new Bio-Formats extension now [here](https://github.com/qupath/qupath-bioformats-extension/releases/tag/v0.0.4). It may help with the CZI files.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-358722518
https://github.com/qupath/qupath/issues/135#issuecomment-359426438:83,Deployability,install,installed,83,"Thank you! I managed to get things working as it happens however. I removed and re-installed several times and it seemed to like that! . > On 18 Jan 2018, at 17:35, Pete <notifications@github.com> wrote:; > ; > There's a new Bio-Formats extension now here. It may help with the CZI files.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-359426438
https://github.com/qupath/qupath/issues/136#issuecomment-357000908:263,Safety,detect,detection,263,"Just to get things started, you do not need to select anything before saving! I always have those two commands at the end of my scripts, and they are not related to what has been selected, it is just a full list of everything that shows up when you look in ""Show detection measurements"" or ""Show annotation measurements"" in the Measure menu. I wonder if you remove the selectDetections if maybe that will help things, since selecting all of the detections might cause a slowdown that messes up the save measurements command. You also might try the guiscript=true command at the top of your script, which seems to help some of the cases where the script doesn't allow a command to finish before trying the next one. Is it generating one file for every slide image?; Could you show us the part of your script where outDetectionsStatFname is created?. The only issues I have ever had with the saveDetectionMeasurements were when the output was over 2GB, and it doesn't sound like the issue here, so I am not sure what is happening.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357000908
https://github.com/qupath/qupath/issues/136#issuecomment-357000908:445,Safety,detect,detections,445,"Just to get things started, you do not need to select anything before saving! I always have those two commands at the end of my scripts, and they are not related to what has been selected, it is just a full list of everything that shows up when you look in ""Show detection measurements"" or ""Show annotation measurements"" in the Measure menu. I wonder if you remove the selectDetections if maybe that will help things, since selecting all of the detections might cause a slowdown that messes up the save measurements command. You also might try the guiscript=true command at the top of your script, which seems to help some of the cases where the script doesn't allow a command to finish before trying the next one. Is it generating one file for every slide image?; Could you show us the part of your script where outDetectionsStatFname is created?. The only issues I have ever had with the saveDetectionMeasurements were when the output was over 2GB, and it doesn't sound like the issue here, so I am not sure what is happening.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357000908
https://github.com/qupath/qupath/issues/136#issuecomment-357016567:138,Integrability,depend,depending,138,"I wasn't sure whether select annotations/detections had to be called before the actual processing but if it can be avoived it is great as depending on how many objects you have it might be slow. yes it is generating one file per slide with the idea of deleting everything once the analysis is over for the slide (although this bit of code is commented now). . outAnnoationsStatFname = ""H://""+strfnameTrim+""_steatosis_annotations.txt"". This is the line creating the variable holding the filename. . It is not an issue of size (I thought about that too) because if you limit the analysis to the first 10 tiles for every slide you are dealing with files of <100K. Although the complete file it should be < 20MB.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357016567
https://github.com/qupath/qupath/issues/136#issuecomment-357016567:465,Modifiability,variab,variable,465,"I wasn't sure whether select annotations/detections had to be called before the actual processing but if it can be avoived it is great as depending on how many objects you have it might be slow. yes it is generating one file per slide with the idea of deleting everything once the analysis is over for the slide (although this bit of code is commented now). . outAnnoationsStatFname = ""H://""+strfnameTrim+""_steatosis_annotations.txt"". This is the line creating the variable holding the filename. . It is not an issue of size (I thought about that too) because if you limit the analysis to the first 10 tiles for every slide you are dealing with files of <100K. Although the complete file it should be < 20MB.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357016567
https://github.com/qupath/qupath/issues/136#issuecomment-357016567:41,Safety,detect,detections,41,"I wasn't sure whether select annotations/detections had to be called before the actual processing but if it can be avoived it is great as depending on how many objects you have it might be slow. yes it is generating one file per slide with the idea of deleting everything once the analysis is over for the slide (although this bit of code is commented now). . outAnnoationsStatFname = ""H://""+strfnameTrim+""_steatosis_annotations.txt"". This is the line creating the variable holding the filename. . It is not an issue of size (I thought about that too) because if you limit the analysis to the first 10 tiles for every slide you are dealing with files of <100K. Although the complete file it should be < 20MB.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357016567
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:158,Safety,detect,detection,158,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:530,Safety,detect,detections,530,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:656,Safety,detect,detections,656,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:895,Safety,detect,detections,895,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:925,Safety,detect,detections,925,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:941,Safety,detect,detections,941,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:1049,Safety,detect,detections,1049,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:1248,Safety,detect,detections,1248,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:1266,Safety,detect,detection,1266,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357019559:1393,Safety,detect,detection,1393,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559
https://github.com/qupath/qupath/issues/136#issuecomment-357022294:335,Usability,simpl,simply,335,"Ok, if the deletion part is commented out entirely, and the names are not overlapping, my only thoughts are whether the removal of the selectDetections code changes anything, as that slowdown has caused problems in another script that dealt with merging annotations (https://github.com/qupath/qupath/issues/129). The other would be to simply include the folder name and let the function generate the filename, to see if that part is working. `saveDetectionMeasurements(""H://"", )`",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357022294
https://github.com/qupath/qupath/issues/136#issuecomment-357023840:271,Usability,feedback,feedback,271,the removal of selectDetectionMeasurement() and guiscript=true didn't change anything. . I will give a try to the suggestions above and try from another machine. The current platform is a Windows but at home I have a Mac. . Will let you know. Thanks a mill for the quick feedback.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357023840
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:195,Performance,perform,perform,195,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:110,Safety,detect,detection,110,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:143,Safety,detect,detections,143,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:210,Safety,detect,detections,210,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:259,Safety,detect,detections,259,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357025283:297,Safety,detect,detections,297,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283
https://github.com/qupath/qupath/issues/136#issuecomment-357201421:491,Modifiability,plugin,plugin,491,all suggestions above did not work. . getDetections() doesn't seem to be defined or it is not visible within the java classes I import. I will try to setup IntelliJ. However getDetectionObjects() has a size 0 (both single and batch mode). Could this be the problem ? What I realised is that the same script but on objects that are created with Qupath and not with ImageJ works fine in both batch and single slide mode. Is there maybe a problem with the type of objects created by the ImageJ plugin that import the objects into qupath ?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357201421
https://github.com/qupath/qupath/issues/136#issuecomment-357388634:578,Safety,detect,detection,578,"Oops, yes, he did say that in the first post. I think my wires got crossed while reading the forum post on automating the ImageJ macro runner across images. It is interesting that his import (and more importantly export) works for a single slide. I am still wondering if it not working in batch mode means that something isn't being given time to complete. @erexhepa When running it for a single slide, once all of the imported ROIs are in place, can you then use getDetectionObjects (on it's own as a separate script or menu command) to target anything? Does the Measure->Show detection measurements populate as soon as the script is complete?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357388634
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:2484,Availability,down,downsample,2484,"ion.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++; imp2 = IJ.getImage();; imp2.close();; }; ; }. ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:1714,Deployability,integrat,integrated,1714,"ass = annotation.getPathClass(); ; def roi = annotation.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:2261,Deployability,Update,Update,2261,"ion.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++; imp2 = IJ.getImage();; imp2.close();; }; ; }. ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:1714,Integrability,integrat,integrated,1714,"ass = annotation.getPathClass(); ; def roi = annotation.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:2330,Safety,Detect,Detection,2330,"ion.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++; imp2 = IJ.getImage();; imp2.close();; }; ; }. ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429324:1990,Usability,clear,clear,1990,"ion.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++; imp2 = IJ.getImage();; imp2.close();; }; ; }. ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324
https://github.com/qupath/qupath/issues/136#issuecomment-357429745:527,Modifiability,plugin,plugin,527,"Aaaah.... that makes sense. The *Send Overlay to QuPath* command doesn't support batch mode, and requests the image currently open in the viewer. Code is at https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupathj/QUPath_Send_Overlay_to_QuPath.java#L90. So the results are presumably being sent to the wrong image when called in batch mode. Because the `createPathObjectsFromROIs` method is `public static` it is hopefully enough to let you do the conversion in your script without relying on the plugin. You should be able to use `serverIJ` and add to the hierarchy returned by `getCurrentHierarchy()`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429745
https://github.com/qupath/qupath/issues/136#issuecomment-357668235:783,Deployability,integrat,integrated,783,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235
https://github.com/qupath/qupath/issues/136#issuecomment-357668235:783,Integrability,integrat,integrated,783,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235
https://github.com/qupath/qupath/issues/136#issuecomment-357668235:1284,Safety,detect,detected,1284,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235
https://github.com/qupath/qupath/issues/136#issuecomment-357668235:1680,Safety,detect,detectionObjects,1680,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235
https://github.com/qupath/qupath/issues/136#issuecomment-357668235:1089,Usability,clear,clear,1089,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235
https://github.com/qupath/qupath/issues/137#issuecomment-357349047:477,Availability,down,downsample,477,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047
https://github.com/qupath/qupath/issues/137#issuecomment-357349047:1084,Safety,detect,detection,1084,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047
https://github.com/qupath/qupath/issues/137#issuecomment-357349047:58,Usability,learn,learning,58,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047
https://github.com/qupath/qupath/issues/137#issuecomment-357349047:88,Usability,learn,learning,88,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047
https://github.com/qupath/qupath/issues/137#issuecomment-357349047:1070,Usability,Simpl,Simple,1070,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047
https://github.com/qupath/qupath/issues/138#issuecomment-357477993:246,Availability,down,downsample,246,"While viewers are unsynced, this should get you started. Maybe Pete will have a way to sync based on the current center of one viewer, but this will temporarily lock them together. Use your own X Y coordinates for pixel location and your desired downsample. Just click into each one of the viewers in turn and run:. ```; def viewer = getQuPath().getViewer(); viewer.setCenterPixelLocation(10000, 10000);; viewer.setDownsampleFactor(2); ```; Then check the sync box.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/138#issuecomment-357477993
https://github.com/qupath/qupath/issues/138#issuecomment-357478697:59,Performance,load,load,59,"Yes, pre-create two separate empty vieweres first and then load image into each viewer solves the issue!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/138#issuecomment-357478697
https://github.com/qupath/qupath/issues/140#issuecomment-359291582:173,Usability,simpl,simple,173,"@Svidro Sorry to trouble you again. I've tried hard to code some Groovy script, but it's still quite mysterious to me. I'm wondering if you could show me the code to do the simple task of drawing a polygon on an opened image? I'll then try my best to follow up on your code. Assuming the coordinates of the polygon is X: [1, 2, 3, 4, 5], Y: [1, 2, 3, 4, 5]. Thanks so much~",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/140#issuecomment-359291582
https://github.com/qupath/qupath/issues/140#issuecomment-359361318:509,Availability,error,error,509,"@Svidro Really appreciate your code!!! I guess it's little bit too much to ask, but I'm wondering if you could do me a final favor to teach me the code of reading coordinates from a json format like:; ```json; {; ""tumor"": [; {; ""name"": ""Annotation 0"",; ""vertices"": [; [; 100,; 150; ],; [; 200,; 250; ],; [; 300,; 350; ]; ]; },; {; ""name"": ""Annotation 1"",; ""vertices"": [; [; 1000,; 1500; ],; [; 2000,; 2500; ],; [; 3000,; 3500; ]; ]; }; ]; }; ```. I tried to use import groovy.json.JsonSlurper; But it gave me error of; `Script1.groovy: 5: unable to resolve class groovy.json.JsonSlurper`; With this part done, my entire issue should be resolved.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/140#issuecomment-359361318
https://github.com/qupath/qupath/issues/141#issuecomment-358633899:639,Availability,avail,available,639,"Oh dear, that does look suspiciously similar to the picture in @Svidro's link. As it happens, I've just been working on a pretty major revision of the QuPath Bio-Formats extension this morning. It should solve a lot of issues, but I don't know if it will solve this one. However, it will at least give some extra entries in the preference pane that would allow you to selectively enable/disable Bio-Formats for specific image extensions, so that you could ensure that OpenSlide is used for scn if you wanted. If nothing too bad appears in the next couple of hours I'll merge the changes with the main branch and then the extension will be available for testing. Or see [here](https://github.com/petebankhead/qupath-bioformats-extension) if you're happy to compile it yourself while it's still a work-in-progress.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358633899
https://github.com/qupath/qupath/issues/141#issuecomment-358633899:653,Testability,test,testing,653,"Oh dear, that does look suspiciously similar to the picture in @Svidro's link. As it happens, I've just been working on a pretty major revision of the QuPath Bio-Formats extension this morning. It should solve a lot of issues, but I don't know if it will solve this one. However, it will at least give some extra entries in the preference pane that would allow you to selectively enable/disable Bio-Formats for specific image extensions, so that you could ensure that OpenSlide is used for scn if you wanted. If nothing too bad appears in the next couple of hours I'll merge the changes with the main branch and then the extension will be available for testing. Or see [here](https://github.com/petebankhead/qupath-bioformats-extension) if you're happy to compile it yourself while it's still a work-in-progress.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358633899
https://github.com/qupath/qupath/issues/141#issuecomment-358634515:378,Security,access,access,378,"In the meantime, I see at the bottom of the panel on the left *Image list (3)*. If you double-click on that, you should see another two images - and you can double click on each of them to see how they look. From the few .scn files I've seen, the 'default' that opens up usually isn't the whole slide scan that you probably want, and it's necessary to go to the *Image list* to access it. You can also remove the Bio-Formats extension from your QuPath extensions directory, so as to let OpenSlide have a go. Maybe it has more success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358634515
https://github.com/qupath/qupath/issues/141#issuecomment-358716701:14,Deployability,update,update,14,"The extension update is now [here](https://github.com/qupath/qupath-bioformats-extension/releases/tag/v0.0.4). If it doesn't solve the problem, try going to *Edit &rarr; Preferences...* and find the entry called *Never use Bio-Formats for image extensions*. Type `.scn` there and QuPath should default to using OpenSlide... which may possibly help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358716701
https://github.com/qupath/qupath/issues/141#issuecomment-358716701:89,Deployability,release,releases,89,"The extension update is now [here](https://github.com/qupath/qupath-bioformats-extension/releases/tag/v0.0.4). If it doesn't solve the problem, try going to *Edit &rarr; Preferences...* and find the entry called *Never use Bio-Formats for image extensions*. Type `.scn` there and QuPath should default to using OpenSlide... which may possibly help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358716701
https://github.com/qupath/qupath/issues/141#issuecomment-358745153:140,Availability,avail,avail,140,"I have installed the new extension with the same results. I tried to exclude the .scn file from bioformats so that OpenSlide opens it to no avail it comes up with file can't open, however, I downloaded a sample of the .scn file from openslide it opens OK ; It could well be the issue @Svidro illuded to.; Its seems like this is an ongoing issue https://github.com/openslide/openslide/issues/189, The files I have here are produced by Leica Versa while our older .scn from SCN400 work OK",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358745153
https://github.com/qupath/qupath/issues/141#issuecomment-358745153:191,Availability,down,downloaded,191,"I have installed the new extension with the same results. I tried to exclude the .scn file from bioformats so that OpenSlide opens it to no avail it comes up with file can't open, however, I downloaded a sample of the .scn file from openslide it opens OK ; It could well be the issue @Svidro illuded to.; Its seems like this is an ongoing issue https://github.com/openslide/openslide/issues/189, The files I have here are produced by Leica Versa while our older .scn from SCN400 work OK",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358745153
https://github.com/qupath/qupath/issues/141#issuecomment-358745153:7,Deployability,install,installed,7,"I have installed the new extension with the same results. I tried to exclude the .scn file from bioformats so that OpenSlide opens it to no avail it comes up with file can't open, however, I downloaded a sample of the .scn file from openslide it opens OK ; It could well be the issue @Svidro illuded to.; Its seems like this is an ongoing issue https://github.com/openslide/openslide/issues/189, The files I have here are produced by Leica Versa while our older .scn from SCN400 work OK",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358745153
https://github.com/qupath/qupath/issues/141#issuecomment-358746900:219,Integrability,depend,depends,219,"Ah, I was also using the OpenSlide example to see if it worked. If you can somehow send me an example file with the problem I'd be happy to investigate. Although it sounds like it is outside the domain of QuPath, which depends on either OpenSlide or Bio-Formats to access the pixels. (If it looks ok when opened by Bio-Formats in Fiji (www.fiji.sc) then it might be a QuPath thing again, although not one I've seen before.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358746900
https://github.com/qupath/qupath/issues/141#issuecomment-358746900:265,Security,access,access,265,"Ah, I was also using the OpenSlide example to see if it worked. If you can somehow send me an example file with the problem I'd be happy to investigate. Although it sounds like it is outside the domain of QuPath, which depends on either OpenSlide or Bio-Formats to access the pixels. (If it looks ok when opened by Bio-Formats in Fiji (www.fiji.sc) then it might be a QuPath thing again, although not one I've seen before.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358746900
https://github.com/qupath/qupath/issues/141#issuecomment-358757127:38,Availability,avail,avail,38,"Hi Pete. I tried ImageJ earlier to no avail same issue with the pink overlay, looks like a bioformat issue, . here is a link to the file if you would like to have a look. I will try and get in touch with the guys up at Dundee regarding this issue . https://drive.google.com/file/d/1-zEYM58GxPxk5ldECU3LU-A4ZpSMVqJd/view?usp=sharing. Mustafa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358757127
https://github.com/qupath/qupath/issues/141#issuecomment-358951720:683,Security,Access,Access,683,"Do these colors look more plausible to you?. ![scn_tile](https://user-images.githubusercontent.com/4690904/35150761-7e875fbe-fd13-11e7-98c2-21a026638c2b.jpg). My suspicion is that the photometric interpretation is causing the trouble. Here's a (very hack-y) QuPath script that looks to pull out some tiles after having switched the photometric interpretation from Y_CB_CR to RGB. ```groovy; import ij.ImagePlus; import ij.process.ColorProcessor; import loci.formats.in.LeicaSCNReader; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. // Try to get the TIFF parser (this takes a bit of a search?); // Assume that we have a LeicaSCNReader somewhere; def reader = server.manager.getPrimaryReader(server, server.filePath); while (!(reader instanceof LeicaSCNReader)); reader = reader.getReader(); reader = reader as LeicaSCNReader; def tiffParser = reader.tiffParser as TiffParser. // Get tile size; int w = reader.getOptimalTileWidth(); int h = reader.getOptimalTileHeight(). // Loop through the IFDs and see if we can extract an image, somehow; for (ifd in tiffParser.getIFDs()) {; try {; // Check the original photometric interpretation; print 'Original photometric interpretation: ' + (ifd.getPhotometricInterpretation()); // Hack to artificially set it to RGB; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); def bytes = tiffParser.getTile(ifd, null, 0, 0); // Convert to an ImageJ image for display; int[] rgb = new int[w*h]; for (int i = 0; i < w*h; i++) {; int r = bytes[i]; int g = bytes[w*h+i]; int b = bytes[w*h*2+i]; rgb[i] = (r << 16) + (g << 8) + b; }; def cp = new ColorProcessor(w, h, rgb); new ImagePlus(""Tile"", cp).show(); } catch (Exception e) {; print e.getLocalizedMessage(); }; }; ```. If this is correct, h",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358951720
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2708,Availability,error,error,2708,"using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2406,Modifiability,extend,extends,2406,"e QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERP",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2899,Modifiability,extend,extends,2899,"using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2026,Performance,cache,cache,2026,"rp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:303,Security,access,accessing,303,"Well, there's a way you could do it.... If you try opening the image and running the following script, it should intercept the requests and change the photometric interpretation when needed. So you should then be able to work with the whole slide image directly. It does this with some very messy code, accessing private fields and such. Therefore I don't really recommend it... but it might help check whether it's on the right track. Note that I think you'll need to go to the QuPath preferences and turn off the Bio-Formats parallelization option for it to work. ```groovy; import javafx.application.Platform; import loci.common.RandomAccessInputStream; import loci.common.services.ServiceFactory; import loci.formats.ClassList; import loci.formats.FormatException; import loci.formats.IFormatReader; import loci.formats.ImageReader; import loci.formats.gui.BufferedImageReader; import loci.formats.in.LeicaSCNReader; import loci.formats.services.OMEXMLService; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(read",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:1196,Security,Access,Access,1196,"e to work with the whole slide image directly. It does this with some very messy code, accessing private fields and such. Therefore I don't really recommend it... but it might help check whether it's on the right track. Note that I think you'll need to go to the QuPath preferences and turn off the Bio-Formats parallelization option for it to work. ```groovy; import javafx.application.Platform; import loci.common.RandomAccessInputStream; import loci.common.services.ServiceFactory; import loci.formats.ClassList; import loci.formats.FormatException; import loci.formats.IFormatReader; import loci.formats.ImageReader; import loci.formats.gui.BufferedImageReader; import loci.formats.in.LeicaSCNReader; import loci.formats.services.OMEXMLService; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2539,Testability,log,logger,2539,"using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2701,Testability,LOG,LOGGER,2701,"using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2011,Usability,Clear,Clear,2011,"rp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2187,Usability,clear,clearCacheForServer,2187,"e current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847
https://github.com/qupath/qupath/issues/141#issuecomment-400023655:417,Availability,error,error,417,"I also had some problems using the bioformats package and scn files. After installing the plugin, when I try to open my images on qupath, qupath tries to open my scn files using the bioformats server (not openslide) and it cannot determine the magnification metadata I tried manually editing the metadata into the qpproj file, but this had no effect. Turning off the bioformats plugin in edit>preferences resolved my error.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-400023655
https://github.com/qupath/qupath/issues/141#issuecomment-400023655:75,Deployability,install,installing,75,"I also had some problems using the bioformats package and scn files. After installing the plugin, when I try to open my images on qupath, qupath tries to open my scn files using the bioformats server (not openslide) and it cannot determine the magnification metadata I tried manually editing the metadata into the qpproj file, but this had no effect. Turning off the bioformats plugin in edit>preferences resolved my error.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-400023655
https://github.com/qupath/qupath/issues/141#issuecomment-400023655:90,Modifiability,plugin,plugin,90,"I also had some problems using the bioformats package and scn files. After installing the plugin, when I try to open my images on qupath, qupath tries to open my scn files using the bioformats server (not openslide) and it cannot determine the magnification metadata I tried manually editing the metadata into the qpproj file, but this had no effect. Turning off the bioformats plugin in edit>preferences resolved my error.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-400023655
https://github.com/qupath/qupath/issues/141#issuecomment-400023655:378,Modifiability,plugin,plugin,378,"I also had some problems using the bioformats package and scn files. After installing the plugin, when I try to open my images on qupath, qupath tries to open my scn files using the bioformats server (not openslide) and it cannot determine the magnification metadata I tried manually editing the metadata into the qpproj file, but this had no effect. Turning off the bioformats plugin in edit>preferences resolved my error.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-400023655
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:3002,Availability,error,error,3002,"into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2700,Modifiability,extend,extends,2700,"e QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERP",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:3193,Modifiability,extend,extends,3193,"into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2320,Performance,cache,cache,2320,"rp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:1490,Security,Access,Access,1490,"mewhat realistic image. . **_But now the problem is_** the image can be zoomed to a minimum extent as its pixels get fragmented at X20. My question: is it possible to recode in such a way that the image can be seen at X20 and also run analysis on that? Please suggest any alternative if you have any. Thanks for your support. Sincerely, Partha. **Your code:**. import javafx.application.Platform; import loci.common.RandomAccessInputStream; import loci.common.services.ServiceFactory; import loci.formats.ClassList; import loci.formats.FormatException; import loci.formats.IFormatReader; import loci.formats.ImageReader; import loci.formats.gui.BufferedImageReader; import loci.formats.in.LeicaSCNReader; import loci.formats.services.OMEXMLService; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2833,Testability,log,logger,2833,"into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2995,Testability,LOG,LOGGER,2995,"into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col); }. public byte[] getSamples(IFD ifd, byte[] buf, int x, int y,; long width, long height, int overlapX, int overlapY); throws FormatException, IOException; {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getSamples(ifd, buf, x, y, width, height, overlapX, overlapY). }. }",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2305,Usability,Clear,Clear,2305,"rp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435208389:2481,Usability,clear,clearCacheForServer,2481,"e current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byte[] buf, int row, int col) throws FormatException, IOException {; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); return super.getTile(ifd, buf, row, col",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435208389
https://github.com/qupath/qupath/issues/141#issuecomment-435301582:64,Deployability,install,installing,64,"Hi @pssaha did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at https://github.com/qupath/qupath/issues/141#issuecomment-400023655 ? Further instructions are at https://github.com/qupath/qupath-bioformats-extension#performance; This would leave the job of reading the image to OpenSlide; I don't know what the status of .scn support is there. Regarding the script, I don't see why my code should be limited in the resolution; is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? Many slide formats contain multiple images, and versions of the same image. Under the 'Image' tab you can explore the 'Image list' and 'Associated images'. Or if you're working with a [Project](https://github.com/qupath/qupath/wiki/Projects) then all images in the file should be added to the project immediately. Nevertheless, I don't really recommend my script. It was just put together to try to help explore the issue, but it is rather inconvenient to use and I don't know if the image it produces in the end really matches with the original or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435301582
https://github.com/qupath/qupath/issues/141#issuecomment-435301582:305,Performance,perform,performance,305,"Hi @pssaha did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at https://github.com/qupath/qupath/issues/141#issuecomment-400023655 ? Further instructions are at https://github.com/qupath/qupath-bioformats-extension#performance; This would leave the job of reading the image to OpenSlide; I don't know what the status of .scn support is there. Regarding the script, I don't see why my code should be limited in the resolution; is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? Many slide formats contain multiple images, and versions of the same image. Under the 'Image' tab you can explore the 'Image list' and 'Associated images'. Or if you're working with a [Project](https://github.com/qupath/qupath/wiki/Projects) then all images in the file should be added to the project immediately. Nevertheless, I don't really recommend my script. It was just put together to try to help explore the issue, but it is rather inconvenient to use and I don't know if the image it produces in the end really matches with the original or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435301582
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:189,Deployability,install,installing,189,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:607,Deployability,release,releases,607,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:620,Deployability,INSTALL,INSTALL-,620,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:666,Deployability,install,install,666,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:733,Deployability,install,installing,733,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435641891:1320,Performance,load,loading,1320,"Hello @petebankhead, I apologize for being out of network for a while. You asked me two questions above. Please let me answer them:. 1. Did you also try it without Bio-Formats, e.g. before installing it or by turning it off for .scn (as was reported to workaround the problem at #141 (comment)? ; Answer: Sure, I did that as before I wrote my first comment, but it says ""sorry I can't open *.scn"". That perhaps says that OpenSlide is not being used by default on my system. . In order to let OpenSlide help in some ways externally, I went back to Openslide.org, specifically to https://files.openslides.org/releases/1.3/INSTALL-1.3.txt , followed the instruction to install openslide on Windows 32bits. But could not have success in installing finally (couldn't run on cmd). I even didn't know whether or how I could link this to QuPath. Anyway, just letting you know my attempt. 2. is it possible that you're actually looking at an overview image/thumbnail rather than the full resolution image? ; Answer: I am afraid, it's not possible as I'll have to quantify the signals in the fully resolved scanned brightfield image (X20). That is the main goal of using QuPath for my project. I already had success in segregating my signals based on their intensity in the extracted region of the entire image, but I am stuck in loading the whole image on QuPath. If I can solve this, I am all set. Looks like this is challenging now!! I have in my mind to convert these .scn files to tiff if it is possible. I thank you for your care and suggestions. Please let me know if you have something in mind. I'll appreciate your help. Sorry again for the belated comment. Many thanks, Sincerely, Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435641891
https://github.com/qupath/qupath/issues/141#issuecomment-435651179:26,Deployability,install,install,26,"For 1. you didn't need to install OpenSlide yourself - just excluding/disabling Bio-Formats is enough, and QuPath should default to using OpenSlide. This has support for at least [some .scn](https://openslide.org/formats/leica/) files, but not necessarily all of them and I guess not yours. > Note: This is true for Windows, Mac and some variations of Linux. The default version of OpenSlide might not work currently on all kinds of Linux. For 2. I fully understand you need the full-resolution image; my point is that it may not be the full-resolution image that you have opened. If there are multiple images in the file and you drag it onto QuPath, then one of these multiple images will be displayed - but it might not be the full-resolution image you want. I describe in my last answer how you can access the other images in the file from within QuPath (either under the 'Image' tab or through a project). Nevertheless, if you need to rely on Bio-Formats then the 'pink' issue has to be resolved, and the problem appears to be in Bio-Formats and not QuPath. If it hasn't been fixed yet, then if you are able to export your image in another format (e.g. .svs) then this may help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435651179
https://github.com/qupath/qupath/issues/141#issuecomment-435651179:802,Security,access,access,802,"For 1. you didn't need to install OpenSlide yourself - just excluding/disabling Bio-Formats is enough, and QuPath should default to using OpenSlide. This has support for at least [some .scn](https://openslide.org/formats/leica/) files, but not necessarily all of them and I guess not yours. > Note: This is true for Windows, Mac and some variations of Linux. The default version of OpenSlide might not work currently on all kinds of Linux. For 2. I fully understand you need the full-resolution image; my point is that it may not be the full-resolution image that you have opened. If there are multiple images in the file and you drag it onto QuPath, then one of these multiple images will be displayed - but it might not be the full-resolution image you want. I describe in my last answer how you can access the other images in the file from within QuPath (either under the 'Image' tab or through a project). Nevertheless, if you need to rely on Bio-Formats then the 'pink' issue has to be resolved, and the problem appears to be in Bio-Formats and not QuPath. If it hasn't been fixed yet, then if you are able to export your image in another format (e.g. .svs) then this may help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435651179
https://github.com/qupath/qupath/issues/143#issuecomment-361588582:481,Availability,Down,Downsample,481,"If it's TIFF you want, then it's best to send it to ImageJ and save from there. There's still a size limit, so if you want to export especially large regions and that still doesn't work then let me know... in the short term you might need a script to work around that limit. Two extra notes:; * QuPath can't export regions that are approaching the size of a whole slide yet at all; i.e. it can handle thousands of pixels along each dimension, but not tens of thousands.; * If the *Downsample factor* is 1 and the image is RGB, then *Export image region* should give you the same pixels in the PNG as you'd get in the TIFF, at the full resolution.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/143#issuecomment-361588582
https://github.com/qupath/qupath/issues/144#issuecomment-363409447:433,Integrability,depend,depends,433,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447
https://github.com/qupath/qupath/issues/144#issuecomment-363409447:331,Security,access,accessible,331,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447
https://github.com/qupath/qupath/issues/144#issuecomment-363409447:724,Testability,test,tested,724,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447
https://github.com/qupath/qupath/issues/144#issuecomment-363409447:626,Usability,clear,clearer,626,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447
https://github.com/qupath/qupath/issues/144#issuecomment-363409447:692,Usability,intuit,intuitive,692,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447
https://github.com/qupath/qupath/issues/144#issuecomment-364498226:160,Security,access,accessible,160,"I explored a bit more, and it turns out that I had already done most of the difficult part in storing annotation descriptions, and what remains is to make them accessible. I had a quick look (the code is on my fork of QuPath) and can add descriptions to both the images and the annotations. Currently, the annotation descriptions are just displayed as a tooltip under the 'Annotations' tab; they need a better home eventually. I won't get a chance to look further for at least the next few days, but to answer your questions:. > Do you save description data to the image files or to the qpproj file?. Currently to the `.qpproj` file. This is just JSON and can be opened in any text editor. > Are the annotations stored to the project or to the image?. In the `.qpdata` file. This is a binary file, which is in a trickier format (using Java serialization). Potentially these files can be large and complex, storing the relationship between millions of objects (annotations, cells...). But in your case they might be very small, and easily parse-able in a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364498226
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1368,Availability,down,download,1368,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:256,Modifiability,enhance,enhance,256,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1327,Security,access,accessed,1327,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1309,Testability,test,test,1309,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1387,Testability,test,testdata,1387,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1427,Testability,log,log,1427,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1704,Testability,log,log,1704,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1769,Testability,log,log,1769,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1070,Usability,feedback,feedback,1070,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1584,Usability,feedback,feedback,1584,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591
https://github.com/qupath/qupath/issues/144#issuecomment-374198719:14,Deployability,update,updates,14,"Check out the updates described [in this blog post](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html) - it explains how projects can be arranged and descriptions added. Also, in the version described there, you can press *Enter* and then add some description text for annotations. (*Viewing* the description remains rather sub-optimal... either press *Enter* again, or see it as a tooltip when hovering over the annotation under the *Annotations* tab on the left.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-374198719
https://github.com/qupath/qupath/issues/144#issuecomment-374198719:108,Deployability,update,updates,108,"Check out the updates described [in this blog post](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html) - it explains how projects can be arranged and descriptions added. Also, in the version described there, you can press *Enter* and then add some description text for annotations. (*Viewing* the description remains rather sub-optimal... either press *Enter* again, or see it as a tooltip when hovering over the annotation under the *Annotations* tab on the left.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-374198719
https://github.com/qupath/qupath/issues/144#issuecomment-632216712:16,Energy Efficiency,reduce,reduce,16,"In an effort to reduce our pending 'GitHub issues', and because this has been mostly addressed, I'll close this :). It is now possible to add descriptions to annotations (in v0.2.0-m12... and soon the stable v0.2.0). It's also possible to view the 'name' of the annotation superimposed on top of the image (press `N` to show/hide it).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-632216712
https://github.com/qupath/qupath/issues/145#issuecomment-363809051:91,Deployability,update,updated,91,"Hi! I just wanted to quickly verify that you are using Pete's newest Bioformats extension (updated 20 days ago) and Bioformats 5.7.3. . I suspect everything is up to date since the 4plex works, but I had some problems a few weeks ago, and realized I had not updated Bioformats (separately from the extension) in a while, which turned out to be my problem. And being sure you have both of those may help Pete troubleshoot the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/145#issuecomment-363809051
https://github.com/qupath/qupath/issues/145#issuecomment-363809051:258,Deployability,update,updated,258,"Hi! I just wanted to quickly verify that you are using Pete's newest Bioformats extension (updated 20 days ago) and Bioformats 5.7.3. . I suspect everything is up to date since the 4plex works, but I had some problems a few weeks ago, and realized I had not updated Bioformats (separately from the extension) in a while, which turned out to be my problem. And being sure you have both of those may help Pete troubleshoot the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/145#issuecomment-363809051
https://github.com/qupath/qupath/issues/145#issuecomment-363923313:41,Deployability,release,release,41,"This problem should be fixed in the next release, alongside a few other changes to help give more control over performance-related options.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/145#issuecomment-363923313
https://github.com/qupath/qupath/issues/145#issuecomment-363923313:111,Performance,perform,performance-related,111,"This problem should be fixed in the next release, alongside a few other changes to help give more control over performance-related options.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/145#issuecomment-363923313
https://github.com/qupath/qupath/issues/146#issuecomment-364010607:384,Energy Efficiency,adapt,adapt,384,"Many things are possible with scripting! The original classifier script is around somewhere, but here is a simplified version I have on my gist. I edited it a bit so that you can see how it would be used in your case. https://gist.github.com/Svidro/5b016e192a33c883c0bd20de18eb7764#file-classifier-sample-groovy; Note that in this case it was looking for Channel 2 spots, but you can adapt this to any channel or stain, or multiple channels of spots at the same time (Dual positive 1-3, etc)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-364010607
https://github.com/qupath/qupath/issues/146#issuecomment-364010607:384,Modifiability,adapt,adapt,384,"Many things are possible with scripting! The original classifier script is around somewhere, but here is a simplified version I have on my gist. I edited it a bit so that you can see how it would be used in your case. https://gist.github.com/Svidro/5b016e192a33c883c0bd20de18eb7764#file-classifier-sample-groovy; Note that in this case it was looking for Channel 2 spots, but you can adapt this to any channel or stain, or multiple channels of spots at the same time (Dual positive 1-3, etc)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-364010607
https://github.com/qupath/qupath/issues/146#issuecomment-364010607:107,Usability,simpl,simplified,107,"Many things are possible with scripting! The original classifier script is around somewhere, but here is a simplified version I have on my gist. I edited it a bit so that you can see how it would be used in your case. https://gist.github.com/Svidro/5b016e192a33c883c0bd20de18eb7764#file-classifier-sample-groovy; Note that in this case it was looking for Channel 2 spots, but you can adapt this to any channel or stain, or multiple channels of spots at the same time (Dual positive 1-3, etc)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-364010607
https://github.com/qupath/qupath/issues/146#issuecomment-366444082:206,Safety,Detect,Detection,206,"Hi Svidro:. Thanks for your help!. I attempted to run your script but was unsuccessful. . I used the Estimate stain vectors function > Auto to make sure that the vectors were set correctly. I then ran Cell Detection followed by the Subcellular Classifier (Experimental) to identify the spots. QuPath nicely identifies the spots and separates the clusters! I then annotated ""Stroma"" (where the ISH signal is located) and ""Tumor"" and ran the Detection Classifier. QuPath perfectly separates stroma and tumor cells. Then I ran your script. QuPath seems to have classified all cells as if they have > 15+ spots. . Here is a screenshot. I would appreciate your thoughts. , ![image](https://user-images.githubusercontent.com/36250970/36341754-3ad312da-13c1-11e8-9287-eaed3de4b7d2.png). Thanks for your help!!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-366444082
https://github.com/qupath/qupath/issues/146#issuecomment-366444082:440,Safety,Detect,Detection,440,"Hi Svidro:. Thanks for your help!. I attempted to run your script but was unsuccessful. . I used the Estimate stain vectors function > Auto to make sure that the vectors were set correctly. I then ran Cell Detection followed by the Subcellular Classifier (Experimental) to identify the spots. QuPath nicely identifies the spots and separates the clusters! I then annotated ""Stroma"" (where the ISH signal is located) and ""Tumor"" and ran the Detection Classifier. QuPath perfectly separates stroma and tumor cells. Then I ran your script. QuPath seems to have classified all cells as if they have > 15+ spots. . Here is a screenshot. I would appreciate your thoughts. , ![image](https://user-images.githubusercontent.com/36250970/36341754-3ad312da-13c1-11e8-9287-eaed3de4b7d2.png). Thanks for your help!!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-366444082
https://github.com/qupath/qupath/issues/146#issuecomment-366458274:531,Safety,detect,detection-object-measurements,531,"Whenever everything is classified as positive, it usually means the wording is not quite right in the description of the feature (which is going to be from your example, not the script). For example, if I change my fluorescent example to read ""Surbcellular:"" all of my spots become classified as 15+. For your brightfield images, it is probably something like Subcellular: DAB: etc. If you have trouble getting it just right, you can try using:; https://gist.github.com/Svidro/5e4c29630e8d2ef36988184987d1028f#file-print-a-list-of-detection-object-measurements; It will print out a list in your script window which you can directly copy and paste. Edit: I also fixed an incorrect ""pathCellObject"" that was in the Gist version of the script. Oops.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-366458274
https://github.com/qupath/qupath/issues/146#issuecomment-368318946:39,Safety,detect,detection,39,"Hi Svidro:. When I run the Subcellular detection (experimental) command, the program perfectly identifies the red ISH spots in the image. Here are my subcellular detection parameters:; ![image](https://user-images.githubusercontent.com/36250970/36643217-911c24d2-1a16-11e8-9693-b8e3aeb1aee2.png). When I run the script: setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"",1,4,10), The program perfectly divides the classes into 4 categories, Negative 1+, 2+ and 3+:; ![image](https://user-images.githubusercontent.com/36250970/36643281-3288c096-1a17-11e8-8920-e47c8109b580.png). However, when I substitute your script for the one above (using exactly the same settings), the program fails to divide the classes into 5 categories (Negative through 4+) and here is the output: ; ![image](https://user-images.githubusercontent.com/36250970/36643319-b580f8ba-1a17-11e8-909d-6e6c5e619ee0.png). My goal is to have an 5-category output that will match the Advanced Cell Diagnostics scoring scheme. I would appreciate your thoughts. . Thanks!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368318946
https://github.com/qupath/qupath/issues/146#issuecomment-368318946:162,Safety,detect,detection,162,"Hi Svidro:. When I run the Subcellular detection (experimental) command, the program perfectly identifies the red ISH spots in the image. Here are my subcellular detection parameters:; ![image](https://user-images.githubusercontent.com/36250970/36643217-911c24d2-1a16-11e8-9693-b8e3aeb1aee2.png). When I run the script: setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"",1,4,10), The program perfectly divides the classes into 4 categories, Negative 1+, 2+ and 3+:; ![image](https://user-images.githubusercontent.com/36250970/36643281-3288c096-1a17-11e8-8920-e47c8109b580.png). However, when I substitute your script for the one above (using exactly the same settings), the program fails to divide the classes into 5 categories (Negative through 4+) and here is the output: ; ![image](https://user-images.githubusercontent.com/36250970/36643319-b580f8ba-1a17-11e8-909d-6e6c5e619ee0.png). My goal is to have an 5-category output that will match the Advanced Cell Diagnostics scoring scheme. I would appreciate your thoughts. . Thanks!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368318946
https://github.com/qupath/qupath/issues/146#issuecomment-368327932:122,Safety,detect,detection,122,"Ah, no, the script does not create sub-categories for each cell type, it overwrites cell classes based on the subcellular detection count. I would have to look into something a bit different to do what is in your top image. I'm not sure what the bottom image is though. The result of the script if you swap in DAB should be something like:; ![image](https://user-images.githubusercontent.com/23145209/36644405-c7245426-1a0e-11e8-8c52-4a525fd5588f.png). At least based on the shoddy naming scheme I used in the basic script!. Note that it was not designed to subdivide tumor or stroma cells into categories, but to create new categories within annotation regions purely based on a spot count. I would have to look into some different scripting to subdivide that way, though Pete recently posted a script that has a function I did want to test out.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368327932
https://github.com/qupath/qupath/issues/146#issuecomment-368327932:837,Testability,test,test,837,"Ah, no, the script does not create sub-categories for each cell type, it overwrites cell classes based on the subcellular detection count. I would have to look into something a bit different to do what is in your top image. I'm not sure what the bottom image is though. The result of the script if you swap in DAB should be something like:; ![image](https://user-images.githubusercontent.com/23145209/36644405-c7245426-1a0e-11e8-8c52-4a525fd5588f.png). At least based on the shoddy naming scheme I used in the basic script!. Note that it was not designed to subdivide tumor or stroma cells into categories, but to create new categories within annotation regions purely based on a spot count. I would have to look into some different scripting to subdivide that way, though Pete recently posted a script that has a function I did want to test out.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368327932
https://github.com/qupath/qupath/issues/146#issuecomment-368337080:118,Safety,detect,detection,118,"Pete and Svidro:. That's got it! Thanks both so much for your help. . I have one final question. The subcellular spot detection seems to be picking up yellow in addition to red. After designating the ROI and doing a cell count, I used the Analyze > Preprocessing > Estimate stain vectors command, selected ""Auto"", then OK. The program picks up the red spots, beautifully, but also seems to pick up some aberrant yellow pigment. Here are a few images:; ![image](https://user-images.githubusercontent.com/36250970/36645494-c2c50a14-1a37-11e8-9932-2b15b61a5e31.png). ![image](https://user-images.githubusercontent.com/36250970/36645503-d0a0d780-1a37-11e8-9e32-3dca42a8ec52.png). Any thoughts on how to avoid detection of the yellow pigment?. Thanks again for this program and your help!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368337080
https://github.com/qupath/qupath/issues/146#issuecomment-368337080:699,Safety,avoid,avoid,699,"Pete and Svidro:. That's got it! Thanks both so much for your help. . I have one final question. The subcellular spot detection seems to be picking up yellow in addition to red. After designating the ROI and doing a cell count, I used the Analyze > Preprocessing > Estimate stain vectors command, selected ""Auto"", then OK. The program picks up the red spots, beautifully, but also seems to pick up some aberrant yellow pigment. Here are a few images:; ![image](https://user-images.githubusercontent.com/36250970/36645494-c2c50a14-1a37-11e8-9932-2b15b61a5e31.png). ![image](https://user-images.githubusercontent.com/36250970/36645503-d0a0d780-1a37-11e8-9e32-3dca42a8ec52.png). Any thoughts on how to avoid detection of the yellow pigment?. Thanks again for this program and your help!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368337080
https://github.com/qupath/qupath/issues/146#issuecomment-368337080:705,Safety,detect,detection,705,"Pete and Svidro:. That's got it! Thanks both so much for your help. . I have one final question. The subcellular spot detection seems to be picking up yellow in addition to red. After designating the ROI and doing a cell count, I used the Analyze > Preprocessing > Estimate stain vectors command, selected ""Auto"", then OK. The program picks up the red spots, beautifully, but also seems to pick up some aberrant yellow pigment. Here are a few images:; ![image](https://user-images.githubusercontent.com/36250970/36645494-c2c50a14-1a37-11e8-9932-2b15b61a5e31.png). ![image](https://user-images.githubusercontent.com/36250970/36645503-d0a0d780-1a37-11e8-9e32-3dca42a8ec52.png). Any thoughts on how to avoid detection of the yellow pigment?. Thanks again for this program and your help!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368337080
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:278,Availability,down,down,278,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:601,Safety,detect,detect,601,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1312,Safety,detect,detection,1312,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1366,Safety,detect,detected,1366,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1793,Safety,detect,detection,1793,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1447,Usability,learn,learning,1447,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1517,Usability,learn,learn-by-example,1517,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368339801:1675,Usability,simpl,simple,1675,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801
https://github.com/qupath/qupath/issues/146#issuecomment-368345195:786,Availability,down,down,786,"Hi Pete:. Thanks so much for your helpful comments!. I am a veterinary pathologist working with novel immunotherapeutic approaches to cancer treatment. We use in situ hybridization extensively for target discovery and to identify target + cells within our xenograft models. In addition to measuring a reduction in xenograft size via calipers, I am interested to use QuPath to document a reduction in the number of ISH target + cells / unit area of the xenograft. It would be incredibly helpful to have a ""learn by example"" approach to speed the task. Maybe you would select ISH- stromal cells, ISH+ stromal cells, ISH- tumor cells and ISH+ tumor cells, etc. as annotations and then run the Classifier?. I am also involved in gene therapy experiments in which we are attempting to knock down mRNA expression in specific cell populations in vivo. I would like to use QuPath to identify the cell population using annotations, then measure the amount of ISH signal per cell in treated vs untreated animals. In this case, rather than eliminating the cells of interest, we are attempting to demonstrate a reduction in ISH signal per cell. Thus, simply designating cells as ""positive"" or ""negative"" will not suffice. Rather, using the script you wrote above would be helpful to show that you have a reduction of cells listed as 4+ and 3+ and an increase in cells listed as 0 or 1+. Alternatively, if you could calculate an ""H score"" based upon a 5-point scale (negative, 1+, 2+, 3+, 4+), that would be a great way to compare between groups. . I think the intersection between pathology and artificial intelligence / machine learning is fascinating. I wonder if it would be feasible to learn Groovy so I can write my own scripts? . Thanks again!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368345195
https://github.com/qupath/qupath/issues/146#issuecomment-368345195:505,Usability,learn,learn,505,"Hi Pete:. Thanks so much for your helpful comments!. I am a veterinary pathologist working with novel immunotherapeutic approaches to cancer treatment. We use in situ hybridization extensively for target discovery and to identify target + cells within our xenograft models. In addition to measuring a reduction in xenograft size via calipers, I am interested to use QuPath to document a reduction in the number of ISH target + cells / unit area of the xenograft. It would be incredibly helpful to have a ""learn by example"" approach to speed the task. Maybe you would select ISH- stromal cells, ISH+ stromal cells, ISH- tumor cells and ISH+ tumor cells, etc. as annotations and then run the Classifier?. I am also involved in gene therapy experiments in which we are attempting to knock down mRNA expression in specific cell populations in vivo. I would like to use QuPath to identify the cell population using annotations, then measure the amount of ISH signal per cell in treated vs untreated animals. In this case, rather than eliminating the cells of interest, we are attempting to demonstrate a reduction in ISH signal per cell. Thus, simply designating cells as ""positive"" or ""negative"" will not suffice. Rather, using the script you wrote above would be helpful to show that you have a reduction of cells listed as 4+ and 3+ and an increase in cells listed as 0 or 1+. Alternatively, if you could calculate an ""H score"" based upon a 5-point scale (negative, 1+, 2+, 3+, 4+), that would be a great way to compare between groups. . I think the intersection between pathology and artificial intelligence / machine learning is fascinating. I wonder if it would be feasible to learn Groovy so I can write my own scripts? . Thanks again!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368345195
https://github.com/qupath/qupath/issues/146#issuecomment-368345195:1139,Usability,simpl,simply,1139,"Hi Pete:. Thanks so much for your helpful comments!. I am a veterinary pathologist working with novel immunotherapeutic approaches to cancer treatment. We use in situ hybridization extensively for target discovery and to identify target + cells within our xenograft models. In addition to measuring a reduction in xenograft size via calipers, I am interested to use QuPath to document a reduction in the number of ISH target + cells / unit area of the xenograft. It would be incredibly helpful to have a ""learn by example"" approach to speed the task. Maybe you would select ISH- stromal cells, ISH+ stromal cells, ISH- tumor cells and ISH+ tumor cells, etc. as annotations and then run the Classifier?. I am also involved in gene therapy experiments in which we are attempting to knock down mRNA expression in specific cell populations in vivo. I would like to use QuPath to identify the cell population using annotations, then measure the amount of ISH signal per cell in treated vs untreated animals. In this case, rather than eliminating the cells of interest, we are attempting to demonstrate a reduction in ISH signal per cell. Thus, simply designating cells as ""positive"" or ""negative"" will not suffice. Rather, using the script you wrote above would be helpful to show that you have a reduction of cells listed as 4+ and 3+ and an increase in cells listed as 0 or 1+. Alternatively, if you could calculate an ""H score"" based upon a 5-point scale (negative, 1+, 2+, 3+, 4+), that would be a great way to compare between groups. . I think the intersection between pathology and artificial intelligence / machine learning is fascinating. I wonder if it would be feasible to learn Groovy so I can write my own scripts? . Thanks again!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368345195
https://github.com/qupath/qupath/issues/146#issuecomment-368345195:1617,Usability,learn,learning,1617,"Hi Pete:. Thanks so much for your helpful comments!. I am a veterinary pathologist working with novel immunotherapeutic approaches to cancer treatment. We use in situ hybridization extensively for target discovery and to identify target + cells within our xenograft models. In addition to measuring a reduction in xenograft size via calipers, I am interested to use QuPath to document a reduction in the number of ISH target + cells / unit area of the xenograft. It would be incredibly helpful to have a ""learn by example"" approach to speed the task. Maybe you would select ISH- stromal cells, ISH+ stromal cells, ISH- tumor cells and ISH+ tumor cells, etc. as annotations and then run the Classifier?. I am also involved in gene therapy experiments in which we are attempting to knock down mRNA expression in specific cell populations in vivo. I would like to use QuPath to identify the cell population using annotations, then measure the amount of ISH signal per cell in treated vs untreated animals. In this case, rather than eliminating the cells of interest, we are attempting to demonstrate a reduction in ISH signal per cell. Thus, simply designating cells as ""positive"" or ""negative"" will not suffice. Rather, using the script you wrote above would be helpful to show that you have a reduction of cells listed as 4+ and 3+ and an increase in cells listed as 0 or 1+. Alternatively, if you could calculate an ""H score"" based upon a 5-point scale (negative, 1+, 2+, 3+, 4+), that would be a great way to compare between groups. . I think the intersection between pathology and artificial intelligence / machine learning is fascinating. I wonder if it would be feasible to learn Groovy so I can write my own scripts? . Thanks again!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368345195
https://github.com/qupath/qupath/issues/146#issuecomment-368345195:1678,Usability,learn,learn,1678,"Hi Pete:. Thanks so much for your helpful comments!. I am a veterinary pathologist working with novel immunotherapeutic approaches to cancer treatment. We use in situ hybridization extensively for target discovery and to identify target + cells within our xenograft models. In addition to measuring a reduction in xenograft size via calipers, I am interested to use QuPath to document a reduction in the number of ISH target + cells / unit area of the xenograft. It would be incredibly helpful to have a ""learn by example"" approach to speed the task. Maybe you would select ISH- stromal cells, ISH+ stromal cells, ISH- tumor cells and ISH+ tumor cells, etc. as annotations and then run the Classifier?. I am also involved in gene therapy experiments in which we are attempting to knock down mRNA expression in specific cell populations in vivo. I would like to use QuPath to identify the cell population using annotations, then measure the amount of ISH signal per cell in treated vs untreated animals. In this case, rather than eliminating the cells of interest, we are attempting to demonstrate a reduction in ISH signal per cell. Thus, simply designating cells as ""positive"" or ""negative"" will not suffice. Rather, using the script you wrote above would be helpful to show that you have a reduction of cells listed as 4+ and 3+ and an increase in cells listed as 0 or 1+. Alternatively, if you could calculate an ""H score"" based upon a 5-point scale (negative, 1+, 2+, 3+, 4+), that would be a great way to compare between groups. . I think the intersection between pathology and artificial intelligence / machine learning is fascinating. I wonder if it would be feasible to learn Groovy so I can write my own scripts? . Thanks again!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368345195
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:932,Deployability,update,update,932,"My experience with ISH makes me prefer straight measurement of estimated spot count versus using or creating H-scores. Sets of numbers representing+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:1540,Modifiability,variab,variables,1540,"esenting+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off all of the check boxes, lowering the min spot size, and make use of the clusters as all of those get combined into the Num spots estimated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:828,Safety,detect,detections,828,"My experience with ISH makes me prefer straight measurement of estimated spot count versus using or creating H-scores. Sets of numbers representing+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:1459,Safety,detect,detection,1459,"esenting+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off all of the check boxes, lowering the min spot size, and make use of the clusters as all of those get combined into the Num spots estimated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:1597,Usability,learn,learning,1597,"esenting+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off all of the check boxes, lowering the min spot size, and make use of the clusters as all of those get combined into the Num spots estimated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/146#issuecomment-368380554:1836,Usability,learn,learned,1836,"esenting+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off all of the check boxes, lowering the min spot size, and make use of the clusters as all of those get combined into the Num spots estimated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1025,Availability,error,error,1025,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1128,Availability,error,error,1128,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1305,Availability,error,errors,1305,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1134,Integrability,message,message,1134,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:154,Safety,detect,detection,154,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:576,Safety,detect,detection,576,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:830,Safety,detect,detection,830,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:927,Safety,detect,detection,927,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1255,Safety,detect,detection,1255,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1575,Safety,detect,detection,1575,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1038,Testability,log,log,1038,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1102,Testability,log,log,1102,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365346916:1383,Testability,log,log,1383,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916
https://github.com/qupath/qupath/issues/147#issuecomment-365446425:475,Safety,detect,detection,475,"Hi Svidro, ; thanks for your ideas. ; I discovered that I merged twice and now work with the first part. . selectAnnotations();; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getPathClass() == getPathClass(""NameOfClass"")}; mergeAnnotations(annotations). It does not change anything about the problem. ; Also the sleep time of 100 milliseconds does not help. . And I do not start celldetection immeadetly after merging. It comes much later. . The cell detection runs very well - as allways. They appear in the viewer and in the ""show detection results"". ; But not in the annotation results anymore AND not in the anntoations tab, where you can normally see the object count within an ROI/annotation. . I try to upload such an annotation qudata file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446425
https://github.com/qupath/qupath/issues/147#issuecomment-365446425:557,Safety,detect,detection,557,"Hi Svidro, ; thanks for your ideas. ; I discovered that I merged twice and now work with the first part. . selectAnnotations();; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getPathClass() == getPathClass(""NameOfClass"")}; mergeAnnotations(annotations). It does not change anything about the problem. ; Also the sleep time of 100 milliseconds does not help. . And I do not start celldetection immeadetly after merging. It comes much later. . The cell detection runs very well - as allways. They appear in the viewer and in the ""show detection results"". ; But not in the annotation results anymore AND not in the anntoations tab, where you can normally see the object count within an ROI/annotation. . I try to upload such an annotation qudata file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446425
https://github.com/qupath/qupath/issues/147#issuecomment-365446924:28,Testability,log,log,28,[Final_1-100_H211_HD_20x_19.log](https://github.com/qupath/qupath/files/1722146/Final_1-100_H211_HD_20x_19.log). I changed the .qudata into .log. ; Was that right?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446924
https://github.com/qupath/qupath/issues/147#issuecomment-365446924:107,Testability,log,log,107,[Final_1-100_H211_HD_20x_19.log](https://github.com/qupath/qupath/files/1722146/Final_1-100_H211_HD_20x_19.log). I changed the .qudata into .log. ; Was that right?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446924
https://github.com/qupath/qupath/issues/147#issuecomment-365446924:141,Testability,log,log,141,[Final_1-100_H211_HD_20x_19.log](https://github.com/qupath/qupath/files/1722146/Final_1-100_H211_HD_20x_19.log). I changed the .qudata into .log. ; Was that right?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446924
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:454,Deployability,update,update,454,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:889,Deployability,update,update,889,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:1160,Deployability,update,update-selected-annotation-groovy,1160,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:142,Performance,load,load,142,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:958,Safety,detect,detections,958,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365453095:983,Safety,detect,detections,983,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095
https://github.com/qupath/qupath/issues/147#issuecomment-365536462:592,Safety,detect,detection,592,"I don't think changing the extension of .qpdata files works here, and this may be the source of not being able to access it - would need to zip up the original file. But note that the cell count is never shown when an annotation is *classified* in that location in QuPath v0.1.2. It's also not an ideal place to get this number, because it is not actually a cell count but rather a count of the number of *direct child objects*. This should be the same as the cell count if there are no other objects (e.g. nested annotations), but otherwise it may not be. In my own QuPath fork I've added a detection count to the main built-in measurements for all annotations, which looks deeper through the hierarchy to get all cells - even if they are inside nested annotations. This works also for unclassified cells, but in v0.1.2 counts are only provided if the cells are classified. As a workaround in v0.1.2 you could set your cells to have any arbitrary class, e.g.; ```groovy; getCellObjects().each { it.setPathClass(getPathClass('My cell')) }; fireHierarchyUpdate(); ```; Then they should at least appear in any annotation measurement tables.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365536462
https://github.com/qupath/qupath/issues/147#issuecomment-365536462:114,Security,access,access,114,"I don't think changing the extension of .qpdata files works here, and this may be the source of not being able to access it - would need to zip up the original file. But note that the cell count is never shown when an annotation is *classified* in that location in QuPath v0.1.2. It's also not an ideal place to get this number, because it is not actually a cell count but rather a count of the number of *direct child objects*. This should be the same as the cell count if there are no other objects (e.g. nested annotations), but otherwise it may not be. In my own QuPath fork I've added a detection count to the main built-in measurements for all annotations, which looks deeper through the hierarchy to get all cells - even if they are inside nested annotations. This works also for unclassified cells, but in v0.1.2 counts are only provided if the cells are classified. As a workaround in v0.1.2 you could set your cells to have any arbitrary class, e.g.; ```groovy; getCellObjects().each { it.setPathClass(getPathClass('My cell')) }; fireHierarchyUpdate(); ```; Then they should at least appear in any annotation measurement tables.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365536462
https://github.com/qupath/qupath/issues/150#issuecomment-368320960:14,Security,access,access,14,"I'm afraid my access to systems running Linux is pretty limited, but I hope to give it a bit more attention in a few weeks... In the meantime, I'd suggest trying to build QuPath from source. You could try it from the main repo here (which [involves eclipse + Maven in a fairly cumbersome way](https://github.com/qupath/qupath/issues/84)), or from my fork [here](https://github.com/petebankhead/qupath). On my fork I've tried to greatly streamline the process of building the software using [Gradle](https://github.com/petebankhead/qupath#building-qupath-with-gradle), which should also make it easier to investigate the changes that may be necessary to get it to really work cross-platform. This might also help: https://github.com/qupath/qupath/issues/51",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368320960
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:107,Availability,error,errors,107,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:228,Availability,Error,Error,228,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:642,Availability,ERROR,ERROR,642,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2856,Availability,error,error,2856,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:3124,Availability,Error,Error,3124,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1397,Deployability,install,installExtension,1397,"read] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thr",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2571,Deployability,update,update,2571,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2862,Integrability,message,message,2862,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:576,Performance,cache,cache,576,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:691,Performance,load,load,691,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:955,Performance,load,load,955,"Thank you !; With Gradle the build ends properly despite some warnings and It ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Na",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1065,Performance,load,loadLibrary,1065," ran in a CentOS 7, with some errors, but it ran :. ```; $ QuPath; 13:20:05.914 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$17",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1176,Performance,load,loadLibrary,1176," - Launching QuPath with args: ; Prism-ES2 Error : GL_VERSION (major.minor) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1241,Performance,load,loadNativeLibrary,1241,"r) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2560,Performance,Perform,Performing,2560,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1960,Security,secur,security,1960,"ve Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1969,Security,Access,AccessController,1969,"at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size wi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2982,Security,Xss,Xss,2982,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650
https://github.com/qupath/qupath/issues/150#issuecomment-368859872:513,Deployability,install,install,513,"Ok, good, since it's building ok can you have a look for a `.jar` file inside QuPath starting `qupath-extension-openslide` and then move/rename it (so that QuPath won't find it)? My hope is this will prevent QuPath trying to load the troublesome library. You may not be able to open whole slide images then (although adding the [Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension) could work around that, at least for some formats). But if it at least starts ok then hopefully you could install OpenSlide with your package manager, and the problem changes to getting QuPath to find it whenever you put the `.jar` file back...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368859872
https://github.com/qupath/qupath/issues/150#issuecomment-368859872:225,Performance,load,load,225,"Ok, good, since it's building ok can you have a look for a `.jar` file inside QuPath starting `qupath-extension-openslide` and then move/rename it (so that QuPath won't find it)? My hope is this will prevent QuPath trying to load the troublesome library. You may not be able to open whole slide images then (although adding the [Bio-Formats extension](https://github.com/qupath/qupath-bioformats-extension) could work around that, at least for some formats). But if it at least starts ok then hopefully you could install OpenSlide with your package manager, and the problem changes to getting QuPath to find it whenever you put the `.jar` file back...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368859872
https://github.com/qupath/qupath/issues/150#issuecomment-368861735:41,Availability,error,error,41,"Well, clearly I didn't actually read the error message, sorry... looks like it's OpenCV and not OpenSlide that seems to be triggering the trouble.; Could you replace `openslide` with `opencv` in those last instructions...?. Or if you are feeling particularly bold you could also try switching to the `java9` branch on my fork, where I am trying out a different version of OpenCV - which might possibly avoid the problem entirely.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368861735
https://github.com/qupath/qupath/issues/150#issuecomment-368861735:47,Integrability,message,message,47,"Well, clearly I didn't actually read the error message, sorry... looks like it's OpenCV and not OpenSlide that seems to be triggering the trouble.; Could you replace `openslide` with `opencv` in those last instructions...?. Or if you are feeling particularly bold you could also try switching to the `java9` branch on my fork, where I am trying out a different version of OpenCV - which might possibly avoid the problem entirely.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368861735
https://github.com/qupath/qupath/issues/150#issuecomment-368861735:402,Safety,avoid,avoid,402,"Well, clearly I didn't actually read the error message, sorry... looks like it's OpenCV and not OpenSlide that seems to be triggering the trouble.; Could you replace `openslide` with `opencv` in those last instructions...?. Or if you are feeling particularly bold you could also try switching to the `java9` branch on my fork, where I am trying out a different version of OpenCV - which might possibly avoid the problem entirely.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368861735
https://github.com/qupath/qupath/issues/150#issuecomment-368861735:6,Usability,clear,clearly,6,"Well, clearly I didn't actually read the error message, sorry... looks like it's OpenCV and not OpenSlide that seems to be triggering the trouble.; Could you replace `openslide` with `opencv` in those last instructions...?. Or if you are feeling particularly bold you could also try switching to the `java9` branch on my fork, where I am trying out a different version of OpenCV - which might possibly avoid the problem entirely.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368861735
https://github.com/qupath/qupath/issues/150#issuecomment-368862255:205,Safety,detect,detection,205,"Basically, you can hide any jar that has `extension` in the name and QuPath should still work - it will just be missing whatever functionality the jar provided. In the OpenCV case, the main things are the detection classifiers and wand tool.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368862255
https://github.com/qupath/qupath/issues/150#issuecomment-370794394:38,Availability,error,error,38,"I tried to delete extensions, but the error remains.; It does not matter, the program works and seems to suit the user.; Thank you.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-370794394
https://github.com/qupath/qupath/issues/151#issuecomment-495996483:170,Testability,test,tested,170,as a workaround for 0.2.0-m2: try to replace app/libopenslide-0.dll with the appropriate libopenslide-0.dll file from https://github.com/Markus-PP/openslide-vmic. I have tested with my .vmic files and it seems to work,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/151#issuecomment-495996483
https://github.com/qupath/qupath/issues/153#issuecomment-370398858:87,Availability,error,error,87,"The title of this issue is issue looks quite dramatic, but I don't understand what the error is at all. Can you explain further? Was cell detection applied to a brightfield image with the image type set to 'Fluorescence'?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370398858
https://github.com/qupath/qupath/issues/153#issuecomment-370398858:138,Safety,detect,detection,138,"The title of this issue is issue looks quite dramatic, but I don't understand what the error is at all. Can you explain further? Was cell detection applied to a brightfield image with the image type set to 'Fluorescence'?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370398858
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:214,Availability,error,errors,214,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:312,Availability,error,errors,312,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:615,Deployability,update,updated,615,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:204,Safety,detect,detection,204,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:302,Safety,detect,detection,302,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:773,Safety,detect,detection,773,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:883,Safety,detect,detection,883,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370400288:56,Testability,log,log,56,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288
https://github.com/qupath/qupath/issues/153#issuecomment-370411000:142,Safety,detect,detections,142,"Also after switching to channel 1 it still happens. I can repeat the same script. Sometimes I get the right cell distribution, sometimes cell detections from other parts of the image are randomly copied to places where they do absolutely not fit to the behind image content. I could not find a pattern yet, that the phenomen might follow.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370411000
https://github.com/qupath/qupath/issues/154#issuecomment-371117298:18,Testability,test,tested,18,"I admit I haven't tested it, but I think I see the problem in the code [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core-processing-awt/src/main/java/qupath/lib/algorithms/IntensityFeaturesPlugin.java#L341). Basically, QuPath is looking for a parameter called `tileSizePx` when the actual name it should be looking for is `tileSizePixels`. I guess it was changed at some point in one place but not the other. If this is correct, then it *should* work if you have pixel size (µm) information in the image, but fail if you don't. That might also explain why it went unnoticed for a while. Does that match with what you see? If so it should be a relatively small fix in the code to make it work for images that lack pixel size information.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/154#issuecomment-371117298
https://github.com/qupath/qupath/issues/154#issuecomment-371119105:61,Availability,avail,available,61,"Hi Pete, ; yes indeed. It works if pixel size information is available. . I work with jpg´s without pixel size information at the moment. . Thank you for your explanation!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/154#issuecomment-371119105
https://github.com/qupath/qupath/issues/155#issuecomment-371256921:26,Integrability,depend,depending,26,"One reason I ask is that, depending upon the expected localization, there might be an argument for making the intensity measurements in a very small circular/rectangular region at the highest resolution, so as to make a measurement just around the cell centroid - not across the full region. The other reason is that I'm currently quite interested in adding the ability to detect different stains by providing sample colors - without any color deconvolution step. I'm not sure how relevant or helpful it would be here though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371256921
https://github.com/qupath/qupath/issues/155#issuecomment-371256921:373,Safety,detect,detect,373,"One reason I ask is that, depending upon the expected localization, there might be an argument for making the intensity measurements in a very small circular/rectangular region at the highest resolution, so as to make a measurement just around the cell centroid - not across the full region. The other reason is that I'm currently quite interested in adding the ability to detect different stains by providing sample colors - without any color deconvolution step. I'm not sure how relevant or helpful it would be here though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371256921
https://github.com/qupath/qupath/issues/155#issuecomment-371260102:238,Testability,test,testing,238,"Thanks Pete, I'll give that a shot. They're all cytoplasmic stains, without any expected overlapping (thankfully!). I have quite a few of these multiplexed whole slide images, I can share if you think they would be useful for development testing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371260102
https://github.com/qupath/qupath/issues/155#issuecomment-371327542:166,Energy Efficiency,Green,Green,166,"I've made some progress. After cell detection, I did _Analyze → Calculate features → Add intensity features (experimental)._, with a pixel size of 1 um. I chose Red, Green, and Blue, and Mean. Then the following code:. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Brown = PathClassFactory.getPathClass(""Brown""); def Red = PathClassFactory.getPathClass(""Red""); def Purple = PathClassFactory.getPathClass(""Purple""); def Teal = PathClassFactory.getPathClass(""Teal""). def rmean = ""ROI: 1.00 µm per pixel: Red: Mean""; def gmean = ""ROI: 1.00 µm per pixel: Green: Mean""; def bmean = ""ROI: 1.00 µm per pixel: Blue: Mean"". for (def cell :getCellObjects()) {; ; double r = cell.getMeasurementList().getMeasurementValue(rmean); double g = cell.getMeasurementList().getMeasurementValue(gmean); double b = cell.getMeasurementList().getMeasurementValue(bmean); ; if (isBrown(r,g,b)); cell.setPathClass(Brown). else if (isPurple(r,g,b)) ; cell.setPathClass(Purple). else if (isTeal(r,g,b)); cell.setPathClass(Teal). else if (isRed(r,g,b)) ; cell.setPathClass(Red). }; ```. the `isBrown()`, etc. functions just do some simple thresholding of the r,g,b values to decide what color a cell is stained. I'm still tweaking those functions, but it's working pretty well (white outlines are unclassified cells, the rest are outlined in the appropriate color):. ![5-plex snapshot](https://user-images.githubusercontent.com/3537118/37124548-9755fc06-221d-11e8-93c5-dc4f02dd68ac.png). I think this will work well enough for my application (we'll be presenting this data as a platform presentation at USCAP in Vancouver in a couple weeks, if anyone is interested in multiplex IHC).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371327542
https://github.com/qupath/qupath/issues/155#issuecomment-371327542:611,Energy Efficiency,Green,Green,611,"I've made some progress. After cell detection, I did _Analyze → Calculate features → Add intensity features (experimental)._, with a pixel size of 1 um. I chose Red, Green, and Blue, and Mean. Then the following code:. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Brown = PathClassFactory.getPathClass(""Brown""); def Red = PathClassFactory.getPathClass(""Red""); def Purple = PathClassFactory.getPathClass(""Purple""); def Teal = PathClassFactory.getPathClass(""Teal""). def rmean = ""ROI: 1.00 µm per pixel: Red: Mean""; def gmean = ""ROI: 1.00 µm per pixel: Green: Mean""; def bmean = ""ROI: 1.00 µm per pixel: Blue: Mean"". for (def cell :getCellObjects()) {; ; double r = cell.getMeasurementList().getMeasurementValue(rmean); double g = cell.getMeasurementList().getMeasurementValue(gmean); double b = cell.getMeasurementList().getMeasurementValue(bmean); ; if (isBrown(r,g,b)); cell.setPathClass(Brown). else if (isPurple(r,g,b)) ; cell.setPathClass(Purple). else if (isTeal(r,g,b)); cell.setPathClass(Teal). else if (isRed(r,g,b)) ; cell.setPathClass(Red). }; ```. the `isBrown()`, etc. functions just do some simple thresholding of the r,g,b values to decide what color a cell is stained. I'm still tweaking those functions, but it's working pretty well (white outlines are unclassified cells, the rest are outlined in the appropriate color):. ![5-plex snapshot](https://user-images.githubusercontent.com/3537118/37124548-9755fc06-221d-11e8-93c5-dc4f02dd68ac.png). I think this will work well enough for my application (we'll be presenting this data as a platform presentation at USCAP in Vancouver in a couple weeks, if anyone is interested in multiplex IHC).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371327542
https://github.com/qupath/qupath/issues/155#issuecomment-371327542:36,Safety,detect,detection,36,"I've made some progress. After cell detection, I did _Analyze → Calculate features → Add intensity features (experimental)._, with a pixel size of 1 um. I chose Red, Green, and Blue, and Mean. Then the following code:. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Brown = PathClassFactory.getPathClass(""Brown""); def Red = PathClassFactory.getPathClass(""Red""); def Purple = PathClassFactory.getPathClass(""Purple""); def Teal = PathClassFactory.getPathClass(""Teal""). def rmean = ""ROI: 1.00 µm per pixel: Red: Mean""; def gmean = ""ROI: 1.00 µm per pixel: Green: Mean""; def bmean = ""ROI: 1.00 µm per pixel: Blue: Mean"". for (def cell :getCellObjects()) {; ; double r = cell.getMeasurementList().getMeasurementValue(rmean); double g = cell.getMeasurementList().getMeasurementValue(gmean); double b = cell.getMeasurementList().getMeasurementValue(bmean); ; if (isBrown(r,g,b)); cell.setPathClass(Brown). else if (isPurple(r,g,b)) ; cell.setPathClass(Purple). else if (isTeal(r,g,b)); cell.setPathClass(Teal). else if (isRed(r,g,b)) ; cell.setPathClass(Red). }; ```. the `isBrown()`, etc. functions just do some simple thresholding of the r,g,b values to decide what color a cell is stained. I'm still tweaking those functions, but it's working pretty well (white outlines are unclassified cells, the rest are outlined in the appropriate color):. ![5-plex snapshot](https://user-images.githubusercontent.com/3537118/37124548-9755fc06-221d-11e8-93c5-dc4f02dd68ac.png). I think this will work well enough for my application (we'll be presenting this data as a platform presentation at USCAP in Vancouver in a couple weeks, if anyone is interested in multiplex IHC).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371327542
https://github.com/qupath/qupath/issues/155#issuecomment-371327542:1164,Usability,simpl,simple,1164,"I've made some progress. After cell detection, I did _Analyze → Calculate features → Add intensity features (experimental)._, with a pixel size of 1 um. I chose Red, Green, and Blue, and Mean. Then the following code:. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Brown = PathClassFactory.getPathClass(""Brown""); def Red = PathClassFactory.getPathClass(""Red""); def Purple = PathClassFactory.getPathClass(""Purple""); def Teal = PathClassFactory.getPathClass(""Teal""). def rmean = ""ROI: 1.00 µm per pixel: Red: Mean""; def gmean = ""ROI: 1.00 µm per pixel: Green: Mean""; def bmean = ""ROI: 1.00 µm per pixel: Blue: Mean"". for (def cell :getCellObjects()) {; ; double r = cell.getMeasurementList().getMeasurementValue(rmean); double g = cell.getMeasurementList().getMeasurementValue(gmean); double b = cell.getMeasurementList().getMeasurementValue(bmean); ; if (isBrown(r,g,b)); cell.setPathClass(Brown). else if (isPurple(r,g,b)) ; cell.setPathClass(Purple). else if (isTeal(r,g,b)); cell.setPathClass(Teal). else if (isRed(r,g,b)) ; cell.setPathClass(Red). }; ```. the `isBrown()`, etc. functions just do some simple thresholding of the r,g,b values to decide what color a cell is stained. I'm still tweaking those functions, but it's working pretty well (white outlines are unclassified cells, the rest are outlined in the appropriate color):. ![5-plex snapshot](https://user-images.githubusercontent.com/3537118/37124548-9755fc06-221d-11e8-93c5-dc4f02dd68ac.png). I think this will work well enough for my application (we'll be presenting this data as a platform presentation at USCAP in Vancouver in a couple weeks, if anyone is interested in multiplex IHC).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371327542
https://github.com/qupath/qupath/issues/155#issuecomment-617095912:122,Safety,detect,detection,122,"Hi, I have an image to analyse but do not have hematoxylin and wonder if I can do cell segmentation by using other colour detection? If yes then how can I change the script",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-617095912
https://github.com/qupath/qupath/issues/156#issuecomment-371739798:365,Deployability,install,installed,365,"QuPath can handle TIFF files much bigger than 1.49 GB. But it is important that they are stored in a pyramidal format, with the image data stored at different resolutions - as it typical if the images are from a whole slide scanner. Is that the case for your image? Or can you say more about how it was created?. If your image is pyramidal, and you haven't already installed the QuPath Bio-Formats extension, you could try this to see if it helps by increasing the range of supported images: https://github.com/qupath/qupath-bioformats-extension. > Note the installation instructions at the bottom of the page; if it does not work immediately, consider adding `.tif` to the *Always use Bio-Formats for the specified image extensions* preference option, to make sure that no other image reader tries to handle the TIFF instead. But if you do this and encounter problems with other TIFFs, remember to reset this option to let QuPath decide which reader is most appropriate - which is the default behavior. Otherwise, this link may help: https://github.com/openslide/openslide/wiki/CreatingPyramidalTIFFs",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371739798
https://github.com/qupath/qupath/issues/156#issuecomment-371739798:558,Deployability,install,installation,558,"QuPath can handle TIFF files much bigger than 1.49 GB. But it is important that they are stored in a pyramidal format, with the image data stored at different resolutions - as it typical if the images are from a whole slide scanner. Is that the case for your image? Or can you say more about how it was created?. If your image is pyramidal, and you haven't already installed the QuPath Bio-Formats extension, you could try this to see if it helps by increasing the range of supported images: https://github.com/qupath/qupath-bioformats-extension. > Note the installation instructions at the bottom of the page; if it does not work immediately, consider adding `.tif` to the *Always use Bio-Formats for the specified image extensions* preference option, to make sure that no other image reader tries to handle the TIFF instead. But if you do this and encounter problems with other TIFFs, remember to reset this option to let QuPath decide which reader is most appropriate - which is the default behavior. Otherwise, this link may help: https://github.com/openslide/openslide/wiki/CreatingPyramidalTIFFs",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371739798
https://github.com/qupath/qupath/issues/156#issuecomment-371740975:16,Availability,down,downloaded,16,"Thanks a lot. I downloaded tif from camelyon16 datasets. A single one is over 1GB. I have installed bioformats extension, but it seems cannot help. Should I need some format transformed? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371740975
https://github.com/qupath/qupath/issues/156#issuecomment-371740975:90,Deployability,install,installed,90,"Thanks a lot. I downloaded tif from camelyon16 datasets. A single one is over 1GB. I have installed bioformats extension, but it seems cannot help. Should I need some format transformed? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371740975
https://github.com/qupath/qupath/issues/156#issuecomment-371741529:124,Availability,error,error,124,"Ah ok, it should be a pyramidal TIFF then. Are you running QuPath on Linux, by any chance? Or what platform? Do you see any error message when you try, either popping up or under *View &rarr; Show log*?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371741529
https://github.com/qupath/qupath/issues/156#issuecomment-371741529:130,Integrability,message,message,130,"Ah ok, it should be a pyramidal TIFF then. Are you running QuPath on Linux, by any chance? Or what platform? Do you see any error message when you try, either popping up or under *View &rarr; Show log*?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371741529
https://github.com/qupath/qupath/issues/156#issuecomment-371741529:197,Testability,log,log,197,"Ah ok, it should be a pyramidal TIFF then. Are you running QuPath on Linux, by any chance? Or what platform? Do you see any error message when you try, either popping up or under *View &rarr; Show log*?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371741529
https://github.com/qupath/qupath/issues/156#issuecomment-371769693:379,Deployability,install,installing,379,"I can open Camelyon16 images with QuPath on macOS 10.13, Ubuntu 16.04 and Windows 10 (the last two through VirtualBox). So it definitely *should* work. I'd certainly like to find a way to resolve it since it doesn't. I didn't have any luck with Bio-Formats though - so that suggestion can be discarded. My best guess is that you're using Linux and the solution involves building/installing OpenSlide separately. You can then remove/replace any OpenSlide-related files from within the *qupath/app* directory. If you copy your own OpenSlide files into that directory then it should be ok; otherwise, you probably need to set the Java library path within *QuPath.cfg* (which is also in the same directory).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371769693
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:46,Availability,error,errors,46,"Hi, I test in Mac OS 10.13.3, I find log with errors:. ERROR: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif; at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:111); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at loci.formats.Memoizer.setId(Memoizer.java:677); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1156); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1111); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:1025); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:234); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:198); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:46); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:55,Availability,ERROR,ERROR,55,"Hi, I test in Mac OS 10.13.3, I find log with errors:. ERROR: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif; at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:111); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at loci.formats.Memoizer.setId(Memoizer.java:677); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1156); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1111); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:1025); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:234); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:198); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:46); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:9240,Availability,Error,Error,9240," at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:9702,Availability,ERROR,ERROR,9702,"n.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logb",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:9823,Availability,ERROR,ERROR,9823," com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logback-core-1.1.7.jar:jars/opencv-3.1.0.jar:jars/openslide-3.4.1_2.jar:jars/packager.jar:jars/reactfx",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:10954,Availability,ERROR,ERROR,10954,"ntHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logback-core-1.1.7.jar:jars/opencv-3.1.0.jar:jars/openslide-3.4.1_2.jar:jars/packager.jar:jars/reactfx-2.0-M4u1.jar:jars/richtextfx-0.6.10.jar:jars/slf4j-api-1.7.20.jar:jars/undofx-1.2.jar:jars/wellbehavedfx-0.1.1.jar:QuPathApp.jar; ERROR: Open image: Sorry, I can't open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif. Thank you for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:3844,Security,access,access,3844,com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); Caused by No such class: javax.media.jai.NullOpImage at loci.common.ReflectedUniverse.exec(ReflectedUniverse.java:161); at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:104); at loci.formats.FormatReader.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:4063,Security,secur,security,4063,patchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); Caused by No such class: javax.media.jai.NullOpImage at loci.common.ReflectedUniverse.exec(ReflectedUniverse.java:161); at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:104); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at ,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:4072,Security,Access,AccessController,4072,l.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); Caused by No such class: javax.media.jai.NullOpImage at loci.common.ReflectedUniverse.exec(ReflectedUniverse.java:161); at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:104); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at loci.formats.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:8441,Security,access,access,8441,com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:8660,Security,secur,security,8660,patchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not ,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:8669,Security,Access,AccessController,8669,l.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that O,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:6,Testability,test,test,6,"Hi, I test in Mac OS 10.13.3, I find log with errors:. ERROR: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif; at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:111); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at loci.formats.Memoizer.setId(Memoizer.java:677); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1156); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1111); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:1025); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:234); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:198); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:46); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:37,Testability,log,log,37,"Hi, I test in Mac OS 10.13.3, I find log with errors:. ERROR: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif; at loci.formats.in.TiffJAIReader.initFile(TiffJAIReader.java:111); at loci.formats.FormatReader.setId(FormatReader.java:1397); at loci.formats.DelegateReader.setId(DelegateReader.java:300); at loci.formats.ImageReader.setId(ImageReader.java:839); at loci.formats.ReaderWrapper.setId(ReaderWrapper.java:650); at loci.formats.Memoizer.setId(Memoizer.java:677); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1156); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1111); at qupath.lib.images.servers.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:1025); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:234); at qupath.lib.images.servers.BioFormatsImageServer.<init>(BioFormatsImageServer.java:198); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:46); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:10690,Testability,log,logback-classic-,10690,"ntHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logback-core-1.1.7.jar:jars/opencv-3.1.0.jar:jars/openslide-3.4.1_2.jar:jars/packager.jar:jars/reactfx-2.0-M4u1.jar:jars/richtextfx-0.6.10.jar:jars/slf4j-api-1.7.20.jar:jars/undofx-1.2.jar:jars/wellbehavedfx-0.1.1.jar:QuPathApp.jar; ERROR: Open image: Sorry, I can't open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif. Thank you for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:10721,Testability,log,logback-core-,10721,"ntHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logback-core-1.1.7.jar:jars/opencv-3.1.0.jar:jars/openslide-3.4.1_2.jar:jars/packager.jar:jars/reactfx-2.0-M4u1.jar:jars/richtextfx-0.6.10.jar:jars/slf4j-api-1.7.20.jar:jars/undofx-1.2.jar:jars/wellbehavedfx-0.1.1.jar:QuPathApp.jar; ERROR: Open image: Sorry, I can't open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif. Thank you for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371771791:10895,Usability,undo,undofx-,10895,"ntHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); WARN: Error opening /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ: Could not open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with ImageJ; WARN: Unable to open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif with OpenSlide: /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif: Not a file that OpenSlide can recognize; ERROR: Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, BioFormats); 	; ERROR: /Applications/QuPath.app/Contents/Java/QuPathApp.jar:qupath/qupath-core-0.1.2.jar:qupath/qupath-core-awt-0.1.2.jar:qupath/qupath-core-processing-0.1.2.jar:qupath/qupath-core-processing-awt-0.1.2.jar:qupath/qupath-extension-ij-0.1.2.jar:qupath/qupath-extension-input-0.1.2.jar:qupath/qupath-extension-opencv-0.1.2.jar:qupath/qupath-extension-openslide-0.1.2.jar:qupath/qupath-extension-pen-0.1.2.jar:qupath/qupath-extension-script-editor-0.1.2.jar:qupath/qupath-gui-fx-0.1.2.jar:qupath/qupath-processing-ij-0.1.2.jar:qupath/qupath-processing-opencv-0.1.2.jar:jars/commons-math3-3.6.1.jar:jars/controlsfx-8.40.12.jar:jars/flowless-0.4.5.jar:jars/groovy-2.4.7.jar:jars/groovy-jsr223-2.4.7.jar:jars/gson-2.8.0.jar:jars/ij-1.51g.jar:jars/jfxtras-common-8.0-r5.jar:jars/jfxtras-menu-8.0-r5.jar:jars/jinput-2.0.6.jar:jars/jpen-2-150301.jar:jars/jutils-1.0.0.jar:jars/logback-classic-1.1.7.jar:jars/logback-core-1.1.7.jar:jars/opencv-3.1.0.jar:jars/openslide-3.4.1_2.jar:jars/packager.jar:jars/reactfx-2.0-M4u1.jar:jars/richtextfx-0.6.10.jar:jars/slf4j-api-1.7.20.jar:jars/undofx-1.2.jar:jars/wellbehavedfx-0.1.1.jar:QuPathApp.jar; ERROR: Open image: Sorry, I can't open /Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif. Thank you for your help!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371771791
https://github.com/qupath/qupath/issues/156#issuecomment-371778042:282,Availability,avail,available,282,"Ah, my best guess was wrong. But now that I know the image, I have tried it out... and it opens for me on my Mac, also 10.13.3, without problems (using OpenSlide). Do all .tif whole slide images fail for you in QuPath? Do any other formats work (e.g. SVS or NDPI - there are freely available test images on the OpenSlide website)?. A lot of that error message comes from the failed Bio-Formats attempt - you might want to remove or disable it since it didn't solve the problem. But the log shows that OpenSlide was also tried without success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371778042
https://github.com/qupath/qupath/issues/156#issuecomment-371778042:346,Availability,error,error,346,"Ah, my best guess was wrong. But now that I know the image, I have tried it out... and it opens for me on my Mac, also 10.13.3, without problems (using OpenSlide). Do all .tif whole slide images fail for you in QuPath? Do any other formats work (e.g. SVS or NDPI - there are freely available test images on the OpenSlide website)?. A lot of that error message comes from the failed Bio-Formats attempt - you might want to remove or disable it since it didn't solve the problem. But the log shows that OpenSlide was also tried without success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371778042
https://github.com/qupath/qupath/issues/156#issuecomment-371778042:352,Integrability,message,message,352,"Ah, my best guess was wrong. But now that I know the image, I have tried it out... and it opens for me on my Mac, also 10.13.3, without problems (using OpenSlide). Do all .tif whole slide images fail for you in QuPath? Do any other formats work (e.g. SVS or NDPI - there are freely available test images on the OpenSlide website)?. A lot of that error message comes from the failed Bio-Formats attempt - you might want to remove or disable it since it didn't solve the problem. But the log shows that OpenSlide was also tried without success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371778042
https://github.com/qupath/qupath/issues/156#issuecomment-371778042:292,Testability,test,test,292,"Ah, my best guess was wrong. But now that I know the image, I have tried it out... and it opens for me on my Mac, also 10.13.3, without problems (using OpenSlide). Do all .tif whole slide images fail for you in QuPath? Do any other formats work (e.g. SVS or NDPI - there are freely available test images on the OpenSlide website)?. A lot of that error message comes from the failed Bio-Formats attempt - you might want to remove or disable it since it didn't solve the problem. But the log shows that OpenSlide was also tried without success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371778042
https://github.com/qupath/qupath/issues/156#issuecomment-371778042:486,Testability,log,log,486,"Ah, my best guess was wrong. But now that I know the image, I have tried it out... and it opens for me on my Mac, also 10.13.3, without problems (using OpenSlide). Do all .tif whole slide images fail for you in QuPath? Do any other formats work (e.g. SVS or NDPI - there are freely available test images on the OpenSlide website)?. A lot of that error message comes from the failed Bio-Formats attempt - you might want to remove or disable it since it didn't solve the problem. But the log shows that OpenSlide was also tried without success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371778042
https://github.com/qupath/qupath/issues/156#issuecomment-371779995:150,Modifiability,plugin,plugins,150,"<img width=""706"" alt=""default"" src=""https://user-images.githubusercontent.com/3804756/37204061-c24f1e3e-23ca-11e8-92ed-3b5005c2e443.png"">. this is my plugins",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371779995
https://github.com/qupath/qupath/issues/156#issuecomment-371780923:218,Deployability,install,installed,218,"Under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? It might be using Bio-Formats or something else. I'm curious as to whether OpenSlide is working for you at all. Also, if you have OpenSlide installed some other way (e.g. with Python), can it read the file?. I know there can also be trouble if there are any non-English characters in the path to the file, but it doesn't look like the case from the log.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371780923
https://github.com/qupath/qupath/issues/156#issuecomment-371780923:427,Testability,log,log,427,"Under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? It might be using Bio-Formats or something else. I'm curious as to whether OpenSlide is working for you at all. Also, if you have OpenSlide installed some other way (e.g. with Python), can it read the file?. I know there can also be trouble if there are any non-English characters in the path to the file, but it doesn't look like the case from the log.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371780923
https://github.com/qupath/qupath/issues/156#issuecomment-371784054:32,Deployability,install,install,32,"OK when QuPath failed, I try to install Openslide independently, becauses my project needs. I have installed openslide in \usr\local\Celluar. and openslide python interface by Anaconda in /anaconda/lib/python36. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371784054
https://github.com/qupath/qupath/issues/156#issuecomment-371784054:99,Deployability,install,installed,99,"OK when QuPath failed, I try to install Openslide independently, becauses my project needs. I have installed openslide in \usr\local\Celluar. and openslide python interface by Anaconda in /anaconda/lib/python36. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371784054
https://github.com/qupath/qupath/issues/156#issuecomment-371784054:163,Integrability,interface,interface,163,"OK when QuPath failed, I try to install Openslide independently, becauses my project needs. I have installed openslide in \usr\local\Celluar. and openslide python interface by Anaconda in /anaconda/lib/python36. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371784054
https://github.com/qupath/qupath/issues/156#issuecomment-371846805:95,Modifiability,plugin,plugin,95,"supplement : it seems the size problem, i can open tif with 120MB but 1.4G can not. Problem of plugin?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371846805
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:89,Availability,avail,available,89,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:799,Deployability,install,installation,799,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:191,Energy Efficiency,monitor,monitor,191,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:277,Energy Efficiency,monitor,monitor,277,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:295,Testability,log,log,295,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371850256:356,Usability,clear,clear,356,"It shouldn't be file size. Under *Help &rarr; Show setup options* I can restrict the RAM available to QUPath to 1GB and can still open the image without problems. You can also try the memory monitor from https://petebankhead.github.io/qupath/scripting/2018/03/06/script-memory-monitor.html. The log says `Not a file that OpenSlide can recognize`. It's not clear to me if *any* images are working for you using OpenSlide. I asked above: under the *Image* tab does it say *OpenSlide* beside the entry *Server type*? If you see that for any images, then we can conclude that OpenSlide is (at least partially) working. But if you always see *ImageJ server* or *Bio-Formats server*, then it probably isn't and that's the problem that needs to be solved. In that case, it would help to know if a separate installation of OpenSlide on your machine can read the image at all through any means.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371850256
https://github.com/qupath/qupath/issues/156#issuecomment-371990019:78,Availability,error,errors,78,"Hi, I tried to use openslide to show Tumor_005.tif 1.49G in command line, and errors:. OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/Tumor_005.tif'); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda/lib/python3.6/site-packages/openslide/__init__.py"", line 154, in __init__; self._osr = lowlevel.open(filename); File ""/anaconda/lib/python3.6/site-packages/openslide/lowlevel.py"", line 174, in _check_open; ""Unsupported or missing image file""); openslide.lowlevel.OpenSlideUnsupportedFormatError: Unsupported or missing image file; ; It is very strange and seems opensilde cannot work in my macbook",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371990019
https://github.com/qupath/qupath/issues/156#issuecomment-371990304:11,Testability,test,test,11,But with a test.svs 1.8M it works strange!!!; OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'); OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371990304
https://github.com/qupath/qupath/issues/156#issuecomment-371990304:125,Testability,test,test,125,But with a test.svs 1.8M it works strange!!!; OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'); OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371990304
https://github.com/qupath/qupath/issues/156#issuecomment-371990304:216,Testability,test,test,216,But with a test.svs 1.8M it works strange!!!; OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'); OpenSlide('/Users/dzf/camelyon16-grand-challenge/data/TrainingData/Train_Tumor/test.svs'),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/156#issuecomment-371990304
https://github.com/qupath/qupath/issues/157#issuecomment-372155003:355,Safety,Detect,Detecting-objects,355,"If you upload a sample slide I could probably generate a sample script... but from the image it seems like either _Analyze->Region Identification->Positive Pixel Count_ within an annotation (you might try searching https://groups.google.com/forum/#!forum/qupath-users), or _Analyze-> Cell Analysis-> Cell Detection_ (https://github.com/qupath/qupath/wiki/Detecting-objects) with Optical Density chosen instead of Hematoxylin should give decent results. SLICs might also give you a simple way to detect area, and then if you add more measurements to them (Add Intensity Measurements) relating to texture (Haralick, etc) you might be able to automatically distinguish between tumor and stroma. If you want to play around with that, it's also under _Region Identification->Tiles and Superpixels_. https://github.com/qupath/qupath/issues/121 has an example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372155003
https://github.com/qupath/qupath/issues/157#issuecomment-372155003:495,Safety,detect,detect,495,"If you upload a sample slide I could probably generate a sample script... but from the image it seems like either _Analyze->Region Identification->Positive Pixel Count_ within an annotation (you might try searching https://groups.google.com/forum/#!forum/qupath-users), or _Analyze-> Cell Analysis-> Cell Detection_ (https://github.com/qupath/qupath/wiki/Detecting-objects) with Optical Density chosen instead of Hematoxylin should give decent results. SLICs might also give you a simple way to detect area, and then if you add more measurements to them (Add Intensity Measurements) relating to texture (Haralick, etc) you might be able to automatically distinguish between tumor and stroma. If you want to play around with that, it's also under _Region Identification->Tiles and Superpixels_. https://github.com/qupath/qupath/issues/121 has an example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372155003
https://github.com/qupath/qupath/issues/157#issuecomment-372155003:481,Usability,simpl,simple,481,"If you upload a sample slide I could probably generate a sample script... but from the image it seems like either _Analyze->Region Identification->Positive Pixel Count_ within an annotation (you might try searching https://groups.google.com/forum/#!forum/qupath-users), or _Analyze-> Cell Analysis-> Cell Detection_ (https://github.com/qupath/qupath/wiki/Detecting-objects) with Optical Density chosen instead of Hematoxylin should give decent results. SLICs might also give you a simple way to detect area, and then if you add more measurements to them (Add Intensity Measurements) relating to texture (Haralick, etc) you might be able to automatically distinguish between tumor and stroma. If you want to play around with that, it's also under _Region Identification->Tiles and Superpixels_. https://github.com/qupath/qupath/issues/121 has an example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372155003
https://github.com/qupath/qupath/issues/157#issuecomment-372454094:80,Testability,test,test,80,"Hi!; Sorry for the delay.; Here is the link (huge, 7.3 gb); http://pathology.ee/test/slide.scn; One of my slides (Leica). Quite good example, has positive and negative areas and a damaged area (no need to measure it).; I was trying to solve the problem using Your advice, but still no results.; If You ll be able to help me, I d be very grateful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372454094
https://github.com/qupath/qupath/issues/157#issuecomment-372679831:63,Availability,down,download,63,"Sounds good, but I have been a bit busy here, just started the download now, and probably won't be back to take a look at it for ~12 hrs. Should be able to have a look at it then.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372679831
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:619,Availability,down,downsampleFactor,619,"So I took a quick run at it, and came up with a few options.; First off, due to your somewhat off-white background, I would definitely use something like:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAn",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:1177,Energy Efficiency,adapt,adaptRegularization,1177,"s('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:3050,Integrability,depend,depends,3050," ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.com/23145209/37378645-52636d20-26ed-11e8-88ac-5401852cb5bc.png). It really depends on what exactly you are interested in measuring.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:1177,Modifiability,adapt,adaptRegularization,1177,"s('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:577,Safety,detect,detect,577,"So I took a quick run at it, and came up with a few options.; First off, due to your somewhat off-white background, I would definitely use something like:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAn",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:1960,Safety,detect,detection,1960," Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.co",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:2040,Safety,detect,detect,2040,"agej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.com/23145209/37378645-52636d20-26ed-11e8-88ac-5401852cb5bc.png). It r",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:2081,Safety,detect,detectionImageBrightfield,2081," ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.com/23145209/37378645-52636d20-26ed-11e8-88ac-5401852cb5bc.png). It really depends on what exactly you are interested in measuring.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-372875465:491,Testability,test,tested,491,"So I took a quick run at it, and came up with a few options.; First off, due to your somewhat off-white background, I would definitely use something like:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAn",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465
https://github.com/qupath/qupath/issues/157#issuecomment-373134413:406,Integrability,depend,depending,406,"WOW!; Thanks for the great answer!; Unfortunately I am not currently at home; I was only able to test it on my notebook, which sometimes crashes.; Still, thanks to You I got a very good result:; https://i.imgur.com/3eaQ7s1.jpg; All the positive areas are detected and the % of positive staining in selected area is also calculated (the main idea is to show that the expression of positive staining changes depending on the cancers grade).; I will only be able to take an adequate try in a couple of days.; Anyway, I am very grateful!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373134413
https://github.com/qupath/qupath/issues/157#issuecomment-373134413:255,Safety,detect,detected,255,"WOW!; Thanks for the great answer!; Unfortunately I am not currently at home; I was only able to test it on my notebook, which sometimes crashes.; Still, thanks to You I got a very good result:; https://i.imgur.com/3eaQ7s1.jpg; All the positive areas are detected and the % of positive staining in selected area is also calculated (the main idea is to show that the expression of positive staining changes depending on the cancers grade).; I will only be able to take an adequate try in a couple of days.; Anyway, I am very grateful!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373134413
https://github.com/qupath/qupath/issues/157#issuecomment-373134413:97,Testability,test,test,97,"WOW!; Thanks for the great answer!; Unfortunately I am not currently at home; I was only able to test it on my notebook, which sometimes crashes.; Still, thanks to You I got a very good result:; https://i.imgur.com/3eaQ7s1.jpg; All the positive areas are detected and the % of positive staining in selected area is also calculated (the main idea is to show that the expression of positive staining changes depending on the cancers grade).; I will only be able to take an adequate try in a couple of days.; Anyway, I am very grateful!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373134413
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:720,Integrability,depend,depending,720,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:122,Safety,detect,detection,122,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:265,Safety,detect,detection,265,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:360,Safety,detect,detection,360,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:815,Safety,detect,detection,815,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373141585:432,Security,access,access,432,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585
https://github.com/qupath/qupath/issues/157#issuecomment-373143331:94,Safety,Detect,Detections,94,> might be the D or H key?. It's 'H' for 'Hide' :); But I've been tempted to make it 'D' for 'Detections'... [List of shortcut keys](https://github.com/qupath/qupath/wiki/Shortcut-keys),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373143331
https://github.com/qupath/qupath/issues/157#issuecomment-374020816:43,Testability,test,test,43,"Well, as promised; I had an opportunity to test Your script on a bigger amount of glasses.; It seems that everything is fine; I will now start a new project with a new staining, probably ~100 glasses, with analytics fully based on QuPath; Still need to understand, how to analyse stroma in H&E staining :); But anyway, I am really grateful for Your advice. If ill be able to publish my results, I will let You know!; I`ll close this topic as the solution was found.; UPD not closing yet, let it be a couple of days :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374020816
https://github.com/qupath/qupath/issues/157#issuecomment-374022361:284,Performance,perform,perform,284,"If you are looking at H&E, I usually found it best to divide up the tissue; using superpixels, add texture and color measurements, then classify based; on the measurements. Once your areas are classified, there is a command to merge them all into; new annotations, which you can then perform Positive pixel or Cell; detection on. A combination of two of the steps described above. On Mar 18, 2018 10:36 AM, ""geodza"" <notifications@github.com> wrote:. > Well, as promised; > I had an opportunity to test Your script on a bigger amount of glasses.; > It seems that everything is fine; > I will now start a new project with a new staining, probably ~100 glasses,; > with analytics fully based on QuPath; > Still need to understand, how to analyse stroma in H&E staining :); > But anyway, I am really grateful for Your advice. If ill be able to; > publish my results, I will let You know!; > I`ll close this topic as the solution was found.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/157#issuecomment-374020816>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-UInIm1YbnApmIKVlfq9PPDSVpZfks5tfpsjgaJpZM4Sl4d_>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374022361
https://github.com/qupath/qupath/issues/157#issuecomment-374022361:316,Safety,detect,detection,316,"If you are looking at H&E, I usually found it best to divide up the tissue; using superpixels, add texture and color measurements, then classify based; on the measurements. Once your areas are classified, there is a command to merge them all into; new annotations, which you can then perform Positive pixel or Cell; detection on. A combination of two of the steps described above. On Mar 18, 2018 10:36 AM, ""geodza"" <notifications@github.com> wrote:. > Well, as promised; > I had an opportunity to test Your script on a bigger amount of glasses.; > It seems that everything is fine; > I will now start a new project with a new staining, probably ~100 glasses,; > with analytics fully based on QuPath; > Still need to understand, how to analyse stroma in H&E staining :); > But anyway, I am really grateful for Your advice. If ill be able to; > publish my results, I will let You know!; > I`ll close this topic as the solution was found.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/157#issuecomment-374020816>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-UInIm1YbnApmIKVlfq9PPDSVpZfks5tfpsjgaJpZM4Sl4d_>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374022361
https://github.com/qupath/qupath/issues/157#issuecomment-374022361:498,Testability,test,test,498,"If you are looking at H&E, I usually found it best to divide up the tissue; using superpixels, add texture and color measurements, then classify based; on the measurements. Once your areas are classified, there is a command to merge them all into; new annotations, which you can then perform Positive pixel or Cell; detection on. A combination of two of the steps described above. On Mar 18, 2018 10:36 AM, ""geodza"" <notifications@github.com> wrote:. > Well, as promised; > I had an opportunity to test Your script on a bigger amount of glasses.; > It seems that everything is fine; > I will now start a new project with a new staining, probably ~100 glasses,; > with analytics fully based on QuPath; > Still need to understand, how to analyse stroma in H&E staining :); > But anyway, I am really grateful for Your advice. If ill be able to; > publish my results, I will let You know!; > I`ll close this topic as the solution was found.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/157#issuecomment-374020816>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-UInIm1YbnApmIKVlfq9PPDSVpZfks5tfpsjgaJpZM4Sl4d_>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374022361
https://github.com/qupath/qupath/issues/157#issuecomment-374023479:122,Usability,learn,learn,122,"Thanks for the advice!; I will firstly start with immunohistochemistry; the H&E step will be in a month or two. I hope to learn QuPath more fluently during this time, but I am almost sure this was not the last scream for help I post on Your forum :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374023479
https://github.com/qupath/qupath/issues/157#issuecomment-374036497:280,Usability,learn,learn,280,"Well, Pete's forum, really! I am just a user that really enjoys this; stuff. :). On Mar 18, 2018 10:56 AM, ""geodza"" <notifications@github.com> wrote:. > Thanks for the advice!; > I will firstly start with immunohistochemistry; the H&E step will be in a; > month or two. I hope to learn QuPath more fluently during this time, but I; > am almost sure this was not the last scream for help I post on Your forum :); >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/157#issuecomment-374023479>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-bKNly9QrF-G4kkz87cALU9U6BG3ks5tfp_bgaJpZM4Sl4d_>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374036497
https://github.com/qupath/qupath/issues/157#issuecomment-374165232:279,Availability,down,down,279,"Everyone's forum :). You might want to check out [this new blog post](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html) describing how to try out lots of new QuPath improvements early. Especially check out the bit about *Positive pixel count* (about half-way down the page), which describes now & improved outputs that the command can give.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374165232
https://github.com/qupath/qupath/issues/157#issuecomment-374165232:126,Deployability,update,updates,126,"Everyone's forum :). You might want to check out [this new blog post](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html) describing how to try out lots of new QuPath improvements early. Especially check out the bit about *Positive pixel count* (about half-way down the page), which describes now & improved outputs that the command can give.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374165232
https://github.com/qupath/qupath/issues/158#issuecomment-373683258:851,Availability,avail,available,851,"You need an instance of [`PathClass`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/objects/classes/PathClass.java). *But*, you should never call the construction for `PathClass` directly. There is some explanation [here](https://groups.google.com/d/msg/qupath-users/44HBd-5nbaQ/VHbENs9TBAAJ). Something like this should work:; ```groovy; def tumor = getPathClass('Tumor'); def stroma = getPathClass('Stroma'); getAnnotationObjects().eachWithIndex { annotation , i ->; if (i % 2 == 0); annotation.setPathClass(tumor); else; annotation.setPathClass(stroma); }; fireHierarchyUpdate(); ```; But you can change the text to be whatever you want, rather than `Tumor` and `Stroma` (although probably best to avoid colons`:` in any name, since these are typically used to separate *sub*-classifications). Regarding finding available methods, I've just added a [blog post](https://petebankhead.github.io/qupath/scripting/2018/03/16/script-print-methods-and-fields.html) with a bit more info. If you are happy to use IntelliJ, that's probably easiest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-373683258
https://github.com/qupath/qupath/issues/158#issuecomment-373683258:737,Safety,avoid,avoid,737,"You need an instance of [`PathClass`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/objects/classes/PathClass.java). *But*, you should never call the construction for `PathClass` directly. There is some explanation [here](https://groups.google.com/d/msg/qupath-users/44HBd-5nbaQ/VHbENs9TBAAJ). Something like this should work:; ```groovy; def tumor = getPathClass('Tumor'); def stroma = getPathClass('Stroma'); getAnnotationObjects().eachWithIndex { annotation , i ->; if (i % 2 == 0); annotation.setPathClass(tumor); else; annotation.setPathClass(stroma); }; fireHierarchyUpdate(); ```; But you can change the text to be whatever you want, rather than `Tumor` and `Stroma` (although probably best to avoid colons`:` in any name, since these are typically used to separate *sub*-classifications). Regarding finding available methods, I've just added a [blog post](https://petebankhead.github.io/qupath/scripting/2018/03/16/script-print-methods-and-fields.html) with a bit more info. If you are happy to use IntelliJ, that's probably easiest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-373683258
https://github.com/qupath/qupath/issues/158#issuecomment-376154987:58,Safety,avoid,avoid,58,"Potentially, with a bit of effort. It's easier if you can avoid needing to handle mouse clicks etc., and don't mind simply placing the circle at the center of the current field of view. You can always then move it afterwards if you need to refine the position manually, using the existing *Move* tool. A similar processing for creating a rectangle is described on [this blog post](https://petebankhead.github.io/qupath/scripting/2018/03/09/script-create-fixed-size-region.html). `RectangleROI` appears twice in that script. If you just replace it with `EllipseROI` in both places it should do the job (and of course change the `PathClass` bit if you want). The `sizeMicrons` value specified in the script should correspond to the diameter.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-376154987
https://github.com/qupath/qupath/issues/158#issuecomment-376154987:116,Usability,simpl,simply,116,"Potentially, with a bit of effort. It's easier if you can avoid needing to handle mouse clicks etc., and don't mind simply placing the circle at the center of the current field of view. You can always then move it afterwards if you need to refine the position manually, using the existing *Move* tool. A similar processing for creating a rectangle is described on [this blog post](https://petebankhead.github.io/qupath/scripting/2018/03/09/script-create-fixed-size-region.html). `RectangleROI` appears twice in that script. If you just replace it with `EllipseROI` in both places it should do the job (and of course change the `PathClass` bit if you want). The `sizeMicrons` value specified in the script should correspond to the diameter.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-376154987
https://github.com/qupath/qupath/issues/159#issuecomment-375386261:921,Integrability,depend,depending,921,"I may have to wait until I get home for this to actually work correctly, or Pete can fix it, but mostly you want to change the way you choose the objects you get, since I don't know if you have several annotations, or one giant merged annotation. A script from a while back here: https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-cell-summary-measurements-to-annotation-groovy; Shows how to add the sum of the positive areas to the annotation, though I don't recall at the moment how to access the annotation's area in a script. I'm sure I have done it before, but most of my QuPath stuff is at home (~8 hours from now). All you would need at the end of this script (within each annotation loop) is to divide your new value by the total area and multiply by 100, if desired. Be very careful doing this, however, as little things like your cell expansion radius can have a dramatic effect on this value depending on the density of your cells! And sometimes depending on the perimeter of your annotation as the cells can stretch outside of your annotation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/159#issuecomment-375386261
https://github.com/qupath/qupath/issues/159#issuecomment-375386261:975,Integrability,depend,depending,975,"I may have to wait until I get home for this to actually work correctly, or Pete can fix it, but mostly you want to change the way you choose the objects you get, since I don't know if you have several annotations, or one giant merged annotation. A script from a while back here: https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-cell-summary-measurements-to-annotation-groovy; Shows how to add the sum of the positive areas to the annotation, though I don't recall at the moment how to access the annotation's area in a script. I'm sure I have done it before, but most of my QuPath stuff is at home (~8 hours from now). All you would need at the end of this script (within each annotation loop) is to divide your new value by the total area and multiply by 100, if desired. Be very careful doing this, however, as little things like your cell expansion radius can have a dramatic effect on this value depending on the density of your cells! And sometimes depending on the perimeter of your annotation as the cells can stretch outside of your annotation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/159#issuecomment-375386261
https://github.com/qupath/qupath/issues/159#issuecomment-375386261:506,Security,access,access,506,"I may have to wait until I get home for this to actually work correctly, or Pete can fix it, but mostly you want to change the way you choose the objects you get, since I don't know if you have several annotations, or one giant merged annotation. A script from a while back here: https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-cell-summary-measurements-to-annotation-groovy; Shows how to add the sum of the positive areas to the annotation, though I don't recall at the moment how to access the annotation's area in a script. I'm sure I have done it before, but most of my QuPath stuff is at home (~8 hours from now). All you would need at the end of this script (within each annotation loop) is to divide your new value by the total area and multiply by 100, if desired. Be very careful doing this, however, as little things like your cell expansion radius can have a dramatic effect on this value depending on the density of your cells! And sometimes depending on the perimeter of your annotation as the cells can stretch outside of your annotation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/159#issuecomment-375386261
https://github.com/qupath/qupath/issues/159#issuecomment-375472432:656,Integrability,depend,depending,656,"I had a little bit of time and think I have it figured out... ```; //In this case, it will add the total area taken up by Positive class cells within each annotation to their parent; //annotation as ""Positive Area"". import qupath.lib.objects.PathCellObject. hierarchy = getCurrentHierarchy(). for (annotation in getAnnotationObjects()){; //Block 1; def positiveCells = hierarchy.getDescendantObjects(annotation,null, PathCellObject).findAll{it.getPathClass() == getPathClass(""Positive"")}; double totalArea = 0; for (def cell in positiveCells){; totalArea += cell.getMeasurementList().getMeasurementValue(""Cell: Area""); }; //Comment the following in or out depending on whether you want to see the output; //println(""Mean area for Positive is: "" + totalArea/positiveCells.size); //println(""Total Positive Area is: "" + totalArea); ; //Add the total as ""Positive Area"" to each annotation.; annotation.getMeasurementList().putMeasurement(""Positive Area"", totalArea); def annotationArea = annotation.getROI().getArea(); annotation.getMeasurementList().putMeasurement(""Positive Area %"", totalArea/annotationArea*100); //Block 2 - add as many blocks as you have classes; //repeat above; }; ```. Just change all instances of Positive to your class, and duplicate as many times as you want within the annotation loop.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/159#issuecomment-375472432
https://github.com/qupath/qupath/issues/160#issuecomment-375334835:357,Availability,error,error,357,"I know there are some updates to how OpenCV operates with the newest version of QuPath. Are you running that one or the older 1.2? (I don't know that it is entirely official yet, but you can find it here https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). I don't have anything immediately useful, just wanting to check which version the error is happening in!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375334835
https://github.com/qupath/qupath/issues/160#issuecomment-375334835:22,Deployability,update,updates,22,"I know there are some updates to how OpenCV operates with the newest version of QuPath. Are you running that one or the older 1.2? (I don't know that it is entirely official yet, but you can find it here https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). I don't have anything immediately useful, just wanting to check which version the error is happening in!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375334835
https://github.com/qupath/qupath/issues/160#issuecomment-375334835:260,Deployability,update,updates,260,"I know there are some updates to how OpenCV operates with the newest version of QuPath. Are you running that one or the older 1.2? (I don't know that it is entirely official yet, but you can find it here https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). I don't have anything immediately useful, just wanting to check which version the error is happening in!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375334835
https://github.com/qupath/qupath/issues/160#issuecomment-375339965:255,Availability,avail,available,255,"I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that *might* affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the `.qpclassifier` file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the [QuPath user forum on Google Groups](https://groups.google.com/forum/#!forum/qupath-users) I can contact you directly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375339965
https://github.com/qupath/qupath/issues/160#issuecomment-375339965:149,Deployability,update,updates,149,"I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that *might* affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the `.qpclassifier` file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the [QuPath user forum on Google Groups](https://groups.google.com/forum/#!forum/qupath-users) I can contact you directly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375339965
https://github.com/qupath/qupath/issues/160#issuecomment-375339965:217,Deployability,update,updates,217,"I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that *might* affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the `.qpclassifier` file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the [QuPath user forum on Google Groups](https://groups.google.com/forum/#!forum/qupath-users) I can contact you directly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375339965
https://github.com/qupath/qupath/issues/160#issuecomment-375345642:509,Availability,error,error,509,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642
https://github.com/qupath/qupath/issues/160#issuecomment-375345642:515,Integrability,message,message,515,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642
https://github.com/qupath/qupath/issues/160#issuecomment-375345642:189,Performance,load,loading,189,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642
https://github.com/qupath/qupath/issues/160#issuecomment-375345642:407,Performance,load,loading,407,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642
https://github.com/qupath/qupath/issues/160#issuecomment-375345642:641,Security,secur,security,641,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642
https://github.com/qupath/qupath/issues/160#issuecomment-375346429:318,Availability,error,error,318,"Hi Pete,. I’ve attached the classifier file. Thanks very much for your help,. Cam. From: Pete [mailto:notifications@github.com]; Sent: 22 March 2018 15:07; To: qupath/qupath <qupath@noreply.github.com>; Cc: Camilla Coulson-Gilmer <>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] loading classifier error (#160). I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that might affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the .qpclassifier file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the QuPath user forum on Google Groups<https://groups.google.com/forum/#!forum/qupath-users> I can contact you directly. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/160#issuecomment-375339965>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj60nFu_XkbrWH1Xr6vaENeGtItS4XCuks5tg74MgaJpZM4S3J1c>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375346429
https://github.com/qupath/qupath/issues/160#issuecomment-375346429:585,Availability,avail,available,585,"Hi Pete,. I’ve attached the classifier file. Thanks very much for your help,. Cam. From: Pete [mailto:notifications@github.com]; Sent: 22 March 2018 15:07; To: qupath/qupath <qupath@noreply.github.com>; Cc: Camilla Coulson-Gilmer <>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] loading classifier error (#160). I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that might affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the .qpclassifier file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the QuPath user forum on Google Groups<https://groups.google.com/forum/#!forum/qupath-users> I can contact you directly. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/160#issuecomment-375339965>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj60nFu_XkbrWH1Xr6vaENeGtItS4XCuks5tg74MgaJpZM4S3J1c>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375346429
https://github.com/qupath/qupath/issues/160#issuecomment-375346429:481,Deployability,update,updates,481,"Hi Pete,. I’ve attached the classifier file. Thanks very much for your help,. Cam. From: Pete [mailto:notifications@github.com]; Sent: 22 March 2018 15:07; To: qupath/qupath <qupath@noreply.github.com>; Cc: Camilla Coulson-Gilmer <>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] loading classifier error (#160). I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that might affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the .qpclassifier file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the QuPath user forum on Google Groups<https://groups.google.com/forum/#!forum/qupath-users> I can contact you directly. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/160#issuecomment-375339965>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj60nFu_XkbrWH1Xr6vaENeGtItS4XCuks5tg74MgaJpZM4S3J1c>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375346429
https://github.com/qupath/qupath/issues/160#issuecomment-375346429:549,Deployability,update,updates,549,"Hi Pete,. I’ve attached the classifier file. Thanks very much for your help,. Cam. From: Pete [mailto:notifications@github.com]; Sent: 22 March 2018 15:07; To: qupath/qupath <qupath@noreply.github.com>; Cc: Camilla Coulson-Gilmer <>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] loading classifier error (#160). I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that might affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the .qpclassifier file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the QuPath user forum on Google Groups<https://groups.google.com/forum/#!forum/qupath-users> I can contact you directly. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/160#issuecomment-375339965>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj60nFu_XkbrWH1Xr6vaENeGtItS4XCuks5tg74MgaJpZM4S3J1c>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375346429
https://github.com/qupath/qupath/issues/160#issuecomment-375346429:299,Performance,load,loading,299,"Hi Pete,. I’ve attached the classifier file. Thanks very much for your help,. Cam. From: Pete [mailto:notifications@github.com]; Sent: 22 March 2018 15:07; To: qupath/qupath <qupath@noreply.github.com>; Cc: Camilla Coulson-Gilmer <>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] loading classifier error (#160). I don't know, I haven't seen this problem before - and if nothing has changed in the meantime, I see no reason why the classifier wouldn't work. The updates mentioned above shouldn't affect this (more accurately, the updates that might affect it aren't available there yet). When you say you copied and pasted the classifier, I guess you mean the whole file through Windows Explorer?. Do you have any more luck if you try running it from a different location, e.g. copy it to the Desktop and try from there?. If you are able to send me the .qpclassifier file then I can investigate some more. If there isn't a way for you to upload it here and you haven't already got my email address from somewhere, then if you sign up to the QuPath user forum on Google Groups<https://groups.google.com/forum/#!forum/qupath-users> I can contact you directly. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/160#issuecomment-375339965>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj60nFu_XkbrWH1Xr6vaENeGtItS4XCuks5tg74MgaJpZM4S3J1c>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375346429
https://github.com/qupath/qupath/issues/161#issuecomment-375335956:376,Security,confidential,confidentiality,376,"If you want help with a particular project, please post more information over at https://groups.google.com/forum/#!forum/qupath-users. I would recommend at least copy of your workflow script (https://github.com/qupath/qupath/wiki/Workflows) so we know what you have tried and/or are trying. And perhaps some small jpeg images so we know what you are looking at (if allowed by confidentiality).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375335956
https://github.com/qupath/qupath/issues/161#issuecomment-375336673:610,Security,confidential,confidentiality,610,"Thank You for the quick response, will do!. > On 22 Mar 2018, at 15:56, Svidro <notifications@github.com> wrote:; > ; > If you want help with a particular project, please post more information over at https://groups.google.com/forum/#!forum/qupath-users <https://groups.google.com/forum/#!forum/qupath-users>; > I would recommend at least copy of your workflow script (https://github.com/qupath/qupath/wiki/Workflows <https://github.com/qupath/qupath/wiki/Workflows>) so we know what you have tried and/or are trying.; > ; > And perhaps some small jpeg images so we know what you are looking at (if allowed by confidentiality).; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/qupath/qupath/issues/161#issuecomment-375335956>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Aj62c1nfD8q8Q2p2iSVzMVUc7IyXMSaWks5tg7uagaJpZM4S3MDO>.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336673
https://github.com/qupath/qupath/issues/161#issuecomment-375336894:843,Safety,detect,detection,843,"There's a description of how I've done it in the past in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5). In particular, see the [Supplementary material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-017-17204-5/MediaObjects/41598_2017_17204_MOESM1_ESM.pdf) - especially around p 13. The supplementary material also shows a really elaborate script on p15... but actually it's *much* simpler now:; ```groovy; setCellIntensityClassifications('Cell: DAB OD max', 0.35); ```. However, all of that is too complicated If you are will to draw regions of interest, and don't need to bother with separating out epithelial/non-epithelial cells (which may be really difficult and not accurate enough in brightfield images for PD-L1). In that case, it should be much easier to simply run *Positive cell detection* as described [here](https://github.com/qupath/qupath/wiki/Detecting-objects). The only thing you should need to chnage is the measurement at the bottom (*Nucleus: DAB OD mean* probably isn't right, *Cell: DAB OD max* or *Cell: DAB OD mean* should do better).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336894
https://github.com/qupath/qupath/issues/161#issuecomment-375336894:912,Safety,Detect,Detecting-objects,912,"There's a description of how I've done it in the past in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5). In particular, see the [Supplementary material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-017-17204-5/MediaObjects/41598_2017_17204_MOESM1_ESM.pdf) - especially around p 13. The supplementary material also shows a really elaborate script on p15... but actually it's *much* simpler now:; ```groovy; setCellIntensityClassifications('Cell: DAB OD max', 0.35); ```. However, all of that is too complicated If you are will to draw regions of interest, and don't need to bother with separating out epithelial/non-epithelial cells (which may be really difficult and not accurate enough in brightfield images for PD-L1). In that case, it should be much easier to simply run *Positive cell detection* as described [here](https://github.com/qupath/qupath/wiki/Detecting-objects). The only thing you should need to chnage is the measurement at the bottom (*Nucleus: DAB OD mean* probably isn't right, *Cell: DAB OD max* or *Cell: DAB OD mean* should do better).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336894
https://github.com/qupath/qupath/issues/161#issuecomment-375336894:435,Usability,simpl,simpler,435,"There's a description of how I've done it in the past in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5). In particular, see the [Supplementary material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-017-17204-5/MediaObjects/41598_2017_17204_MOESM1_ESM.pdf) - especially around p 13. The supplementary material also shows a really elaborate script on p15... but actually it's *much* simpler now:; ```groovy; setCellIntensityClassifications('Cell: DAB OD max', 0.35); ```. However, all of that is too complicated If you are will to draw regions of interest, and don't need to bother with separating out epithelial/non-epithelial cells (which may be really difficult and not accurate enough in brightfield images for PD-L1). In that case, it should be much easier to simply run *Positive cell detection* as described [here](https://github.com/qupath/qupath/wiki/Detecting-objects). The only thing you should need to chnage is the measurement at the bottom (*Nucleus: DAB OD mean* probably isn't right, *Cell: DAB OD max* or *Cell: DAB OD mean* should do better).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336894
https://github.com/qupath/qupath/issues/161#issuecomment-375336894:817,Usability,simpl,simply,817,"There's a description of how I've done it in the past in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5). In particular, see the [Supplementary material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-017-17204-5/MediaObjects/41598_2017_17204_MOESM1_ESM.pdf) - especially around p 13. The supplementary material also shows a really elaborate script on p15... but actually it's *much* simpler now:; ```groovy; setCellIntensityClassifications('Cell: DAB OD max', 0.35); ```. However, all of that is too complicated If you are will to draw regions of interest, and don't need to bother with separating out epithelial/non-epithelial cells (which may be really difficult and not accurate enough in brightfield images for PD-L1). In that case, it should be much easier to simply run *Positive cell detection* as described [here](https://github.com/qupath/qupath/wiki/Detecting-objects). The only thing you should need to chnage is the measurement at the bottom (*Nucleus: DAB OD mean* probably isn't right, *Cell: DAB OD max* or *Cell: DAB OD mean* should do better).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336894
https://github.com/qupath/qupath/issues/162#issuecomment-377154596:1502,Deployability,update,updates,1502,"I think the current answer is 'no'. As I understand your question, you mean tiles containing pixel data - is that right?. I have been working on some related things that could change this situation, making it possible to overlay different images and apply a (rigid) transformation if necessary to aid alignment... but as one project among many, it could take some time for the changes I'm making to become really useful. And I'm not actively working on any more complex registration - just shifts and rotations. Can you say more about what your aim is? For example,; * Do you primarily want this for visualization or analysis?; * Do you have different tissue sections, or the same tissue restained? (I guess the first, but the second is certainly easier on the image processing side...); * Which stains (colors) are you using for each TMA?. I'm not sure if it helps or you have already seen it, but with [Multiple viewers](https://github.com/qupath/qupath/wiki/Multiple-images) it is already possible to view different TMA cores side-by-side, and then navigate the grid using the arrow keys. TMA cores at the same grid location will be displayed together. You could also export each TMA core as a TIFF image from QuPath, and explore aligning these using some of Fiji/ImageJ's [image registration](https://imagej.net/Category:Registration) tools on a core-by-core basis. This could require quite a bit of effort. > Sidenote: I'm using [this blog](https://petebankhead.github.io) to describe some of the updates I'm working on, but which aren't yet in a QuPath release - it's also a good place to give feedback/suggestions to help shape where the changes go.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377154596
https://github.com/qupath/qupath/issues/162#issuecomment-377154596:1559,Deployability,release,release,1559,"I think the current answer is 'no'. As I understand your question, you mean tiles containing pixel data - is that right?. I have been working on some related things that could change this situation, making it possible to overlay different images and apply a (rigid) transformation if necessary to aid alignment... but as one project among many, it could take some time for the changes I'm making to become really useful. And I'm not actively working on any more complex registration - just shifts and rotations. Can you say more about what your aim is? For example,; * Do you primarily want this for visualization or analysis?; * Do you have different tissue sections, or the same tissue restained? (I guess the first, but the second is certainly easier on the image processing side...); * Which stains (colors) are you using for each TMA?. I'm not sure if it helps or you have already seen it, but with [Multiple viewers](https://github.com/qupath/qupath/wiki/Multiple-images) it is already possible to view different TMA cores side-by-side, and then navigate the grid using the arrow keys. TMA cores at the same grid location will be displayed together. You could also export each TMA core as a TIFF image from QuPath, and explore aligning these using some of Fiji/ImageJ's [image registration](https://imagej.net/Category:Registration) tools on a core-by-core basis. This could require quite a bit of effort. > Sidenote: I'm using [this blog](https://petebankhead.github.io) to describe some of the updates I'm working on, but which aren't yet in a QuPath release - it's also a good place to give feedback/suggestions to help shape where the changes go.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377154596
https://github.com/qupath/qupath/issues/162#issuecomment-377154596:1600,Usability,feedback,feedback,1600,"I think the current answer is 'no'. As I understand your question, you mean tiles containing pixel data - is that right?. I have been working on some related things that could change this situation, making it possible to overlay different images and apply a (rigid) transformation if necessary to aid alignment... but as one project among many, it could take some time for the changes I'm making to become really useful. And I'm not actively working on any more complex registration - just shifts and rotations. Can you say more about what your aim is? For example,; * Do you primarily want this for visualization or analysis?; * Do you have different tissue sections, or the same tissue restained? (I guess the first, but the second is certainly easier on the image processing side...); * Which stains (colors) are you using for each TMA?. I'm not sure if it helps or you have already seen it, but with [Multiple viewers](https://github.com/qupath/qupath/wiki/Multiple-images) it is already possible to view different TMA cores side-by-side, and then navigate the grid using the arrow keys. TMA cores at the same grid location will be displayed together. You could also export each TMA core as a TIFF image from QuPath, and explore aligning these using some of Fiji/ImageJ's [image registration](https://imagej.net/Category:Registration) tools on a core-by-core basis. This could require quite a bit of effort. > Sidenote: I'm using [this blog](https://petebankhead.github.io) to describe some of the updates I'm working on, but which aren't yet in a QuPath release - it's also a good place to give feedback/suggestions to help shape where the changes go.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377154596
https://github.com/qupath/qupath/issues/162#issuecomment-377162445:1038,Energy Efficiency,monitor,monitors,1038,"Thank you for the reply.; Currently my aim is to cut identical areas in the same TMA slide but with different antigen captured.; All IHC are DAB-based, so all antigens are expressed in brown; (we are not using multicolored multiplex IHC). . We scan a TMA slide after IHC, bleach it clean, and then repeat IHC and scanning with the next antigen. ; So technically all our scanned slides are from one identical slide, but after the scanning process ; the slides are misaligned and aligning the whole slide (or even a TMA core) ; without sacrificing image quality was impossible; (at least with a normal desktop with i7 cpu and 32gb of ram). . For now, we manually cut parts of TMA image (about 4K x 4K pixels), align images, and overlap perfectly align images with cellprofiler.; ; I thought it would be much easier to cut the images from identical regions if tiles provided from; qupath could be moved and rotated (as a sequence of rough alignment before perfect alignment with; cellprofiler) since we are using literally putting rulers on monitors to get a similar region from different scans.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377162445
https://github.com/qupath/qupath/issues/162#issuecomment-377167248:999,Deployability,integrat,integration,999,"Ah! Bleaching and rescanning changes things; what I'm currently working on *might* be exactly what you need. This is some related discussion on [Google Groups](https://groups.google.com/d/msg/qupath-users/XNdaWK_9Ex4/VKHAbBGDBAAJ). If you'd be interested in collaborating on this, and perhaps sharing some images to help me develop the tool to do what you need, please send me a message. I'm quite find-able on Twitter, ResearchGate or LinkedIn... or if you sign up to the QuPath Google Group I'll get a notification and can write to you directly. Otherwise I'll post a reply back here once I have something worth testing, but I haven't got an expected timeframe yet. . The CellProfiler bit is also interesting. If we can achieve the alignment then maybe this step wouldn't be necessary and everything could be done in QuPath. But if you do need more CellProfiler-specific functionality then it would be good to discuss if there's a way to help streamline that bit of the process too - since better integration with CellProfiler is something that has already come up (e.g. #123).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377167248
https://github.com/qupath/qupath/issues/162#issuecomment-377167248:379,Integrability,message,message,379,"Ah! Bleaching and rescanning changes things; what I'm currently working on *might* be exactly what you need. This is some related discussion on [Google Groups](https://groups.google.com/d/msg/qupath-users/XNdaWK_9Ex4/VKHAbBGDBAAJ). If you'd be interested in collaborating on this, and perhaps sharing some images to help me develop the tool to do what you need, please send me a message. I'm quite find-able on Twitter, ResearchGate or LinkedIn... or if you sign up to the QuPath Google Group I'll get a notification and can write to you directly. Otherwise I'll post a reply back here once I have something worth testing, but I haven't got an expected timeframe yet. . The CellProfiler bit is also interesting. If we can achieve the alignment then maybe this step wouldn't be necessary and everything could be done in QuPath. But if you do need more CellProfiler-specific functionality then it would be good to discuss if there's a way to help streamline that bit of the process too - since better integration with CellProfiler is something that has already come up (e.g. #123).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377167248
https://github.com/qupath/qupath/issues/162#issuecomment-377167248:999,Integrability,integrat,integration,999,"Ah! Bleaching and rescanning changes things; what I'm currently working on *might* be exactly what you need. This is some related discussion on [Google Groups](https://groups.google.com/d/msg/qupath-users/XNdaWK_9Ex4/VKHAbBGDBAAJ). If you'd be interested in collaborating on this, and perhaps sharing some images to help me develop the tool to do what you need, please send me a message. I'm quite find-able on Twitter, ResearchGate or LinkedIn... or if you sign up to the QuPath Google Group I'll get a notification and can write to you directly. Otherwise I'll post a reply back here once I have something worth testing, but I haven't got an expected timeframe yet. . The CellProfiler bit is also interesting. If we can achieve the alignment then maybe this step wouldn't be necessary and everything could be done in QuPath. But if you do need more CellProfiler-specific functionality then it would be good to discuss if there's a way to help streamline that bit of the process too - since better integration with CellProfiler is something that has already come up (e.g. #123).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377167248
https://github.com/qupath/qupath/issues/162#issuecomment-377167248:614,Testability,test,testing,614,"Ah! Bleaching and rescanning changes things; what I'm currently working on *might* be exactly what you need. This is some related discussion on [Google Groups](https://groups.google.com/d/msg/qupath-users/XNdaWK_9Ex4/VKHAbBGDBAAJ). If you'd be interested in collaborating on this, and perhaps sharing some images to help me develop the tool to do what you need, please send me a message. I'm quite find-able on Twitter, ResearchGate or LinkedIn... or if you sign up to the QuPath Google Group I'll get a notification and can write to you directly. Otherwise I'll post a reply back here once I have something worth testing, but I haven't got an expected timeframe yet. . The CellProfiler bit is also interesting. If we can achieve the alignment then maybe this step wouldn't be necessary and everything could be done in QuPath. But if you do need more CellProfiler-specific functionality then it would be good to discuss if there's a way to help streamline that bit of the process too - since better integration with CellProfiler is something that has already come up (e.g. #123).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/162#issuecomment-377167248
https://github.com/qupath/qupath/issues/163#issuecomment-379423069:145,Performance,load,load,145,"The last time I remember those fields being missing from an image, the pixel size information was missing from the metadata. For example, if you load a basic JPG file into QuPath, you will see the same missing Spot and cluster parameters since there are no micron based measurements to make. Edit for clarity: You should check and make sure that the metadata is both there in your original files, and after loading into QuPath in the Image tab under Pixel Width and Height.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379423069
https://github.com/qupath/qupath/issues/163#issuecomment-379423069:407,Performance,load,loading,407,"The last time I remember those fields being missing from an image, the pixel size information was missing from the metadata. For example, if you load a basic JPG file into QuPath, you will see the same missing Spot and cluster parameters since there are no micron based measurements to make. Edit for clarity: You should check and make sure that the metadata is both there in your original files, and after loading into QuPath in the Image tab under Pixel Width and Height.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379423069
https://github.com/qupath/qupath/issues/163#issuecomment-379423138:38,Usability,guid,guide,38,"I haven't yet had time to write up my guide on google groups, but at the following link ; https://gist.github.com/Svidro/6171d6d24a85539d3af5d417bc928d50; You can find a 3 step process which can let you create both nuclei and whole cells. Hopefully I will get around to creating the ""How to"" this weekend, but it seems like it might be useful for what you are doing. Or at least it could give you a nuclear count in addition to the rest of your cells. Although on second thought, with the overlapping nuclei, it might not be so useful!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379423138
https://github.com/qupath/qupath/issues/163#issuecomment-379492221:188,Performance,load,loading,188,"Thank you for your prompt reply. ; I checked and made sure them as per your suggestion. Although the original files have their metadata (Pixel width/ height), they have been missing after loading into QuPath. I can use the QuPath program on the pictures taken before, and they still have the metadata after loading into QuPath.; ![2018-04-07 14 48 28](https://user-images.githubusercontent.com/38146083/38459044-d6b4add0-3a72-11e8-96fb-894f69624a8d.png). However the pictures taken recently have lost their metadata after loading into QuPath.; ![2018-04-07 14 51 12](https://user-images.githubusercontent.com/38146083/38459068-268df8d4-3a73-11e8-9075-84300f43d46b.png). What could be the problem? Do you have any solutions?. And also I appreciate your advice about nuclear counting. Actually what we need to do is ""counting the ISH-puncta inside the cell"", not nuclear. Pete helped us on this program before. Here is the link (https://groups.google.com/forum/#!topic/qupath-users/_k4SkC445ZE). Thanks,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379492221
https://github.com/qupath/qupath/issues/163#issuecomment-379492221:307,Performance,load,loading,307,"Thank you for your prompt reply. ; I checked and made sure them as per your suggestion. Although the original files have their metadata (Pixel width/ height), they have been missing after loading into QuPath. I can use the QuPath program on the pictures taken before, and they still have the metadata after loading into QuPath.; ![2018-04-07 14 48 28](https://user-images.githubusercontent.com/38146083/38459044-d6b4add0-3a72-11e8-96fb-894f69624a8d.png). However the pictures taken recently have lost their metadata after loading into QuPath.; ![2018-04-07 14 51 12](https://user-images.githubusercontent.com/38146083/38459068-268df8d4-3a73-11e8-9075-84300f43d46b.png). What could be the problem? Do you have any solutions?. And also I appreciate your advice about nuclear counting. Actually what we need to do is ""counting the ISH-puncta inside the cell"", not nuclear. Pete helped us on this program before. Here is the link (https://groups.google.com/forum/#!topic/qupath-users/_k4SkC445ZE). Thanks,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379492221
https://github.com/qupath/qupath/issues/163#issuecomment-379492221:522,Performance,load,loading,522,"Thank you for your prompt reply. ; I checked and made sure them as per your suggestion. Although the original files have their metadata (Pixel width/ height), they have been missing after loading into QuPath. I can use the QuPath program on the pictures taken before, and they still have the metadata after loading into QuPath.; ![2018-04-07 14 48 28](https://user-images.githubusercontent.com/38146083/38459044-d6b4add0-3a72-11e8-96fb-894f69624a8d.png). However the pictures taken recently have lost their metadata after loading into QuPath.; ![2018-04-07 14 51 12](https://user-images.githubusercontent.com/38146083/38459068-268df8d4-3a73-11e8-9075-84300f43d46b.png). What could be the problem? Do you have any solutions?. And also I appreciate your advice about nuclear counting. Actually what we need to do is ""counting the ISH-puncta inside the cell"", not nuclear. Pete helped us on this program before. Here is the link (https://groups.google.com/forum/#!topic/qupath-users/_k4SkC445ZE). Thanks,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379492221
https://github.com/qupath/qupath/issues/163#issuecomment-379493712:1693,Deployability,release,released,1693,"possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: ImageJ* is affected - and even then not always. It should be fairly clear if it causes trouble, in that spots appear where they shouldn't.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712
https://github.com/qupath/qupath/issues/163#issuecomment-379493712:1790,Deployability,update,updates,1790,"possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: ImageJ* is affected - and even then not always. It should be fairly clear if it causes trouble, in that spots appear where they shouldn't.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712
https://github.com/qupath/qupath/issues/163#issuecomment-379493712:1130,Safety,safe,safe,1130," Nikon software? Is there any possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: ImageJ* is affected - and even then not always. It should be fairly clear if it causes trouble, in that spots",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712
https://github.com/qupath/qupath/issues/163#issuecomment-379493712:449,Usability,clear,clear,449,"It's strange that the pixel sizes are now missing... do I understand correctly that they are visible in the Nikon software? Is there any possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: Ima",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712
https://github.com/qupath/qupath/issues/163#issuecomment-379493712:2066,Usability,clear,clear,2066,"possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: ImageJ* is affected - and even then not always. It should be fairly clear if it causes trouble, in that spots appear where they shouldn't.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712
https://github.com/qupath/qupath/issues/163#issuecomment-379493767:192,Performance,load,loading,192,"Oh, I didn't realize you worked with him! I have chatted with Alex a bit from the microscopyra account. I would guess something changed with how you are taking or processing the images before loading them into QuPath. ****Oops, you mentioned you checked the Nikon software above your posted images!**** Another thing is I think you might have been working with MIP files, so I would check to see if both the originals AND the MIP both have the correct metadata. Finally, one option might be to add the metadata back in. In one of the emails to Alex I mentioned how to add the metadata into the .nd2 files using ImageJ. If you want to try that... And Pete just beat me to it :) You should be able to use that Image-Properties to edit the correct pixel data back in!. Further edit: Last time I wasn't getting pixel data from the .nd2 files, it was because my version of the bioformats_package.jar was out of date, so I would start with that suggestion of Pete's",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493767
https://github.com/qupath/qupath/issues/163#issuecomment-379565929:112,Modifiability,plugin,plugin,112,"In ImageJ it's quick, but as Pete mentioned, you can't actually save the file as a .nd2 file (unless there is a plugin that I do not know of!). If you use FIJI, you can save as an OME-TIFF, which will open with the Bio-Formats server, thus avoiding the threading problem (I think) that Pete mentioned above, so I would recommend that. Open FIJI/ImageJ, then File->Open your .nd2 file.; Then go to Image-> Properties, and change your XY pixel sizes to whatever you want.; ![change pixel size 1](https://user-images.githubusercontent.com/23145209/38470206-591f7e0c-3b14-11e8-8588-0952d4715b42.JPG); ![change pixel size 2](https://user-images.githubusercontent.com/23145209/38470212-5d7bdad6-3b14-11e8-97d9-586637de7659.JPG). Save as the OME-TIFF type, which for me was all the way at the bottom of the Save as... menu. I looked into a couple of other programs to try to edit the metadata while still keeping the file as .nd2, but did not have any success with nip or XnView. If you do convert, definitely keep both versions of the file! While the TIFF will have pixel sizes, it will not have most of the other metadata contained in the .nd2 files, such as microscope settings.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379565929
https://github.com/qupath/qupath/issues/163#issuecomment-379565929:240,Safety,avoid,avoiding,240,"In ImageJ it's quick, but as Pete mentioned, you can't actually save the file as a .nd2 file (unless there is a plugin that I do not know of!). If you use FIJI, you can save as an OME-TIFF, which will open with the Bio-Formats server, thus avoiding the threading problem (I think) that Pete mentioned above, so I would recommend that. Open FIJI/ImageJ, then File->Open your .nd2 file.; Then go to Image-> Properties, and change your XY pixel sizes to whatever you want.; ![change pixel size 1](https://user-images.githubusercontent.com/23145209/38470206-591f7e0c-3b14-11e8-8588-0952d4715b42.JPG); ![change pixel size 2](https://user-images.githubusercontent.com/23145209/38470212-5d7bdad6-3b14-11e8-97d9-586637de7659.JPG). Save as the OME-TIFF type, which for me was all the way at the bottom of the Save as... menu. I looked into a couple of other programs to try to edit the metadata while still keeping the file as .nd2, but did not have any success with nip or XnView. If you do convert, definitely keep both versions of the file! While the TIFF will have pixel sizes, it will not have most of the other metadata contained in the .nd2 files, such as microscope settings.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379565929
https://github.com/qupath/qupath/issues/163#issuecomment-379566248:404,Deployability,update,updates,404,"Also, since these files are being read with the Bio-Formats extension, I looked that up quickly and at:; https://docs.openmicroscopy.org/bio-formats/5.7.2/formats/nikon-nis-elements-nd2.html; You can read that there are two versions of .nd2 files. It may be that previously you were saving as the older version (jpeg2000 compressed) versus the new version which may be ZIP compressed. I am unsure if the updates you mentioned might have transitioned you between versions, but there may be some file settings you could change regarding how it compresses your data.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379566248
https://github.com/qupath/qupath/issues/164#issuecomment-380835137:129,Availability,down,down,129,"Thanks, this looks like a bug in the Bio-Formats extension. I can replicate the problem with the attached image. I've tracked it down to one line [here](https://github.com/qupath/qupath-bioformats-extension/blob/master/src/main/java/qupath/lib/images/servers/BioFormatsImageServer.java#L670) - presumably `mergeChannels` contains some logic to treat 4-channel 8-bit images are ARGB. If I open the image in ImageJ and save it as a multichannel image then all 4 channels are measured, as they should be. So it's not an inherent limitation in the cell detection. If I'm correct, most other combinations of channel numbers and bit-depths should be fine... It should be a fairly straightforward fix. I'm travelling at the moment, but will have a look soon.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/164#issuecomment-380835137
https://github.com/qupath/qupath/issues/164#issuecomment-380835137:549,Safety,detect,detection,549,"Thanks, this looks like a bug in the Bio-Formats extension. I can replicate the problem with the attached image. I've tracked it down to one line [here](https://github.com/qupath/qupath-bioformats-extension/blob/master/src/main/java/qupath/lib/images/servers/BioFormatsImageServer.java#L670) - presumably `mergeChannels` contains some logic to treat 4-channel 8-bit images are ARGB. If I open the image in ImageJ and save it as a multichannel image then all 4 channels are measured, as they should be. So it's not an inherent limitation in the cell detection. If I'm correct, most other combinations of channel numbers and bit-depths should be fine... It should be a fairly straightforward fix. I'm travelling at the moment, but will have a look soon.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/164#issuecomment-380835137
https://github.com/qupath/qupath/issues/164#issuecomment-380835137:335,Testability,log,logic,335,"Thanks, this looks like a bug in the Bio-Formats extension. I can replicate the problem with the attached image. I've tracked it down to one line [here](https://github.com/qupath/qupath-bioformats-extension/blob/master/src/main/java/qupath/lib/images/servers/BioFormatsImageServer.java#L670) - presumably `mergeChannels` contains some logic to treat 4-channel 8-bit images are ARGB. If I open the image in ImageJ and save it as a multichannel image then all 4 channels are measured, as they should be. So it's not an inherent limitation in the cell detection. If I'm correct, most other combinations of channel numbers and bit-depths should be fine... It should be a fairly straightforward fix. I'm travelling at the moment, but will have a look soon.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/164#issuecomment-380835137
https://github.com/qupath/qupath/issues/164#issuecomment-383477860:103,Deployability,release,releases,103,This issue is hopefully now resolved in [v0.0.6](https://github.com/qupath/qupath-bioformats-extension/releases).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/164#issuecomment-383477860
https://github.com/qupath/qupath/issues/165#issuecomment-381105876:225,Usability,clear,clear,225,"I didn't actually know .mrxs files could contain annotations... The [first post here](https://github.com/openslide/openslide/issues/118) contains the teasing phrase *'pure xml with pretty obvious content'*, although it's not clear to me how easy it is to know which .dat file contains the annotations in each case. @DanaCase created a really useful script to parse Aperio annotations at https://github.com/qupath/qupath/issues/61#issuecomment-359990015. Creating a parser that can handle annotations in a variety of formats could be an extremely useful contribution (and 'fun' student project?)... I'm afraid it's not something I am likely to get a chance to work on myself any time soon, but I can help with the QuPath side (i.e. converting coordinates into ROIs and objects that QuPath can display). I'll flag this as 'help wanted'...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/165#issuecomment-381105876
https://github.com/qupath/qupath/issues/165#issuecomment-381391292:480,Integrability,depend,depends,480,.mrxs files do contain annotations created with viewer/management plaftorm from 3DHistech. They are contained in the folder corresponding to the digital slide. You have to parse the .dat files and look the last 3 files (from the numerical index) for an XML formated text at the beginning of the file. There isn't much documentation about their file format to be able to automate the interpretation of the annotations (i.e. which one is the file with the annotations 2nd/3rd as it depends on the version of scanner and software controller). . Sometime you see within the annotations file some annotations that are not displayed in the viewer from 3DHistech (i.e. deleted annotations). What I would recommend is to name the annotations (when you crate them) with labels you define yourself so that you know what to look for when parsing the xlm file. . Let me know if you have more questions.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/165#issuecomment-381391292
https://github.com/qupath/qupath/issues/166#issuecomment-381163241:103,Availability,mask,mask,103,"Neat idea, would love to see the script if you get this working! I wonder how easily you could add the mask as an extra channel in the .tiff image and keep the original for reference as well?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/166#issuecomment-381163241
https://github.com/qupath/qupath/issues/170#issuecomment-383882612:125,Availability,error,error,125,"Thanks. There isn't a pixel classifier here, only on an experimental bit of a branch on my fork... but indeed I get the same error. Fixed now, good to catch it early :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/170#issuecomment-383882612
https://github.com/qupath/qupath/issues/171#issuecomment-384084486:432,Integrability,depend,depending,432,"Unless you can automate detection of the tumor area by texture for each (in which case you can handle every image independently anyway), I can't think of an easy way to do that with un-adjusted images within QuPath unless you already knew the X-Y shift and rotational angle change each time. That said, there is software out there that can automatically align whole slide samples, though this can often be a time consuming process (depending on the resolution/computer speed/etc). . This thread has some additional info: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/XNdaWK_9Ex4/-w8T4cqGBAAJ; and some other recommended free software: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/VLJL6UCXqEk/c9j-RCMVBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/171#issuecomment-384084486
https://github.com/qupath/qupath/issues/171#issuecomment-384084486:24,Safety,detect,detection,24,"Unless you can automate detection of the tumor area by texture for each (in which case you can handle every image independently anyway), I can't think of an easy way to do that with un-adjusted images within QuPath unless you already knew the X-Y shift and rotational angle change each time. That said, there is software out there that can automatically align whole slide samples, though this can often be a time consuming process (depending on the resolution/computer speed/etc). . This thread has some additional info: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/XNdaWK_9Ex4/-w8T4cqGBAAJ; and some other recommended free software: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/VLJL6UCXqEk/c9j-RCMVBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/171#issuecomment-384084486
https://github.com/qupath/qupath/issues/172#issuecomment-387779230:61,Integrability,depend,depends,61,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230
https://github.com/qupath/qupath/issues/172#issuecomment-387779230:753,Integrability,depend,depend,753,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230
https://github.com/qupath/qupath/issues/172#issuecomment-387779230:495,Performance,perform,perform,495,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230
https://github.com/qupath/qupath/issues/172#issuecomment-387779230:349,Safety,detect,detection,349,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230
https://github.com/qupath/qupath/issues/172#issuecomment-387779230:519,Safety,detect,detection,519,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230
https://github.com/qupath/qupath/issues/172#issuecomment-388539146:52,Availability,toler,tolerate,52,"If you don't have a huge number of cores, and could tolerate just manually annotating and deleting certain regions, that might be the easiest way... draw around the region you don't want (*after* detecting cells/superpixels or whatever your previous step was) and press *Backspace* to delete the annotation - and then choose *No* when asked about keeping descendent objects. Based on the description, my guess is you're using *Positive cell detection*. You might also try to create a classifier (as described [here](https://github.com/qupath/qupath/wiki/Classifying-objects)) and leave it up to the classifier to find the areas of carbon based on whatever features have been calculated; for example, you could assign classifications for *Carbon* and *Valid* (or whatever other category names you want to use). Then delete the carbon areas and reapply the positive/negative classifications using something like the following script:. ```groovy; carbon = getDetectionObjects().findAll {it.getPathClass() == getPathClass('Carbon')}; removeObjects(carbon, true); setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```. If this doesn't work well enough, then you can tell QuPath to calculate new features for each cell using *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)*; I'd suggest adding the mean values for red, green and blue as a starting point and see if that's enough. Otherwise, if you're able to provide an example image and say a bit more about what steps are involved in your analysis then maybe we can think of other ways.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-388539146
https://github.com/qupath/qupath/issues/172#issuecomment-388539146:1357,Energy Efficiency,green,green,1357,"If you don't have a huge number of cores, and could tolerate just manually annotating and deleting certain regions, that might be the easiest way... draw around the region you don't want (*after* detecting cells/superpixels or whatever your previous step was) and press *Backspace* to delete the annotation - and then choose *No* when asked about keeping descendent objects. Based on the description, my guess is you're using *Positive cell detection*. You might also try to create a classifier (as described [here](https://github.com/qupath/qupath/wiki/Classifying-objects)) and leave it up to the classifier to find the areas of carbon based on whatever features have been calculated; for example, you could assign classifications for *Carbon* and *Valid* (or whatever other category names you want to use). Then delete the carbon areas and reapply the positive/negative classifications using something like the following script:. ```groovy; carbon = getDetectionObjects().findAll {it.getPathClass() == getPathClass('Carbon')}; removeObjects(carbon, true); setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```. If this doesn't work well enough, then you can tell QuPath to calculate new features for each cell using *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)*; I'd suggest adding the mean values for red, green and blue as a starting point and see if that's enough. Otherwise, if you're able to provide an example image and say a bit more about what steps are involved in your analysis then maybe we can think of other ways.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-388539146
https://github.com/qupath/qupath/issues/172#issuecomment-388539146:196,Safety,detect,detecting,196,"If you don't have a huge number of cores, and could tolerate just manually annotating and deleting certain regions, that might be the easiest way... draw around the region you don't want (*after* detecting cells/superpixels or whatever your previous step was) and press *Backspace* to delete the annotation - and then choose *No* when asked about keeping descendent objects. Based on the description, my guess is you're using *Positive cell detection*. You might also try to create a classifier (as described [here](https://github.com/qupath/qupath/wiki/Classifying-objects)) and leave it up to the classifier to find the areas of carbon based on whatever features have been calculated; for example, you could assign classifications for *Carbon* and *Valid* (or whatever other category names you want to use). Then delete the carbon areas and reapply the positive/negative classifications using something like the following script:. ```groovy; carbon = getDetectionObjects().findAll {it.getPathClass() == getPathClass('Carbon')}; removeObjects(carbon, true); setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```. If this doesn't work well enough, then you can tell QuPath to calculate new features for each cell using *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)*; I'd suggest adding the mean values for red, green and blue as a starting point and see if that's enough. Otherwise, if you're able to provide an example image and say a bit more about what steps are involved in your analysis then maybe we can think of other ways.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-388539146
https://github.com/qupath/qupath/issues/172#issuecomment-388539146:441,Safety,detect,detection,441,"If you don't have a huge number of cores, and could tolerate just manually annotating and deleting certain regions, that might be the easiest way... draw around the region you don't want (*after* detecting cells/superpixels or whatever your previous step was) and press *Backspace* to delete the annotation - and then choose *No* when asked about keeping descendent objects. Based on the description, my guess is you're using *Positive cell detection*. You might also try to create a classifier (as described [here](https://github.com/qupath/qupath/wiki/Classifying-objects)) and leave it up to the classifier to find the areas of carbon based on whatever features have been calculated; for example, you could assign classifications for *Carbon* and *Valid* (or whatever other category names you want to use). Then delete the carbon areas and reapply the positive/negative classifications using something like the following script:. ```groovy; carbon = getDetectionObjects().findAll {it.getPathClass() == getPathClass('Carbon')}; removeObjects(carbon, true); setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```. If this doesn't work well enough, then you can tell QuPath to calculate new features for each cell using *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)*; I'd suggest adding the mean values for red, green and blue as a starting point and see if that's enough. Otherwise, if you're able to provide an example image and say a bit more about what steps are involved in your analysis then maybe we can think of other ways.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-388539146
https://github.com/qupath/qupath/issues/173#issuecomment-389972084:453,Availability,down,downsample,453,"Just linked this in the forums as well, but if you can define how you want to draw the annotation within a text file (groovy script) you might be able to use:; https://groups.google.com/forum/#!searchin/qupath-users/command$20line$20|sort:date/qupath-users/lE5AJDcxA28/JR0UouPLAAAJ; to get started. The following positions the viewer (although you need to create the viewer first, see the whole file in the link below):; ```; viewer.setDownsampleFactor(downsample); viewer.setCenterPixelLocation(xCoordinate, yCoordinate);; ```; from: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054#file-slide-explore-groovy; which was modified from who knows where... I think Pete's memory monitor. Exporting simple annotations as coordinate arrays is fairly straightforward (and definitely on the forums somewhere), but I am not as sure about XML formatting...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/173#issuecomment-389972084
https://github.com/qupath/qupath/issues/173#issuecomment-389972084:691,Energy Efficiency,monitor,monitor,691,"Just linked this in the forums as well, but if you can define how you want to draw the annotation within a text file (groovy script) you might be able to use:; https://groups.google.com/forum/#!searchin/qupath-users/command$20line$20|sort:date/qupath-users/lE5AJDcxA28/JR0UouPLAAAJ; to get started. The following positions the viewer (although you need to create the viewer first, see the whole file in the link below):; ```; viewer.setDownsampleFactor(downsample); viewer.setCenterPixelLocation(xCoordinate, yCoordinate);; ```; from: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054#file-slide-explore-groovy; which was modified from who knows where... I think Pete's memory monitor. Exporting simple annotations as coordinate arrays is fairly straightforward (and definitely on the forums somewhere), but I am not as sure about XML formatting...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/173#issuecomment-389972084
https://github.com/qupath/qupath/issues/173#issuecomment-389972084:710,Usability,simpl,simple,710,"Just linked this in the forums as well, but if you can define how you want to draw the annotation within a text file (groovy script) you might be able to use:; https://groups.google.com/forum/#!searchin/qupath-users/command$20line$20|sort:date/qupath-users/lE5AJDcxA28/JR0UouPLAAAJ; to get started. The following positions the viewer (although you need to create the viewer first, see the whole file in the link below):; ```; viewer.setDownsampleFactor(downsample); viewer.setCenterPixelLocation(xCoordinate, yCoordinate);; ```; from: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054#file-slide-explore-groovy; which was modified from who knows where... I think Pete's memory monitor. Exporting simple annotations as coordinate arrays is fairly straightforward (and definitely on the forums somewhere), but I am not as sure about XML formatting...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/173#issuecomment-389972084
https://github.com/qupath/qupath/issues/174#issuecomment-390186531:444,Availability,down,down,444,"Hi Adam, the problem is access to the images - for which I can see you're using a custom extension, and not something that's part of QuPath itself. I got an email about this issue a while back; the conclusion then was that if you can access the .svs image files directly, rather than via the extension, the problem should go away. I'll close the issue here because it isn't really within QuPath itself. If you can send me an email (or track me down on ResearchGate, LinkedIn, Twitter or elsewhere) then I can discuss it further there. The missing annotations thing is a bit of a mystery, and may or may not be connected. If you can find a way to reproduce it please let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/174#issuecomment-390186531
https://github.com/qupath/qupath/issues/174#issuecomment-390186531:24,Security,access,access,24,"Hi Adam, the problem is access to the images - for which I can see you're using a custom extension, and not something that's part of QuPath itself. I got an email about this issue a while back; the conclusion then was that if you can access the .svs image files directly, rather than via the extension, the problem should go away. I'll close the issue here because it isn't really within QuPath itself. If you can send me an email (or track me down on ResearchGate, LinkedIn, Twitter or elsewhere) then I can discuss it further there. The missing annotations thing is a bit of a mystery, and may or may not be connected. If you can find a way to reproduce it please let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/174#issuecomment-390186531
https://github.com/qupath/qupath/issues/174#issuecomment-390186531:234,Security,access,access,234,"Hi Adam, the problem is access to the images - for which I can see you're using a custom extension, and not something that's part of QuPath itself. I got an email about this issue a while back; the conclusion then was that if you can access the .svs image files directly, rather than via the extension, the problem should go away. I'll close the issue here because it isn't really within QuPath itself. If you can send me an email (or track me down on ResearchGate, LinkedIn, Twitter or elsewhere) then I can discuss it further there. The missing annotations thing is a bit of a mystery, and may or may not be connected. If you can find a way to reproduce it please let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/174#issuecomment-390186531
https://github.com/qupath/qupath/issues/175#issuecomment-391612905:82,Testability,log,log,82,Are you using QuPath v0.1.2?; Does anything useful appear under *View &rarr; Show log*?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391612905
https://github.com/qupath/qupath/issues/175#issuecomment-391972148:45,Testability,Log,Log,45,Yes it is Version v0.1.2. ; I try to get the Log information. It is not my own computer.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391972148
https://github.com/qupath/qupath/issues/175#issuecomment-391973431:242,Deployability,configurat,configuration,242,"My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either. There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example). I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391973431
https://github.com/qupath/qupath/issues/175#issuecomment-391973431:287,Deployability,install,installation,287,"My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either. There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example). I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391973431
https://github.com/qupath/qupath/issues/175#issuecomment-391973431:242,Modifiability,config,configuration,242,"My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either. There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example). I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391973431
https://github.com/qupath/qupath/issues/175#issuecomment-391973431:470,Testability,test,tested,470,"My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either. There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example). I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391973431
https://github.com/qupath/qupath/issues/175#issuecomment-391974886:143,Deployability,install,installed,143,"thanks for link and idea. ; I personally do not have access to this computer. Pity :); But what I remember is, that for example the person who installed QuPath deleted the QuPath folder in the user folder. ; As far as I understood the text in the linked page, that seems not to be the reason. But maybe he changed also something else that I did not find. . In case I find the reason, I will post it here. . For now, the person in charge seems to prefer just to reinstall and see what happens.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391974886
https://github.com/qupath/qupath/issues/175#issuecomment-391974886:430,Energy Efficiency,charge,charge,430,"thanks for link and idea. ; I personally do not have access to this computer. Pity :); But what I remember is, that for example the person who installed QuPath deleted the QuPath folder in the user folder. ; As far as I understood the text in the linked page, that seems not to be the reason. But maybe he changed also something else that I did not find. . In case I find the reason, I will post it here. . For now, the person in charge seems to prefer just to reinstall and see what happens.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391974886
https://github.com/qupath/qupath/issues/175#issuecomment-391974886:53,Security,access,access,53,"thanks for link and idea. ; I personally do not have access to this computer. Pity :); But what I remember is, that for example the person who installed QuPath deleted the QuPath folder in the user folder. ; As far as I understood the text in the linked page, that seems not to be the reason. But maybe he changed also something else that I did not find. . In case I find the reason, I will post it here. . For now, the person in charge seems to prefer just to reinstall and see what happens.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-391974886
https://github.com/qupath/qupath/issues/175#issuecomment-404452989:18,Usability,feedback,feedback,18,I did not get any feedback anymore. The issue can be closed.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-404452989
https://github.com/qupath/qupath/issues/175#issuecomment-644769313:251,Deployability,configurat,configuration,251,"> My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either.; > ; > There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example).; > ; > I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem. I had a look in the QuPath.cfg file and reallocated the memory from 50% to 100%. ; This worked. Thanks for the help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-644769313
https://github.com/qupath/qupath/issues/175#issuecomment-644769313:296,Deployability,install,installation,296,"> My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either.; > ; > There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example).; > ; > I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem. I had a look in the QuPath.cfg file and reallocated the memory from 50% to 100%. ; This worked. Thanks for the help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-644769313
https://github.com/qupath/qupath/issues/175#issuecomment-644769313:251,Modifiability,config,configuration,251,"> My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either.; > ; > There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example).; > ; > I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem. I had a look in the QuPath.cfg file and reallocated the memory from 50% to 100%. ; This worked. Thanks for the help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-644769313
https://github.com/qupath/qupath/issues/175#issuecomment-644769313:486,Testability,test,tested,486,"> My best guess is that it's related to user permissions. But I really don't know - I haven't seen this either.; > ; > There's also one obscure tip that might be relevant at the very bottom of [this page](https://github.com/qupath/qupath/wiki/Paths-&-configuration). Basically, inside the QuPath installation there should be a file `QuPath.cfg`. You could try opening that in a plain text editor and on a line below [JVMOptions] adding `-Xmx8G` for 8 GB (for example).; > ; > I haven't tested this to check it works, but then my memory settings are being read from my preferences so I can't replicate the exact problem. I had a look in the QuPath.cfg file and reallocated the memory from 50% to 100%. ; This worked. Thanks for the help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/175#issuecomment-644769313
https://github.com/qupath/qupath/issues/176#issuecomment-394919066:569,Availability,down,downsampleFactor,569,"I was able to find your example script located here. https://groups.google.com/forum/#!searchin/qupath-users/macro%7Csort:date/qupath-users/C3GRBF614N8/iewaOLGDAgAJ. ```; import qupath.imagej.plugins.ImageJMacroRunner; import qupath.lib.plugins.parameters.ParameterList. // Create a macro runner so we can check what the parameter list contains; def params = new ImageJMacroRunner(getQuPath()).getParameterList(); print ParameterList.getParameterListJSON(params, ' '). // Change the value of a parameter, using the JSON to identify the key; params.getParameters().get('downsampleFactor').setValue(4.0 as double); print ParameterList.getParameterListJSON(params, ' '). // Get the macro text and other required variables; def macro = 'print(""Overlay size: "" + Overlay.size)'; def imageData = getCurrentImageData(); def annotations = getAnnotationObjects(). // Loop through the annotations and run the macro; for (annotation in annotations) {; ImageJMacroRunner.runMacro(params, imageData, null, annotation, macro); }; print 'Done!'. ```; and replaced the ; `def macro = 'print(""Overlay size: "" + Overlay.size)'` ; with ; `def macro = new File(""myMacroPath/MacroName.ijm"").text`. and it worked!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/176#issuecomment-394919066
https://github.com/qupath/qupath/issues/176#issuecomment-394919066:192,Modifiability,plugin,plugins,192,"I was able to find your example script located here. https://groups.google.com/forum/#!searchin/qupath-users/macro%7Csort:date/qupath-users/C3GRBF614N8/iewaOLGDAgAJ. ```; import qupath.imagej.plugins.ImageJMacroRunner; import qupath.lib.plugins.parameters.ParameterList. // Create a macro runner so we can check what the parameter list contains; def params = new ImageJMacroRunner(getQuPath()).getParameterList(); print ParameterList.getParameterListJSON(params, ' '). // Change the value of a parameter, using the JSON to identify the key; params.getParameters().get('downsampleFactor').setValue(4.0 as double); print ParameterList.getParameterListJSON(params, ' '). // Get the macro text and other required variables; def macro = 'print(""Overlay size: "" + Overlay.size)'; def imageData = getCurrentImageData(); def annotations = getAnnotationObjects(). // Loop through the annotations and run the macro; for (annotation in annotations) {; ImageJMacroRunner.runMacro(params, imageData, null, annotation, macro); }; print 'Done!'. ```; and replaced the ; `def macro = 'print(""Overlay size: "" + Overlay.size)'` ; with ; `def macro = new File(""myMacroPath/MacroName.ijm"").text`. and it worked!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/176#issuecomment-394919066
https://github.com/qupath/qupath/issues/176#issuecomment-394919066:237,Modifiability,plugin,plugins,237,"I was able to find your example script located here. https://groups.google.com/forum/#!searchin/qupath-users/macro%7Csort:date/qupath-users/C3GRBF614N8/iewaOLGDAgAJ. ```; import qupath.imagej.plugins.ImageJMacroRunner; import qupath.lib.plugins.parameters.ParameterList. // Create a macro runner so we can check what the parameter list contains; def params = new ImageJMacroRunner(getQuPath()).getParameterList(); print ParameterList.getParameterListJSON(params, ' '). // Change the value of a parameter, using the JSON to identify the key; params.getParameters().get('downsampleFactor').setValue(4.0 as double); print ParameterList.getParameterListJSON(params, ' '). // Get the macro text and other required variables; def macro = 'print(""Overlay size: "" + Overlay.size)'; def imageData = getCurrentImageData(); def annotations = getAnnotationObjects(). // Loop through the annotations and run the macro; for (annotation in annotations) {; ImageJMacroRunner.runMacro(params, imageData, null, annotation, macro); }; print 'Done!'. ```; and replaced the ; `def macro = 'print(""Overlay size: "" + Overlay.size)'` ; with ; `def macro = new File(""myMacroPath/MacroName.ijm"").text`. and it worked!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/176#issuecomment-394919066
https://github.com/qupath/qupath/issues/176#issuecomment-394919066:709,Modifiability,variab,variables,709,"I was able to find your example script located here. https://groups.google.com/forum/#!searchin/qupath-users/macro%7Csort:date/qupath-users/C3GRBF614N8/iewaOLGDAgAJ. ```; import qupath.imagej.plugins.ImageJMacroRunner; import qupath.lib.plugins.parameters.ParameterList. // Create a macro runner so we can check what the parameter list contains; def params = new ImageJMacroRunner(getQuPath()).getParameterList(); print ParameterList.getParameterListJSON(params, ' '). // Change the value of a parameter, using the JSON to identify the key; params.getParameters().get('downsampleFactor').setValue(4.0 as double); print ParameterList.getParameterListJSON(params, ' '). // Get the macro text and other required variables; def macro = 'print(""Overlay size: "" + Overlay.size)'; def imageData = getCurrentImageData(); def annotations = getAnnotationObjects(). // Loop through the annotations and run the macro; for (annotation in annotations) {; ImageJMacroRunner.runMacro(params, imageData, null, annotation, macro); }; print 'Done!'. ```; and replaced the ; `def macro = 'print(""Overlay size: "" + Overlay.size)'` ; with ; `def macro = new File(""myMacroPath/MacroName.ijm"").text`. and it worked!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/176#issuecomment-394919066
https://github.com/qupath/qupath/issues/177#issuecomment-398244678:486,Integrability,depend,depending,486,"I can think of easy enough ways to get the single horseshoe idea to work, but it sounds like you would want this to find multiple holes and interconnect them all, and the outside of the exterior polygon? At that point you need something like nearest neighbors to find the closest vertices of all of the inner polygons, and after that connect the inner polygons to the outer polygon using another nearest neighbors based on the entire interior structure... And this could get really bad depending on how many vertices were on the outer polygon (open up a massive highway if two vertices are far enough apart due to smoothing or the edge of an image/slide). Maybe a safer way would be to create very thin (1 pixel wide) rectangles between single vertices and subtract annotations? Just kind of spitballing here. I do not have enough experience digging into AWT polygons to know the structure of the vertices.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/177#issuecomment-398244678
https://github.com/qupath/qupath/issues/177#issuecomment-398244678:664,Safety,safe,safer,664,"I can think of easy enough ways to get the single horseshoe idea to work, but it sounds like you would want this to find multiple holes and interconnect them all, and the outside of the exterior polygon? At that point you need something like nearest neighbors to find the closest vertices of all of the inner polygons, and after that connect the inner polygons to the outer polygon using another nearest neighbors based on the entire interior structure... And this could get really bad depending on how many vertices were on the outer polygon (open up a massive highway if two vertices are far enough apart due to smoothing or the edge of an image/slide). Maybe a safer way would be to create very thin (1 pixel wide) rectangles between single vertices and subtract annotations? Just kind of spitballing here. I do not have enough experience digging into AWT polygons to know the structure of the vertices.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/177#issuecomment-398244678
https://github.com/qupath/qupath/issues/177#issuecomment-401276047:1083,Integrability,interoperab,interoperability,1083,"I guess since the split method gives you the arrays for the exterior polygons and for the holes, you could do an exhaustive search for the pair of vertices where one of the points on the exterior is closest to a point on the interior. Then insert the interior points into the exterior polygon's list of vertices and... see how that looks. It sounds like you've been able to get all the data out of QuPath, and now it becomes a problem to solve elsewhere. Not sure how much influence you have on the server, but getting it to support GeoJSON/shapes with holes would sound more rewarding... albeit potentially difficult. I can definitely envisage writing a generic GeoJSON exporter for QuPath ROIs; that sounds like something worthwhile (related to the recent discussion on [shapefiles](https://github.com/qupath/qupath/issues/95#issuecomment-395886486)). This has been on my personal todo list for a while, but pretty low priority as I don't have a specific need for it at the minute - and nor do I know of anyone with such a need. It would definitely be higher priority it it helped interoperability with software for some genuinely useful purpose. But I'm not sure if it would help much in your case, unless you can get your server to support GeoJSON.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/177#issuecomment-401276047
https://github.com/qupath/qupath/issues/178#issuecomment-398618472:20,Integrability,depend,depends,20,"It is possible, but depends on how regular the sequential sections are. I have seen it done before, but the registration was not done in QuPath. You can definitely take whole sets of objects and alter their position by translation and rotation, but determining how much of a translation and rotation are needed are somewhat up to you. In short, I would recommend finding an external solutions to match up your images as perfectly as possible, and then you can copy and paste your detections between images, and use ""Add Intensity Features"" for whole cell measurements [or a script ](https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-nuclear-and-cytoplasmic-color-vector-means-groovy) for cytoplams/nuclear measurements to generate values using the new image data. Further information, though much of it references each other.; https://github.com/qupath/qupath/issues/171; https://github.com/qupath/qupath/issues/162. A couple of posts on image registration in general.; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/5-JMvmCKRBo/6NeAyDwsBQAJ; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/VLJL6UCXqEk/lvu6LO0bBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398618472
https://github.com/qupath/qupath/issues/178#issuecomment-398618472:480,Safety,detect,detections,480,"It is possible, but depends on how regular the sequential sections are. I have seen it done before, but the registration was not done in QuPath. You can definitely take whole sets of objects and alter their position by translation and rotation, but determining how much of a translation and rotation are needed are somewhat up to you. In short, I would recommend finding an external solutions to match up your images as perfectly as possible, and then you can copy and paste your detections between images, and use ""Add Intensity Features"" for whole cell measurements [or a script ](https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-nuclear-and-cytoplasmic-color-vector-means-groovy) for cytoplams/nuclear measurements to generate values using the new image data. Further information, though much of it references each other.; https://github.com/qupath/qupath/issues/171; https://github.com/qupath/qupath/issues/162. A couple of posts on image registration in general.; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/5-JMvmCKRBo/6NeAyDwsBQAJ; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/VLJL6UCXqEk/lvu6LO0bBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398618472
https://github.com/qupath/qupath/issues/178#issuecomment-398666277:1560,Modifiability,plugin,plugins,1560,"@AnthonyOrvedahl Figuring out the rotation or adjustments necessary to make the cells overlap is a difficult problem to solve, and beyond the scope of QuPath currently. Potentially anything is possible, since QuPath is open source and supports scripts and extensions, and so someone might take on the task of adding this functionality in the future. I have looked a bit into aligning slides to transfer larger regions, but the kind of fine-grained alignment necessary for cell-by-cell measurements is much more awkward and it isn't something I am actively working on myself. As @Svidro says, if you take care of registering the slides elsewhere then it may well be possible to hack together something in QuPath to transfer the detected cells and that could be useful... but it would take some effort and would probably not be ideal in terms of workflow or accuracy. Two other ways in which QuPath might help with looking at multiple markers per cell:; * Support for brightfield and fluorescence multiplexing; * Ability to align restained sections of the same tissue. Both are things I'm looking to add or improve in QuPath. To some extent, the first is already present; a nice solution for the second one would also them mean better support for images registered-outside-of-QuPath... but it's not quite there yet. One other things: if you've any screenshots of example images that would be helpful. I've assumed you're working with brightfield whole slide images. Registering smaller image regions is more doable, as there are a range of relevant registration plugins within [Fiji](https://imagej.net/Registration).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398666277
https://github.com/qupath/qupath/issues/178#issuecomment-398666277:727,Safety,detect,detected,727,"@AnthonyOrvedahl Figuring out the rotation or adjustments necessary to make the cells overlap is a difficult problem to solve, and beyond the scope of QuPath currently. Potentially anything is possible, since QuPath is open source and supports scripts and extensions, and so someone might take on the task of adding this functionality in the future. I have looked a bit into aligning slides to transfer larger regions, but the kind of fine-grained alignment necessary for cell-by-cell measurements is much more awkward and it isn't something I am actively working on myself. As @Svidro says, if you take care of registering the slides elsewhere then it may well be possible to hack together something in QuPath to transfer the detected cells and that could be useful... but it would take some effort and would probably not be ideal in terms of workflow or accuracy. Two other ways in which QuPath might help with looking at multiple markers per cell:; * Support for brightfield and fluorescence multiplexing; * Ability to align restained sections of the same tissue. Both are things I'm looking to add or improve in QuPath. To some extent, the first is already present; a nice solution for the second one would also them mean better support for images registered-outside-of-QuPath... but it's not quite there yet. One other things: if you've any screenshots of example images that would be helpful. I've assumed you're working with brightfield whole slide images. Registering smaller image regions is more doable, as there are a range of relevant registration plugins within [Fiji](https://imagej.net/Registration).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398666277
https://github.com/qupath/qupath/issues/179#issuecomment-399142573:303,Availability,down,down,303,"There are a few options:; * Get the measurements from *Measure &rarr; Show annotation measurements*, copy them into a spreadsheet and add them up there; * When you're drawing with the *Brush* tool (or the *Wand* might be nicer, if you have good contrast between the purple stain and surroundings), hold down *Shift* to append to an existing annotation - if you're pressing *Shift*, different regions can be discontinuous but still counted as one (similarly, you can hold down *Alt* to use the *Brush* or *Wand* and subtract regions); * Select all the annotations (either in the *Annotations* pane on the left, or by alt-clicking on them with the *Move* tool selected in the main image), right-click on the image and choose *Annotations &rarr; Merge selected annotations*. Hopefully one of those helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399142573
https://github.com/qupath/qupath/issues/179#issuecomment-399142573:471,Availability,down,down,471,"There are a few options:; * Get the measurements from *Measure &rarr; Show annotation measurements*, copy them into a spreadsheet and add them up there; * When you're drawing with the *Brush* tool (or the *Wand* might be nicer, if you have good contrast between the purple stain and surroundings), hold down *Shift* to append to an existing annotation - if you're pressing *Shift*, different regions can be discontinuous but still counted as one (similarly, you can hold down *Alt* to use the *Brush* or *Wand* and subtract regions); * Select all the annotations (either in the *Annotations* pane on the left, or by alt-clicking on them with the *Move* tool selected in the main image), right-click on the image and choose *Annotations &rarr; Merge selected annotations*. Hopefully one of those helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399142573
https://github.com/qupath/qupath/issues/179#issuecomment-399149480:1081,Availability,down,down,1081,"Hi Pete,. That's very helpful, thanks a lot ! It will make my analysis way faster. Sincerely,. GOEPP Julie; Manager of the Primary Airway Cell Biobank (PACB); Cystic Fibrosis Translational Research Center (CFTRc)<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>; McGill University - Department of Physiology; McIntyre Building, Room 1012; 3655 Promenade Sir William Osler; Montreal – Qc – Canada – H3G 1Y6; (514) 398-4323 (ext #2 or 3); PACB Website<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>. ________________________________; De : Pete <notifications@github.com>; Envoyé : 21 juin 2018 11:23:17; À : qupath/qupath; Cc : Julie Goepp, Ms; Author; Objet : Re: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). There are a few options:. * Get the measurements from Measure → Show annotation measurements, copy them into a spreadsheet and add them up there; * When you're drawing with the Brush tool (or the Wand might be nicer, if you have good contrast between the purple stain and surroundings), hold down Shift to append to an existing annotation - if you're pressing Shift, different regions can be discontinuous but still counted as one (similarly, you can hold down Alt to use the Brush or Wand and subtract regions); * Select all the annotations (either in the Annotations pane on the left, or by alt-clicking on them with the Move tool selected in the main image), right-click on the image and choose Annotations → Merge selected annotations. Hopefully one of those helps!. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/179#issuecomment-399142573>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AmmAR_KTr2VFQD77eEVrU9ppSThbe9tKks5t-7pkgaJpZM4UyRk4>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399149480
https://github.com/qupath/qupath/issues/179#issuecomment-399149480:1245,Availability,down,down,1245,"Hi Pete,. That's very helpful, thanks a lot ! It will make my analysis way faster. Sincerely,. GOEPP Julie; Manager of the Primary Airway Cell Biobank (PACB); Cystic Fibrosis Translational Research Center (CFTRc)<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>; McGill University - Department of Physiology; McIntyre Building, Room 1012; 3655 Promenade Sir William Osler; Montreal – Qc – Canada – H3G 1Y6; (514) 398-4323 (ext #2 or 3); PACB Website<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>. ________________________________; De : Pete <notifications@github.com>; Envoyé : 21 juin 2018 11:23:17; À : qupath/qupath; Cc : Julie Goepp, Ms; Author; Objet : Re: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). There are a few options:. * Get the measurements from Measure → Show annotation measurements, copy them into a spreadsheet and add them up there; * When you're drawing with the Brush tool (or the Wand might be nicer, if you have good contrast between the purple stain and surroundings), hold down Shift to append to an existing annotation - if you're pressing Shift, different regions can be discontinuous but still counted as one (similarly, you can hold down Alt to use the Brush or Wand and subtract regions); * Select all the annotations (either in the Annotations pane on the left, or by alt-clicking on them with the Move tool selected in the main image), right-click on the image and choose Annotations → Merge selected annotations. Hopefully one of those helps!. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/179#issuecomment-399142573>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AmmAR_KTr2VFQD77eEVrU9ppSThbe9tKks5t-7pkgaJpZM4UyRk4>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399149480
https://github.com/qupath/qupath/issues/179#issuecomment-399192393:2085,Availability,down,down,2085,"ath/qupath; qupath/qupath; Cc : Author; Objet : RE: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). Hi Pete,. That's very helpful, thanks a lot ! It will make my analysis way faster. Sincerely,. GOEPP Julie; Manager of the Primary Airway Cell Biobank (PACB); Cystic Fibrosis Translational Research Center (CFTRc)<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>; McGill University - Department of Physiology; McIntyre Building, Room 1012; 3655 Promenade Sir William Osler; Montreal – Qc – Canada – H3G 1Y6; (514) 398-4323 (ext #2 or 3); PACB Website<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>. ________________________________; De : Pete <notifications@github.com>; Envoyé : 21 juin 2018 11:23:17; À : qupath/qupath; Cc : Julie Goepp, Ms; Author; Objet : Re: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). There are a few options:. * Get the measurements from Measure → Show annotation measurements, copy them into a spreadsheet and add them up there; * When you're drawing with the Brush tool (or the Wand might be nicer, if you have good contrast between the purple stain and surroundings), hold down Shift to append to an existing annotation - if you're pressing Shift, different regions can be discontinuous but still counted as one (similarly, you can hold down Alt to use the Brush or Wand and subtract regions); * Select all the annotations (either in the Annotations pane on the left, or by alt-clicking on them with the Move tool selected in the main image), right-click on the image and choose Annotations → Merge selected annotations. Hopefully one of those helps!. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/179#issuecomment-399142573>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AmmAR_KTr2VFQD77eEVrU9ppSThbe9tKks5t-7pkgaJpZM4UyRk4>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399192393
https://github.com/qupath/qupath/issues/179#issuecomment-399192393:2249,Availability,down,down,2249,"ath/qupath; qupath/qupath; Cc : Author; Objet : RE: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). Hi Pete,. That's very helpful, thanks a lot ! It will make my analysis way faster. Sincerely,. GOEPP Julie; Manager of the Primary Airway Cell Biobank (PACB); Cystic Fibrosis Translational Research Center (CFTRc)<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>; McGill University - Department of Physiology; McIntyre Building, Room 1012; 3655 Promenade Sir William Osler; Montreal – Qc – Canada – H3G 1Y6; (514) 398-4323 (ext #2 or 3); PACB Website<http://mcgill.ca/cftrc/platforms/primary-airway-cell-biobank-pacb>. ________________________________; De : Pete <notifications@github.com>; Envoyé : 21 juin 2018 11:23:17; À : qupath/qupath; Cc : Julie Goepp, Ms; Author; Objet : Re: [qupath/qupath] Any way to add area measurement from several bruch tool areas ? (#179). There are a few options:. * Get the measurements from Measure → Show annotation measurements, copy them into a spreadsheet and add them up there; * When you're drawing with the Brush tool (or the Wand might be nicer, if you have good contrast between the purple stain and surroundings), hold down Shift to append to an existing annotation - if you're pressing Shift, different regions can be discontinuous but still counted as one (similarly, you can hold down Alt to use the Brush or Wand and subtract regions); * Select all the annotations (either in the Annotations pane on the left, or by alt-clicking on them with the Move tool selected in the main image), right-click on the image and choose Annotations → Merge selected annotations. Hopefully one of those helps!. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/179#issuecomment-399142573>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AmmAR_KTr2VFQD77eEVrU9ppSThbe9tKks5t-7pkgaJpZM4UyRk4>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399192393
https://github.com/qupath/qupath/issues/179#issuecomment-399201573:280,Deployability,toggle,toggle,280,"If you zoom in more, by default the brush will be effectively smaller and so it's easier to select a region without changing the shape. Of you change just switch to the *Move* tool to select another region by double-clicking on it, without any risk of changing its shape. You can toggle between tools by just pressing `M` and `B`. In general, you might find 'locking' annotations helpful - that helps avoid changing them accidentally, and also allows you to draw _new_ regions inside an existing annotation with the brush. To do so, select the annotation and then right-click on it, and choose *Annotations &rarr; Lock*. Finally, if you are doing a lot of painstaking annotations be sure to save regularly (*Ctrl + S*)... or consider trying the beta/pre-release version [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). Installation is a bit more awkward, but it does provide (limited) undo support along with many other improvements - so may be worth it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399201573
https://github.com/qupath/qupath/issues/179#issuecomment-399201573:754,Deployability,release,release,754,"If you zoom in more, by default the brush will be effectively smaller and so it's easier to select a region without changing the shape. Of you change just switch to the *Move* tool to select another region by double-clicking on it, without any risk of changing its shape. You can toggle between tools by just pressing `M` and `B`. In general, you might find 'locking' annotations helpful - that helps avoid changing them accidentally, and also allows you to draw _new_ regions inside an existing annotation with the brush. To do so, select the annotation and then right-click on it, and choose *Annotations &rarr; Lock*. Finally, if you are doing a lot of painstaking annotations be sure to save regularly (*Ctrl + S*)... or consider trying the beta/pre-release version [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). Installation is a bit more awkward, but it does provide (limited) undo support along with many other improvements - so may be worth it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399201573
https://github.com/qupath/qupath/issues/179#issuecomment-399201573:833,Deployability,update,updates,833,"If you zoom in more, by default the brush will be effectively smaller and so it's easier to select a region without changing the shape. Of you change just switch to the *Move* tool to select another region by double-clicking on it, without any risk of changing its shape. You can toggle between tools by just pressing `M` and `B`. In general, you might find 'locking' annotations helpful - that helps avoid changing them accidentally, and also allows you to draw _new_ regions inside an existing annotation with the brush. To do so, select the annotation and then right-click on it, and choose *Annotations &rarr; Lock*. Finally, if you are doing a lot of painstaking annotations be sure to save regularly (*Ctrl + S*)... or consider trying the beta/pre-release version [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). Installation is a bit more awkward, but it does provide (limited) undo support along with many other improvements - so may be worth it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399201573
https://github.com/qupath/qupath/issues/179#issuecomment-399201573:848,Deployability,Install,Installation,848,"If you zoom in more, by default the brush will be effectively smaller and so it's easier to select a region without changing the shape. Of you change just switch to the *Move* tool to select another region by double-clicking on it, without any risk of changing its shape. You can toggle between tools by just pressing `M` and `B`. In general, you might find 'locking' annotations helpful - that helps avoid changing them accidentally, and also allows you to draw _new_ regions inside an existing annotation with the brush. To do so, select the annotation and then right-click on it, and choose *Annotations &rarr; Lock*. Finally, if you are doing a lot of painstaking annotations be sure to save regularly (*Ctrl + S*)... or consider trying the beta/pre-release version [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). Installation is a bit more awkward, but it does provide (limited) undo support along with many other improvements - so may be worth it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399201573
