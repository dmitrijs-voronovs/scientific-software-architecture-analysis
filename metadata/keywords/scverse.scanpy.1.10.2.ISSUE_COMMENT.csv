quality_attribute,keyword,matched_word,sentence,source,author,repo,version,url
sample,perf,perfectly,Then also DPT will perfectly do its job.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/25#issuecomment-310275631
sample,fast,faster,my dpt runs faster than tSNE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/25#issuecomment-310461316
sample,fast,fast,"- the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/29#issuecomment-321782798
sample,fast,fast,Scanpy is really awesome and fast !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/29#issuecomment-417509829
sample,fast,fast,Things are still progressing fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324338365
sample,fast,faster,"egress_out should be more stable now, but it's not faster yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-344125455
sample,optimiz,optimization,I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135
sample,perf,performance,I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135
sample,perf,performance,I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111
sample,perf,performs,"egress_out`, one performs an additional gene-wise correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/48#issuecomment-347354902
sample,speed,speeding,This only concerns speeding up the reading of slow (e.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346776672
sample,speed,speed,"is already quite old for the speed with which Scanpy evolves, so I probably missed something.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/56#issuecomment-354906745
sample,optimiz,optimized,"I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662
sample,perf,performance,"I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662
sample,fast,fast,I hope that is conveniently fast enough for you (if not let us know).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662
sample,perf,perfectly,"Thanks, the example works perfectly well now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-284644334
sample,fast,fastest,4 minutes wasn’t even my fastest bugfix 😜,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/10#issuecomment-285007753
sample,perf,perform,"It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646
sample,fast,fast,"So, one probably fast computation of this is the following",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/27#issuecomment-314744802
sample,perf,perfectly,"No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33#issuecomment-324471700
sample,fast,fast,It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324589126
sample,fast,fast,Things are progressing very fast and structure and maintenance of the package are becoming more and more professional.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324638985
sample,fast,fastest,That might be the fastest way to achieve this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/84#issuecomment-364918543
sample,speed,speed,I'm confident that I can speed this up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-365873899
sample,perf,perform,rg/) to perform quantitative interference on the directionality of the edges?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/96#issuecomment-393690042
sample,fast,fast,"@falexwolf correct me if i’m wrong, but: i think igraph is just super fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370369405
sample,speed,speed,most of our advertised speed comes from using it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370369405
sample,fast,faster,"@flying-sheep the only thing where `igraph` is used in Scanpy is for graph drawing, where it's incredibly faster than `networkx` (completely forget about `networkx` in this respect); the performant `louvain` implementation is due to the `louvain` package, which simply uses `igraph`'s graph data structures",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215
sample,perf,performant,"@flying-sheep the only thing where `igraph` is used in Scanpy is for graph drawing, where it's incredibly faster than `networkx` (completely forget about `networkx` in this respect); the performant `louvain` implementation is due to the `louvain` package, which simply uses `igraph`'s graph data structures",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215
sample,fast,fastpath,"finalize(categories, ordered, fastpath=False)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fastpath,"y in _finalize(self, categories, ordered, fastpath)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fastpath,--> 335                                                   fastpath=fastpath),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fastpath,--> 335                                                   fastpath=fastpath),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fastpath,"y in validate_categories(categories, fastpath)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fastpath,502         if not fastpath and not is_list_like(categories):,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409
sample,fast,fast,"The reason I used a R-py interface is that there's no decent MNN correct on python yet, and scran's implementation is already fast and efficient enough, and I think this is meant to be an optional feature that provides a handy fix for those in need.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002082
sample,fast,faster,"Now it already runs much faster than the scran version, and I'm planning to add more speedups, eg Cython and CUDA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384268335
sample,speed,speedups,"Now it already runs much faster than the scran version, and I'm planning to add more speedups, eg Cython and CUDA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384268335
sample,speed,speedup,"So, I'd recommend to use numba if you need to speedup something.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384310269
sample,optimiz,optimize,"There is still much to optimize, according to my tests, the 'adjust variance' step takes most time, and the best solution may still be rewriting it in C, as scran did, although somehow they made it single-threaded.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384385090
sample,perf,perfect,"Yes perfect, thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/145#issuecomment-386718360
sample,fast,fastgenomics,fastgenomics/scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-390604622
sample,fast,faster,"My bandwidth is limited these days, I will certainly do it at some point, but it's faster if you do it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420332760
sample,perf,performance,"I was looking at the scanpy function to compute the mean and variance an noticed that it had some comments inside, pointing to performance issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392049026
sample,perf,perfectly,It works perfectly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/165#issuecomment-393891243
sample,perf,performed,"091) says ""MNN correction improves differential expression analyses, After batch correction is performed, the corrected expression values can be used in routine downstream analyses such as clustering prior to differential gene expression identification"" in his Nature Biotech paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173
sample,perf,performed,"Typically batch correction or data integration methods would be used to obtain good clustering of the data, however once differential testing is performed it is still unclear whether the corrected data can or should be used (no batch correction method is perfect and may overcorrect).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806
sample,perf,perfect,"Typically batch correction or data integration methods would be used to obtain good clustering of the data, however once differential testing is performed it is still unclear whether the corrected data can or should be used (no batch correction method is perfect and may overcorrect).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806
sample,perf,perform,Could you tell us how to perform it with scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-396115524
sample,perf,performing,"and batch correction generally takes log-normalized data, so the data you have before performing this function will be log-normalized most of the time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/172#issuecomment-398721208
sample,optimiz,optimization,"This may possibly change in the future, as we haven't focused on hard optimization yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-398857838
sample,fast,fast,guess a wrapper should be something fast to implement :) I was thinking,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-492392283
sample,optimiz,optimizing,"I'm not sure whether this is fundamentally solvable - optimizing an embedding is a very hard task and UMAP has the best approach to this so far - this is one of the reasons why we came up with PAGA, which is not affected by these problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/174#issuecomment-398681291
sample,perf,performs,"the validation doesn't exist in this problem space, isn't sufficiently comprehensive/relevant, performs poorly against other fundamentally sound methodologies, or has such restrictive assumptions it isn't broadly useful/applicable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893
sample,perf,performance,"Instead I'd like to have an open discussion about the benefits, limitations, and relative performance of the various imputation methods available with the goal leading to something like @gokceneraslan suggested.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893
sample,speed,speedup,"Also, I wouldn't have thought that the speedup would be so dramatic,  but of course, already for better memory efficiency we should have done it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196
sample,speed,speedup,a huge speedup and better convergence if you install `Multicore-tSNE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999
sample,optimiz,optimization,"If the cost function increases during initial optimization,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999
sample,optimiz,optimization,"optimization, the early exaggeration factor or the learning rate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999
sample,optimiz,optimization,Change this to use different intial states for the optimization.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999
sample,fast,faster,"Yes, `n_jobs>2` will be faster as computations are done in parallel.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/194#issuecomment-404259032
sample,optimiz,optimizes,"I'd say it doesn't actually make a lot of sense to use the silhouette coefficient for evaluation: the Louvain algorithm optimizes modularity, which you can view as the graph-based version of a silhouette coefficient (""ratio"" of intra-cluster edges versus inter-cluster edges as compared to intra-cluster distances vs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/223#issuecomment-409829464
sample,optimiz,optimization,As the clustering is an optimization of the modularity I would argue it makes little sense to use modularity to evaluate the clustering again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/223#issuecomment-409960942
sample,optimiz,optimize,"Especially at different resolutions, the modularity values you obtain are not really comparable (as the resolution parameter is introduced to not optimize pure modularity and get the same result you would otherwise get at resolution 1).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/223#issuecomment-409960942
sample,optimiz,optimization,It would then just be an assessment of the approach of using a KNN graph and modularity optimization.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/223#issuecomment-409960942
sample,optimiz,optimization,modularity optimization at a fixed resolution).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/223#issuecomment-409960942
sample,perf,perform,It may also perform worse as you are putting more emphasis on the euclidean distances between transcriptomes than you may want (are the values more important or only the order of the distances?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-415853701
sample,perf,perform,"I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-415956113
sample,perf,perform,"Using protein-protein interaction data, I've noticed that similarity scores perform worse than using network neighbourhoods based on cutoffs to cluster data (this does not have to be the case for scRNA-seq of course).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676
sample,perf,performs,"@fidelram So based on that could you say that the non-weighted method performs better for cluster 10 (PNEC/Brush cluster) as it is identified in this partition, but merged with other cells in cluster 3 in the weighted partition?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416207545
sample,perf,perform,"I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777
sample,optimiz,optimization,"When I say ""representation"", I mean a feature space representation, which is directly amenable to differentiable mappings, hence optimization and learning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-424802342
sample,speed,speed,"It has a client-side cache system to speed up multiple look-ups, but that can be turned off to limit client-side memory usage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-460942661
sample,fast,fast,It should be as fast as it possibly gets.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422092425
sample,perf,perfectly,"I'd merge immediately, things seem to work perfectly now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425450932
sample,perf,perfect,"Just one tiny cosmetic thing; for these scatter plots, don't you think it would be nice to have them be a perfect square?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425450932
sample,perf,perfect,"I guess it's really also totally fine if things are no perfect squares anymore, really just change it if you feel it's easy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425451588
sample,speed,speed,"I'd like to think there are repeated computations (like layout) some memoization could speed up, but haven't figured out how.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426852062
sample,optimiz,optimized,"The matplotlib scatter function takes care of the layout, but I don't see how this can be further optimized.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426894394
sample,optimiz,optimization,"From `%prun`, it looks like about half of `matplotlib`'s plotting time is spent figuring out where to put points, and the extents of the plot, so I figured that could be a good target for optimization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-427228991
sample,optimiz,optimized,@ivirshup For what you want we need to look into bokeh or plotly as they are optimized to render thousands of points quickly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-427291301
sample,fast,faster,"Right now, everyone working with up to 1M cells should do it in memory; it's just incredibly much faster and a few 10GBs of memory of 1M cells  on a server are no problem these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422100623
sample,perf,performs,So I'd assume that it'd be some work to wrap sklearn's CCA or pyrcca so that it performs similar to Seurat's CCA on single cell data.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-424548158
sample,perf,perform,4810         # perform the reindex on the axes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683
sample,speed,speed,"I don't know why @tcallies added the wilcoxon this way at the time, but I assume for speed and memory reasons.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589
sample,speed,speed,"I'm merging this but will restore the previous Wilcoxon implementation, for speed reasons.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427480716
sample,speed,speed,It's highly competitive in terms of speed and accuracy with other libraries (https://github.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649
sample,optimiz,optimization,that shows how little I think about optimization ^^.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427379020
sample,perf,perform,raise Exception('Cannot perform logistic regression on a single cluster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427093467
sample,optimiz,optimizes,"Louvain method optimizes global modularity but, as other methods, may miss some “true” communities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/279#issuecomment-426898375
sample,optimiz,optimization,"If that's the case, it's just about imperfect optimization, which is expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/279#issuecomment-426950213
sample,perf,perfectly,"Just tested, works perfectly with the main command.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-484503926
sample,perf,performed,"ca(adata, **params)` is then performed on the those hvg per default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-428513659
sample,perf,performed,"are usually performed on PCA space, they implicitly use hvg as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-428513659
sample,fast,fast,"@flying-sheep: I'm not worrying about the build time of the docs, that's decently fast in all my tests so far.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/302#issuecomment-441766825
sample,perf,performance,I'd have thought that it could be this line that brings considerable performance gain (I sent you the reference in an email some time ago):,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441476938
sample,fast,faster,Now it seems like the problem in the recursion as reading simple files with pre-specified paths is faster and takes less memory.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441478499
sample,perf,performance,"But I hope that this won't be a performance bottleneck, as it's all small-scale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441478797
sample,speed,speedup,"This should change with their next release, and give some speedup here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663
sample,perf,performance,"Since summing over a matrix is likely a pretty light computation compared to what follows, I don't think there's a strong performance argument for keeping it as the default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-436161904
sample,optimiz,optimize,"No problem, gave a chance to optimize the code a bit (peak memory was about 3x AnnData size, now down to about 2x).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-437745410
sample,perf,perfectly,"It works perfectly, don't know how I missed that in the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/347#issuecomment-436545082
sample,perf,performance,Hashsolo performance was comparable with other methods but is able to recover cell types with lower CMO counts.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008
sample,fast,fast,"Hm, yes it's nice that things are simpler now, but the point of the script before was to use the fast installation of the conda binaries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463
sample,speed,speed,"Well, so essentially, this PR reversed what I did quite some time ago to speed up the CI.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439747800
sample,fast,fast,"CircleCI claims to be super fast, can be considered maybe no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439755698
sample,speed,speed,"> Well, so essentially, this PR reversed what I did quite some time ago to speed up the CI.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439811200
sample,speed,speed,"Test times now are really nice, in particular, as I can easily speed them up further.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439837732
sample,fast,fast,The former is fast to add (though I didn't see it in the R implementation?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/364#issuecomment-1372358911
sample,fast,fast,The former is fast to add (though I didn't see it in the R implementation?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/364#issuecomment-1372378914
sample,fast,fast,"Yes, I totally agree that creating a fast implementation is probably not straightforward.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/364#issuecomment-1372444139
sample,perf,perfectly,"This is perfectly the canonical way it should look like - I thought that instead of 'Group1', you'd have a list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-439836100
sample,perf,perfectly,This is all looks fine and should work perfectly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440391801
sample,perf,perfectly,` perfectly solves this problem :+1:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/368#issuecomment-439971336
sample,perf,performance,"om/theislab/scanpy/commit/cee23dc13cf2b77d8e23ee0f91eb55fac0e35ed8, sorry confounded with some style change); it would be nice to have a link to your performance benchmarks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889
sample,fast,fast,This is really a bug that should be solved fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/372#issuecomment-441022399
sample,perf,performance,"However, doing so has a performance hit and requires flawless annotations (because if the annotations were wrong, that *would* start suddenly throwing errors)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441252542
sample,perf,performance,"Has a performance hit (as said) but given proper type hints, it makes your code safer and the error messages better (“Function blah excepted a parameter foo of type Bar, but you passed a foo of type Baz”)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142
sample,perf,performance,"But likely, I'll keep playing around and reading documentation of packages using shift-tab in jupyter and develop using emacs relatively plain (there were times when I worked with quite some extensions, but these days, I'm back to almost plain for performance reasons - I know that's probably not smart, but anyways).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441472798
sample,fast,fast,so no “move fast and break things” but instead to identify problems and fix them before they occur.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441590874
sample,fast,faster,"I meant that it needs a bit of imagination to put other things in there than actual gene symbols, but I feel like it’s faster to see!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441589801
sample,fast,faster,"I meant that it needs a bit of imagination to put other things in there than actual gene symbols, but I feel like it’s faster to see!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441598874
sample,fast,fastest,I am not sure if it uses the fastest way to export the matrix to text and whether it wastes memory.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/382#issuecomment-443216376
sample,perf,performance,"If there are performance problems, we can still address them in an update.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/382#issuecomment-443398324
sample,fast,faster,It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893
sample,fast,faster,> It’s both mecessary and faster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446235136
sample,perf,perform,bs` variable with the two groups and the perform `sc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
sample,perf,performs,"tml) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
sample,perf,perform,"For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
sample,perf,performs,"This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
sample,perf,perform,"They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
sample,perf,performing,"om/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
sample,perf,performs,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173
sample,fast,fast,"This field is developing very fast, more and more advanced DE test methos are emerging, it's better to adopt these powerful methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-551411475
sample,fast,fast,"It's fast, and quite versatile.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-635510212
sample,perf,performing,"Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
sample,perf,performance,"There are a couple of sanity checks running in the background, which are easy to call at the beginning of the plotting functions, for instance, if they don't cost performance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/422#issuecomment-456034330
sample,perf,perform,"raise TypeError(""Cannot perform inplace log1p on integer array"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
sample,perf,perfectly,No longer throwing an error is a perfectly fine change!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441
sample,perf,perfectly,I think it's perfectly fine to have this better and more stringent behavior.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-457870095
sample,perf,perform,4354         # perform the reindex on the axes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
sample,perf,perfect,"If the top PCs are enough for you, you get perfect reproducibility, as in the tutorials [clustering](https://scanpy-tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-474290381
sample,perf,performing,"So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293
sample,perf,performance,I think we should use `@njit` to be sure we have compiled performance-critical parts going forward.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/462#issuecomment-461002334
sample,perf,performance,"Maybe the user wants provenance, but maybe they want performance information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
sample,perf,performed,"et_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
sample,perf,perfectly,So at the end this worked perfectly well to export raw data matrix,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468791595
sample,perf,performs,"This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089
sample,perf,perfectly,The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552
sample,speed,speed,"That's a great point, I'll definitely implement that to speed things up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
sample,perf,performing,So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
sample,fast,fast,"(=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476617390
sample,perf,perfectly,"tml#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477
sample,perf,performance,I couldn't see how to easily implement on-disk concatenation on it) and it didn't seem to offer performance gains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487930836
sample,perf,perfectly,"that’s not the issue, forward slashes and relative paths work perfectly on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532
sample,optimiz,optimization,"@gokceneraslan since they are largely the same thing (just a different optimization strategy), do we even need to keep both?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/570#issuecomment-478211254
sample,perf,perfect,But I expect slight variations and no perfect consistence.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219
sample,speed,speed,"in it and is smaller, that is, would speed up tests considerably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054
sample,speed,speeding,* I've been pretty successful at speeding up the tests by just running them in parallel.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348
sample,speed,speeding,> I've been pretty successful at speeding up the tests by just running them in parallel.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
sample,perf,perfectly,"I also don’t see that import error, `import scanpy` works perfectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185
sample,speed,speed,Has anyone compared the two for speed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483172902
sample,fast,faster,"I looked at it a while ago (for one test dataset, probably), and got the impression that `louvain` was faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692
sample,fast,fast,"That said, they're both very fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692
sample,optimiz,optimization,"Also, the most computationally intense part is the embedding optimization, not the graph construction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732
sample,fast,faster,cache=True)                                # write a cache file for faster subsequent reading,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
sample,fast,faster,----> 4     cache=True)                                # write a cache file for faster subsequent reading,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
sample,fast,fast_multiget,"ast_multiget(val, oindex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
sample,fast,faster,"If someone who is having this issue can please provide an example like this, we'll be able to help much faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-497943914
sample,fast,faster,"This will let me play around with their naming scheme and the usefulness a bit more, while scanpy gets the faster, more thorough tests and improved `calculate_qc_metrics`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939
sample,optimiz,optimize,"That said, we're very inefficient about mean and variance calculation, so I think that's a better place to optimize.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802
sample,fast,fast,I initially thought that PCA is such a fast step that much logging is not needed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385
sample,perf,perfectly,"ank_genes_groups_heatmap(pbmc, n_genes=3, standard_scale='var'), you would find it is not aligned perfectly, especially for the local magnified heatmap.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517510719
sample,perf,perform,"You don't want to process all rows, so you can perform either",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098188
sample,perf,performed,I have performed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098188
sample,perf,performance,performance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913
sample,speed,speed,So speed is more than 10X time faster for larger dataset with,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913
sample,fast,faster,So speed is more than 10X time faster for larger dataset with,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913
sample,speed,speed,I understand the benefits of sampling regarding computational speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494314699
sample,perf,perform,What I'm not clear on is how you choose your weights for the calculations you perform here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494314699
sample,speed,speed,> I understand the benefits of sampling regarding computational speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494327494
sample,perf,perform,> you perform here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494327494
sample,perf,perform,"so you sample based on how representative a cell is of its neighbours, and then you use that weight to calculated PCA, marker genes, and perform visualizations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494336456
sample,speed,speed,We'll accept the speed trade-off of backed mode to allow for scalability here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/650#issuecomment-499511619
sample,optimiz,optimize_layout,ptimize_layout`](https://github.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071
sample,perf,performed,"You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928
sample,optimiz,optimize,The other possibility is that you already expect the number of clusters so you can optimize the resolution based on your previous knowledge.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271
sample,optimiz,optimizing,"I think it's totally based on biological knowledge rather than optimizing paramters, like resolution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498057572
sample,perf,performed,- I performed a hyperparameter search for the resolution (steps of 0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
sample,optimiz,optimize,"In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
sample,optimiz,optimizing,"In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
sample,optimiz,optimized,"In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
sample,perf,perform,(Each vector will contain 100K elements) I couldn't even load the matrix into memory to perform any form of dimension reduction.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678
sample,perf,performed,It seems as though Scanpy was smart enough to realize I hadn't performed PCA and thus did it for me using the default settings.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/680#issuecomment-498856082
sample,fast,fast,"Thanks for the fast reply @LuckyMD,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/681#issuecomment-499155259
sample,perf,performing,"However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
sample,perf,performance,"In kBET paper, the performance of ComBat in simple batch correction scenarios is impressive.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-503083216
sample,perf,performance,"If there is a way to improve the performance of scipy version, it might be worth trying",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/698#issuecomment-528512005
sample,speed,speed,I don't think there is a way to speed-up `scipy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/698#issuecomment-528788211
sample,perf,performed,darrays` when operations are performed on them.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/699#issuecomment-504639751
sample,perf,performs,Also note that Combat is a simple batch correction method that performs a linear correction of the batch effect.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527750807
sample,perf,performs,Also note that Combat is a simple batch correction method that performs a linear correction of the batch effect.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527754924
sample,perf,performed,Regressing out should indeed be performed before highly variable gene selection.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/707#issuecomment-505387662
sample,speed,speed,The reason it might not have been done on all genes initially is for speed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/707#issuecomment-505387662
sample,speed,speed,Would you then suggest to regress after subsetting HVGs (for speed reasons) and then re-searching and re-subsetting HVGs after the unwanted source of variation is corrected for?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/707#issuecomment-508908575
sample,perf,perfect,but clearly not perfect coverage.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744
sample,perf,perform,Then you need to perform multiple testing correction over those p-values.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515061065
sample,fast,fastICA,and I tried fastICA from sklearn once but I couldn't obtain similar results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-519089834
sample,fast,fastica,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-519397103
sample,fast,fastICA,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-540475625
sample,perf,performed,`ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-540475625
sample,optimiz,optimized,"The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/792#issuecomment-523824420
sample,perf,perfectly,om/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/792#issuecomment-523843131
sample,optimiz,optimization,But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529235054
sample,optimiz,optimization,But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529329056
sample,optimiz,optimized,"The quality score is modularity, which is optimized.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529377195
sample,optimiz,optimized,"However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529377195
sample,optimiz,optimization,There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088
sample,perf,perfect,"Right now, for example, you can get a perfect quality (=1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088
sample,optimiz,optimization,"After all, that's what the algorithm uses for optimization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088
sample,optimiz,optimization,"tml#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529791688
sample,optimiz,optimizing,"tml#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529791688
sample,optimiz,optimized,"> The quality score is modularity, which is optimized.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529791688
sample,optimiz,optimization,"To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529791688
sample,optimiz,optimized,"To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529791688
sample,optimiz,optimization,"To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529929977
sample,optimiz,optimized,"To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529929977
sample,optimiz,optimization,"If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-531683547
sample,speed,speed,Will greatly increase the speed of most of my analysis workflows 😃,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/823#issuecomment-529470126
sample,speed,speed,This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530432997
sample,speed,speedups,"Wow, nice, those are some impressive speedups!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-530789566
sample,perf,perfectly,"Thanks, that option is very useful and works perfectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/831#issuecomment-531750992
sample,fast,fast,@gokceneraslan - thanks for the fast response.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530530037
sample,fast,fast,> @gokceneraslan - thanks for the fast response.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530659556
sample,perf,perfectly,"hape[1]); the previous three code worked perfectly), I got some error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532502522
sample,perf,perfectly,ank_genes_groups) is not perfectly clear about it:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/842#issuecomment-531820364
sample,fast,fast,"We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499
sample,fast,faster,We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534067279
sample,fast,faster,> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715
sample,fast,faster,"om/COMBINE-lab/EDS) (a binary matrix format), and I wrote a small Rust library to convert it to other formats (h5, csv, mtx) and found EDS is faster to load and uses less memory, at least in R.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/856#issuecomment-538028764
sample,fast,faster,so `StandardScaler` only gives 32 bit floats and isn’t faster than your solution?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/857#issuecomment-537418940
sample,perf,perform,"Now, I would like choose a cell type (one specific identified clusters) to perform trajectory analysis according to treatment (in my case batch_category).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/859#issuecomment-565168151
sample,perf,performance,"If we don't convert dtypes back to what they originally were, there's a slight performance boost since we don't have to have two copies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197
sample,fast,fast,* We describe a fast approximation to GLM-PCA in the paper which involves transforming raw counts to either Pearson or deviance residuals from a null model then applying standard PCA to that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230
sample,fast,fast,"This approach is just as fast as PCA as long as the null model can be computed in closed-form, which is what we have implemented here: https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230
sample,fast,faster,"The idea is similar to the sctransform approach used by seurat, but the computation is simpler and faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230
sample,speed,speed,"A factor of 10 isn’t that bad for something that’s more complex, and I doubt PCA speed is the bottleneck for most datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540691814
sample,perf,performance,"Since GLM-PCA doesn’t model zero inflation, it’s probably a really good base for distance calculations in scanpy in cases where its performance is sufficient.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-592476723
sample,fast,fast,"These residuals, based on binomial and poisson approximation to multinomial, can be computed in closed form so they are computationally as fast as log-transforming.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190
sample,perf,performance,"If the performance is acceptable, it might make a good addition.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-558999208
sample,perf,performing,"For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-822286073
sample,fast,faster,"There is a faster version of it, which runs on PCA I think though, but it's not in scanpy external.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-543582157
sample,fast,faster,The small improvement on scanpy's side would allow us to read such data faster :-),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-578061167
sample,fast,faster,"However, it doesn't seem to run any faster and actually throws an error now",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553019440
sample,optimiz,optimized,"I tried running this earlier today using the script in theislab/scanpy_usage#17, and for 130K cells NN took 53s unoptimized vs 35s optimized (32 cores).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553420798
sample,speed,speedup,"(Not a proportionate speedup, but still worthwhile.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553420798
sample,speed,speedup,The UMAP speedup shown in that script is significant too.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553420798
sample,fast,fast,"This is because it needs fast access to each variable, so they correspond to rows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-559928610
sample,perf,perfect,Besides the fact that it seems like a perfect fit for this scanpy module as I understand it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-764195420
sample,optimiz,optimize_layout,def optimize_layout(,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223
sample,perf,performance,I'd be interested in seeing the performance impact across the pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-554871161
sample,optimiz,optimized,"Contrast this to the optimized version where the materialize step is not needed, and the data remains a dask array throughout the `filter_genes` method: https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037
sample,perf,performance,I'd be interested in seeing the performance impact across the pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037
sample,fast,faster,"This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880
sample,perf,performance,I'd be interested in seeing the performance impact across the pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880
sample,fast,faster,"This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557317682
sample,perf,perfectly,"Just to answer those that, like me, are beginners in python, the solution provided by @ivirshup works perfectly (of course for `louvain` and `leiden,` and any other `adata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/925#issuecomment-941184403
sample,perf,performance,What's the performance difference here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/929#issuecomment-558069573
sample,perf,performance,Except for “What's the performance difference here”:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591
sample,fast,faster,"It’s not too bad, but we should use base 2 for everything that isn’t the natural logarithm: log2 can be calculated much faster on regular hardware due to binary storage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591
sample,perf,performance,No idea about the error in the performance test.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626
sample,optimiz,optimize_layout,"loat32, copy=False)` from within the call to the `optimize_layout` function: lines 1137 and 1138 in [umap_.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948#issuecomment-571264900
sample,perf,perfectly,As I didn't know how to deal with it I just applied the function @LuckyMD posted above and it worked perfectly alright.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-897602161
sample,perf,perfectly,"It was so hard to debug as locally, everything worked out perfectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/972#issuecomment-572153175
sample,perf,perform,Looking at #842 this is possible by subsetting the data on the groups of interest and then perform the analysis (one-vs-rest).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/984#issuecomment-656111734
sample,fast,fast,"So assuming that we are only interested in downsampling, then I'd say `NearMiss` and related are straightforward and scalable (just need to compute a kmeans whcih is really fast)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1043141030
sample,perf,performed,"also, the fact that reshuflling is performed is not in docs and should be documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1054226637
sample,fast,fast,> then I'd say NearMiss and related are straightforward and scalable (just need to compute a kmeans whcih is really fast),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364
sample,perf,performed,> reshuflling is performed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364
sample,fast,faster,# could be something faster here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-615304326
sample,perf,perform,"I guess my question is, post clipping values to a maximum, I think the mean of the transformed values might not be 0 anymore so if you were just to perform, var(transformed values), it will not equal the same value as variances_norm equation for the sparse approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-1040462161
sample,perf,perform,"Reading through the referenced paper provided (Stuart 2019) its not clear whether they perform the variance of zscores post clipping, or with the assumption that mean zscore is 0 preclipping.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-1040462161
sample,perf,perfectly,"Yes I did, it works perfectly fine (see response [here](https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1007#issuecomment-578151477
sample,perf,perform,I can't think of many other Python toolkits that don't return a copy when you perform some operation on a data object.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-583875715
sample,speed,speed,"@ivirshup is just busy trying to speed up slicing in `AnnData` though, so maybe he can comment on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584211262
sample,perf,performance,I think a core advantage of scanpy over the bioconductor ecosystem is the performance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584460629
sample,perf,performance,I'm also confused by how this results in a performance decrease?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458
sample,perf,performance,I'm also confused by how this results in a performance decrease?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245
sample,perf,perfectly,"I got a lot ""Keyerror"" before, but I tried your tested code, it worked perfectly!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-585508877
sample,fast,fast,Thank you for the fast response.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627935185
sample,perf,performance,* Do you think the performance improvements will also be implemented in leidenalg?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586667992
sample,perf,performant,The reason the `igraph` implementation is more performant than `leidenalg` is exactly because it does not provide other quality functions or a multiplex approach.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586676271
sample,perf,performance,Any chance you could point me to some benchmarks on performance?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586696126
sample,perf,performed,I haven't performed an in-depth benchmark comparison.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791
sample,speed,speed,"I have a large single cell set, where i'd love to speed up the Leiden clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1038854940
sample,speed,speed,Just wondering if this might be a potential area for speed gains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1038854940
sample,perf,performance,Some benchmarks of performance would also be great.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1038930856
sample,speed,speed,So there are definite speed gains to be had with the igraph implementation of Leiden clustering.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039424473
sample,fast,faster,"6x faster at clustering a 185,000 cell dataset vs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039424473
sample,speed,speed,tml#Clustering-the-neighborhood-graph) there is no practically speed difference (too small a dateset to matter).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039424473
sample,fast,faster,The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011
sample,speed,speed,I have now done a speed comparison with adata object of 1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011
sample,speed,speed,Good to see the large speed gains!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040010654
sample,fast,faster,"@vtraag, could you comment on what about this implementation makes it faster?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040084560
sample,speed,speed,I'm wondering how much the speed gains could be from number of iterations.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040084560
sample,speed,speed,I'm not sure how large the speed gains of this would be immediately.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040092975
sample,speed,speed,"When comparing the speed of both implementations, indeed the number of iterations should of course be identical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040690584
sample,optimiz,optimization,My suspicion (and hope) would be that unstable clusters / points are the ones that drag on the optimization process.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040854081
sample,fast,faster,omunity_leiden` still appear faster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1042914000
sample,fast,faster,ommunity_leiden` appears faster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1047551968
sample,fast,faster,ommunity_leiden` is faster than `sc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1047590549
sample,fast,faster,omunity_leiden` still appear faster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1047590549
sample,fast,faster,"@ivirshup if it's still faster with the same value of `n_iterations`, then why not make the switch?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1272443125
sample,perf,perfect,"> The perfect implementation of implicit data centering must be solver agnostic, allowing any matrix-free sparse PCA and SVD solver from scipy and scikit to be used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984
sample,perf,perfect,adding support to call any matrix-free scikit SVD/PCA solver in #12794 (comment) would make it perfect PR for implicit data centering.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984
sample,perf,performance,Ideally what I'd like from a benchmark of performance would be time and memory usage for the product of these conditions:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984
sample,fast,faster,"By the way, I was curious why ‘nomean’ was so much faster than implicit mean centering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589773868
sample,speed,speed,So the speed difference is due to differences in the solvers (arpack vs randomized).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589773868
sample,fast,faster,It's actually faster to do implicit mean centering on the small and large datasets using a single thread.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589925688
sample,perf,performance,"Either way, it looks like single threaded performance is good, and multithreaded is adding surprisingly little for a lot of spent computation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-590137028
sample,perf,performance,@ivirshup I think the benchmarks have shown satisfactory performance of this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-591647662
sample,perf,performance,"* From the stability and performance checks, I think this could be similar enough make it the default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-592268817
sample,perf,performance,"@atarashansky, the performance is looking very very good:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593738303
sample,speed,speed,rg/docs/python/) to speed up data transfer?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590136165
sample,speed,speed,rg/docs/python/) to speed up data transfer?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256
sample,fast,faster,The main idea is making these wrappers faster and take less memory.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590215132
sample,optimiz,optimizer,# then run the optimizer,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1107#issuecomment-600076328
sample,optimiz,optimize,"where `adata` is a list of `AnnData` objects, `use_computed` switches between recalculate partitions (`False`) or optimize partitions already calculated (`True`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1107#issuecomment-600076328
sample,fast,fastpath,"y in __init__(self, data, index, dtype, name, copy, fastpath)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-836604848
sample,perf,perfectly,`leidenalg` functions work perfectly in case of 3+ graphs and it is extremely fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-600333969
sample,fast,fast,`leidenalg` functions work perfectly in case of 3+ graphs and it is extremely fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-600333969
sample,perf,performs,"Again, this is because by design, CLR isn't just a rescaling: it performs cell-specific centering relative to all markers in a relative ratio way, so doesn't preserve a 1-to-1 monotonic mapping as a rescaling function like log, asinh, biexponential/logicle/vlog would.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215
sample,perf,perform,You can still use the CLR transformation function provided in the previous posts to transform the data and perform the rest of the analysis steps using scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-1054761336
sample,speed,speedup,I will test out how much speedup can be gained by using the matplotlib approach (assuming the colors for every node are the same) and get back to you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-604356387
sample,speed,speed,"I don't think the speed is a major issue, since the above example is an extreme case (255 categories).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449
sample,speed,speed,"Currently, I don't have any trick up my sleeve on how to speed it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449
sample,fast,faster,"Not sure how relevant this PR will be, since @VolkerBergen has faster and more robust implementation, but as a triage version, it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-653803793
sample,fast,faster,"Unfortunately, it's just much faster than other graph layout algorithms I've tried, and provides good looking results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1132#issuecomment-605791792
sample,perf,performance,"However, i didn't want to store the same value multiple times, it doesn't make much difference in performance, but still gives uneasy feelings, i would say.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-614656197
sample,optimiz,optimized,"This suggests, that `0/0` in a sparse setting remains `0` (I guess thats what you see); it makes sense for an efficient sparse matrix implementation, as the `0` is not even represented in the sparse data, so scaling with anything is optimized away.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-622613221
sample,perf,perform,Usually it's fine but recently I could not perform it with the same data input.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-615878967
sample,perf,performance,"I’m not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618719727
sample,perf,perform,"The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788
sample,perf,performance,"""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788
sample,fast,fast,Thank you very much for your fast reply.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861
sample,perf,perfectly,No worries - I really can't tell what the issue is since it works perfectly fine locally.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-624694414
sample,perf,perfectly,"I recall that this issue occurred even in a docker container, so I'm not sure we can perfectly automate this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620877208
sample,perf,performance,"I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395
sample,fast,faster,It seems to work quite a bit faster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-633311550
sample,fast,faster,It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833
sample,fast,fast,This will be very fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833
sample,fast,faster,"Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748543070
sample,fast,faster,"Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748670360
sample,perf,perfect,"Thinking about this a bit further, yes, that does make perfect sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748689903
sample,perf,performs,"opy()`, which performs a deep copy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1239#issuecomment-631951443
sample,speed,speed,om/bhargavchippada/forceatlas2  You may want to search in that package if computations can be speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1242#issuecomment-633517120
sample,perf,performed,you can check here that the log is actually performed as you suggest: https://github.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1251#issuecomment-702373149
sample,perf,performing,"I have the excat same issue, which prevents me from performing further analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183
sample,perf,perform,"aw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1266#issuecomment-639506245
sample,fast,fast,But it’s fast enough to do that too if we want to have it easy and there’s a delauney implementation in something we already import (e.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1287#issuecomment-706180849
sample,fast,fastMNN,"This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353
sample,fast,fastMNN,It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353
sample,perf,performed,It has performed quite well in our [benchmark of data integration methods](https://www.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157
sample,perf,perform,"@VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157
sample,fast,fast,Thank you for the fast reply.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-735661916
sample,perf,performing,"Ahh okay, I misunderstood the process then – my understanding was that some of the mnn correction would be carried over when performing velocity analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-735661916
sample,speed,speedup,I only used this version so I don't know if it brings any speedup but results were very nice usually.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-654548899
sample,speed,speedup,"This implementation takes very little time (a couple seconds per iteration on ~10k cells), so a speedup might not make much difference, but if you think using the pytorch implementation would be better, I can certainly switch to that one easily enough.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-659075154
sample,fast,fast,You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the “merge upstream changes” button and us hitting the “squash & merge” button happens fast enough.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662064808
sample,perf,perfect,"Looks perfect now, merging.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662100175
sample,perf,performance,eighbors doesn't have hsnw which has superior performance from what I've seen in my data and literature https://arxiv.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1318#issuecomment-658987394
sample,perf,performed,We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665592723
sample,perf,performance,"@falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954
sample,fast,faster,"Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665549817
sample,perf,performed,"tml) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665580053
sample,perf,perform,"As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665745151
sample,fast,fasteners,fasteners           NA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831
sample,perf,perfect,"yet, this would be perfect:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666989163
sample,fast,fastjsonschema,fastjsonschema          2.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336
sample,perf,performed,The analysis steps that are performed in those are quite old and would not be considered as good practice anymore.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1357#issuecomment-669090138
sample,speed,speed,and not really help with the speed up you were looking for above.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1357#issuecomment-669120508
sample,perf,performance,"From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1359#issuecomment-670421732
sample,fast,faster,"I believe pynndescent faster, if non-deterministic, but I get constant output from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-674658333
sample,perf,perfect,You are absolutely correct that log transformation removes the perfect comparison of relative expression values that mean normalization provides.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643
sample,perf,perfect,so there's not really a perfect answer here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643
sample,perf,performing,This leads to many methods performing better with log transformation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643
sample,perf,perfectly,But I guess to have perfectly separated coloring I need to manually pick which color is for which cluster.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1366#issuecomment-673944797
sample,optimiz,optimization,"This would start becoming more of an optimization problem, and more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1366#issuecomment-763341345
sample,perf,perfectly,y develop` worked perfectly for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1377#issuecomment-675422847
sample,fast,fast,"However, I still think taking adjacency matrix powers will not be as fast as a BFS/DFS.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701344124
sample,perf,performance,> General question about performance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1388#issuecomment-740092654
sample,fast,faster,"Is this faster than calling the previous function separately on each group, then concatenating the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1388#issuecomment-740092654
sample,fast,fast,More interesting is that regress_out becomes lightning fast when n_jobs = 24 and with BLAS multi threading disabled:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-684103610
sample,fast,fast,> More interesting is that regress_out becomes lightning fast when n_jobs = 24 and with BLAS multi threading disabled:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-691913240
sample,fast,fast,I continue to get the putative over scheduling and sometimes a crash (on big datasets) when using all cores versus the super fast completion when using 1/2 cores) on a 32 core/64 thread threadripper.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-720680171
sample,optimiz,optimize,We do not generally optimize methods that were published elsewhere.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414
sample,optimiz,optimization,so maybe there is little room for optimization here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414
sample,optimiz,optimize,We do not generally optimize methods that were published elsewhere.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229
sample,optimiz,optimization,so maybe there is little room for optimization here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229
sample,speed,speedup,"It's, the threshold value, thus just a single value that gets converted to float32, which won't yield any considerable speedup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1456#issuecomment-709197166
sample,perf,perfectly,Works perfectly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1502#issuecomment-730297381
sample,optimiz,optimization,"I never get adjustText to work without  numerous rounds of parameter optimization, so yeah, I agree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1513#issuecomment-839982675
sample,perf,perform,The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738766770
sample,perf,perform,"And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692
sample,speed,speedup,Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1025689932
sample,speed,speedup,TSNE sees a massive speedup.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1025689932
sample,speed,speedup,"I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960
sample,speed,speedup,I feel that `scale` and  `regress_out` could benefit from such speedup for example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106490794
sample,perf,performed,I performed a speed comparison on a 100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110
sample,speed,speed,I performed a speed comparison on a 100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110
sample,speed,speedup,The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110
sample,fast,faster,But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759340575
sample,fast,faster,"Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-762763727
sample,optimiz,optimization,"To me, the alternative would be to error for non-normalized data since the optimization won't converge properly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636
sample,fast,faster,"> Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636
sample,fast,faster,"I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-922497079
sample,perf,perfect,I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-968181500
sample,perf,perfect,> I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606
sample,perf,performing,"Maybe things like single-cell-tutorial as F1000 recommended paper, or the news about top performing data integration methods, once the paper is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1571#issuecomment-754704191
sample,perf,perfomance,"Also, the loss of perfomance from reverting #1499 should be partially mitigated by improvements in pandas (see https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421
sample,perf,performance,"We can then make a release now, and can patch in performance boosts during the release cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421
sample,perf,performed,"pynb), ""Log-transformation of data and scaling should always be performed before scoring.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381
sample,perf,performed,"pynb), ""Log-transformation of data and scaling should always be performed before scoring.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1466032257
sample,perf,perfectly,@ivirshup perfectly fine with me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763583210
sample,fast,fastest,It is in my opinion the fastest option out there and jobs spin up really fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763593668
sample,fast,fast,It is in my opinion the fastest option out there and jobs spin up really fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763593668
sample,fast,fast,We could certainly move some of the fast and easy checks to Github Actions and leave the more heavy jobs for Azure.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763593668
sample,perf,perfectly,It is very annoying that the lines do not align perfectly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1603#issuecomment-768097032
sample,speed,speed,:zap: speed response and to the point :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625#issuecomment-772445520
sample,perf,perform,"IMHO, once you have those values you can perform any statistical test on their distributions to tell if there's a difference in activation of a certain pathway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1629#issuecomment-781323134
sample,perf,performance,"Also, I would not be initially concerned about performance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-778222682
sample,optimiz,optimized,We can later see how can be optimized.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-778222682
sample,fast,fastest,"- Hmm, I think `statsmodels` can do regression on lots of different models, but from the source paper it sounds like using Poisson was simplest/fastest and did not affect the results too much when compared to negative binomial regression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077
sample,perf,perfectly,"I'll PR a sparsing check and conversion (and yes @ivirshup , I'll add a test :-) ), but the workaround is perfectly valid for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663
sample,fast,fast,thank you for the fast response and for the information!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1647#issuecomment-778494956
sample,fast,faster,You said you used some automated tools to get faster compliance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670
sample,fast,faster,> You said you used some automated tools to get faster compliance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785875783
sample,perf,performs,I would like to add Moran's I as an bio conservation integration metric to scIB - this is for me the only metric that does not require cell subtype annotation (which is cumbersome and unreliable procedure) and it performs similar to current scIB metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-787504982
sample,fast,faster,"Also, maybe there's a faster way to calculate it than with a fixed number of iterations, especially for structured grids like we have with visium data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-801888764
sample,fast,faster,"They use parametric null models to get significances for their scores, which would be significantly faster than permutation testing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-846745204
sample,fast,fasteners,fasteners           NA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745
sample,fast,fast,I even think in GLM-PCA they describe a fast approximation using [deviance residuals](https://genomebiology.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797848694
sample,fast,fast,"> I even think in GLM-PCA they describe a fast approximation using deviance residuals, so why not add that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798444591
sample,perf,performance,It makes sense to me to change defaults as more information becomes available about performance/popularity.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817
sample,fast,fast,Another very important feature of this process though is that it needs to be **fast**.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-799276115
sample,fast,fast,"I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693
sample,fast,fast,"> I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-828228025
sample,perf,perform,"One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-872954063
sample,perf,perform,"> One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-874558246
sample,perf,performed,I think it should remain `X_pca` since the normalization is performed on `X`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-890768314
sample,perf,performed,I think it should remain `X_pca` since the normalization is performed on `X`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-890959567
sample,fast,faster,- [ ] Make tests faster (re-use results where possible),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902985395
sample,optimiz,optimized,"The easiest would probably be to add an `return_hvgs` option to `normalize_pearson_residuals()`, which would allow to skip our RAM-optimized HVG selection function for cases where speed / efficiency is needed and RAM usage is not a concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698
sample,speed,speed,"The easiest would probably be to add an `return_hvgs` option to `normalize_pearson_residuals()`, which would allow to skip our RAM-optimized HVG selection function for cases where speed / efficiency is needed and RAM usage is not a concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698
sample,fast,fast,"If we can live without the batch correction for this ""fast lane case"", I can also just implement it without.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698
sample,fast,faster,- [x]  Make tests faster (re-use results where possible),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207
sample,fast,fast,- add an option for fast-lane feature selection?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207
sample,fast,fast,"failing tests, docs, fast-lane HVG).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-912511459
sample,fast,faster,At some point scanpy switched to non-gzipped files by default as file I/O is faster that way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-802982968
sample,fast,faster,I think all that we'd really expose here is a faster [`scipy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803518963
sample,fast,faster,> At some point scanpy switched to non-gzipped files by default as file I/O is faster that way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803518963
sample,fast,faster,"It's much faster than `gzip`, has similar compression, and is barely slower than no compression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803518963
sample,fast,faster,"It's basically just calling pandas to read the coo array, since pandas' csv parser is much faster than scipy's",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803672032
sample,fast,faster,i thought it was faster for both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803987160
sample,perf,performance,"Side note, on performance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288
sample,fast,fast,So right now it looks like computing one permutation is fairly fast (which makes sense).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288
sample,fast,fast,"Now it's fast, 10s for 18k genes and 2k cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-799760109
sample,perf,performance,Since we're not doing iterations anymore this shouldn't be a performance issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-802562555
sample,fast,faster,Initial justification was that it makes a number of computations much faster and doesn't seem to cause problems.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-800776373
sample,perf,perfect,That would be perfect if it’s possible!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753#issuecomment-813954380
sample,perf,perfectly,tml` works perfectly fine in the presence of `.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753#issuecomment-813954380
sample,optimiz,optimize_layout_euclidean,"55     optimize_layout_euclidean,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796
sample,optimiz,optimize_layout_generic,"56     optimize_layout_generic,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796
sample,fast,fast,"41     """"""A fast (pseudo)-random number generator.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466
sample,optimiz,optimize_layout_euclidean,"55     optimize_layout_euclidean,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325
sample,optimiz,optimize_layout_generic,"56     optimize_layout_generic,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325
sample,perf,perfect,"I also agree with Stephen's concerns, minmax is not perfect and can be misleading, and it's safer to be more flexible, provide more normalization options and let the user be responsible for how the plots look like IMO.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-873078527
sample,perf,performing,"Scanpy itself can easily work with very small datasets, but you should always be aware of statistical limitations when performing statistical tests etc on very few cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1764#issuecomment-815287672
sample,perf,perfctr_core,fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937
sample,perf,perfctr_nb,fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937
sample,fast,fastcache,fastcache                 1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310
sample,fast,faster,`mamba` (faster conda) definitely makes this less painful.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-862972961
sample,fast,faster,A counter example of a faster way to compute it could be useful to see too.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1865#issuecomment-861467621
sample,fast,faster,"It still doesn't work with sparse arrays, and our version on a sparse array was much faster than theirs on a dense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892#issuecomment-864875522
sample,speed,speeds,I did not compare speeds for dense v dense.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892#issuecomment-864875522
sample,perf,perform,If this was added as a feature then you could perform your corrections separately for each sample.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1977#issuecomment-953198551
sample,fast,fastmath,"This could be triggered by either use of any parallelism at all or `pynndescent` being pretty liberal with the use of `numba`'s `fastmath`, and different CPUs having different features.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946679078
sample,perf,performance,But we may then have to consider what kind of a performance hit we'd be willing to take for exact reproducibility on discontinued chip sets.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946679078
sample,speed,speed,"In terms of speed I didn't notice a bit difference (maybe 10s slower, but that would require proper benchmarking ofc).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946754682
sample,perf,perfectly,Yes I think traversing a minimum spanning tree is good enough since you can never perfectly order cell states in one dimension while capturing all the key features.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2016#issuecomment-948039275
sample,fast,fasteners,python3-fasteners (= 0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616
sample,perf,performance,We're always up for improved performance!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060#issuecomment-981701546
sample,perf,performance,Do you have any benchmarks of performance here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060#issuecomment-981701546
sample,speed,speedup,On my laptop (an 8-core Intel MacBook Pro) it's about a 10x speedup.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060#issuecomment-981723859
sample,fast,fastest,Installing fa2 package (fastest forceatlas2 python implementation),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096
sample,fast,fastest,Installing fa2 package (fastest forceatlas2 python implementation),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096
sample,perf,perfectly,not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
sample,perf,performed,"The number of cells in each cluster correlates with the number of cells in the organism, so if I performed the in-situ I would get lots of cells that I could mistakenly all identify as cluster 18.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2107#issuecomment-1017354889
sample,fast,fasteners,fasteners                   NA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020206162
sample,speed,speeds,How are the download speeds/ hosting for figshare?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805
sample,speed,speeds,> How are the download speeds/ hosting for figshare?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545
sample,fast,fast,the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545
sample,perf,performing,"5ad format, and as soon as it gets read in memory, it blows up to 28 gb), but for now I have utilized a larger machine for performing my eda, and converted the sparse matrix to a dense one .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147#issuecomment-1053044750
sample,fast,faster,With random initialization it's about 10x faster than UMAP on this system.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051102663
sample,fast,fast,"The quadratic init (default) is as fast as UMAP, but there's an opportunity to optimize that code to use the GPU.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051102663
sample,optimiz,optimize,"The quadratic init (default) is as fast as UMAP, but there's an opportunity to optimize that code to use the GPU.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051102663
sample,fast,faster,This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
sample,speed,speed,"- on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
sample,fast,faster,"- on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
sample,speed,speed,I have a PR at pymde to improve the initialization speed using the GPU (https://github.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051311781
sample,perf,perform,I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062106274
sample,perf,perform,> I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262
sample,fast,fast_knn_indices,"ine=37)     fast_knn_indices,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
sample,optimiz,optimize_layout_euclidean,"ine=41)     optimize_layout_euclidean,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
sample,optimiz,optimize_layout_generic,"ine=42)     optimize_layout_generic,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
sample,optimiz,optimize_layout_inverse,"ine=43)     optimize_layout_inverse,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
sample,fast,fastmath,"ine=30)     fastmath=True,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
sample,perf,performing,"I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
sample,perf,perform,"I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
sample,perf,performing,"One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
sample,perf,perform,"I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
sample,perf,perform,"Hey, thanks for the description - yes your example dataset would be very helpful - if you could post a small code snippet here which generates this dataset and shows the specific steps you perform that would be great.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191785768
sample,perf,perform,#perform scaling in sklearn,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375
sample,perf,perform,#perform scaling in scanpy with the default settings,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375
sample,optimiz,optimized,"For me, I think doing scaling is necessary because if the data is not centred to 0, the plane we find based on the covariance matrix may not be the optimized one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861
sample,optimiz,optimization,The PCA optimization process only works for data with 0 centered I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861
sample,optimiz,optimize,from scipy import optimize,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,optimiz,optimize,"File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,optimiz,optimize,ptimize import *,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,optimiz,optimize,"File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,optimiz,optimize,"File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,optimiz,optimize,"File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
sample,perf,perfectly,"You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
sample,fast,faster,"I’m talking about having two checks that do the same thing, so let’s keep the faster one:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2206#issuecomment-1088547896
sample,fast,fast,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234#issuecomment-2203058298
sample,perf,performed,"Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711
sample,perf,perfect,"@gtca Yes I now see the point about explicit copying preventing the further modification, thanks, that's perfect",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-2071140996
sample,fast,faster,"* Fewer channels to search means easier, faster environment solving.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
sample,fast,faster,">Fewer channels to search means easier, faster environment solving.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
sample,perf,perfectly,I'm having this issue as well -- code that used to run perfectly well is now resulting in segfaults specifically when running `sc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1908671942
sample,perf,perform,When you perform the umap calculation using sc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721
sample,speed,speeding,"For context on our side, there are some other paths for speeding up DE available (probably some form of calculating statistics via https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639
sample,fast,faster,"If you are specifically looking for faster scanpy DE, this makes sense, though there may be some easier paths forward (at least to me).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639
sample,fast,fast,"It's one of those simple things your biologists will love (""this is so fast now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387503006
sample,fast,fast,"It's one of those simple things your biologists will love (""this is so fast now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226
sample,speed,speed,"For large `X` (probably where you want to see the speed up most), this can make you run out of memory.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
sample,fast,faster,"This could also be much faster, if you can just reduce total computation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
sample,perf,performance,"what should not, and most of the recent/upcoming additions are around either performance (dask) or vendoring tools that are either essential + in need of some love (maybe bbknn) or tools that we once relied on, but are no longer maintained and we need to bring in to the package to ensure continuity (scrublet).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352465866
sample,fast,faster,We just introduced our implementation as a faster alternative to the already available one.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339
sample,fast,fastapi,fastapi                   0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
sample,fast,fastapi,fastapi                   0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
sample,perf,perform,So we still need to perform the following work around:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607268186
sample,fast,fastjsonschema,fastjsonschema      NA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519
sample,perf,perfectly,I ran the reproducer on my system and it indeed works perfectly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615
sample,fast,faster,"Tests get a bit slower, real world gets faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
sample,perf,perf,$ perf stat -r 10 -B hatch run +py=3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
sample,perf,perf,$ perf stat -r 10 -B hatch run +py=3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
sample,fast,fast,"The question is “make everything work with dask now, make sure everything is fast later” or “make a few functions work and go fast now, handle other functions later”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2621#issuecomment-1695793742
sample,fast,fast,"The question is “make everything work with dask now, make sure everything is fast later” or “make a few functions work and go fast now, handle other functions later”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2621#issuecomment-1695793742
sample,fast,fast,"> The question is “make everything work with dask now, make sure everything is fast later” or “make a few functions work and go fast now, handle other functions later”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2621#issuecomment-1695849117
sample,fast,fast,"> The question is “make everything work with dask now, make sure everything is fast later” or “make a few functions work and go fast now, handle other functions later”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2621#issuecomment-1695849117
sample,optimiz,optimization,Smells of premature optimization.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2621#issuecomment-1753182156
sample,perf,performance,Do those tank the performance?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533
sample,fast,fast,the use case is a fast conversion from nearest neighbors csr_matrix to a pair of index/distance matrices.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2773#issuecomment-1834356022
sample,perf,perform,"In your example, you are comparing two different methods, that produce different results (like really just perform different computations).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
sample,perf,perfectly,"In the next scanpy version, you can use `flavor='seurat_v3_paper'` to get the HVG ordering that perfectly matches the version they describe in the paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1951978815
sample,fast,faster,"<ins>potentially</ins> faster, much more maintainable, and almost dask-compatible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
sample,fast,faster,Is it faster?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929477612
sample,fast,faster,It would be faster if we used that code on some extension dtype `pd.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929527694
sample,speed,speed,"Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
sample,fast,faster,I think this is cleaner and faster since no code will run that doesn't have to.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908
sample,fast,fast_matrix_market,I believe scipy's `mmread` (which is being used under the hood) recently switched to using `fast_matrix_market` as of scipy `1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2846#issuecomment-1938362632
sample,fast,fast_matrix_market,om/alugowski/fast_matrix_market/issues/22,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2846#issuecomment-1938362632
sample,optimiz,optimized,"Otherwise I'd be fine with the user doing it themselves, but the main value add here would be lower memory overhead/ optimized implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2898#issuecomment-1981827424
sample,optimiz,optimizing,"I'm still dubious of the value, especially when we provide different ways of ways of optimizing the score.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2908#issuecomment-1997873869
sample,optimiz,optimization,"This way we are not comparing scores obtained by optimization functions, just simple ""external"" measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2908#issuecomment-1999868127
sample,perf,perfect,"I re-introduced the check here, which restores perfect compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921#issuecomment-2147517976
sample,fast,fast,I think the current solution is simpler and also really fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2022529797
sample,perf,performance,"But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345
sample,fast,faster,"I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345
sample,fast,faster,"Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345
sample,perf,performance,I have some concerns about the performance of the no numba version for larger datasets.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2036739880
sample,speed,speed,"I think this is good to merge as it gets ~ a 100x speed up, and we can do comparisons on top of this in follow ups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2042551110
sample,perf,performed,"> When i previously performed leiden clustering on my data, the shape of the UMAP changed, as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2034421743
sample,perf,performed,"By clustered UMAP, i mean the UMAP produced after i performed leiden clustering on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2034530366
sample,perf,performed,"Then I dont know what happened, but when I plotted the UMAP without leiden clustering performed, it had a different shape in the UMAP then after I calculated the leiden clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2034530366
sample,perf,performing,In the meantime I can only post this image where I put both UMAPs next to each other and drew what I meant about part of cluster1 being added to cluster2 after performing the leiden clustering:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2034530366
sample,perf,performance,My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034405597
sample,perf,perform,There is currently no consensus on whether or not to perform normalization over genes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034415456
sample,perf,performance,> My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485
sample,perf,performing,"You mentioned that in some benchmarks, performing the densifying scale transform didn't show significant performance improvements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485
sample,perf,performance,"You mentioned that in some benchmarks, performing the densifying scale transform didn't show significant performance improvements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485
sample,perf,performance,"However, I have a further question: if the step of adding this densifying scale transform is included, would it negatively impact the overall performance?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485
sample,speed,speed,"For example, would it reduce the training or inference speed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485
sample,perf,perform,There is currently no consensus on whether or not to perform normalization over genes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034435734
sample,perf,perform,The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2042435682
sample,perf,perfectly,This solution perfectly solved the problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033933074
sample,perf,perform,"It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066797546
sample,perf,performance,Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519
sample,fast,faster,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2122484190
sample,fast,fast,he functions themselves are quite fast.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2100566909
sample,speed,speedup,"It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668
sample,optimiz,optimizations,These t-SNE optimizations are mentioned in the following paper.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2116608798
sample,optimiz,optimized,"sne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265
sample,optimiz,optimized,"As can be seen with the KL divergence values in the above table, while the output of Intel optimized t-SNE is different, it is equivalent in quality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122440284
sample,optimiz,optimization,"om/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2136745993
sample,fast,fasteners,- fasteners==0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062#issuecomment-2114986516
sample,perf,perfect,"Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062#issuecomment-2115841629
sample,perf,performing,@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887
sample,fast,faster,I added the `benchmark` label so we see that it actually makes things faster,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173111949
sample,fast,faster,It would be helpful if you documented a bit why your newly introduced branch is faster with comments.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2175907294
sample,fast,faster,"ooh, this time the benchmark shows really nicely how much faster it is!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2176009635
sample,fast,faster,"> ooh, this time the benchmark shows really nicely how much faster it is!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2177815754
sample,fast,faster,"> > ooh, this time the benchmark shows really nicely how much faster it is!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2181072184
sample,perf,performance,I also get performance warnings about the matmul in the numba_kernel.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2205859591
sample,fast,fastpp,om/IntelLabs/Open-Omics-Acceleration-Framework/blob/main/pipelines/single-cell-RNA-seq-analysis/notebooks/fastpp.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3135#issuecomment-2275907097
sample,fast,fasteners,fasteners                   0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344
sample,fast,fastjsonschema,fastjsonschema              NA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228#issuecomment-2348022832
sample,fast,fastest,I think the fastest way to get this would be if you do a PR!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3241#issuecomment-2363195426
sample,perf,performance,Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263#issuecomment-2385462999
sample,speed,speedup,Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3279#issuecomment-2429335571
sample,perf,performance,"it shouldn’t affect performance at all, just readability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3316#issuecomment-2437410637
