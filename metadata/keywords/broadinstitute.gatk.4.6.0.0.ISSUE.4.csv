id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/pull/3405:503,Security,expose,exposes,503,"The PathSeq filter repartitioning the reads directly before the BWA host filtering step to even out the load on each partition. This is helpful for typical samples with low pathogen abundance, when ~90% of the reads are filtered before this step. . However, in some sample types such as stool, saliva, or environmental samples, one can have a large number of reads (i.e. ~10M) at this stage so the cost of the repartition shuffle outweighs the benefit of load balancing for the slow BWA step. . This PR exposes a tool argument to skip the repartitioning.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3405
https://github.com/broadinstitute/gatk/pull/3406:0,Deployability,Upgrade,Upgrades,0,"Upgrades PathSeqScoreSpark to perform abundance score calculations on the executors rather than the driver. This was crashing on inputs with a lot of pathogen reads. . This also required some minor changes to the `PSPathogenTaxonScore` class to be able to keep track of abundance score contributions that come directly from hits to that taxon and those that are from the taxon's descendents. As a result, some of the test output changed when using bitwise, exact checks on the output. So the tests now check for output equivalence, meaning parsing the scores table, checking that all the taxa are the same, and that the scores are equal to within some defined epsilon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3406
https://github.com/broadinstitute/gatk/pull/3406:30,Performance,perform,perform,30,"Upgrades PathSeqScoreSpark to perform abundance score calculations on the executors rather than the driver. This was crashing on inputs with a lot of pathogen reads. . This also required some minor changes to the `PSPathogenTaxonScore` class to be able to keep track of abundance score contributions that come directly from hits to that taxon and those that are from the taxon's descendents. As a result, some of the test output changed when using bitwise, exact checks on the output. So the tests now check for output equivalence, meaning parsing the scores table, checking that all the taxa are the same, and that the scores are equal to within some defined epsilon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3406
https://github.com/broadinstitute/gatk/pull/3406:417,Testability,test,test,417,"Upgrades PathSeqScoreSpark to perform abundance score calculations on the executors rather than the driver. This was crashing on inputs with a lot of pathogen reads. . This also required some minor changes to the `PSPathogenTaxonScore` class to be able to keep track of abundance score contributions that come directly from hits to that taxon and those that are from the taxon's descendents. As a result, some of the test output changed when using bitwise, exact checks on the output. So the tests now check for output equivalence, meaning parsing the scores table, checking that all the taxa are the same, and that the scores are equal to within some defined epsilon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3406
https://github.com/broadinstitute/gatk/pull/3406:492,Testability,test,tests,492,"Upgrades PathSeqScoreSpark to perform abundance score calculations on the executors rather than the driver. This was crashing on inputs with a lot of pathogen reads. . This also required some minor changes to the `PSPathogenTaxonScore` class to be able to keep track of abundance score contributions that come directly from hits to that taxon and those that are from the taxon's descendents. As a result, some of the test output changed when using bitwise, exact checks on the output. So the tests now check for output equivalence, meaning parsing the scores table, checking that all the taxa are the same, and that the scores are equal to within some defined epsilon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3406
https://github.com/broadinstitute/gatk/issues/3407:499,Security,Validat,ValidateVariants,499,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:532,Security,validat,validate,532,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:12,Testability,test,test,12,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:47,Testability,test,test,47,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:216,Testability,test,test,216,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:552,Testability,test,test,552,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/issues/3407:628,Testability,test,testing,628,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407
https://github.com/broadinstitute/gatk/pull/3408:71,Testability,test,tested,71,- Added the optional flag to run oncotator in the CNV WDL. This is not tested automatically in github.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408
https://github.com/broadinstitute/gatk/pull/3409:51,Deployability,update,updated,51,"When SelectVariants samples are subset and PLs are updated, GQ doesn't appear to get updated. This fixes some incorrect results for LeftAlignAndTrimVariants -split. Also fixes results for SelectVariants -trimAlternates -- PLs are just 0 with no called alts, so there shouldn't be GQ. Port of https://github.com/broadinstitute/gsa-unstable/pull/1625",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409
https://github.com/broadinstitute/gatk/pull/3409:85,Deployability,update,updated,85,"When SelectVariants samples are subset and PLs are updated, GQ doesn't appear to get updated. This fixes some incorrect results for LeftAlignAndTrimVariants -split. Also fixes results for SelectVariants -trimAlternates -- PLs are just 0 with no called alts, so there shouldn't be GQ. Port of https://github.com/broadinstitute/gsa-unstable/pull/1625",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409
https://github.com/broadinstitute/gatk/pull/3410:9,Testability,test,tests,9,Includes tests for both hg19 and hg38.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410
https://github.com/broadinstitute/gatk/issues/3412:31,Availability,error,error,31,We've seen 2 instances of this error now:; ```; java.lang.ArrayIndexOutOfBoundsException: 15; 	at htsjdk.variant.bcf2.BCF2Utils.decodeType(BCF2Utils.java:122); 	at htsjdk.variant.bcf2.BCF2Decoder.decodeInt(BCF2Decoder.java:220); 	at htsjdk.variant.bcf2.BCF2Decoder.decodeNumberOfElements(BCF2Decoder.java:205); 	at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:129); 	at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:125); 	at htsjdk.variant.bcf2.BCF2LazyGenotypesDecoder.parse(BCF2LazyGenotypesDecoder.java:75); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.getGenotypes(LazyGenotypesContext.java:148); 	at htsjdk.variant.variantcontext.GenotypesContext.getMaxPloidy(GenotypesContext.java:431); 	at htsjdk.variant.variantcontext.VariantContext.getMaxPloidy(VariantContext.java:785); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:405); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:92); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:212); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.strea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412
https://github.com/broadinstitute/gatk/issues/3412:1855,Integrability,wrap,wrapAndCopyInto,1855,t.VariantContext.getMaxPloidy(VariantContext.java:785); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:405); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:92); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:212); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412
https://github.com/broadinstitute/gatk/issues/3413:63,Performance,perform,performance,63,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:212,Performance,perform,performance,212,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:463,Performance,perform,performed,463,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:1364,Performance,optimiz,optimized,1364,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:147,Testability,test,tests,147,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:452,Testability,test,tests,452,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:546,Testability,test,tests,546,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:985,Testability,test,test,985,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3413:1229,Testability,test,test,1229,"We've been showing people the plots below on deflater/inflater performance to argue that using compression level 1 always make sense, since in our tests it results in only a slightly larger file, but much better performance:. ![image](https://user-images.githubusercontent.com/798637/28984196-bd03b976-792a-11e7-8a2d-8aa63cdc2aba.png). ![image](https://user-images.githubusercontent.com/798637/28984228-eb7c4a3e-792a-11e7-8a07-f637fb01347a.png). These tests were performed by @gspowley on whole-genome bams. @tfenne reports, however, that in his tests with smaller bams (on the order of 1-2 GB), he is seeing a significantly larger final file with the Intel deflater on compression level 1 than with the JDK deflater on compression level 5. See https://github.com/broadinstitute/picard/issues/879 for the full discussion. We should investigate to better understand how the gap between final file size on compression level 1 vs. level 5 changes with different kinds of input. We should test with variously-sized files (2 GB bam snippets, 30 GB exomes, and ~200 GB genomes), and record final compressed size, time to write the compressed file, and time to read the compressed file on both levels 1 and 5. We should also be sure to test with some whole-genome bams other than the ones used in the initial evaluation, to make sure that the deflater has not been hyper-optimized for just certain specific samples/data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413
https://github.com/broadinstitute/gatk/issues/3414:214,Modifiability,layers,layers,214,"Right now the docker image is too large. It appears that the if the build_docker.sh script its set to run the tests, then it is uploading the test resources into the docker and removing them, resulting in multiple layers which uses unneeded space. We need to remove the resources files from the docker.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3414
https://github.com/broadinstitute/gatk/issues/3414:110,Testability,test,tests,110,"Right now the docker image is too large. It appears that the if the build_docker.sh script its set to run the tests, then it is uploading the test resources into the docker and removing them, resulting in multiple layers which uses unneeded space. We need to remove the resources files from the docker.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3414
https://github.com/broadinstitute/gatk/issues/3414:142,Testability,test,test,142,"Right now the docker image is too large. It appears that the if the build_docker.sh script its set to run the tests, then it is uploading the test resources into the docker and removing them, resulting in multiple layers which uses unneeded space. We need to remove the resources files from the docker.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3414
https://github.com/broadinstitute/gatk/pull/3416:323,Availability,error,errors,323,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:370,Availability,error,errors,370,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:350,Deployability,release,release,350,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:113,Integrability,bridg,bridge,113,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:469,Integrability,depend,dependency,469,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:501,Integrability,bridg,bridge,501,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:584,Integrability,depend,dependency,584,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:663,Integrability,bridg,bridge,663,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:732,Integrability,depend,dependencies,732,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:75,Testability,log,logging,75,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:181,Testability,log,logging,181,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/pull/3416:879,Testability,log,logging,879,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416
https://github.com/broadinstitute/gatk/issues/3417:53,Availability,failure,failures,53,update htsjdk to a current snapshot and fix the test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3417
https://github.com/broadinstitute/gatk/issues/3417:0,Deployability,update,update,0,update htsjdk to a current snapshot and fix the test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3417
https://github.com/broadinstitute/gatk/issues/3417:48,Testability,test,test,48,update htsjdk to a current snapshot and fix the test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3417
https://github.com/broadinstitute/gatk/pull/3418:5,Energy Efficiency,reduce,reduces,5,This reduces the size of the docker image from ~9GB when LFS tests were being run to 2.74GB. fixes #3414,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3418
https://github.com/broadinstitute/gatk/pull/3418:61,Testability,test,tests,61,This reduces the size of the docker image from ~9GB when LFS tests were being run to 2.74GB. fixes #3414,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3418
https://github.com/broadinstitute/gatk/pull/3421:9,Testability,test,tests,9,updating tests; closes #3417,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421
https://github.com/broadinstitute/gatk/pull/3424:57,Deployability,release,release,57,All that was required was pointing to the latest barclay release and; creating a new build target in build.gradle. fixes #1454,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3424
https://github.com/broadinstitute/gatk/pull/3427:111,Safety,detect,detection,111,"Some code cleanup, some existing class extension, some new utility classes. All made to prepare for complex sv detection. This is the beginning. Related changes are put into the same commit for easier review. Test coverage is expected to drop slightly, but will be take care of in later commits.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3427
https://github.com/broadinstitute/gatk/pull/3427:209,Testability,Test,Test,209,"Some code cleanup, some existing class extension, some new utility classes. All made to prepare for complex sv detection. This is the beginning. Related changes are put into the same commit for easier review. Test coverage is expected to drop slightly, but will be take care of in later commits.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3427
https://github.com/broadinstitute/gatk/issues/3429:207,Testability,test,test,207,"We have received two independent reports of this problem. The latest by Brad Chapman, posted [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/41338#Comment_41338) includes a reproducible test case. Files are here: https://s3.amazonaws.com/chapmanb/testcases/gatk4_genotypegvcfs.tar.gz. #### Steps to reproduce:. Running an import, and then a GenotypeGVCFs and SelectVariants to test export:. ```; gatk-launch GenomicsDBImport --genomicsDBWorkspace test_genomicsdb -L chrM:1-1000 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch GenotypeGVCFs --variant gendb://test_genomicsdb -R hg19.fa --output joint.vcf.gz -L chrM:1-1000; gatk-launch SelectVariants -R hg19.fa -V gendb://test_genomicsdb -O extract.vcf.gz; ```. The input GVCFs have calls within the chrM region being tested:. ```; Test1.vcf.gz:chrM 150 . T C,<NON_REF> 49406.77 . DP=1084;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQ0=0;RAW_MQ=3902400.00 GT:AD:DP:GQ:MCL:MMQ:PGT:PID:PL:SB 1/1:0,1081,0:1081:99:0,0,0:0,60,0:0|1:150_T_C:49435,3362,0,49435,3362,49435:0,0,483,598; ```. But the `GenotypeGVCFs` output VCF is empty (file only contains the hdear; no records). Running `SelectVariants` shows the sample but with empty genotype calls:. ```; extract.vcf.gz:chrM 150 . T C,<NON_REF> . . DP=2168;ExcessHet=3.01;MQ0=0;RAW_MQ=7804800.00 GT:AD:DP:GQ:MCL ./.:0,1081,0:1081:99:0.00,0.00 ./.:0,1081,0:1081:99:0.00,0.00; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429
https://github.com/broadinstitute/gatk/issues/3429:268,Testability,test,testcases,268,"We have received two independent reports of this problem. The latest by Brad Chapman, posted [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/41338#Comment_41338) includes a reproducible test case. Files are here: https://s3.amazonaws.com/chapmanb/testcases/gatk4_genotypegvcfs.tar.gz. #### Steps to reproduce:. Running an import, and then a GenotypeGVCFs and SelectVariants to test export:. ```; gatk-launch GenomicsDBImport --genomicsDBWorkspace test_genomicsdb -L chrM:1-1000 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch GenotypeGVCFs --variant gendb://test_genomicsdb -R hg19.fa --output joint.vcf.gz -L chrM:1-1000; gatk-launch SelectVariants -R hg19.fa -V gendb://test_genomicsdb -O extract.vcf.gz; ```. The input GVCFs have calls within the chrM region being tested:. ```; Test1.vcf.gz:chrM 150 . T C,<NON_REF> 49406.77 . DP=1084;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQ0=0;RAW_MQ=3902400.00 GT:AD:DP:GQ:MCL:MMQ:PGT:PID:PL:SB 1/1:0,1081,0:1081:99:0,0,0:0,60,0:0|1:150_T_C:49435,3362,0,49435,3362,49435:0,0,483,598; ```. But the `GenotypeGVCFs` output VCF is empty (file only contains the hdear; no records). Running `SelectVariants` shows the sample but with empty genotype calls:. ```; extract.vcf.gz:chrM 150 . T C,<NON_REF> . . DP=2168;ExcessHet=3.01;MQ0=0;RAW_MQ=7804800.00 GT:AD:DP:GQ:MCL ./.:0,1081,0:1081:99:0.00,0.00 ./.:0,1081,0:1081:99:0.00,0.00; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429
https://github.com/broadinstitute/gatk/issues/3429:398,Testability,test,test,398,"We have received two independent reports of this problem. The latest by Brad Chapman, posted [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/41338#Comment_41338) includes a reproducible test case. Files are here: https://s3.amazonaws.com/chapmanb/testcases/gatk4_genotypegvcfs.tar.gz. #### Steps to reproduce:. Running an import, and then a GenotypeGVCFs and SelectVariants to test export:. ```; gatk-launch GenomicsDBImport --genomicsDBWorkspace test_genomicsdb -L chrM:1-1000 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch GenotypeGVCFs --variant gendb://test_genomicsdb -R hg19.fa --output joint.vcf.gz -L chrM:1-1000; gatk-launch SelectVariants -R hg19.fa -V gendb://test_genomicsdb -O extract.vcf.gz; ```. The input GVCFs have calls within the chrM region being tested:. ```; Test1.vcf.gz:chrM 150 . T C,<NON_REF> 49406.77 . DP=1084;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQ0=0;RAW_MQ=3902400.00 GT:AD:DP:GQ:MCL:MMQ:PGT:PID:PL:SB 1/1:0,1081,0:1081:99:0,0,0:0,60,0:0|1:150_T_C:49435,3362,0,49435,3362,49435:0,0,483,598; ```. But the `GenotypeGVCFs` output VCF is empty (file only contains the hdear; no records). Running `SelectVariants` shows the sample but with empty genotype calls:. ```; extract.vcf.gz:chrM 150 . T C,<NON_REF> . . DP=2168;ExcessHet=3.01;MQ0=0;RAW_MQ=7804800.00 GT:AD:DP:GQ:MCL ./.:0,1081,0:1081:99:0.00,0.00 ./.:0,1081,0:1081:99:0.00,0.00; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429
https://github.com/broadinstitute/gatk/issues/3429:800,Testability,test,tested,800,"We have received two independent reports of this problem. The latest by Brad Chapman, posted [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/41338#Comment_41338) includes a reproducible test case. Files are here: https://s3.amazonaws.com/chapmanb/testcases/gatk4_genotypegvcfs.tar.gz. #### Steps to reproduce:. Running an import, and then a GenotypeGVCFs and SelectVariants to test export:. ```; gatk-launch GenomicsDBImport --genomicsDBWorkspace test_genomicsdb -L chrM:1-1000 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch GenotypeGVCFs --variant gendb://test_genomicsdb -R hg19.fa --output joint.vcf.gz -L chrM:1-1000; gatk-launch SelectVariants -R hg19.fa -V gendb://test_genomicsdb -O extract.vcf.gz; ```. The input GVCFs have calls within the chrM region being tested:. ```; Test1.vcf.gz:chrM 150 . T C,<NON_REF> 49406.77 . DP=1084;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQ0=0;RAW_MQ=3902400.00 GT:AD:DP:GQ:MCL:MMQ:PGT:PID:PL:SB 1/1:0,1081,0:1081:99:0,0,0:0,60,0:0|1:150_T_C:49435,3362,0,49435,3362,49435:0,0,483,598; ```. But the `GenotypeGVCFs` output VCF is empty (file only contains the hdear; no records). Running `SelectVariants` shows the sample but with empty genotype calls:. ```; extract.vcf.gz:chrM 150 . T C,<NON_REF> . . DP=2168;ExcessHet=3.01;MQ0=0;RAW_MQ=7804800.00 GT:AD:DP:GQ:MCL ./.:0,1081,0:1081:99:0.00,0.00 ./.:0,1081,0:1081:99:0.00,0.00; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429
https://github.com/broadinstitute/gatk/pull/3430:103,Deployability,upgrade,upgraded,103,"Added a test to verify that https://github.com/broadinstitute/gatk/issues/3154 is fixed now that we've upgraded htsjdk (though we should keep that ticket open until @sooheelee can verify her particular incarnation of this issue). Also note that while the CRAM MD5 slice calculation is fixed, GATK users can still have problem reading CRAMs made from references containing ambiguity codes if the .dict accompanying the reference was generated with samtools. This is tracked by https://github.com/broadinstitute/gatk/issues/3306, but is really a samtools issue. The simple workaround is to recreate the .dict using CreateSequenceDictionary, which is what I've done to create the test in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430
https://github.com/broadinstitute/gatk/pull/3430:8,Testability,test,test,8,"Added a test to verify that https://github.com/broadinstitute/gatk/issues/3154 is fixed now that we've upgraded htsjdk (though we should keep that ticket open until @sooheelee can verify her particular incarnation of this issue). Also note that while the CRAM MD5 slice calculation is fixed, GATK users can still have problem reading CRAMs made from references containing ambiguity codes if the .dict accompanying the reference was generated with samtools. This is tracked by https://github.com/broadinstitute/gatk/issues/3306, but is really a samtools issue. The simple workaround is to recreate the .dict using CreateSequenceDictionary, which is what I've done to create the test in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430
https://github.com/broadinstitute/gatk/pull/3430:677,Testability,test,test,677,"Added a test to verify that https://github.com/broadinstitute/gatk/issues/3154 is fixed now that we've upgraded htsjdk (though we should keep that ticket open until @sooheelee can verify her particular incarnation of this issue). Also note that while the CRAM MD5 slice calculation is fixed, GATK users can still have problem reading CRAMs made from references containing ambiguity codes if the .dict accompanying the reference was generated with samtools. This is tracked by https://github.com/broadinstitute/gatk/issues/3306, but is really a samtools issue. The simple workaround is to recreate the .dict using CreateSequenceDictionary, which is what I've done to create the test in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430
https://github.com/broadinstitute/gatk/pull/3430:564,Usability,simpl,simple,564,"Added a test to verify that https://github.com/broadinstitute/gatk/issues/3154 is fixed now that we've upgraded htsjdk (though we should keep that ticket open until @sooheelee can verify her particular incarnation of this issue). Also note that while the CRAM MD5 slice calculation is fixed, GATK users can still have problem reading CRAMs made from references containing ambiguity codes if the .dict accompanying the reference was generated with samtools. This is tracked by https://github.com/broadinstitute/gatk/issues/3306, but is really a samtools issue. The simple workaround is to recreate the .dict using CreateSequenceDictionary, which is what I've done to create the test in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430
https://github.com/broadinstitute/gatk/pull/3432:242,Availability,down,downstream,242,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432
https://github.com/broadinstitute/gatk/pull/3432:2,Deployability,UPDATE,UPDATE,2,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432
https://github.com/broadinstitute/gatk/pull/3432:217,Deployability,configurat,configurations,217,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432
https://github.com/broadinstitute/gatk/pull/3432:217,Modifiability,config,configurations,217,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432
https://github.com/broadinstitute/gatk/issues/3437:79,Availability,failure,failures,79,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set … ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437
https://github.com/broadinstitute/gatk/issues/3437:257,Availability,robust,robust,257,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set … ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437
https://github.com/broadinstitute/gatk/issues/3437:634,Energy Efficiency,schedul,scheduled,634,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set … ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437
https://github.com/broadinstitute/gatk/issues/3437:45,Performance,perform,performance,45,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set … ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437
https://github.com/broadinstitute/gatk/issues/3437:57,Testability,test,tests,57,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set … ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437
https://github.com/broadinstitute/gatk/issues/3440:259,Availability,failure,failure,259,"TableCodec has traditionally taken advantage of a quirk of the htsjdk implementation of tabix indexing, where the input stream being indexed was closed and then reopened in between reading of the header and subsequent feature indexing. That quirk had several failure modes (see https://github.com/samtools/htsjdk/issues/393 and https://github.com/samtools/htsjdk/issues/943). These are fixed in https://github.com/samtools/htsjdk/pull/906, and the stream is no longer closed by htsjdk. However, TableCodec required a [modification](https://github.com/broadinstitute/gatk/pull/3403) in order to remain indexable with these fixes, due to its use of a CSV reader (indirectly through TableReader) that buffers input, which thwarts feature-by-feature indexing. We should find a better long term fix for this; either finding a way to prevent OpenCSV from buffering, or possibly using a different CSV implementation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3440
https://github.com/broadinstitute/gatk/pull/3443:42,Availability,down,down,42,"the current repo we are using seems to be down, changing to a different one to unblock us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443
https://github.com/broadinstitute/gatk/issues/3444:119,Availability,failure,failures,119,"We should figure out how to fail the travis build if the before_install or install blocks fail. We have confusing test failures when earlier stages fail, it would be better to error early.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444
https://github.com/broadinstitute/gatk/issues/3444:176,Availability,error,error,176,"We should figure out how to fail the travis build if the before_install or install blocks fail. We have confusing test failures when earlier stages fail, it would be better to error early.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444
https://github.com/broadinstitute/gatk/issues/3444:75,Deployability,install,install,75,"We should figure out how to fail the travis build if the before_install or install blocks fail. We have confusing test failures when earlier stages fail, it would be better to error early.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444
https://github.com/broadinstitute/gatk/issues/3444:114,Testability,test,test,114,"We should figure out how to fail the travis build if the before_install or install blocks fail. We have confusing test failures when earlier stages fail, it would be better to error early.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444
https://github.com/broadinstitute/gatk/pull/3445:27,Security,validat,validating,27,Merge adjacent blocks when validating GVCFs so we use less memory and dont fail when not using an interval argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445
https://github.com/broadinstitute/gatk/pull/3447:507,Availability,error,error,507,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:53,Deployability,configurat,configuration,53,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:80,Deployability,configurat,configuration,80,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:220,Deployability,configurat,configuration,220,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:264,Deployability,configurat,configuration,264,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:313,Deployability,configurat,configuration,313,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:399,Deployability,Configurat,Configuration,399,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:22,Modifiability,config,config,22,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:53,Modifiability,config,configuration,53,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:80,Modifiability,config,configuration,80,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:146,Modifiability,config,config,146,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:220,Modifiability,config,configuration,220,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:264,Modifiability,config,configuration,264,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:313,Modifiability,config,configuration,313,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3447:399,Modifiability,Config,Configuration,399,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447
https://github.com/broadinstitute/gatk/pull/3450:95,Deployability,release,release,95,"Fixes #2738, and is based on #3106 (which should be merged first). Also, requires a Hadoop-BAM release. @lbergelson you mentioned something about changes you made to `HaplotypeCallerEngine` for GVCF - is that relevant to this PR do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3450
https://github.com/broadinstitute/gatk/pull/3453:473,Deployability,Pipeline,Pipeline,473,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:585,Deployability,update,updated,585,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:415,Modifiability,refactor,refactors,415,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:213,Performance,load,loaded,213,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:558,Testability,Test,Tests,558,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:44,Usability,clear,clear,44,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/pull/3453:183,Usability,clear,cleared,183,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453
https://github.com/broadinstitute/gatk/issues/3454:438,Performance,perform,perform,438,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454
https://github.com/broadinstitute/gatk/issues/3454:608,Safety,detect,detect,608,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454
https://github.com/broadinstitute/gatk/issues/3454:654,Security,Validat,ValidateSamFile,654,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454
https://github.com/broadinstitute/gatk/issues/3454:111,Testability,log,logging,111,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454
https://github.com/broadinstitute/gatk/issues/3454:277,Usability,simpl,simple,277,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454
https://github.com/broadinstitute/gatk/pull/3456:494,Availability,down,down,494,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:432,Deployability,configurat,configurations,432,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:695,Deployability,configurat,configuration,695,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:904,Deployability,update,updated,904,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:432,Modifiability,config,configurations,432,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:695,Modifiability,config,configuration,695,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:54,Safety,detect,detectable,54,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:164,Safety,detect,detected,164,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:519,Testability,log,logic,519,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3456:604,Usability,simpl,simple,604,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456
https://github.com/broadinstitute/gatk/pull/3457:566,Availability,down,downstream,566,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457
https://github.com/broadinstitute/gatk/pull/3457:91,Deployability,configurat,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457
https://github.com/broadinstitute/gatk/pull/3457:91,Modifiability,config,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457
https://github.com/broadinstitute/gatk/pull/3457:577,Testability,log,logic,577,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457
https://github.com/broadinstitute/gatk/pull/3457:397,Usability,simpl,simply,397,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457
https://github.com/broadinstitute/gatk/issues/3458:67,Deployability,pipeline,pipeline,67,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:176,Deployability,integrat,integration,176,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:261,Deployability,pipeline,pipeline,261,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:494,Deployability,integrat,integration,494,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:176,Integrability,integrat,integration,176,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:494,Integrability,integrat,integration,494,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3458:76,Performance,perform,performs,76,"@mwalker174's idea (my interpretation, might be slightly off):; SV pipeline performs local assembly at active regions where seemingly a structural variant is present. Pathogen integration into (human) host generates similar signal and it makes sense for the SV pipeline to help identify such sites.; A tool for extracting the locally assembled contigs and their alignments (if any) that potentially useful for this purpose is desired.; And since we output VCF for SV, the potential location of integration would be helpful too.; But for this feature we need #3192 dealt with first, which is now being handled by PR #3457 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458
https://github.com/broadinstitute/gatk/issues/3459:371,Testability,test,testConstructionFromGATKRead,371,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:738,Testability,test,testng,738,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:832,Testability,test,testng,832,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:896,Testability,test,testng,896,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:964,Testability,test,testng,964,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1034,Testability,test,testng,1034,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1050,Testability,Test,TestMethodWorker,1050,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1085,Testability,Test,TestMethodWorker,1085,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1121,Testability,test,testng,1121,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1137,Testability,Test,TestMethodWorker,1137,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1158,Testability,Test,TestMethodWorker,1158,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1194,Testability,test,testng,1194,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1201,Testability,Test,TestRunner,1201,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1223,Testability,Test,TestRunner,1223,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1253,Testability,test,testng,1253,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1260,Testability,Test,TestRunner,1260,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1275,Testability,Test,TestRunner,1275,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1305,Testability,test,testng,1305,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1363,Testability,test,testng,1363,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1429,Testability,test,testng,1429,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1490,Testability,test,testng,1490,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1544,Testability,test,testng,1544,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1614,Testability,test,testng,1614,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1679,Testability,test,testng,1679,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1686,Testability,Test,TestNG,1686,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1715,Testability,Test,TestNG,1715,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1742,Testability,test,testng,1742,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1749,Testability,Test,TestNG,1749,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1773,Testability,Test,TestNG,1773,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1800,Testability,test,testng,1800,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1807,Testability,Test,TestNG,1807,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1824,Testability,Test,TestNG,1824,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1851,Testability,test,testng,1851,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1858,Testability,Test,TestNG,1858,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3459:1869,Testability,Test,TestNG,1869,It seems that it fails to hard-clip the bases array if the cigar has hard-clips. ```; java.lang.IllegalStateException: CIGAR covers 4 bases but the sequence is 8 read bases . 	at org.broadinstitute.hellbender.utils.bwa.BwaMemAlignmentUtils.applyAlignment(BwaMemAlignmentUtils.java:92); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.AlignmentIntervalUnitTest.testConstructionFromGATKRead(AlignmentIntervalUnitTest.java:133); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459
https://github.com/broadinstitute/gatk/issues/3460:745,Availability,down,down,745,"Generally, it is easier on users (and people doing deployment) to have multiple files that list the bam and index files in corresponding order. . So two files, rather than one:; ```; sample1.bam; sample2.bam; ....; ```; and; ```; sample1.bai; sample2.bai; ....; ```. For example, changing the input parameters to:. ```; workflow CNVSomaticPanelWorkflow {; # Workflow input files; ....snip....; # The next two parameters are files that list (in corresponding order) the bam files and bam index files, respectively.; File normal_bams; File normal_bam_idxs; ; # Create (bam, bai) pairs for iterating over scatter loop.; Array[Pair[File,File]] normal_pairs = zip(read_lines(normal_bams), read_lines(normal_bam_idxs)); ....snip....; ```. and further down in that file:. ```; ....snip....; scatter (normal_pair in normal_pairs) {; call CollectCoverage {; input:; padded_targets = select_first([PadTargets.padded_targets, """"]),; bam = normal_pair.left,; bam_idx = normal_pair.right,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk_jar = gatk_jar,; gatk_docker = gatk_docker; }; }; ....snip....; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3460
https://github.com/broadinstitute/gatk/issues/3460:51,Deployability,deploy,deployment,51,"Generally, it is easier on users (and people doing deployment) to have multiple files that list the bam and index files in corresponding order. . So two files, rather than one:; ```; sample1.bam; sample2.bam; ....; ```; and; ```; sample1.bai; sample2.bai; ....; ```. For example, changing the input parameters to:. ```; workflow CNVSomaticPanelWorkflow {; # Workflow input files; ....snip....; # The next two parameters are files that list (in corresponding order) the bam files and bam index files, respectively.; File normal_bams; File normal_bam_idxs; ; # Create (bam, bai) pairs for iterating over scatter loop.; Array[Pair[File,File]] normal_pairs = zip(read_lines(normal_bams), read_lines(normal_bam_idxs)); ....snip....; ```. and further down in that file:. ```; ....snip....; scatter (normal_pair in normal_pairs) {; call CollectCoverage {; input:; padded_targets = select_first([PadTargets.padded_targets, """"]),; bam = normal_pair.left,; bam_idx = normal_pair.right,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk_jar = gatk_jar,; gatk_docker = gatk_docker; }; }; ....snip....; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3460
https://github.com/broadinstitute/gatk/issues/3462:154,Availability,failure,failure,154,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:213,Availability,failure,failure,213,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7563,Availability,ERROR,ERROR,7563,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7664,Availability,ERROR,ERROR,7664,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5608,Deployability,deploy,deploy,5608,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5645,Deployability,deploy,deploy,5645,Tool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5717,Deployability,deploy,deploy,5717,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLik,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5793,Deployability,deploy,deploy,5793,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5864,Deployability,deploy,deploy,5864,am.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:5933,Deployability,deploy,deploy,5933,gram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.appl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1511,Energy Efficiency,schedul,scheduler,1511,.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1582,Energy Efficiency,schedul,scheduler,1582,nstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1941,Energy Efficiency,schedul,scheduler,1941,.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1981,Energy Efficiency,schedul,scheduler,1981,ke.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2079,Energy Efficiency,schedul,scheduler,2079,avaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2176,Energy Efficiency,schedul,scheduler,2176,ly(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2427,Energy Efficiency,schedul,scheduler,2427,319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2507,Energy Efficiency,schedul,scheduler,2507,cheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2612,Energy Efficiency,schedul,scheduler,2612,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2760,Energy Efficiency,schedul,scheduler,2760,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2848,Energy Efficiency,schedul,scheduler,2848,617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2945,Energy Efficiency,schedul,scheduler,2945,.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:3040,Energy Efficiency,schedul,scheduler,3040,.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:3203,Energy Efficiency,schedul,scheduler,3203,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.<init>(ReadMetadata.java:59); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7173,Energy Efficiency,schedul,scheduler,7173,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7244,Energy Efficiency,schedul,scheduler,7244,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1704,Performance,concurren,concurrent,1704,institute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Opti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:1788,Performance,concurren,concurrent,1788,(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7366,Performance,concurren,concurrent,7366,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:7450,Performance,concurren,concurrent,7450,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:133,Safety,abort,aborted,133,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2111,Safety,abort,abortStage,2111, at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2208,Safety,abort,abortStage,2208,org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:2450,Safety,abort,abortStage,2450,RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:443,Security,validat,validateArg,443,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/issues/3462:6105,Security,validat,validateArg,6105,stitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462
https://github.com/broadinstitute/gatk/pull/3464:91,Deployability,configurat,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, significantly overlapping each other on their reference spans. We used to call inversions from such alignments when feasible, but it is more appropriate to emit inverted duplication records. NEEDS TO WAIT UNTIL PARTS 1, 2 AND 3 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464
https://github.com/broadinstitute/gatk/pull/3464:91,Modifiability,config,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, significantly overlapping each other on their reference spans. We used to call inversions from such alignments when feasible, but it is more appropriate to emit inverted duplication records. NEEDS TO WAIT UNTIL PARTS 1, 2 AND 3 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464
https://github.com/broadinstitute/gatk/issues/3465:297,Availability,error,errors,297,"Hi,; I recently used GATK4 Spark local version for somatic variant call. The machine has 40 cores and 160g mem. I tried 20 and 10 cores for each tumor/normal pair in the BQSR step (BaseRecalibratorSpark) and the two samples are processed at the same time. However, the pipeline frequently failes (errors like outofmemory, cannot allocate a page) unless I use 4 cores for each sample. I think the problem should be solved by tuning Spark and JAVA parameters. I considered options like `--conf spark.driver.memory=10g`, `-XX:ParallelGCThreads=10` but had no luck. Can someone suggest the parameter options that I should look at? . Thanks,. -Han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465
https://github.com/broadinstitute/gatk/issues/3465:269,Deployability,pipeline,pipeline,269,"Hi,; I recently used GATK4 Spark local version for somatic variant call. The machine has 40 cores and 160g mem. I tried 20 and 10 cores for each tumor/normal pair in the BQSR step (BaseRecalibratorSpark) and the two samples are processed at the same time. However, the pipeline frequently failes (errors like outofmemory, cannot allocate a page) unless I use 4 cores for each sample. I think the problem should be solved by tuning Spark and JAVA parameters. I considered options like `--conf spark.driver.memory=10g`, `-XX:ParallelGCThreads=10` but had no luck. Can someone suggest the parameter options that I should look at? . Thanks,. -Han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465
https://github.com/broadinstitute/gatk/issues/3465:329,Energy Efficiency,allocate,allocate,329,"Hi,; I recently used GATK4 Spark local version for somatic variant call. The machine has 40 cores and 160g mem. I tried 20 and 10 cores for each tumor/normal pair in the BQSR step (BaseRecalibratorSpark) and the two samples are processed at the same time. However, the pipeline frequently failes (errors like outofmemory, cannot allocate a page) unless I use 4 cores for each sample. I think the problem should be solved by tuning Spark and JAVA parameters. I considered options like `--conf spark.driver.memory=10g`, `-XX:ParallelGCThreads=10` but had no luck. Can someone suggest the parameter options that I should look at? . Thanks,. -Han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465
https://github.com/broadinstitute/gatk/issues/3466:22,Availability,error,error,22,"We're running into an error with GATK 4.0beta3 on some read pairs that appears related to processing clipping on a read. The BAM file itself gets processed fine on GATK 3.8 and the problematic read appears okay on a manual inspection. This is a self-contained reproducible test case that demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk_cigar_error.tar.gz. The error is:; ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:480); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GAT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466
https://github.com/broadinstitute/gatk/issues/3466:386,Availability,error,error,386,"We're running into an error with GATK 4.0beta3 on some read pairs that appears related to processing clipping on a read. The BAM file itself gets processed fine on GATK 3.8 and the problematic read appears okay on a manual inspection. This is a self-contained reproducible test case that demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk_cigar_error.tar.gz. The error is:; ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:480); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GAT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466
https://github.com/broadinstitute/gatk/issues/3466:273,Testability,test,test,273,"We're running into an error with GATK 4.0beta3 on some read pairs that appears related to processing clipping on a read. The BAM file itself gets processed fine on GATK 3.8 and the problematic read appears okay on a manual inspection. This is a self-contained reproducible test case that demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk_cigar_error.tar.gz. The error is:; ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:480); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GAT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466
https://github.com/broadinstitute/gatk/issues/3466:347,Testability,test,testcases,347,"We're running into an error with GATK 4.0beta3 on some read pairs that appears related to processing clipping on a read. The BAM file itself gets processed fine on GATK 3.8 and the problematic read appears okay on a manual inspection. This is a self-contained reproducible test case that demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk_cigar_error.tar.gz. The error is:; ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:480); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GAT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466
https://github.com/broadinstitute/gatk/pull/3467:151,Availability,error,error,151,This fixes a bug in handling the defaults for setting and using our default cluster initialization script for the SV pipeline. The master version will error if no init script parameters are specified.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3467
https://github.com/broadinstitute/gatk/pull/3467:117,Deployability,pipeline,pipeline,117,This fixes a bug in handling the defaults for setting and using our default cluster initialization script for the SV pipeline. The master version will error if no init script parameters are specified.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3467
https://github.com/broadinstitute/gatk/issues/3468:147,Availability,failure,failure,147,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/issues/3468:204,Availability,failure,failure,204,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/issues/3468:1884,Performance,load,loadFromFeatureDataSource,1884,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/issues/3468:126,Safety,abort,aborted,126,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/issues/3468:662,Security,access,access,662,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/issues/3468:1396,Testability,assert,assertFileIsReadable,1396,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468
https://github.com/broadinstitute/gatk/pull/3469:1078,Availability,avail,available,1078,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/pull/3469:89,Deployability,pipeline,pipeline,89,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/pull/3469:2132,Deployability,pipeline,pipeline,2132,"xtension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibly for other variant types. Initial testing shows that these changes slightly increase the number of variants called by the current pipeline, on both the CHM mix and NA12878 data sets, without greatly affecting run time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/pull/3469:487,Integrability,depend,depends,487,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/pull/3469:768,Modifiability,extend,extending,768,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/pull/3469:2036,Testability,test,testing,2036,"xtension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibly for other variant types. Initial testing shows that these changes slightly increase the number of variants called by the current pipeline, on both the CHM mix and NA12878 data sets, without greatly affecting run time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469
https://github.com/broadinstitute/gatk/issues/3471:58,Performance,cache,cache,58,"Currently all VariantWalkers use `100_000` as the feature cache look-ahead settings. This works well for most, but is likely causing memory issues for GenotypeGVCFs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3471
https://github.com/broadinstitute/gatk/pull/3474:40,Deployability,Update,Updates,40,…gning singletons to BwaEngine classes. Updates bwamem-jni depedency to 1.0.2 and adds the possibility of aligning singletons to BwaEngine classes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474
https://github.com/broadinstitute/gatk/pull/3475:357,Integrability,interface,interface,357,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:507,Modifiability,Refactor,Refactor,507,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:15,Testability,test,testing,15,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:61,Testability,test,test,61,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:103,Testability,test,test,103,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:183,Testability,test,test,183,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:203,Testability,test,test,203,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:330,Testability,test,test,330,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:370,Testability,test,testers,370,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:391,Testability,test,testers,391,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:410,Testability,test,test,410,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3475:497,Usability,clear,clear,497,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475
https://github.com/broadinstitute/gatk/pull/3476:0,Integrability,Wrap,Wrapper,0,Wrapper around VC object to access SVContext specific annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476
https://github.com/broadinstitute/gatk/pull/3476:28,Security,access,access,28,Wrapper around VC object to access SVContext specific annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476
https://github.com/broadinstitute/gatk/pull/3478:121,Availability,error,error,121,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478
https://github.com/broadinstitute/gatk/pull/3478:240,Availability,error,error,240,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478
https://github.com/broadinstitute/gatk/pull/3478:127,Integrability,message,message,127,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478
https://github.com/broadinstitute/gatk/pull/3478:220,Integrability,message,message,220,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478
https://github.com/broadinstitute/gatk/pull/3479:31,Testability,log,logger,31,"MathUtils was using the log4j1 logger, fixed to use the log4j 2 logger",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3479
https://github.com/broadinstitute/gatk/pull/3479:64,Testability,log,logger,64,"MathUtils was using the log4j1 logger, fixed to use the log4j 2 logger",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3479
https://github.com/broadinstitute/gatk/pull/3480:497,Deployability,configurat,configuration,497,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/pull/3480:165,Energy Efficiency,reduce,reduce,165,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/pull/3480:497,Modifiability,config,configuration,497,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/pull/3480:737,Performance,perform,performance,737,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/pull/3480:1049,Performance,cache,caches,1049,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/pull/3480:577,Security,expose,expose,577,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480
https://github.com/broadinstitute/gatk/issues/3481:77,Availability,failure,failures,77,"I ran 408 invocations of an nio using command for BQSR using gatk4 and got 2 failures that looked pretty similar. Is there something I might be doing wrong? The two failures were also on different shards. . I cant remember exactly when I built this jar but it was after this commit - https://github.com/broadinstitute/gatk/commit/4df1d16518cbd3a05a45a070d682446878ec4eaa less than a week ago. If you need any more info let me know, thanks. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xms3000m -jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar ApplyBQSR --createOutputBamMD5 --addOutputSAMProgramRecord -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-SortSampleBam/attempt-4/NA12878.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O NA12878.aligned.duplicates_marked.recalibrated.bam -bqsr /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv -SQQ 10 -SQQ 20 -SQQ 30 -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.Ni4zSL; [August 22, 2017 2:52:59 PM UTC] ApplyBQSR --output NA12878.aligned.duplicates_marked.recalibrated.bam --bqsr_recal_file /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv --useOriginalQualities true --static_quantized_quals 10 --static_quantized_quals 20 --static_quantized_quals 30 --intervals chr5:1+ --input gs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:165,Availability,failure,failures,165,"I ran 408 invocations of an nio using command for BQSR using gatk4 and got 2 failures that looked pretty similar. Is there something I might be doing wrong? The two failures were also on different shards. . I cant remember exactly when I built this jar but it was after this commit - https://github.com/broadinstitute/gatk/commit/4df1d16518cbd3a05a45a070d682446878ec4eaa less than a week ago. If you need any more info let me know, thanks. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xms3000m -jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar ApplyBQSR --createOutputBamMD5 --addOutputSAMProgramRecord -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-SortSampleBam/attempt-4/NA12878.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O NA12878.aligned.duplicates_marked.recalibrated.bam -bqsr /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv -SQQ 10 -SQQ 20 -SQQ 30 -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.Ni4zSL; [August 22, 2017 2:52:59 PM UTC] ApplyBQSR --output NA12878.aligned.duplicates_marked.recalibrated.bam --bqsr_recal_file /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv --useOriginalQualities true --static_quantized_quals 10 --static_quantized_quals 20 --static_quantized_quals 30 --intervals chr5:1+ --input gs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:4010,Availability,avail,available,4010,"cs_max_retries 20 --disableToolDefaultReadFilters false; [August 22, 2017 2:52:59 PM UTC] Executing as root@fb0704c97258 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.3-41-g9d05dd8-SNAPSHOT; [August 22, 2017 3:06:11 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 13.19 minutes.; Runtime.totalMemory()=3040870400; htsjdk.samtools.FileTruncatedException: Premature end of file: /PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-SortSampleBam/attempt-4/NA12878.aligned.duplicate_marked.sorted.bam; 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:530); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:6198,Integrability,wrap,wrapAndCopyInto,6198,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:5423,Performance,load,loadNextRecord,5423,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:803,Testability,log,log,803,"I ran 408 invocations of an nio using command for BQSR using gatk4 and got 2 failures that looked pretty similar. Is there something I might be doing wrong? The two failures were also on different shards. . I cant remember exactly when I built this jar but it was after this commit - https://github.com/broadinstitute/gatk/commit/4df1d16518cbd3a05a45a070d682446878ec4eaa less than a week ago. If you need any more info let me know, thanks. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xms3000m -jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar ApplyBQSR --createOutputBamMD5 --addOutputSAMProgramRecord -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-SortSampleBam/attempt-4/NA12878.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O NA12878.aligned.duplicates_marked.recalibrated.bam -bqsr /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv -SQQ 10 -SQQ 20 -SQQ 30 -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.Ni4zSL; [August 22, 2017 2:52:59 PM UTC] ApplyBQSR --output NA12878.aligned.duplicates_marked.recalibrated.bam --bqsr_recal_file /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv --useOriginalQualities true --static_quantized_quals 10 --static_quantized_quals 20 --static_quantized_quals 30 --intervals chr5:1+ --input gs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:5229,Testability,Assert,AssertingIterator,5229,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/issues/3481:5303,Testability,Assert,AssertingIterator,5303,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481
https://github.com/broadinstitute/gatk/pull/3482:47,Testability,test,tests,47,"Move MarkDuplicates/EstimateLibraryComplexity, tests, and resources:; - from `tools.picard.sam` to `tools.walkers.markduplicates` package; - rename both tools to have a “2” suffix; - for now, these are still `PicardCommandLinePrograms`; - remaining related [classes](https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/utils/read/markduplicates) are not moved or renamed, though most have Picard analogs with the same simple name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3482
https://github.com/broadinstitute/gatk/pull/3482:461,Usability,simpl,simple,461,"Move MarkDuplicates/EstimateLibraryComplexity, tests, and resources:; - from `tools.picard.sam` to `tools.walkers.markduplicates` package; - rename both tools to have a “2” suffix; - for now, these are still `PicardCommandLinePrograms`; - remaining related [classes](https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/utils/read/markduplicates) are not moved or renamed, though most have Picard analogs with the same simple name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3482
https://github.com/broadinstitute/gatk/issues/3483:116,Availability,down,downstream,116,"Because in `Main`the call to `Utils.forceJVMLocaleToUSEnglish()` is done in an static block, this is not applied to downstream projects. I wonder if this call can be moved to `Main.mainEntry`, to assess extending classes apply the same locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483
https://github.com/broadinstitute/gatk/issues/3483:203,Modifiability,extend,extending,203,"Because in `Main`the call to `Utils.forceJVMLocaleToUSEnglish()` is done in an static block, this is not applied to downstream projects. I wonder if this call can be moved to `Main.mainEntry`, to assess extending classes apply the same locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483
https://github.com/broadinstitute/gatk/pull/3485:310,Deployability,deploy,deployed,310,"Writing reads was fixed in https://github.com/broadinstitute/gatk/commit/73f2a62bee52518b57a985717770ed3a64d83243, but unfortunately the same problem occurs with variants. This commit (https://github.com/broadinstitute/gatk/commit/a861a23b544012fb8f69358a3999dd587d343547) fixes the problem for variants, when deployed with a Hadoop-BAM fix (https://github.com/HadoopGenomics/Hadoop-BAM/pull/143).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3485
https://github.com/broadinstitute/gatk/issues/3487:3012,Availability,Down,Downsampling,3012,"ormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 17:39:56,368 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz ; INFO 17:39:56,373 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 17:39:56,374 HelpFormatter - Date/Time: 2017/08/22 17:39:56 ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,385 GenomeAnalysisEngine - Strictness is SILENT ; INFO 17:39:57,377 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 17:39:58,497 GenomeAnalysisEngine - Preparing for traversal ; INFO 17:39:58,502 GenomeAnalysisEngine - Done preparing for traversal ; INFO 17:39:58,503 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 17:39:58,503 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 17:39:58,503 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 17:39:58,692 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 17:39:58,697 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7677,Availability,checkpoint,checkpoint,7677,"ence allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and loo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7901,Availability,checkpoint,checkpoint,7901,"2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:8125,Availability,checkpoint,checkpoint,8125,"er - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.txt; WMCF9-CB5:Mutect2 shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 6d93f1ea32c99ae5020881fa8265bdc1. WMCF9-CB5:Mutect2 shlee$ gzcat eta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > eta_headless.txt; WMCF9-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:168,Integrability,message,message,168,"...because it does the following:; - makes it appear no variants were left-aligned when in fact many were left-aligned. ; - In addition, because the tool emits an INFO message for sites that it skips (due to reference allele being too long), it appears doubly confusing as if the tool skips sites that could use left-alignment and only these types of skipped sites are present.; - Finally, for my file, it drops 66,568 variant sites (I did not check alleles) for me silently and without any warning. ## Two suggestions for improvement for LeftAlign's stdout:; 1. A count of variants/sites that were left-aligned OR at least NOT the confusing `0 variants were aligned` message.; 2. The length of the longest reference allele that the tool skipped.; 3. At least the number if not the sites of dropped variant records. My workaround in the meanwhile: I had to `md5` headerless VCFs to confirm the input is different from the output of the tool. . ---; ## Here's how I came to the above; Quick note because I use GATK3.7's LeftAlignAndTrimVariants below. I am using LeftAlignAndTrimVariants from GATK3.7. ### Command; I am using a grch37-->grch38 liftedover (via Picard) VCF as input. It would be more ideal if Picard LiftoverVcf would left-align variants but we cannot have everything we want when we want it. So here I am asking for a better LeftAlign. The output file is for use with GATK4-Mutect2. ```; java -jar $GATK -T LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz; ```. ### Portions of stdout; ```; INFO 17:39:56,364 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,365 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.7-0-gcfedb67, Compiled 2016/12/12 11:21:18 ; INFO 17:39:56,366 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 17:39:56,366 HelpFormatter - For support and documentation go",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:668,Integrability,message,message,668,"...because it does the following:; - makes it appear no variants were left-aligned when in fact many were left-aligned. ; - In addition, because the tool emits an INFO message for sites that it skips (due to reference allele being too long), it appears doubly confusing as if the tool skips sites that could use left-alignment and only these types of skipped sites are present.; - Finally, for my file, it drops 66,568 variant sites (I did not check alleles) for me silently and without any warning. ## Two suggestions for improvement for LeftAlign's stdout:; 1. A count of variants/sites that were left-aligned OR at least NOT the confusing `0 variants were aligned` message.; 2. The length of the longest reference allele that the tool skipped.; 3. At least the number if not the sites of dropped variant records. My workaround in the meanwhile: I had to `md5` headerless VCFs to confirm the input is different from the output of the tool. . ---; ## Here's how I came to the above; Quick note because I use GATK3.7's LeftAlignAndTrimVariants below. I am using LeftAlignAndTrimVariants from GATK3.7. ### Command; I am using a grch37-->grch38 liftedover (via Picard) VCF as input. It would be more ideal if Picard LiftoverVcf would left-align variants but we cannot have everything we want when we want it. So here I am asking for a better LeftAlign. The output file is for use with GATK4-Mutect2. ```; java -jar $GATK -T LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz; ```. ### Portions of stdout; ```; INFO 17:39:56,364 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,365 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.7-0-gcfedb67, Compiled 2016/12/12 11:21:18 ; INFO 17:39:56,366 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 17:39:56,366 HelpFormatter - For support and documentation go",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7305,Integrability,message,messages,7305,"mVariants - Reference allele is too long (236) at position chr1:214679654; skipping that record. Set --reference_window_stop >= 236 ; ...; INFO 21:38:54,227 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from abov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7616,Safety,detect,detected,7616,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7840,Safety,detect,detected,7840,"et --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:8064,Safety,detect,detected,8064,"s were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.txt; WMCF9-CB5:Mutect2 shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 6d93f1ea32c99a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:3198,Security,validat,validation,3198,"ormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 17:39:56,368 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz ; INFO 17:39:56,373 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 17:39:56,374 HelpFormatter - Date/Time: 2017/08/22 17:39:56 ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,385 GenomeAnalysisEngine - Strictness is SILENT ; INFO 17:39:57,377 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 17:39:58,497 GenomeAnalysisEngine - Preparing for traversal ; INFO 17:39:58,502 GenomeAnalysisEngine - Done preparing for traversal ; INFO 17:39:58,503 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 17:39:58,503 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 17:39:58,503 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 17:39:58,692 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 17:39:58,697 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7468,Security,validat,validation,7468,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7499,Usability,Simpl,SimpleTimer,7499,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7723,Usability,Simpl,SimpleTimer,7723,"et --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3487:7947,Usability,Simpl,SimpleTimer,7947,"s were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.txt; WMCF9-CB5:Mutect2 shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 6d93f1ea32c99a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487
https://github.com/broadinstitute/gatk/issues/3488:198,Availability,error,errors,198,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:284,Availability,error,error,284,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:354,Availability,error,error,354,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:117,Performance,load,load,117,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:140,Performance,load,loads,140,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:313,Performance,load,load,313,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3488:162,Security,Validat,ValidateSamFile,162,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488
https://github.com/broadinstitute/gatk/issues/3489:112,Modifiability,config,configurable,112,once #3480 is in and #3447 is in @magicDGS requested that we should expose DEFAULT_FEATURE_CACHE_LOOKAHEAD as a configurable option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3489
https://github.com/broadinstitute/gatk/issues/3489:68,Security,expose,expose,68,once #3480 is in and #3447 is in @magicDGS requested that we should expose DEFAULT_FEATURE_CACHE_LOOKAHEAD as a configurable option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3489
https://github.com/broadinstitute/gatk/pull/3490:293,Security,validat,validating,293,"Fixes issue identified by @kgururaj when investigating GenomicsDB; dropping calls (https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324188028); which is due to incorrect VCF header length descriptions. It looks like this mismatch was reported early by @LeeTL1220; in #3296 when validating VCFs. @davidbenjamin provided a partial fix in #3351, generalizing the output; to include the option of specifying R instead of A using; `includeRefAllele`, fixing MFRL and removing MCL. This fixes the 3 remaining cases, MMQ (which breaks the GenomicsDB; example), MPOS and MBQ. Fixes #3296; Fixes #3429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490
https://github.com/broadinstitute/gatk/issues/3491:49,Deployability,release,release,49,User has reported longer runtimes in GATK4 beta3 release compared to GATK4 beta 2 release. It sounds like this is not expected. Her runtimes are below. The first post in the forum thread has her original report. . | Tool | 4.beta.2 | 4.beta.3 |; | ------------------------------------- | -----------:| -----------:|; | BaseRecalibrator | 1m 3s | 3m 3s |; | ApplyBQSR (scattered) | 4m 48s | 11m 51s |; | HaplotypeCaller (scattered) | 23m 42s | 29m 7s |; | GenotypeGVCFs (scattered) | 4m 6s | 9m 28s |; | VariantRecalibrator (for SNPs) | 4m 7s | 6m 38s |; | VariantRecalibrator (for INDELs) | 2m 7s | 4m 8s |; | ApplyVQSR (for SNPs) | 37s | 2m 36s |; | ApplyVQSR (for INDELs) | 39s | 2m 35s |. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/41669#Comment_41669,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491
https://github.com/broadinstitute/gatk/issues/3491:82,Deployability,release,release,82,User has reported longer runtimes in GATK4 beta3 release compared to GATK4 beta 2 release. It sounds like this is not expected. Her runtimes are below. The first post in the forum thread has her original report. . | Tool | 4.beta.2 | 4.beta.3 |; | ------------------------------------- | -----------:| -----------:|; | BaseRecalibrator | 1m 3s | 3m 3s |; | ApplyBQSR (scattered) | 4m 48s | 11m 51s |; | HaplotypeCaller (scattered) | 23m 42s | 29m 7s |; | GenotypeGVCFs (scattered) | 4m 6s | 9m 28s |; | VariantRecalibrator (for SNPs) | 4m 7s | 6m 38s |; | VariantRecalibrator (for INDELs) | 2m 7s | 4m 8s |; | ApplyVQSR (for SNPs) | 37s | 2m 36s |; | ApplyVQSR (for INDELs) | 39s | 2m 35s |. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/41669#Comment_41669,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491
https://github.com/broadinstitute/gatk/issues/3492:4208,Availability,ERROR,ERROR,4208,"k manager 172.17.0.2:33999 with 4.1 GB RAM, BlockManagerId(driver, 172.17.0.2, 33999); 17/08/22 18:54:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.0.2, 33999); 17/08/22 18:54:43 INFO SparkUI: Stopped Spark web UI at http://172.17.0.2:4040; 17/08/22 18:54:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/08/22 18:54:43 INFO MemoryStore: MemoryStore cleared; 17/08/22 18:54:43 INFO BlockManager: BlockManager stopped; 17/08/22 18:54:43 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/08/22 18:54:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/08/22 18:54:43 INFO SparkContext: Successfully stopped SparkContext; [August 22, 2017 6:54:43 PM UTC] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=299892736; ***********************************************************************. A USER ERROR has occurred: null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:396); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:6150,Availability,echo,echo,6150,"ion$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:396); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 17/08/22 18:54:43 INFO ShutdownHookManager: Shutdown hook called; 17/08/22 18:54:43 INFO ShutdownHookManager: Deleting directory /cromwell_root/tmp.5EEmH0/root/spark-4900f4dd-59fb-4a6d-96c8-8b99edb608ab; ```; I am using the docker image `broadinstitute/gatk:4.beta.3`. Here's the command line:; ```; java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx8g -jar /root/gatk.jar SparkGenomeReadCounts \; --input /cromwell_root/broad-dsde-methods/mehrtash/cromwell-executions/CRAMCollectCoverage/29948994-7457-43b9-b6e3-5d188906595d/call-CramToBam/shard-0/8007540135.bam \; --reference /cromwell_root/broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; --binsize 1000 \; --keepXYMT true \; --disableToolDefaultReadFilters false \; --disableSequenceDictionaryValidation true \; $(if [ true = true ]; then echo "" --disableReadFilter NotDuplicateReadFilter ""; else echo """"; fi) \; --outputFile 8007540135.coverage.tsv \; --verbosity DEBUG; ```. No NIO, no GCS -- everything is localized on the VM HDD at this stage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:6208,Availability,echo,echo,6208,"ion$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:396); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 17/08/22 18:54:43 INFO ShutdownHookManager: Shutdown hook called; 17/08/22 18:54:43 INFO ShutdownHookManager: Deleting directory /cromwell_root/tmp.5EEmH0/root/spark-4900f4dd-59fb-4a6d-96c8-8b99edb608ab; ```; I am using the docker image `broadinstitute/gatk:4.beta.3`. Here's the command line:; ```; java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx8g -jar /root/gatk.jar SparkGenomeReadCounts \; --input /cromwell_root/broad-dsde-methods/mehrtash/cromwell-executions/CRAMCollectCoverage/29948994-7457-43b9-b6e3-5d188906595d/call-CramToBam/shard-0/8007540135.bam \; --reference /cromwell_root/broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; --binsize 1000 \; --keepXYMT true \; --disableToolDefaultReadFilters false \; --disableSequenceDictionaryValidation true \; $(if [ true = true ]; then echo "" --disableReadFilter NotDuplicateReadFilter ""; else echo """"; fi) \; --outputFile 8007540135.coverage.tsv \; --verbosity DEBUG; ```. No NIO, no GCS -- everything is localized on the VM HDD at this stage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1409,Performance,load,load,1409,"nput /cromwell_root/broad-dsde-methods/mehrtash/cromwell-executions/CRAMCollectCoverage/29948994-7457-43b9-b6e3-5d188906595d/call-CramToBam/shard-0/8007540135.bam --disableSequenceDictionaryValidation true --verbosity DEBUG --disableReadFilter NotDuplicateReadFilter --disableToolDefaultReadFilters false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1525,Security,Secur,SecurityManager,1525,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1594,Security,Secur,SecurityManager,1594,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1665,Security,Secur,SecurityManager,1665,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1737,Security,Secur,SecurityManager,1737,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1811,Security,Secur,SecurityManager,1811,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1828,Security,Secur,SecurityManager,1828,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:1845,Security,authenticat,authentication,1845,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3492:3637,Usability,clear,cleared,3637,"8/22 18:54:42 INFO Executor: Starting executor ID driver on host localhost; 17/08/22 18:54:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33999.; 17/08/22 18:54:42 INFO NettyBlockTransferService: Server created on 172.17.0.2:33999; 17/08/22 18:54:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.17.0.2, 33999); 17/08/22 18:54:42 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:33999 with 4.1 GB RAM, BlockManagerId(driver, 172.17.0.2, 33999); 17/08/22 18:54:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.0.2, 33999); 17/08/22 18:54:43 INFO SparkUI: Stopped Spark web UI at http://172.17.0.2:4040; 17/08/22 18:54:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/08/22 18:54:43 INFO MemoryStore: MemoryStore cleared; 17/08/22 18:54:43 INFO BlockManager: BlockManager stopped; 17/08/22 18:54:43 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/08/22 18:54:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/08/22 18:54:43 INFO SparkContext: Successfully stopped SparkContext; [August 22, 2017 6:54:43 PM UTC] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=299892736; ***********************************************************************. A USER ERROR has occurred: null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:396); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.sp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492
https://github.com/broadinstitute/gatk/issues/3493:133,Performance,perform,performing,133,"The docker images on https://hub.docker.com/r/broadinstitute/gatk-nightly/ have the wrong version number on their jars due to docker performing a shallow clone, these need to be corrected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3493
https://github.com/broadinstitute/gatk/pull/3494:479,Testability,test,tests,479,"This pull request fixes three issues in the AlignmentUtils class,. - The treatment of D-over-D in function applyCigarToCigar() is backward.; - In function createReadAlignedToRef() the read start position passed to the leftAlignIndel() call may be incorrect if the haplotype has an indel relative to reference.; - And when the leftAlignIndel() call drops any leading D operator in the result cigar, the read start position needs to be adjusted accordingly. It also adds some unit tests to demonstrate the issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494
https://github.com/broadinstitute/gatk/pull/3495:156,Availability,error,error,156,"Building with Intellij 2017.2 generates an /out directory instead of using the build/ folder from gradle, that is show as untracked but can be committed by error. This folder cannot be changed, even if the compiler output is changed (see CrazyCoder comment in https://stackoverflow.com/questions/45174989/building-with-intellij-2017-2-out-directory-duplicates-files-in-build-director).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3495
https://github.com/broadinstitute/gatk/issues/3500:201,Availability,error,errors,201,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:4,Deployability,patch,patches,4,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:273,Deployability,release,release,273,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:300,Deployability,release,release,300,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:335,Deployability,update,update,335,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:354,Deployability,release,release,354,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3500:406,Integrability,depend,dependency,406,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500
https://github.com/broadinstitute/gatk/issues/3501:1771,Availability,down,down,1771,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:824,Integrability,interface,interface,824,"Implement a `PythonScriptExecutor` that is similar to the existing `RScriptExecutor` (invokes Python with a given set of arguments). Then ask the CNV team to prototype an example tool or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all depend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:1547,Integrability,depend,dependencies,1547,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:1995,Integrability,depend,dependencies,1995,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:295,Modifiability,maintainab,maintainability,295,"Implement a `PythonScriptExecutor` that is similar to the existing `RScriptExecutor` (invokes Python with a given set of arguments). Then ask the CNV team to prototype an example tool or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all depend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:1875,Modifiability,maintainab,maintainability,1875,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:1352,Security,authenticat,authentication,1352,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:253,Usability,learn,learning,253,"Implement a `PythonScriptExecutor` that is similar to the existing `RScriptExecutor` (invokes Python with a given set of arguments). Then ask the CNV team to prototype an example tool or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all depend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3501:1613,Usability,clear,clearly,1613,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501
https://github.com/broadinstitute/gatk/issues/3503:31,Deployability,configurat,configuration,31,"With the addition of the Owner configuration mechanism to GATK, we're going to need to fold (most of) `gatk-launch` into Java, so that the Spark settings can be loaded from Owner before `spark-submit` or `gcloud` are invoked. Note that we'll still need to have a thin GATK launcher script for the sake of the tab completion, which requires that we invoke GATK using a unique command name.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3503
https://github.com/broadinstitute/gatk/issues/3503:31,Modifiability,config,configuration,31,"With the addition of the Owner configuration mechanism to GATK, we're going to need to fold (most of) `gatk-launch` into Java, so that the Spark settings can be loaded from Owner before `spark-submit` or `gcloud` are invoked. Note that we'll still need to have a thin GATK launcher script for the sake of the tab completion, which requires that we invoke GATK using a unique command name.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3503
https://github.com/broadinstitute/gatk/issues/3503:161,Performance,load,loaded,161,"With the addition of the Owner configuration mechanism to GATK, we're going to need to fold (most of) `gatk-launch` into Java, so that the Spark settings can be loaded from Owner before `spark-submit` or `gcloud` are invoked. Note that we'll still need to have a thin GATK launcher script for the sake of the tab completion, which requires that we invoke GATK using a unique command name.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3503
https://github.com/broadinstitute/gatk/pull/3504:20,Performance,perform,performance,20,Picks up VCF header performance fix.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3504
https://github.com/broadinstitute/gatk/issues/3506:235,Availability,down,download,235,"For @davidbenjamin. I am using the beta.3 stable jar. The data was generated in the Cloud using the WDL script commands from the repo and tool defaults. @vdauwera can share the workspace with you so you can see the actual workflow and download the callsets. Here are the five calls with untrimmed REF allele representations from my WES callset:; ```; WMCF9-CB5:8640dac1_waf_wpon shlee$ gzcat other_waf_wpon.vcf.gz | grep -v '#' | less; chr2 38856503 . CT TT . germline_risk;panel_of_normals DP=78;ECNT=1;IN_PON;NLOD=2.87;N_ART_LOD=-2.323e-01;POP_AF=1.000e-03;P_GERMLINE=-1.812e-01;TLOD=6.41 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:24,4:0.213:13,19:0,0:215,172:60,60:8,8:false:false 0/1:30,8:0.249:0,23:0,0:0,183:0,47:0,12:false:false:0.495,0.00,0.500:0.025,0.028,0.947; chr2 99390427 . GT TT . panel_of_normals;t_lod DP=120;ECNT=2;IN_PON;NLOD=6.15;N_ART_LOD=-3.396e-01;POP_AF=2.719e-04;P_GERMLINE=-4.564e+00;TLOD=4.89 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:58,5:0.136:25,31:0,0:211,240:60,60:22,20:false:false 0/1:39,6:0.186:26,31:0,0:235,216:60,60:22,26:false:false:0.202,0.00,0.200:0.011,0.053,0.936; chr7 65961067 . CAAA AAAA . base_quality;panel_of_normals;t_lod DP=178;ECNT=1;IN_PON;NLOD=15.64;N_ART_LOD=-8.858e-01;POP_AF=1.000e-03;P_GERMLINE=-1.452e+01;TLOD=3.82 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,9:0.211:20,2:0,0:169,181:60,60:22,12:false:false 0/1:42,12:0.281:26,5:0,0:155,168:60,60:21,21:false:false:0.253,0.00,0.250:0.011,0.068,0.921; chr10 26536222 . GAAA AAAA . artifact_in_normal;base_quality;panel_of_normals DP=385;ECNT=1;IN_PON;NLOD=7.23;N_ART_LOD=2.38;POP_AF=1.000e-03;P_GERMLINE=-3.938e+00;TLOD=7.64 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,18:0.241:14,6:0,0:169,221:60,60:21,18:false:false 0/1:187,45:0.241:19,8:0,0:134,190:60,60:24,17:false:false:0.111,0.00,0.108:9.821e-04,0.663,0.336; chr20 34445260 . GT TT . germline_risk;panel_of_normals DP=55;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3506
https://github.com/broadinstitute/gatk/issues/3506:2875,Testability,log,log,2875,".00,0.200:0.011,0.053,0.936; chr7 65961067 . CAAA AAAA . base_quality;panel_of_normals;t_lod DP=178;ECNT=1;IN_PON;NLOD=15.64;N_ART_LOD=-8.858e-01;POP_AF=1.000e-03;P_GERMLINE=-1.452e+01;TLOD=3.82 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,9:0.211:20,2:0,0:169,181:60,60:22,12:false:false 0/1:42,12:0.281:26,5:0,0:155,168:60,60:21,21:false:false:0.253,0.00,0.250:0.011,0.068,0.921; chr10 26536222 . GAAA AAAA . artifact_in_normal;base_quality;panel_of_normals DP=385;ECNT=1;IN_PON;NLOD=7.23;N_ART_LOD=2.38;POP_AF=1.000e-03;P_GERMLINE=-3.938e+00;TLOD=7.64 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,18:0.241:14,6:0,0:169,221:60,60:21,18:false:false 0/1:187,45:0.241:19,8:0,0:134,190:60,60:24,17:false:false:0.111,0.00,0.108:9.821e-04,0.663,0.336; chr20 34445260 . GT TT . germline_risk;panel_of_normals DP=55;ECNT=1;IN_PON;NLOD=3.81;N_ART_LOD=-7.874e-01;POP_AF=6.812e-03;P_GERMLINE=-3.466e-01;TLOD=5.80 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:13,0:0.186:35,0:0,0:265,0:60,0:30,0:false:false 0/1:28,6:0.188:21,19:0,0:161,168:60,60:20,23:false:false:0.263,0.00,0.263:0.010,0.100,0.890; ```. I select these from the callset with; ```; gatk-launch SelectVariants \; 	-V HCC1143-vs-HCC1143_BL-filtered.vcf \; 	-O other_waf_wpon.vcf.gz \; 	-xlSelectType SNP \; 	-xlSelectType INDEL; ```. The original BAMs and resource files from which these calls were made are as follows. Data are to GRCh38. - tumor `gs://shlee-dev/hcc/hcc1143_T_clean.bam` and `gs://shlee-dev/hcc/hcc1143_T_clean.bai`; - normal `gs://shlee-dev/hcc/ hcc1143_N_clean.bam` and `gs://shlee-dev/hcc/ hcc1143_N_clean.bai`; - 39 sample PoN generated with beta.1 jar `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz` and `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz.tbi`; - gnomad resource `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz` and `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz.tbi`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3506
https://github.com/broadinstitute/gatk/issues/3506:2932,Testability,log,log,2932,".00,0.200:0.011,0.053,0.936; chr7 65961067 . CAAA AAAA . base_quality;panel_of_normals;t_lod DP=178;ECNT=1;IN_PON;NLOD=15.64;N_ART_LOD=-8.858e-01;POP_AF=1.000e-03;P_GERMLINE=-1.452e+01;TLOD=3.82 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,9:0.211:20,2:0,0:169,181:60,60:22,12:false:false 0/1:42,12:0.281:26,5:0,0:155,168:60,60:21,21:false:false:0.253,0.00,0.250:0.011,0.068,0.921; chr10 26536222 . GAAA AAAA . artifact_in_normal;base_quality;panel_of_normals DP=385;ECNT=1;IN_PON;NLOD=7.23;N_ART_LOD=2.38;POP_AF=1.000e-03;P_GERMLINE=-3.938e+00;TLOD=7.64 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,18:0.241:14,6:0,0:169,221:60,60:21,18:false:false 0/1:187,45:0.241:19,8:0,0:134,190:60,60:24,17:false:false:0.111,0.00,0.108:9.821e-04,0.663,0.336; chr20 34445260 . GT TT . germline_risk;panel_of_normals DP=55;ECNT=1;IN_PON;NLOD=3.81;N_ART_LOD=-7.874e-01;POP_AF=6.812e-03;P_GERMLINE=-3.466e-01;TLOD=5.80 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:13,0:0.186:35,0:0,0:265,0:60,0:30,0:false:false 0/1:28,6:0.188:21,19:0,0:161,168:60,60:20,23:false:false:0.263,0.00,0.263:0.010,0.100,0.890; ```. I select these from the callset with; ```; gatk-launch SelectVariants \; 	-V HCC1143-vs-HCC1143_BL-filtered.vcf \; 	-O other_waf_wpon.vcf.gz \; 	-xlSelectType SNP \; 	-xlSelectType INDEL; ```. The original BAMs and resource files from which these calls were made are as follows. Data are to GRCh38. - tumor `gs://shlee-dev/hcc/hcc1143_T_clean.bam` and `gs://shlee-dev/hcc/hcc1143_T_clean.bai`; - normal `gs://shlee-dev/hcc/ hcc1143_N_clean.bam` and `gs://shlee-dev/hcc/ hcc1143_N_clean.bai`; - 39 sample PoN generated with beta.1 jar `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz` and `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz.tbi`; - gnomad resource `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz` and `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz.tbi`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3506
https://github.com/broadinstitute/gatk/pull/3507:22,Testability,test,test,22,"Randomly noticed this test that was disabled long ago. Between https://github.com/samtools/htsjdk/pull/704 and https://github.com/samtools/htsjdk/pull/906, it now works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3507
https://github.com/broadinstitute/gatk/issues/3508:20,Availability,avail,available,20,"Right now it is not available (even after #3457).; Though the VCF spec doesn't seem to specify if it is mandated, it makes it easier for parsing and making sense of the event. Note that this is different from `PARID`, which, unlike BND that symbols novel adjacency, symbols ; ""novel"" disruptions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3508
https://github.com/broadinstitute/gatk/issues/3510:2623,Availability,error,errors,2623,"P_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep 'chrX'; ##contig=<ID=chrX,length=156040895>; ##contig=<ID=chrX_KI270880v1_alt,length=284869>; ##contig=<ID=chrX_KI270881v1_alt,length=144206>; ##contig=<ID=chrX_KI270913v1_alt,length=274009>; chrX	132097402	.	TACAC	T,TAC	.	.	.; ```; This site should have been called in the PoN. Finally, for the `-vcfs` parameter, if I provide a list of files, one per line, the tool errors with; ```; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file, for input source: /Users/shlee/Desktop/August2017_tutorial_dev/working/list_of_normals_for_pon.txt; 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:253); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:101); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:126); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:2723,Availability,error,error,2723,".455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep 'chrX'; ##contig=<ID=chrX,length=156040895>; ##contig=<ID=chrX_KI270880v1_alt,length=284869>; ##contig=<ID=chrX_KI270881v1_alt,length=144206>; ##contig=<ID=chrX_KI270913v1_alt,length=274009>; chrX	132097402	.	TACAC	T,TAC	.	.	.; ```; This site should have been called in the PoN. Finally, for the `-vcfs` parameter, if I provide a list of files, one per line, the tool errors with; ```; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file, for input source: /Users/shlee/Desktop/August2017_tutorial_dev/working/list_of_normals_for_pon.txt; 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:253); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:101); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:126); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:4685,Deployability,update,update,4685,"ader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:115); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:36); 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:251); 	... 12 more; ```. Either we should update the documentation to point users to use the `--arguments_file` instead (let me know) or we should update the functionality to accept a list of files. Currently, the option is described as:. > --vcfsListFile,-vcfs:File VCFs for samples to include. May be specified either one at a time, or as one or more .list file containing multiple VCFs, one per line. This argument must be specified at least once. Required. . Here is the test data:; [createsomaticpanelofnormals_testcase_shlee.zip](https://github.com/broadinstitute/gatk/files/1251993/createsomaticpanelofnormals_testcase_shlee.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:4790,Deployability,update,update,4790,"ader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:115); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:36); 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:251); 	... 12 more; ```. Either we should update the documentation to point users to use the `--arguments_file` instead (let me know) or we should update the functionality to accept a list of files. Currently, the option is described as:. > --vcfsListFile,-vcfs:File VCFs for samples to include. May be specified either one at a time, or as one or more .list file containing multiple VCFs, one per line. This argument must be specified at least once. Required. . Here is the test data:; [createsomaticpanelofnormals_testcase_shlee.zip](https://github.com/broadinstitute/gatk/files/1251993/createsomaticpanelofnormals_testcase_shlee.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:37,Safety,safe,safeguards,37,"I bring the first point up given the safeguards our previous workflow had in place. In GATK3, CombineVariants checks that all the sample names are unique. You have to add `--genotypemergeoption UNIQUIFY` to allow use of the same normal sample. In GATK4, CreateSomaticPanelOfNormals allows input of the same sample twice and thereby counts the same evidence in the PoN it generates. Granted, I am doing something intentionally stupid here but I can imagine that this could happen accidentally for situations where we are dealing with hundreds of normal samples. . Interestingly, given the same sample twice, for my test case, it generates a PoN that has one less call than the inputs. Here is the command that runs successfully. Note that 2 is a direct copy of 1 made using unix `cp`.; ```; 	gatk-launch CreateSomaticPanelOfNormals \; 		-vcfs 1_normalforpon.vcf.gz \; 		-vcfs 2_normalforpon.vcf.gz \; 		-O 3_discard_practice_pon.vcf.gz; ```. Then I check the number of sites and I see a discrepency.; ```; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep -v '#' | wc -l; 138; WMCF9-CB5:working shlee$ gzcat 1_normalforpon.vcf.gz | grep -v '#' | wc -l; 139; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep -v '#' | wc -l; 139; ```. Probing further we see:; ```; WMCF9-CB5:working shlee$ diff <(gzcat 1_normalforpon.vcf.gz | grep -v '#' | cut -f1,2) <(gzcat 3_discard_practice_pon.vcf.gz | grep -v '#' | cut -f1,2); 139d138; < chrX	153909841; WMCF9-CB5:working shlee$ gzcat 1_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:614,Testability,test,test,614,"I bring the first point up given the safeguards our previous workflow had in place. In GATK3, CombineVariants checks that all the sample names are unique. You have to add `--genotypemergeoption UNIQUIFY` to allow use of the same normal sample. In GATK4, CreateSomaticPanelOfNormals allows input of the same sample twice and thereby counts the same evidence in the PoN it generates. Granted, I am doing something intentionally stupid here but I can imagine that this could happen accidentally for situations where we are dealing with hundreds of normal samples. . Interestingly, given the same sample twice, for my test case, it generates a PoN that has one less call than the inputs. Here is the command that runs successfully. Note that 2 is a direct copy of 1 made using unix `cp`.; ```; 	gatk-launch CreateSomaticPanelOfNormals \; 		-vcfs 1_normalforpon.vcf.gz \; 		-vcfs 2_normalforpon.vcf.gz \; 		-O 3_discard_practice_pon.vcf.gz; ```. Then I check the number of sites and I see a discrepency.; ```; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep -v '#' | wc -l; 138; WMCF9-CB5:working shlee$ gzcat 1_normalforpon.vcf.gz | grep -v '#' | wc -l; 139; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep -v '#' | wc -l; 139; ```. Probing further we see:; ```; WMCF9-CB5:working shlee$ diff <(gzcat 1_normalforpon.vcf.gz | grep -v '#' | cut -f1,2) <(gzcat 3_discard_practice_pon.vcf.gz | grep -v '#' | cut -f1,2); 139d138; < chrX	153909841; WMCF9-CB5:working shlee$ gzcat 1_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3510:5118,Testability,test,test,5118,"ader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:115); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:36); 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:251); 	... 12 more; ```. Either we should update the documentation to point users to use the `--arguments_file` instead (let me know) or we should update the functionality to accept a list of files. Currently, the option is described as:. > --vcfsListFile,-vcfs:File VCFs for samples to include. May be specified either one at a time, or as one or more .list file containing multiple VCFs, one per line. This argument must be specified at least once. Required. . Here is the test data:; [createsomaticpanelofnormals_testcase_shlee.zip](https://github.com/broadinstitute/gatk/files/1251993/createsomaticpanelofnormals_testcase_shlee.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510
https://github.com/broadinstitute/gatk/issues/3514:2857,Availability,recover,recoverDanglingHeads,2857,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:3004,Availability,error,errorCorrectKmers,3004,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:3669,Availability,error,errorCorrectReads,3669,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:5713,Deployability,patch,patch,5713,"VCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 24, 2017 7:26:43 PM EDT] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: 4.beta.3; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:26:43.243 INFO Mutect2 - Deflater: IntelDeflater; 19:26:43.243 INFO Mutect2 - Inflater: IntelInflater; 19:26:43.243 INFO Mutect2 - GCS max retries/reopens: 20; 19:26:43.243 INFO Mutect2 - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 19:26:43.243 INFO Mutect2 - Initializing engine; 19:26:43.871 INFO Mutect2 - Done initializing engine; 19:26:44.130 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.346 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.624 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 19:26:44.624 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 19:26:44.643 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; [WARNING] Ignoring request for 4 threads; not using OpenMP implementation; 19:26:44.664 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 19:26:44.7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:1770,Performance,Load,Loading,1770," for any reference. This allows us (i) to call on ALT-aware mappings if data is such and (ii) call on SNPs and indels generated by putative structural variants that go _across contigs_. I know that this filter is active in the GATK4.beta.3-Mutect2 (see last line):; ```; WMCF9-CB5:align shlee$ gatk-launch Mutect2 -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; Using GATK jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar Mutect2 -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; 19:26:43.105 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [August 24, 2017 7:26:43 PM EDT] Mutect2 --tumorSampleName HCC1143_normal --output 1_normalforpon.vcf.gz --input hcc1143_N_subset500.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:6265,Performance,multi-thread,multi-threaded,6265,"YNC_IO_READ_FOR_SAMTOOLS : false; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:26:43.243 INFO Mutect2 - Deflater: IntelDeflater; 19:26:43.243 INFO Mutect2 - Inflater: IntelInflater; 19:26:43.243 INFO Mutect2 - GCS max retries/reopens: 20; 19:26:43.243 INFO Mutect2 - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 19:26:43.243 INFO Mutect2 - Initializing engine; 19:26:43.871 INFO Mutect2 - Done initializing engine; 19:26:44.130 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.346 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.624 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 19:26:44.624 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 19:26:44.643 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; [WARNING] Ignoring request for 4 threads; not using OpenMP implementation; 19:26:44.664 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 19:26:44.723 INFO ProgressMeter - Starting traversal; 19:26:44.724 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 19:26:54.942 INFO ProgressMeter - chr6:29944953 0.2 200 1174.5; 19:27:04.954 INFO ProgressMeter - chr19:15244950 0.3 460 1364.3; 19:27:07.668 INFO Mutect2 - 18876 read(s) filtered by: (((((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappingQualityNotZeroReadFilter) AND MappedReadFilter) AND PrimaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroRefer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:6384,Performance,Load,Loading,6384,"YNC_IO_WRITE_FOR_SAMTOOLS : true; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:26:43.243 INFO Mutect2 - Deflater: IntelDeflater; 19:26:43.243 INFO Mutect2 - Inflater: IntelInflater; 19:26:43.243 INFO Mutect2 - GCS max retries/reopens: 20; 19:26:43.243 INFO Mutect2 - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 19:26:43.243 INFO Mutect2 - Initializing engine; 19:26:43.871 INFO Mutect2 - Done initializing engine; 19:26:44.130 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.346 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.624 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 19:26:44.624 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 19:26:44.643 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; [WARNING] Ignoring request for 4 threads; not using OpenMP implementation; 19:26:44.664 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 19:26:44.723 INFO ProgressMeter - Starting traversal; 19:26:44.724 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 19:26:54.942 INFO ProgressMeter - chr6:29944953 0.2 200 1174.5; 19:27:04.954 INFO ProgressMeter - chr19:15244950 0.3 460 1364.3; 19:27:07.668 INFO Mutect2 - 18876 read(s) filtered by: (((((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappingQualityNotZeroReadFilter) AND MappedReadFilter) AND PrimaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND ) AND MateOnSameContigOrNoMappedMateReadFilter) A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:2857,Safety,recover,recoverDanglingHeads,2857,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3514:614,Security,expose,exposed,614,"@vdauwera we should modify the M2 WDLs. ; @davidbenjamin this will improve your sensitivity. Currently Mutect2 uses the MateOnSameContigOrNoMappedMateReadFilter filter that filters out any paired read whose mate maps to a different contig. This filter, if I recall correctly, used to be the hidden filter in HaplotypeCaller code that could not be turned off. It necessitated that I remove 0x1 flags in the GRCh38 tutorial (see section 6.1 of <https://gatkforums.broadinstitute.org/gatk/discussion/8017/>) so as to be able to call variants associated with a sample with an alternative haplotype. This filter is now exposed so that users can disable it. In addition to disabling this filter for ALT-aware data, I recommend we turn it off by default for somatic analyses, for any reference. This allows us (i) to call on ALT-aware mappings if data is such and (ii) call on SNPs and indels generated by putative structural variants that go _across contigs_. I know that this filter is active in the GATK4.beta.3-Mutect2 (see last line):; ```; WMCF9-CB5:align shlee$ gatk-launch Mutect2 -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; Using GATK jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar Mutect2 -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; 19:26:43.105 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [August 24, 2017 7:26:43 PM EDT] Mutect2 --tumorSampleNam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514
https://github.com/broadinstitute/gatk/issues/3516:3,Performance,load,loads,3,"It loads all reads for each shard at a time, but it could be lazier and load only 1-2 assembly regions' worth of reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3516
https://github.com/broadinstitute/gatk/issues/3516:72,Performance,load,load,72,"It loads all reads for each shard at a time, but it could be lazier and load only 1-2 assembly regions' worth of reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3516
https://github.com/broadinstitute/gatk/pull/3519:1047,Deployability,update,updated,1047,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519
https://github.com/broadinstitute/gatk/pull/3519:1,Energy Efficiency,Reduce,Reduce,1,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519
https://github.com/broadinstitute/gatk/pull/3519:78,Performance,load,loading,78,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519
https://github.com/broadinstitute/gatk/pull/3519:1067,Testability,test,test,1067,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519
https://github.com/broadinstitute/gatk/pull/3526:432,Availability,error,error,432,"Add `rebalanceChunks` which allows the ExampleNioCountReads to work with inputs that contain many large contigs. I was able to run it on a 300GB full genome input without crashes or hangs. This PR also fixes a bug where ExampleNioCountReads would return different values depending on how much workers were assigned. The bug's now fixed for small inputs, but a related one still happens for large inputs (though the magnitude of the error's less). I'm still submitting since this work is more of a proof-of-concept at this point, but it's good to keep in mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526
https://github.com/broadinstitute/gatk/pull/3526:271,Integrability,depend,depending,271,"Add `rebalanceChunks` which allows the ExampleNioCountReads to work with inputs that contain many large contigs. I was able to run it on a 300GB full genome input without crashes or hangs. This PR also fixes a bug where ExampleNioCountReads would return different values depending on how much workers were assigned. The bug's now fixed for small inputs, but a related one still happens for large inputs (though the magnitude of the error's less). I'm still submitting since this work is more of a proof-of-concept at this point, but it's good to keep in mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526
https://github.com/broadinstitute/gatk/pull/3527:165,Deployability,integrat,integration,165,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:165,Integrability,integrat,integration,165,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:115,Testability,test,tests,115,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:177,Testability,test,tests,177,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:195,Testability,assert,asserting,195,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:286,Testability,test,tests,286,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3527:434,Testability,test,tests,434,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527
https://github.com/broadinstitute/gatk/pull/3530:15,Security,validat,validatevariants,15,fix issue with validatevariants when validatign a gvcf and a record is followed by a record that is fully encompassed by the first one. The interval math was off in this case,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530
https://github.com/broadinstitute/gatk/pull/3530:37,Security,validat,validatign,37,fix issue with validatevariants when validatign a gvcf and a record is followed by a record that is fully encompassed by the first one. The interval math was off in this case,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530
https://github.com/broadinstitute/gatk/issues/3532:525,Availability,Error,Error,525,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:548,Availability,down,downstream,548,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:669,Availability,error,error,669,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:694,Availability,error,error,694,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:1289,Availability,error,error,1289,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:1644,Availability,Error,Error,1644,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:606,Deployability,integrat,integration,606,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:606,Integrability,integrat,integration,606,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:709,Safety,detect,detected,709,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:623,Testability,test,tests,623,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:1395,Testability,log,log,1395,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:1679,Testability,log,log,1679,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/issues/3532:1756,Testability,log,log,1756,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532
https://github.com/broadinstitute/gatk/pull/3536:318,Deployability,integrat,integration,318,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3536:318,Integrability,integrat,integration,318,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3536:161,Testability,test,tests,161,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3536:287,Testability,test,tests,287,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3536:330,Testability,test,test,330,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3536:205,Usability,simpl,simple,205,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536
https://github.com/broadinstitute/gatk/pull/3537:44,Usability,Simpl,Simplifies,44,"…ose options to customize scoring scheme. - Simplifies HostAlignmentReadFilter by using only the alignment identity, defined as the number of matches minus deletions, instead of both identity and coverage, as it seems to have negligible impact on results.; - Similarly, PSScorer uses an identity threshold only and not coverage to filter pathogen alignments. In addition, an option is added to better handle second-best matches. For a given read (or pair), if the best alignment has identity score N, PSScorer now ignores hits with identity score less than N x (1 - x), where x is the ""identity margin.""; - Option to divide abundance scores by genome length; - Option to report normalized abundance scores as a percentage within each kingdom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537
https://github.com/broadinstitute/gatk/issues/3540:2018,Availability,down,down,2018,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:106,Energy Efficiency,adapt,adapter,106,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:746,Energy Efficiency,adapt,adapter,746,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:823,Energy Efficiency,adapt,adapter,823,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1145,Energy Efficiency,adapt,adapter,1145,"e typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1252,Energy Efficiency,adapt,adapter,1252,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1449,Energy Efficiency,adapt,adapter,1449,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1508,Energy Efficiency,adapt,adapter,1508,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1970,Energy Efficiency,adapt,adapter,1970,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:2137,Energy Efficiency,adapt,adapter,2137,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:106,Integrability,adapter,adapter,106,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:746,Integrability,adapter,adapter,746,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:823,Integrability,adapter,adapter,823,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1145,Integrability,adapter,adapter,1145,"e typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1252,Integrability,adapter,adapter,1252,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1449,Integrability,adapter,adapter,1449,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1508,Integrability,adapter,adapter,1508,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1970,Integrability,adapter,adapter,1970,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:2137,Integrability,adapter,adapter,2137,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:106,Modifiability,adapt,adapter,106,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:746,Modifiability,adapt,adapter,746,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:823,Modifiability,adapt,adapter,823,"Base qualities of two (`#`) are handled specially by BWA and our tools and are typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1145,Modifiability,adapt,adapter,1145,"e typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1252,Modifiability,adapt,adapter,1252,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1449,Modifiability,adapt,adapter,1449,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1508,Modifiability,adapt,adapter,1508,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:1970,Modifiability,adapt,adapter,1970,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:2137,Modifiability,adapt,adapter,2137,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3540:2083,Usability,simpl,simply,2083,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540
https://github.com/broadinstitute/gatk/issues/3541:142,Availability,redundant,redundant,142,I can see the reassurance of knowing that the input Locatable is constant and with a non-null contig... yet as a result we are often creating redundant simpleIntervals instances when our objects of interest are some other type of Locatable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541
https://github.com/broadinstitute/gatk/issues/3541:142,Safety,redund,redundant,142,I can see the reassurance of knowing that the input Locatable is constant and with a non-null contig... yet as a result we are often creating redundant simpleIntervals instances when our objects of interest are some other type of Locatable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541
https://github.com/broadinstitute/gatk/issues/3541:152,Usability,simpl,simpleIntervals,152,I can see the reassurance of knowing that the input Locatable is constant and with a non-null contig... yet as a result we are often creating redundant simpleIntervals instances when our objects of interest are some other type of Locatable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541
https://github.com/broadinstitute/gatk/issues/3544:270,Testability,test,tested,270,"Currently GenotypeGVCFs only supports one allele specific annotation. Once the allele specific annotations port is finalized (#3527) then the functionality needs to be added to genotypeGVCFs. In order to be sure that the annotations are working properly, they should be tested against the gatk3 version of genotypeGVCFs allele specific annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3544
https://github.com/broadinstitute/gatk/pull/3545:291,Deployability,pipeline,pipeline,291,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545
https://github.com/broadinstitute/gatk/pull/3545:309,Energy Efficiency,reduce,reduces,309,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545
https://github.com/broadinstitute/gatk/pull/3545:423,Security,expose,exposes,423,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545
https://github.com/broadinstitute/gatk/pull/3546:62,Testability,Test,Testing,62,This reverts commit 43131bb79c610d9ee8f2de3bdec5404002f27d13. Testing to see if this rights the travis builds.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3546
https://github.com/broadinstitute/gatk/pull/3547:12,Testability,test,test,12,…d unwanted test interaction.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3547
https://github.com/broadinstitute/gatk/issues/3548:48,Testability,test,test,48,"If you run this on position 20:10022820 in `src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam` you will get the wrong alt (you get C, but should be T). . Proposed solution: Use findLast() (or reverse b1 and b2 in the compare statement to get this to sort in descending order). ```; private static Nucleotide inferAltFromPileupBaseCounts(final Nucleotide.Counter baseCounts,; final Nucleotide refNucleotide) {; return BASES.stream(); .filter(b -> b != refNucleotide); .sorted((b1, b2) -> Long.compare(baseCounts.get(b1), baseCounts.get(b2))); .findFirst().get();; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3548
https://github.com/broadinstitute/gatk/pull/3551:288,Testability,test,test,288,"There is quite a bit of code annotated with @BeforeSuite that should probably just be @BeforeClass. @BeforeSuite code can run even when no methods in the class are selected in the current suite. Most of it is harmless, but some of it is painfully slow, i.e., using gradle to run a single test method always causes the BwaMemIntegrationTest code to create an index image for the large test reference, which takes 1-2 minutes, before the selected test even starts. We should probably reserve @BeforeSuite for test-infrastructure setup code; most test classes should use @BeforeClass instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3551
https://github.com/broadinstitute/gatk/pull/3551:384,Testability,test,test,384,"There is quite a bit of code annotated with @BeforeSuite that should probably just be @BeforeClass. @BeforeSuite code can run even when no methods in the class are selected in the current suite. Most of it is harmless, but some of it is painfully slow, i.e., using gradle to run a single test method always causes the BwaMemIntegrationTest code to create an index image for the large test reference, which takes 1-2 minutes, before the selected test even starts. We should probably reserve @BeforeSuite for test-infrastructure setup code; most test classes should use @BeforeClass instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3551
https://github.com/broadinstitute/gatk/pull/3551:445,Testability,test,test,445,"There is quite a bit of code annotated with @BeforeSuite that should probably just be @BeforeClass. @BeforeSuite code can run even when no methods in the class are selected in the current suite. Most of it is harmless, but some of it is painfully slow, i.e., using gradle to run a single test method always causes the BwaMemIntegrationTest code to create an index image for the large test reference, which takes 1-2 minutes, before the selected test even starts. We should probably reserve @BeforeSuite for test-infrastructure setup code; most test classes should use @BeforeClass instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3551
https://github.com/broadinstitute/gatk/pull/3551:507,Testability,test,test-infrastructure,507,"There is quite a bit of code annotated with @BeforeSuite that should probably just be @BeforeClass. @BeforeSuite code can run even when no methods in the class are selected in the current suite. Most of it is harmless, but some of it is painfully slow, i.e., using gradle to run a single test method always causes the BwaMemIntegrationTest code to create an index image for the large test reference, which takes 1-2 minutes, before the selected test even starts. We should probably reserve @BeforeSuite for test-infrastructure setup code; most test classes should use @BeforeClass instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3551
https://github.com/broadinstitute/gatk/pull/3551:544,Testability,test,test,544,"There is quite a bit of code annotated with @BeforeSuite that should probably just be @BeforeClass. @BeforeSuite code can run even when no methods in the class are selected in the current suite. Most of it is harmless, but some of it is painfully slow, i.e., using gradle to run a single test method always causes the BwaMemIntegrationTest code to create an index image for the large test reference, which takes 1-2 minutes, before the selected test even starts. We should probably reserve @BeforeSuite for test-infrastructure setup code; most test classes should use @BeforeClass instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3551
https://github.com/broadinstitute/gatk/issues/3552:12,Integrability,depend,dependent,12,"The code is dependent on the nd4j dtype system property being set to ""double"" by gradle. Otherwise the tests (and the tool itself) fail when run from intellij or from the command line. The nd4j unit tests have the same issue. Its easy enough to set the dtype programmatically, though I'm not sure where the best place to do that is.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552
https://github.com/broadinstitute/gatk/issues/3552:103,Testability,test,tests,103,"The code is dependent on the nd4j dtype system property being set to ""double"" by gradle. Otherwise the tests (and the tool itself) fail when run from intellij or from the command line. The nd4j unit tests have the same issue. Its easy enough to set the dtype programmatically, though I'm not sure where the best place to do that is.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552
https://github.com/broadinstitute/gatk/issues/3552:199,Testability,test,tests,199,"The code is dependent on the nd4j dtype system property being set to ""double"" by gradle. Otherwise the tests (and the tool itself) fail when run from intellij or from the command line. The nd4j unit tests have the same issue. Its easy enough to set the dtype programmatically, though I'm not sure where the best place to do that is.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552
https://github.com/broadinstitute/gatk/issues/3553:134,Security,expose,exposed,134,"I noticed that the PairHMM implementation argument is hidden in `LikelihoodEngineArgumentCollection` for some reason. Shouldn't it be exposed as an advanced argument people can choose what pair hmm they want?. It's also present in the `UnifiedArgumentCollection`, but it's never used from there. ```; /**; * The PairHMM implementation to use for genotype likelihood calculations. The various implementations balance a tradeoff of accuracy and runtime.; */; @Hidden; @Argument(fullName = ""pair_hmm_implementation"", shortName = ""pairHMM"", doc = ""The PairHMM implementation to use for genotype likelihood calculations"", optional = true); public PairHMM.Implementation pairHMM = PairHMM.Implementation.FASTEST_AVAILABLE;; ```. It seems like we should remove it from the `UnifiedArgumentCollection` and make it either a normal argument or an advanced argument in the `LikelihoodEngineArgumentCollection`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3553
https://github.com/broadinstitute/gatk/issues/3554:84,Safety,avoid,avoid,84,"I'd be in favor of rewriting these scripts in python. In any case, we should try to avoid issues such as #3301.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554
https://github.com/broadinstitute/gatk/issues/3555:407,Availability,ERROR,ERROR,407,"This Barclay [feature](https://github.com/broadinstitute/barclay/issues/25) automatically expands the contents of a file ending in "".list"" whenever the target argument is a collection. This precludes the use of Picard interval list files ending in "".list"" with -L in GATK, since they contain a sam header. The raw sam header lines wind up getting added as interval strings, which then fails parsing: A USER ERROR has occurred: Badly formed genome unclippedLoc: Failed to parse Genome Location string: @HD	VN:1.5: Problem parsing start/end value in interval string. Value was: 1.5. A short term GATK workaround is to use a file ending in one of the other known Picard interval list extensions (.interval_list, .intervals, or .picard) instead, but we should find a better fix for this since .list seems to be commonly used. Tools such as GetHetCoverage, which take an interval list in an argument typed as a File (--snpIntervals), are able to consume the interval file because the target argument is not a collection, so the auto-expansion is not triggered. I expect this issue could cause more problems in Picard as well once Barclay is the default parser there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555
https://github.com/broadinstitute/gatk/issues/3558:133,Availability,error,error,133,"It appears for at least the last 6 days that our travis tests for the the CNV and M2 WDLs have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:139,Integrability,message,messages,139,"It appears for at least the last 6 days that our travis tests for the the CNV and M2 WDLs have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2163,Performance,concurren,concurrent,2163,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2237,Performance,concurren,concurrent,2237,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2323,Performance,concurren,concurrent,2323,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2401,Performance,concurren,concurrent,2401,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:56,Testability,test,tests,56,"It appears for at least the last 6 days that our travis tests for the the CNV and M2 WDLs have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:999,Testability,Log,LoggingFSM,999,"t the last 6 days that our travis tests for the the CNV and M2 WDLs have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.proce",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:1082,Testability,Log,LoggingFSM,1082,"have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2534,Testability,test,tests,2534,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2563,Testability,test,test,2563,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3558:2623,Testability,test,tests,2623,ckerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)`. The docker script is apparently working because docker tests still run and generate test report output. Someone needs to investigate why theses tests are failing and fix them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558
https://github.com/broadinstitute/gatk/issues/3559:345,Availability,error,errors,345,"Travis rolled out updated images that caused our builds to start failing. It looks like some of the WDL tests had been failing for a [while](https://github.com/broadinstitute/gatk/issues/3558), but that wasn't causing the **builds** to fail until the new Travis images were rolled out, at which point we started running out of space logging the errors. We're temporarily requesting to use the old Travis image (https://github.com/broadinstitute/gatk/pull/3557), but we should revert that once we address the underlying issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3559
https://github.com/broadinstitute/gatk/issues/3559:18,Deployability,update,updated,18,"Travis rolled out updated images that caused our builds to start failing. It looks like some of the WDL tests had been failing for a [while](https://github.com/broadinstitute/gatk/issues/3558), but that wasn't causing the **builds** to fail until the new Travis images were rolled out, at which point we started running out of space logging the errors. We're temporarily requesting to use the old Travis image (https://github.com/broadinstitute/gatk/pull/3557), but we should revert that once we address the underlying issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3559
https://github.com/broadinstitute/gatk/issues/3559:104,Testability,test,tests,104,"Travis rolled out updated images that caused our builds to start failing. It looks like some of the WDL tests had been failing for a [while](https://github.com/broadinstitute/gatk/issues/3558), but that wasn't causing the **builds** to fail until the new Travis images were rolled out, at which point we started running out of space logging the errors. We're temporarily requesting to use the old Travis image (https://github.com/broadinstitute/gatk/pull/3557), but we should revert that once we address the underlying issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3559
https://github.com/broadinstitute/gatk/issues/3559:333,Testability,log,logging,333,"Travis rolled out updated images that caused our builds to start failing. It looks like some of the WDL tests had been failing for a [while](https://github.com/broadinstitute/gatk/issues/3558), but that wasn't causing the **builds** to fail until the new Travis images were rolled out, at which point we started running out of space logging the errors. We're temporarily requesting to use the old Travis image (https://github.com/broadinstitute/gatk/pull/3557), but we should revert that once we address the underlying issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3559
https://github.com/broadinstitute/gatk/issues/3561:452,Modifiability,extend,extend,452,"@vruano has pointed out that our method of finding the best haplotype paths in an assembly graph is equivalent to Dijkstra's algorithm for finding the shortest path in a directed graph, and that the latter is a much simpler implementation. [ Do I understand this correctly?]. We could simplify a bunch of code without changing the output of any tools by switching the implementation to Dijkstra's algorithm, which is implemented in jgrapht (our graphs extend this package's graph class) and apache commons. @vruano has also pointed out that our definition of the best paths may not be optimal, which is a separate issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561
https://github.com/broadinstitute/gatk/issues/3561:216,Usability,simpl,simpler,216,"@vruano has pointed out that our method of finding the best haplotype paths in an assembly graph is equivalent to Dijkstra's algorithm for finding the shortest path in a directed graph, and that the latter is a much simpler implementation. [ Do I understand this correctly?]. We could simplify a bunch of code without changing the output of any tools by switching the implementation to Dijkstra's algorithm, which is implemented in jgrapht (our graphs extend this package's graph class) and apache commons. @vruano has also pointed out that our definition of the best paths may not be optimal, which is a separate issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561
https://github.com/broadinstitute/gatk/issues/3561:285,Usability,simpl,simplify,285,"@vruano has pointed out that our method of finding the best haplotype paths in an assembly graph is equivalent to Dijkstra's algorithm for finding the shortest path in a directed graph, and that the latter is a much simpler implementation. [ Do I understand this correctly?]. We could simplify a bunch of code without changing the output of any tools by switching the implementation to Dijkstra's algorithm, which is implemented in jgrapht (our graphs extend this package's graph class) and apache commons. @vruano has also pointed out that our definition of the best paths may not be optimal, which is a separate issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561
https://github.com/broadinstitute/gatk/pull/3563:27,Testability,test,test,27,Moves RandomDNA class into test from main as it is only used for testing.; Added a random reference creation to RandomDNA.; Added isConcrete method to Nucleotide. Fixes issue #3562.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3563
https://github.com/broadinstitute/gatk/pull/3563:65,Testability,test,testing,65,Moves RandomDNA class into test from main as it is only used for testing.; Added a random reference creation to RandomDNA.; Added isConcrete method to Nucleotide. Fixes issue #3562.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3563
https://github.com/broadinstitute/gatk/issues/3564:101,Testability,test,tested,101,"I'm running into an issue with the latest MuTect2 (also it also goes back as far as beta4, I haven't tested prior to that), where triploid calls get produced. Here's an example output where the normal is diploid `0/0` and the tumor is triploid `0/1/2`:; ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT control_downsample tumor_downsample; 1 725556 . A G,AGAATAGAATGGAATAGAAAGGAATG . . DP=460;ECNT=3;NLOD=54.98,46.06;N_ART_LOD=2.72,8.00;POP_AF=1.000e-03,1.000e-03;P_GERMLINE=-5.185e+01,-4.276e+01;TLOD=6.33,19.76 GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB 0/0:205,6,4:0.020,0.044:101,4,0:104,2,4:34,0:415,467,130:40,25:4,0 0/1/2:209,9,8:0.035,0.047:108,7,4:101,2,4:34,0:404,485,137:28,42:2,0:0.030,0.030,0.035:3.983e-03,5.306e-03,0.991; ```; This happens both if I explictly specify `--ploidy 2` or leave it at the default. Here is a reproducible test case:. wget https://s3.amazonaws.com/chapmanb/testcases/gatk4_mutect2_triploid.tar.gz. You can unpack, edit `REF` in `run_mutect2.sh` to point at a GRCh37 reference, and run to demonstrate the issue. This happens pretty regularly in the outputs, although it is very sensitive to the size of the reference regions. If you decrease the end point in `regions.bed` you'll get diploid calls again. Thanks for the help and please let me know if I can provide any other information.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564
https://github.com/broadinstitute/gatk/issues/3564:866,Testability,test,test,866,"I'm running into an issue with the latest MuTect2 (also it also goes back as far as beta4, I haven't tested prior to that), where triploid calls get produced. Here's an example output where the normal is diploid `0/0` and the tumor is triploid `0/1/2`:; ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT control_downsample tumor_downsample; 1 725556 . A G,AGAATAGAATGGAATAGAAAGGAATG . . DP=460;ECNT=3;NLOD=54.98,46.06;N_ART_LOD=2.72,8.00;POP_AF=1.000e-03,1.000e-03;P_GERMLINE=-5.185e+01,-4.276e+01;TLOD=6.33,19.76 GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB 0/0:205,6,4:0.020,0.044:101,4,0:104,2,4:34,0:415,467,130:40,25:4,0 0/1/2:209,9,8:0.035,0.047:108,7,4:101,2,4:34,0:404,485,137:28,42:2,0:0.030,0.030,0.035:3.983e-03,5.306e-03,0.991; ```; This happens both if I explictly specify `--ploidy 2` or leave it at the default. Here is a reproducible test case:. wget https://s3.amazonaws.com/chapmanb/testcases/gatk4_mutect2_triploid.tar.gz. You can unpack, edit `REF` in `run_mutect2.sh` to point at a GRCh37 reference, and run to demonstrate the issue. This happens pretty regularly in the outputs, although it is very sensitive to the size of the reference regions. If you decrease the end point in `regions.bed` you'll get diploid calls again. Thanks for the help and please let me know if I can provide any other information.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564
https://github.com/broadinstitute/gatk/issues/3564:917,Testability,test,testcases,917,"I'm running into an issue with the latest MuTect2 (also it also goes back as far as beta4, I haven't tested prior to that), where triploid calls get produced. Here's an example output where the normal is diploid `0/0` and the tumor is triploid `0/1/2`:; ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT control_downsample tumor_downsample; 1 725556 . A G,AGAATAGAATGGAATAGAAAGGAATG . . DP=460;ECNT=3;NLOD=54.98,46.06;N_ART_LOD=2.72,8.00;POP_AF=1.000e-03,1.000e-03;P_GERMLINE=-5.185e+01,-4.276e+01;TLOD=6.33,19.76 GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB 0/0:205,6,4:0.020,0.044:101,4,0:104,2,4:34,0:415,467,130:40,25:4,0 0/1/2:209,9,8:0.035,0.047:108,7,4:101,2,4:34,0:404,485,137:28,42:2,0:0.030,0.030,0.035:3.983e-03,5.306e-03,0.991; ```; This happens both if I explictly specify `--ploidy 2` or leave it at the default. Here is a reproducible test case:. wget https://s3.amazonaws.com/chapmanb/testcases/gatk4_mutect2_triploid.tar.gz. You can unpack, edit `REF` in `run_mutect2.sh` to point at a GRCh37 reference, and run to demonstrate the issue. This happens pretty regularly in the outputs, although it is very sensitive to the size of the reference regions. If you decrease the end point in `regions.bed` you'll get diploid calls again. Thanks for the help and please let me know if I can provide any other information.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564
https://github.com/broadinstitute/gatk/issues/3566:52,Security,Expose,Expose,52,This is often needed since the docker image is big. Expose this parameter with a 20GB value,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3566
https://github.com/broadinstitute/gatk/issues/3567:75,Integrability,depend,dependencies,75,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567
https://github.com/broadinstitute/gatk/issues/3567:219,Integrability,depend,depend,219,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567
https://github.com/broadinstitute/gatk/issues/3567:27,Testability,test,test,27,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567
https://github.com/broadinstitute/gatk/issues/3567:280,Testability,test,test,280,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567
https://github.com/broadinstitute/gatk/issues/3567:389,Testability,test,test,389,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567
https://github.com/broadinstitute/gatk/issues/3569:118,Deployability,install,installedProviders,118,"It seems that you can find out what FileSystem corresponds to what URI/URL by using the return of FileSystemProviders.installedProviders. Instead BucketUtils has hard-wired scheme names and has many conditional (isCould... isHadoop) for operations that can be done by using the appropriate FileSystem implementation that in turn can be resolved looking at that list. I guess that there are extant utility classes that process that list once for subsequent queries (e.g. scheme-name -> FS), but I have not confirmed that. Otherwise it is easy to write one. Is there is a reason what we need to do our own thing in BucketUtils?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569
https://github.com/broadinstitute/gatk/pull/3571:91,Deployability,configurat,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to ; * the same chromosome with reference order switch but without strand switch, or; * different chromosomes. This brings us (unfiltered) ~6000 mated BND records, half of which are on canonical chromosomes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571
https://github.com/broadinstitute/gatk/pull/3571:91,Modifiability,config,configuration,91,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to ; * the same chromosome with reference order switch but without strand switch, or; * different chromosomes. This brings us (unfiltered) ~6000 mated BND records, half of which are on canonical chromosomes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571
https://github.com/broadinstitute/gatk/pull/3577:17,Integrability,wrap,wraps,17,@takutosato This wraps up the documentation part of our quarterly goals.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3577
https://github.com/broadinstitute/gatk/pull/3579:127,Safety,safe,safe,127,cluster timed self-termination (beta) feature.; Fixes #3574 considering that several people are suggesting beta from gcloud is safe enough.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3579
https://github.com/broadinstitute/gatk/pull/3581:29,Availability,failure,failures,29,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:86,Availability,failure,failures,86,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:524,Deployability,upgrade,upgrade,524,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:267,Modifiability,Enhance,EnhancerByMockitoWithCGLIB,267,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:24,Testability,test,test,24,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:126,Testability,mock,mocked,126,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:374,Testability,mock,mockito,374,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:382,Testability,mock,mockito,382,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:435,Testability,mock,mockito,435,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:646,Testability,mock,mockito,646,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3581:654,Testability,mock,mockito,654,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581
https://github.com/broadinstitute/gatk/pull/3584:15,Deployability,Update,Updates,15,@LeeTL1220 . * Updates command line arguments to conform to new GATK standard.; * Removes M2 wdl hacks no longer needed as of Cromwell 27,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3584
https://github.com/broadinstitute/gatk/pull/3586:9,Performance,Concurren,ConcurrentModificationExceptions,9,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/pull/3586:61,Testability,mock,mocked,61,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/pull/3586:106,Testability,mock,mocked,106,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/pull/3586:202,Testability,Mock,Mocks,202,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/pull/3586:244,Testability,mock,mocked,244,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/pull/3586:317,Testability,mock,mock,317,"I've had ConcurrentModificationExceptions several times when mocked ReferenceMultiSource objects are both mocked and broadcast ([for example](https://travis-ci.org/broadinstitute/gatk/jobs/275982454)). Mocks appear to be mutated, even when the mocked object is immutable, so serialization can fail. This replaces the mock object with a faked one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3586
https://github.com/broadinstitute/gatk/issues/3587:113,Testability,log,logging,113,"We had a first attempt at this in https://github.com/broadinstitute/gatk/pull/2751, but this did not capture all logging output (from Spark, C code, etc.) to the log file. What we need to do is capture all of stdout and stderr, and write that to a file, taking care to interleave them properly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3587
https://github.com/broadinstitute/gatk/issues/3587:162,Testability,log,log,162,"We had a first attempt at this in https://github.com/broadinstitute/gatk/pull/2751, but this did not capture all logging output (from Spark, C code, etc.) to the log file. What we need to do is capture all of stdout and stderr, and write that to a file, taking care to interleave them properly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3587
https://github.com/broadinstitute/gatk/pull/3588:85,Testability,test,test,85,updating to a new htsjdk snapshot and updating our VariantContextWriters to compile. test may fail on this....,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588
https://github.com/broadinstitute/gatk/issues/3591:55,Availability,error,error,55,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:174,Availability,Error,Error,174,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:471,Availability,Error,Error,471,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3620,Availability,Error,Error,3620,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:5141,Availability,ERROR,ERROR,5141,(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337); 	... 32 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [cb87810a-0133-42b3-a954-363b62adce39] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:5242,Availability,ERROR,ERROR,5242,(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337); 	... 32 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [cb87810a-0133-42b3-a954-363b62adce39] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3215,Deployability,deploy,deploy,3215,TKSparkTool.runPipeline(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAda,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3252,Deployability,deploy,deploy,3252,0); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3325,Deployability,deploy,deploy,3325,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(H,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3402,Deployability,deploy,deploy,3402,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.htt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3474,Deployability,deploy,deploy,3474, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shade,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3544,Deployability,deploy,deploy,3544,MainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:165,Integrability,message,message,165,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:203,Security,secur,security,203,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:212,Security,access,access,212,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:500,Security,secur,security,500,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:509,Security,access,access,509,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3649,Security,secur,security,3649,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:3658,Security,access,access,3658,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:18,Testability,test,tests,18,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3591:1444,Testability,assert,assertFileIsReadable,1444,geException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:390); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:370); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591
https://github.com/broadinstitute/gatk/issues/3593:87,Availability,error,error,87,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/issues/3593:460,Availability,error,error,460,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/issues/3593:466,Integrability,message,message,466,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/issues/3593:36,Security,hash,hash,36,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/issues/3593:65,Security,hash,hash,65,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/issues/3593:485,Security,hash,hashes,485,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593
https://github.com/broadinstitute/gatk/pull/3595:210,Availability,error,errors,210,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:297,Availability,error,error,297,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:240,Deployability,update,updates,240,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:303,Integrability,message,messages,303,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:90,Security,hash,hash,90,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:229,Security,hash,hash,229,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/pull/3595:252,Security,hash,hash,252,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595
https://github.com/broadinstitute/gatk/issues/3599:228,Availability,error,error,228,"We had a little bit of trouble with AllelicCNV at the Finland workshop last week. Apologies that this isn't the most complete bug report, but the hands-on portion of the workshop moved pretty fast. Soo Hee took a picture of the error with her phone:; ![image](https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png); The rest of the relevant line is ""undefined symbol: cblas_daxpy"". The version was the GATK4 beta 4 release and the command was:; ```; gatk-launch AllelicCNV \; --tumorHets tumor_hets.tsv \; --tangentNormalized tumor_C.tn.tsv \; --segments tumor_C.seg \; --outputPrefix acnv \; --intervalThresholdCopyRatio 5.0; ```; The inputs are in the AllelicCNV workshop bundle in Google Drive: https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ. I think the host institution was running Red Hat, but it might have been Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried to reproduce the error since it seems platform-specific, but maybe some weirdo who doesn't use a Mac (@LeeTL1220) would give it a shot?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599
https://github.com/broadinstitute/gatk/issues/3599:979,Availability,error,error,979,"We had a little bit of trouble with AllelicCNV at the Finland workshop last week. Apologies that this isn't the most complete bug report, but the hands-on portion of the workshop moved pretty fast. Soo Hee took a picture of the error with her phone:; ![image](https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png); The rest of the relevant line is ""undefined symbol: cblas_daxpy"". The version was the GATK4 beta 4 release and the command was:; ```; gatk-launch AllelicCNV \; --tumorHets tumor_hets.tsv \; --tangentNormalized tumor_C.tn.tsv \; --segments tumor_C.seg \; --outputPrefix acnv \; --intervalThresholdCopyRatio 5.0; ```; The inputs are in the AllelicCNV workshop bundle in Google Drive: https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ. I think the host institution was running Red Hat, but it might have been Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried to reproduce the error since it seems platform-specific, but maybe some weirdo who doesn't use a Mac (@LeeTL1220) would give it a shot?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599
https://github.com/broadinstitute/gatk/issues/3599:461,Deployability,release,release,461,"We had a little bit of trouble with AllelicCNV at the Finland workshop last week. Apologies that this isn't the most complete bug report, but the hands-on portion of the workshop moved pretty fast. Soo Hee took a picture of the error with her phone:; ![image](https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png); The rest of the relevant line is ""undefined symbol: cblas_daxpy"". The version was the GATK4 beta 4 release and the command was:; ```; gatk-launch AllelicCNV \; --tumorHets tumor_hets.tsv \; --tangentNormalized tumor_C.tn.tsv \; --segments tumor_C.seg \; --outputPrefix acnv \; --intervalThresholdCopyRatio 5.0; ```; The inputs are in the AllelicCNV workshop bundle in Google Drive: https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ. I think the host institution was running Red Hat, but it might have been Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried to reproduce the error since it seems platform-specific, but maybe some weirdo who doesn't use a Mac (@LeeTL1220) would give it a shot?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599
https://github.com/broadinstitute/gatk/pull/3600:104,Integrability,interface,interfaces,104,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:535,Integrability,wrap,wrap,535,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:0,Modifiability,refactor,refactoring,0,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:171,Modifiability,Refactor,Refactoring,171,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:327,Modifiability,Refactor,Refactoring,327,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:71,Performance,optimiz,optimized,71,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/pull/3600:586,Testability,test,test,586,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600
https://github.com/broadinstitute/gatk/issues/3601:78,Deployability,update,update,78,"The script is no longer located at scripts/install_R_packages.R, so we should update the readme accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3601
https://github.com/broadinstitute/gatk/pull/3602:36,Deployability,install,installation,36,Updating the README.md to fix the R installation instructions which were out of date.; scripts/install_R_packages.R -> scripts/docker/gatkbase/install_R_packages.R; fixes #3601,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3602
https://github.com/broadinstitute/gatk/issues/3605:1367,Safety,avoid,avoids,1367,"I'm running into a consistent core dump in GATK 4 beta 5 (GKL 0.5.8) related to deflation with the Intel Genomics Library. This occurs on a AWS m4.4xlarge machine running Ubuntu 16.04 and consistently core dumps and provides this stack trace:. https://gist.github.com/chapmanb/006c1c9abeb21e9baf244d17d7ae1003. Running ApplyBQSR:; ```; unset JAVA_HOME && export PATH=/mnt/work/bcbio/anaconda/bin:$PATH && gatk-launch --javaOptions '-Xms1000m -Xmx46965m -XX:+UseSerialGC -Djava.io.tmpdir=/mnt/work/cwl/bcbio_validation_workflows/somatic-giab-mix/bunny_work/main-somatic-giab-mix-2017-09-23-094842.494/root/postprocess_alignment/2/bcbiotx/tmpLCoup3' ApplyBQSRSpark --sparkMaster local[16] --input /mnt/work/cwl/bcbio_validation_workflows/somatic-giab-mix/bunny_work/main-somatic-giab-mix-2017-09-22-201054.451/root/alignment/2/merge_split_alignments/align/giab-mix-tumor/giab-mix-tumor-sort.bam --output /mnt/work/cwl/bcbio_validation_workflows/somatic-giab-mix/bunny_work/main-somatic-giab-mix-2017-09-23-094842.494/root/postprocess_alignment/2/bcbiotx/tmpLCoup3/giab-mix-tumor-sort-recal.bam --bqsr_recal_file /mnt/work/cwl/bcbio_validation_workflows/somatic-giab-mix/bunny_work/main-somatic-giab-mix-2017-09-23-094842.494/root/postprocess_alignment/2/align/giab-mix-tumor/giab-mix-tumor-sort-recal.grp; ```; Adding `--use_jdk_deflater` to the ApplyBQSR command line avoids the issue. I'm not sure if the java stack dump and command line provide enough information to be useful or if having a reproducible case is needed. The case above reproduces but has fairly large BAM files and I haven't been able to get a more minimal case, but I could prepare and share if it would be helpful. Thanks much for looking at this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605
https://github.com/broadinstitute/gatk/issues/3607:478,Availability,down,down,478,"When running the current version of the SV pipeline against the NA12878_PCR-_30X bam file aligned to hg19/b37, stage 10 is held up by a single assembly task that takes much longer than the others. Unfortunately I don't have exact timings yet, and haven't identified the assembly issue that's causing the problem, but I wanted to log this as an issue so we don't forget about it. It's possible that other samples will have similar outlier assemblies so it would be good to track down cases like this so that we can try to identify and remove pathological intervals. @tedsharpe if you find yourself with free time could you take a look at this? Whatever is going wrong with it might be fixed or relevant to your work on debugging assemblies and kmer gathering (if we're lucky perhaps your 'diffuse k-mer' fix will solve this issue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3607
https://github.com/broadinstitute/gatk/issues/3607:43,Deployability,pipeline,pipeline,43,"When running the current version of the SV pipeline against the NA12878_PCR-_30X bam file aligned to hg19/b37, stage 10 is held up by a single assembly task that takes much longer than the others. Unfortunately I don't have exact timings yet, and haven't identified the assembly issue that's causing the problem, but I wanted to log this as an issue so we don't forget about it. It's possible that other samples will have similar outlier assemblies so it would be good to track down cases like this so that we can try to identify and remove pathological intervals. @tedsharpe if you find yourself with free time could you take a look at this? Whatever is going wrong with it might be fixed or relevant to your work on debugging assemblies and kmer gathering (if we're lucky perhaps your 'diffuse k-mer' fix will solve this issue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3607
https://github.com/broadinstitute/gatk/issues/3607:329,Testability,log,log,329,"When running the current version of the SV pipeline against the NA12878_PCR-_30X bam file aligned to hg19/b37, stage 10 is held up by a single assembly task that takes much longer than the others. Unfortunately I don't have exact timings yet, and haven't identified the assembly issue that's causing the problem, but I wanted to log this as an issue so we don't forget about it. It's possible that other samples will have similar outlier assemblies so it would be good to track down cases like this so that we can try to identify and remove pathological intervals. @tedsharpe if you find yourself with free time could you take a look at this? Whatever is going wrong with it might be fixed or relevant to your work on debugging assemblies and kmer gathering (if we're lucky perhaps your 'diffuse k-mer' fix will solve this issue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3607
https://github.com/broadinstitute/gatk/issues/3608:58,Performance,perform,performance,58,I believe we discovered that `IntervalSkipList` had worse performance than htsjdk's `OverlapDetector`. It's probably best to remove IntervalSkipList in this case and prefer the htsjdk version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3608
https://github.com/broadinstitute/gatk/issues/3609:181,Testability,test,tests,181,"https://github.com/broadinstitute/gatk/pull/3575 added GenomicsDB support for non-diploid genotypes and also for preserving phasing information in genotypes. We still need to craft tests to prove that this functionality works as intended, however.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3609
https://github.com/broadinstitute/gatk/pull/3611:47,Deployability,pipeline,pipeline,47,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:403,Deployability,integrat,integration,403,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:403,Integrability,integrat,integration,403,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:443,Modifiability,refactor,refactored,443,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:378,Security,validat,validated,378,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:64,Testability,log,logged,64,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/pull/3611:415,Testability,test,tests,415,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611
https://github.com/broadinstitute/gatk/issues/3612:38,Testability,test,tests,38,@SHuang-Broad We still have these SGA tests that always skip. Has the need for that been replaced by Fermilite and BWA? Can we delete that code / remove those tests?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612
https://github.com/broadinstitute/gatk/issues/3612:159,Testability,test,tests,159,@SHuang-Broad We still have these SGA tests that always skip. Has the need for that been replaced by Fermilite and BWA? Can we delete that code / remove those tests?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612
https://github.com/broadinstitute/gatk/pull/3613:46,Testability,test,tests,46,"by removing SGA associated classes, tools and tests, which are mostly skipped anyway",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3613
https://github.com/broadinstitute/gatk/pull/3614:157,Testability,test,tested,157,This **experimental** tool allows users to use `FilterByOrientationBias` with VCF calls from tools other than M2. Indels are supported though not thoroughly tested. (Note that `FilterByOrientationBias` does not ever consider indels). This tool requires:; - VCF; - A bam file for the normal and tumor samples in the VCF. The sample name in the bam files must match the sample names in the VCF.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3614
https://github.com/broadinstitute/gatk/issues/3619:79,Availability,error,error,79,Picard added a test that runs all the data providers and makes sure they don't error out and cause skipped tests. Maybe we should add a similar test. see https://github.com/broadinstitute/picard/pull/931,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3619
https://github.com/broadinstitute/gatk/issues/3619:15,Testability,test,test,15,Picard added a test that runs all the data providers and makes sure they don't error out and cause skipped tests. Maybe we should add a similar test. see https://github.com/broadinstitute/picard/pull/931,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3619
https://github.com/broadinstitute/gatk/issues/3619:107,Testability,test,tests,107,Picard added a test that runs all the data providers and makes sure they don't error out and cause skipped tests. Maybe we should add a similar test. see https://github.com/broadinstitute/picard/pull/931,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3619
https://github.com/broadinstitute/gatk/issues/3619:144,Testability,test,test,144,Picard added a test that runs all the data providers and makes sure they don't error out and cause skipped tests. Maybe we should add a similar test. see https://github.com/broadinstitute/picard/pull/931,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3619
https://github.com/broadinstitute/gatk/pull/3620:231,Availability,mask,masked,231,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3620:551,Availability,down,download,551,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3620:602,Deployability,update,update,602,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3620:364,Testability,test,test,364,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3620:439,Testability,test,tests,439,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3620:592,Testability,test,tests,592,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620
https://github.com/broadinstitute/gatk/pull/3622:23,Deployability,update,update,23,"I asked about a status update on the travis image space issue in the travis ticket, and based on feedback I tried moving to the new image. It seems to work now. Fixes https://github.com/broadinstitute/gatk/issues/3559.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3622
https://github.com/broadinstitute/gatk/pull/3622:97,Usability,feedback,feedback,97,"I asked about a status update on the travis image space issue in the travis ticket, and based on feedback I tried moving to the new image. It seems to work now. Fixes https://github.com/broadinstitute/gatk/issues/3559.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3622
https://github.com/broadinstitute/gatk/issues/3623:295,Modifiability,variab,variables,295,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3623:46,Testability,Test,Test,46,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3623:80,Testability,Test,Test,80,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3623:144,Testability,Test,Test,144,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3623:173,Testability,Test,Test,173,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3623:273,Testability,Test,Test,273,"From the comments in the code:. ```; // TODO: Test with multiallelics; // TODO: Test with multiallelics and symbolic at the same time; // TODO: Test with symbolic; // TODO: Test with information missing from the VCF and make sure appropriate exception is thrown.; // TODO: Test with more cutoff variables; // TODO: Once above five TODOs are done (at least), AnnotatePairOrientation can be taken out of Experimental status.; ```; We can raise the priority if this tool gains traction. That seems unlikely since this is still a bit of a niche tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3623
https://github.com/broadinstitute/gatk/issues/3625:94,Availability,down,download,94,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should be able to remove the download of picard.jar from .travis.yml, and change the M2 WDL to no longer depend having access to it. Workflow calls to picard tools can be replaced with calls to the same tools in GATK, although the argument syntax will have to change from picard style to Barclay style (""I=..."" to ""-I ..."").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625
https://github.com/broadinstitute/gatk/issues/3625:170,Integrability,depend,depend,170,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should be able to remove the download of picard.jar from .travis.yml, and change the M2 WDL to no longer depend having access to it. Workflow calls to picard tools can be replaced with calls to the same tools in GATK, although the argument syntax will have to change from picard style to Barclay style (""I=..."" to ""-I ..."").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625
https://github.com/broadinstitute/gatk/issues/3625:184,Security,access,access,184,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should be able to remove the download of picard.jar from .travis.yml, and change the M2 WDL to no longer depend having access to it. Workflow calls to picard tools can be replaced with calls to the same tools in GATK, although the argument syntax will have to change from picard style to Barclay style (""I=..."" to ""-I ..."").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625
https://github.com/broadinstitute/gatk/issues/3627:76,Deployability,update,update,76,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should add/update the gradle tasks for gatkDoc and gatkTabComplete to generate unified (GATK and Picard) doc and tab completion script.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3627
https://github.com/broadinstitute/gatk/pull/3628:472,Performance,tune,tuned,472,This PR adds logic to use imprecise evidence (gathered from discordant read pair mappings and split reads with supplementary alignments) to:. - Annotate events that we are calling from assembled breakpoints with the number of discordant read pairs and split reads that support those events.; - Call new variants when an imprecise evidence link supporting a deletion is supported by a minimum number of pieces of evidence (set to 7 by default in this PR; parameters can be tuned later). In an initial run on the CHM mix this uses 3500 evidence-target clusters to annotate our existing deletion calls and makes an additional 670 IMPRECISE deletion calls. Initial visual evaluations against the CHM truth set looks good on visual inspection; more detailed evaluations will follow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628
https://github.com/broadinstitute/gatk/pull/3628:13,Testability,log,logic,13,This PR adds logic to use imprecise evidence (gathered from discordant read pair mappings and split reads with supplementary alignments) to:. - Annotate events that we are calling from assembled breakpoints with the number of discordant read pairs and split reads that support those events.; - Call new variants when an imprecise evidence link supporting a deletion is supported by a minimum number of pieces of evidence (set to 7 by default in this PR; parameters can be tuned later). In an initial run on the CHM mix this uses 3500 evidence-target clusters to annotate our existing deletion calls and makes an additional 670 IMPRECISE deletion calls. Initial visual evaluations against the CHM truth set looks good on visual inspection; more detailed evaluations will follow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628
https://github.com/broadinstitute/gatk/issues/3631:1574,Availability,avail,available,1574,"NIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:5217,Availability,recover,recoverDanglingHeads,5217,GQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:5364,Availability,error,errorCorrectKmers,5364,GQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:5979,Availability,error,errorCorrectReads,5979,GQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:7466,Availability,Avail,Available,7466,"ype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --output_mode EMIT_VARIANTS_ONLY --allSitePLs false --readShardSize 5000 --readShardPadding 100 --minAssemblyRegionSize 50 --maxAssemblyRegionSize 300 --assemblyRegionPadding 100 --maxReadsPerAlignmentStart 50 --activeProbabilityThreshold 0.002 --maxProbPropagationDistance 50 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 9, 2017 10:13:02 AM AST] Executing as nkathiresan@nsnode11 on Linux 3.10.0-229.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.2-14-g4229219-SNAPSHOT; [INFO] Available threads: 32; [INFO] Requested threads: 1024; [WARNING] Using 32 available threads, but 1024 were requested; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.utils.MathUtils$Log10Cache).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; **[August 11, 2017 12:34:22 PM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. **Elapsed time: 3,021.34 minutes.****; Runtime.totalMemory()=57773916160; + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh. ; Thanks a lot,; With Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/10340/gatk-3-7-and-gatk-4-beta2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:7540,Availability,avail,available,7540,"ype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --output_mode EMIT_VARIANTS_ONLY --allSitePLs false --readShardSize 5000 --readShardPadding 100 --minAssemblyRegionSize 50 --maxAssemblyRegionSize 300 --assemblyRegionPadding 100 --maxReadsPerAlignmentStart 50 --activeProbabilityThreshold 0.002 --maxProbPropagationDistance 50 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 9, 2017 10:13:02 AM AST] Executing as nkathiresan@nsnode11 on Linux 3.10.0-229.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.2-14-g4229219-SNAPSHOT; [INFO] Available threads: 32; [INFO] Requested threads: 1024; [WARNING] Using 32 available threads, but 1024 were requested; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.utils.MathUtils$Log10Cache).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; **[August 11, 2017 12:34:22 PM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. **Elapsed time: 3,021.34 minutes.****; Runtime.totalMemory()=57773916160; + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh. ; Thanks a lot,; With Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/10340/gatk-3-7-and-gatk-4-beta2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:88,Deployability,release,release,88,"User reporting major time differences between 3.7 HaplotypeCaller and GATK4 latest beta release. . ----; User Report; ----. Dear team,. I am using GATK 4 Beta2 for testing HaplotypeCaller for our NGS workflow. . The command which I used is: . _time -p /gpfs/software/genomics/GATK/4b.2/gatk/gatk-launch HaplotypeCaller \ ; --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; --input NA12892.recal.bam \ ; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \ ; --emitRefConfidence GVCF \; --readValidationStringency LENIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:2745,Deployability,pipeline,pipeline,2745," 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --output NA12892.raw.snps.indels.g.vcf --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --readValidationStringency LENIENT --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --createOutputVariantIndex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:3033,Deployability,pipeline,pipeline,3033,"ster spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --output NA12892.raw.snps.indels.g.vcf --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --readValidationStringency LENIENT --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --createOutputVariantIndex true --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9 --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:3577,Deployability,pipeline,pipeline,3577,"kka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --output NA12892.raw.snps.indels.g.vcf --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --readValidationStringency LENIENT --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --createOutputVariantIndex true --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9 --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 --GVCFGQBands 14 --GVCFGQBands 15 --GVCFGQBands 16 --GVCFGQBands 17 --GVCFGQBands 18 --GVCFGQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:1475,Energy Efficiency,reduce,reduce,1475,"bsnp_138.vcf.gz \ ; --emitRefConfidence GVCF \; --readValidationStringency LENIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:1870,Energy Efficiency,reduce,reduce,1870,"reads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:2500,Energy Efficiency,reduce,reducer,2500,"the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:5217,Safety,recover,recoverDanglingHeads,5217,GQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:164,Testability,test,testing,164,"User reporting major time differences between 3.7 HaplotypeCaller and GATK4 latest beta release. . ----; User Report; ----. Dear team,. I am using GATK 4 Beta2 for testing HaplotypeCaller for our NGS workflow. . The command which I used is: . _time -p /gpfs/software/genomics/GATK/4b.2/gatk/gatk-launch HaplotypeCaller \ ; --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; --input NA12892.recal.bam \ ; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \ ; --emitRefConfidence GVCF \; --readValidationStringency LENIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:1588,Testability,benchmark,benchmarking,1588,"NIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:1960,Testability,log,logs,1960,"ase/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:7627,Testability,log,logger,7627,"ype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --output_mode EMIT_VARIANTS_ONLY --allSitePLs false --readShardSize 5000 --readShardPadding 100 --minAssemblyRegionSize 50 --maxAssemblyRegionSize 300 --assemblyRegionPadding 100 --maxReadsPerAlignmentStart 50 --activeProbabilityThreshold 0.002 --maxProbPropagationDistance 50 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 9, 2017 10:13:02 AM AST] Executing as nkathiresan@nsnode11 on Linux 3.10.0-229.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.2-14-g4229219-SNAPSHOT; [INFO] Available threads: 32; [INFO] Requested threads: 1024; [WARNING] Using 32 available threads, but 1024 were requested; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.utils.MathUtils$Log10Cache).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; **[August 11, 2017 12:34:22 PM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. **Elapsed time: 3,021.34 minutes.****; Runtime.totalMemory()=57773916160; + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh. ; Thanks a lot,; With Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/10340/gatk-3-7-and-gatk-4-beta2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/issues/3631:7774,Testability,log,logging,7774,"ype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --output_mode EMIT_VARIANTS_ONLY --allSitePLs false --readShardSize 5000 --readShardPadding 100 --minAssemblyRegionSize 50 --maxAssemblyRegionSize 300 --assemblyRegionPadding 100 --maxReadsPerAlignmentStart 50 --activeProbabilityThreshold 0.002 --maxProbPropagationDistance 50 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 9, 2017 10:13:02 AM AST] Executing as nkathiresan@nsnode11 on Linux 3.10.0-229.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.2-14-g4229219-SNAPSHOT; [INFO] Available threads: 32; [INFO] Requested threads: 1024; [WARNING] Using 32 available threads, but 1024 were requested; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.utils.MathUtils$Log10Cache).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; **[August 11, 2017 12:34:22 PM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. **Elapsed time: 3,021.34 minutes.****; Runtime.totalMemory()=57773916160; + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh. ; Thanks a lot,; With Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/10340/gatk-3-7-and-gatk-4-beta2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631
https://github.com/broadinstitute/gatk/pull/3635:11,Deployability,update,updated,11,htsjdk has updated to a newer version of snappy (https://github.com/samtools/htsjdk/pull/872) which makes it compatible with the rest of the world's snappy. this means we can re-enable snappy usage in htsjdk which should give performance improvements in tools that use `SortingCollection`. this is a permanent solution to #2026 that replaces the changes we made in #2028,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3635
https://github.com/broadinstitute/gatk/pull/3635:226,Performance,perform,performance,226,htsjdk has updated to a newer version of snappy (https://github.com/samtools/htsjdk/pull/872) which makes it compatible with the rest of the world's snappy. this means we can re-enable snappy usage in htsjdk which should give performance improvements in tools that use `SortingCollection`. this is a permanent solution to #2026 that replaces the changes we made in #2028,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3635
https://github.com/broadinstitute/gatk/pull/3636:55,Usability,simpl,simple,55,@LeeTL1220 you were right. Fortunately the fix is very simple.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3636
https://github.com/broadinstitute/gatk/pull/3639:38,Availability,error,error,38,… mismatches is too large. Removes an error that is thrown when the number of mismatches is greater than the number of mismatches/mismatches in the cigar. . It appears that some aligners do this. I am seeing it frequently in soft-clipped reads in TCGA RNA-seq BAMs (maybe a STAR bug?). . I would prefer to remove the thrown error rather than assume the dev will be aware of this issue and will catch it externally.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3639
https://github.com/broadinstitute/gatk/pull/3639:324,Availability,error,error,324,… mismatches is too large. Removes an error that is thrown when the number of mismatches is greater than the number of mismatches/mismatches in the cigar. . It appears that some aligners do this. I am seeing it frequently in soft-clipped reads in TCGA RNA-seq BAMs (maybe a STAR bug?). . I would prefer to remove the thrown error rather than assume the dev will be aware of this issue and will catch it externally.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3639
https://github.com/broadinstitute/gatk/issues/3641:102,Modifiability,Extend,Extend,102,"This is a useful class when strictly dealing with pileups. However, it only supports point mutations. Extend to indels....",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3641
https://github.com/broadinstitute/gatk/issues/3642:48,Integrability,depend,depends,48,"The code that composes the result output folder depends on ```git batch --contains HASH``` to pick up a line with a standard branch name (e.g. ``` joe_doe_bugfix```) . However this is not neceserely the case if the current checkout is not attach to a local branch... for example when one does ```git fetch; git checkout origin/master```. In that case a typical git-batch line that gets picked up is ```* (HEAD detached at origin/master)``` and in this case it will use ""origin/master)"" rather than ""joe_doe_bugfix"" to be part of the result output directory name. The problem is the ""/"" and "")"" which causes problems later at least when running copy_sv_results.sh as they are not escaped appropriately. Obvious ways to address this: ; 1. remove that component of the output name as is not needed to make it quite unique.; 2. change the sub-command to handle that situation. ; 3. or fail early (before spinning the cluster) if the GATK git checkout is detached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642
https://github.com/broadinstitute/gatk/issues/3642:83,Security,HASH,HASH,83,"The code that composes the result output folder depends on ```git batch --contains HASH``` to pick up a line with a standard branch name (e.g. ``` joe_doe_bugfix```) . However this is not neceserely the case if the current checkout is not attach to a local branch... for example when one does ```git fetch; git checkout origin/master```. In that case a typical git-batch line that gets picked up is ```* (HEAD detached at origin/master)``` and in this case it will use ""origin/master)"" rather than ""joe_doe_bugfix"" to be part of the result output directory name. The problem is the ""/"" and "")"" which causes problems later at least when running copy_sv_results.sh as they are not escaped appropriately. Obvious ways to address this: ; 1. remove that component of the output name as is not needed to make it quite unique.; 2. change the sub-command to handle that situation. ; 3. or fail early (before spinning the cluster) if the GATK git checkout is detached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642
https://github.com/broadinstitute/gatk/issues/3647:21,Deployability,pipeline,pipeline,21,"Right now, in master pipeline we have one `INSERTED_SEQUENCE` AND `INSDERTED_SEQUENCE_MAPPINGS` annotation each, with the 2nd annotation taking possibly multiple values whereas the 1st only 1 value. We need to improve this. ; A possible solution is to have one annotation with paired multiple entries as suggested by @cwhelan . The goal is to make transforming symb alt allele records to BND records easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3647
https://github.com/broadinstitute/gatk/issues/3648:375,Availability,avail,available,375,"GATK4 has a number of options that presumably alter performance in different ways under different conditions, including and probably not limited to: Intel Deflater/Inflater, snappy, and HTSJDK's various USE_ASYNC_XXXXX_READ params. I can appreciate there is probably not a one-size fits all answer, but would it be possible to provide some type of general guidance on what's available, and when one or the other might be worth evaluating? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648
https://github.com/broadinstitute/gatk/issues/3648:52,Performance,perform,performance,52,"GATK4 has a number of options that presumably alter performance in different ways under different conditions, including and probably not limited to: Intel Deflater/Inflater, snappy, and HTSJDK's various USE_ASYNC_XXXXX_READ params. I can appreciate there is probably not a one-size fits all answer, but would it be possible to provide some type of general guidance on what's available, and when one or the other might be worth evaluating? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648
https://github.com/broadinstitute/gatk/issues/3648:356,Usability,guid,guidance,356,"GATK4 has a number of options that presumably alter performance in different ways under different conditions, including and probably not limited to: Intel Deflater/Inflater, snappy, and HTSJDK's various USE_ASYNC_XXXXX_READ params. I can appreciate there is probably not a one-size fits all answer, but would it be possible to provide some type of general guidance on what's available, and when one or the other might be worth evaluating? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648
https://github.com/broadinstitute/gatk/issues/3651:21,Availability,error,error,21,"Hi,. I am having the error below when I try to run PrintReadsSpark using an external spark cluster. ```; ./gatk-launch PrintReadsSpark -I ~/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O ~/storage/output.bam -- --sparkRunner SPARK --sparkMaster spark://192.168.1.110:7077; Using GATK jar /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar; Running:; spark-submit --master spark://192.168.1.110:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar PrintReadsSpark -I /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O /home/centos/storage/output.bam --sparkMaster spark://192.168.1.110:7077; 05:27:50.924 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 05:27:51.034 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 3, 2017 5:27:51 AM UTC] PrintReadsSpark --output /home/centos/storage/output.bam --input /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam --sparkMaster spark://192.168.1.110:7077 --readValidationStringe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3435,Availability,ERROR,ERROR,3435," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3553,Availability,ERROR,ERROR,3553," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3618,Availability,ERROR,ERROR,3618," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3697,Availability,ERROR,ERROR,3697," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3818,Availability,ERROR,ERROR,3818," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3190,Deployability,patch,patch,3190," false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:1429,Modifiability,variab,variables,1429,"compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar PrintReadsSpark -I /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O /home/centos/storage/output.bam --sparkMaster spark://192.168.1.110:7077; 05:27:50.924 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 05:27:51.034 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 3, 2017 5:27:51 AM UTC] PrintReadsSpark --output /home/centos/storage/output.bam --input /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam --sparkMaster spark://192.168.1.110:7077 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Lin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:1555,Modifiability,config,configured,1555,"compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar PrintReadsSpark -I /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O /home/centos/storage/output.bam --sparkMaster spark://192.168.1.110:7077; 05:27:50.924 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 05:27:51.034 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 3, 2017 5:27:51 AM UTC] PrintReadsSpark --output /home/centos/storage/output.bam --input /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam --sparkMaster spark://192.168.1.110:7077 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Lin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3536,Modifiability,variab,variable,3536," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:1616,Performance,Load,Loading,1616,"ION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar PrintReadsSpark -I /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O /home/centos/storage/output.bam --sparkMaster spark://192.168.1.110:7077; 05:27:50.924 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 05:27:51.034 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 3, 2017 5:27:51 AM UTC] PrintReadsSpark --output /home/centos/storage/output.bam --input /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam --sparkMaster spark://192.168.1.110:7077 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO Print",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3601,Performance,load,loaded,3601," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3742,Performance,load,loaded,3742," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:3997,Testability,log,logger,3997," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/issues/3651:4117,Testability,log,logging,4117," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651
https://github.com/broadinstitute/gatk/pull/3653:223,Deployability,release,release,223,Adds dynamic sizing to m2 wdl as well as standardization of each task in terms of what control a user can have over it. This is the first step pegging spec ops to a commit and then merging with the mutect.wdl proper once a release is to be made.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3653
https://github.com/broadinstitute/gatk/pull/3655:194,Integrability,depend,depends,194,This addresses the problem where serialized GMMs for VQSR assumed the annotation order would be the same between the commands that generated them and the commands that used them. VQSR no longer depends on the commandline order of the annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3655
https://github.com/broadinstitute/gatk/issues/3657:16,Testability,log,logic,16,"The conditional logic (wgs vs exome, T/N vs T-only) should not be based on the presence or absence of file inputs. This should instead be done using an explicit switch, eg a “mode” argument. Otherwise people are going to run into all sorts of trouble.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657
https://github.com/broadinstitute/gatk/issues/3659:2410,Energy Efficiency,schedul,scheduler,2410,y_work/main-giab-joint-2017-10-02-100534.907/root/postprocess_alignment/2/align/NA24631/NA24631-sort-recal.bam -L /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/gatk-haplotype/chr15/NA24631-chr15_68578892_84670250-block-regions.bed --interval_set_rule INTERSECTION --sparkMaster local[16] --conf spark.local.dir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2482,Energy Efficiency,schedul,scheduler,2482,2/align/NA24631/NA24631-sort-recal.bam -L /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/gatk-haplotype/chr15/NA24631-chr15_68578892_84670250-block-regions.bed --interval_set_rule INTERSECTION --sparkMaster local[16] --conf spark.local.dir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2846,Energy Efficiency,schedul,scheduler,2846,idation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2886,Energy Efficiency,schedul,scheduler,2886,7-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2985,Energy Efficiency,schedul,scheduler,2985,zBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3083,Energy Efficiency,schedul,scheduler,3083,lidation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3337,Energy Efficiency,schedul,scheduler,3337,-GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3418,Energy Efficiency,schedul,scheduler,3418,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3524,Energy Efficiency,schedul,scheduler,3524,he.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3674,Energy Efficiency,schedul,scheduler,3674,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3763,Energy Efficiency,schedul,scheduler,3763,va.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3861,Energy Efficiency,schedul,scheduler,3861,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:264); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3957,Energy Efficiency,schedul,scheduler,3957,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:264); 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:126); 	at org.apache.spark.rdd.Ordered,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:4122,Energy Efficiency,schedul,scheduler,4122,.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:264); 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:126); 	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); 	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:9664,Energy Efficiency,schedul,scheduler,9664,NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:130); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:67); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```; Thanks for any suggestions or pointers to debug further.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:9736,Energy Efficiency,schedul,scheduler,9736,NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:130); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:67); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```; Thanks for any suggestions or pointers to debug further.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2606,Performance,concurren,concurrent,2606,7-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/gatk-haplotype/chr15/NA24631-chr15_68578892_84670250-block-regions.bed --interval_set_rule INTERSECTION --sparkMaster local[16] --conf spark.local.dir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:2691,Performance,concurren,concurrent,2691,5/NA24631-chr15_68578892_84670250-block-regions.bed --interval_set_rule INTERSECTION --sparkMaster local[16] --conf spark.local.dir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:9860,Performance,concurren,concurrent,9860,NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:130); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:67); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```; Thanks for any suggestions or pointers to debug further.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:9945,Performance,concurren,concurrent,9945,NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:130); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:67); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```; Thanks for any suggestions or pointers to debug further.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3017,Safety,abort,abortStage,3017,ingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3115,Safety,abort,abortStage,3115,b-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/issues/3659:3360,Safety,abort,abortStage,3360,ceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659
https://github.com/broadinstitute/gatk/pull/3663:101,Deployability,upgrade,upgrade,101,"User brought up that Broad's google-cloud-sdk is not up to date, so I added a note telling people to upgrade regularly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3663
https://github.com/broadinstitute/gatk/issues/3664:102,Availability,error,error,102,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664
https://github.com/broadinstitute/gatk/issues/3664:251,Deployability,pipeline,pipelines,251,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664
https://github.com/broadinstitute/gatk/issues/3664:158,Testability,test,test-logs,158,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664
https://github.com/broadinstitute/gatk/issues/3664:190,Testability,test,tests,190,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664
https://github.com/broadinstitute/gatk/issues/3664:196,Testability,test,test,196,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664
https://github.com/broadinstitute/gatk/pull/3667:384,Testability,test,tests,384,"the sample swap issue seems to have been caused by the fact that the callset.json files had the sample names globally sorted; the actual data was entered in the order the sample names were input, but each bactch was sorted within the batch. this produced a mismatch between data and samplename mapping. fixing it by using sorted map everywhere sample names are handled; modifying our tests to use an out of order sample map file and multiple batches",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3667
https://github.com/broadinstitute/gatk/pull/3668:887,Availability,down,down,887,"Dealing with case when two alignment blocks contain each other in their ref span, indicating duplication.; Instead of outputting CIGARs for the duplicated units like we did for duplication records now in master pipeline, we output alt haplotype sequence from the evidence contigs we assembled, since we did an experiment work with inverted duplications. Some performance evaluation based on the logs. ```; master.vcf. 10:28:46.262 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6324 variants.; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 237; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/pull/3668:1601,Availability,down,down,1601,".277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known issues__:; 1. Arguably, these calls may not have high confidence since we are likely NOT having the duplicated region fully assembled. But we could develop a filter later and be less stringent in the discovery stage.; 2. The inserted sequence mapping annotation is still an issue we need to iron out, in the sense that when one ref span is a completely enclosed in the other with some bases in the larger ref span uncovered by the the smaller ref span (i.e. a true containment from both boundaries instead of a one-boundary coincidence), there's actually insert sequence between the two copies ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/pull/3668:211,Deployability,pipeline,pipeline,211,"Dealing with case when two alignment blocks contain each other in their ref span, indicating duplication.; Instead of outputting CIGARs for the duplicated units like we did for duplication records now in master pipeline, we output alt haplotype sequence from the evidence contigs we assembled, since we did an experiment work with inverted duplications. Some performance evaluation based on the logs. ```; master.vcf. 10:28:46.262 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6324 variants.; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 237; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/pull/3668:359,Performance,perform,performance,359,"Dealing with case when two alignment blocks contain each other in their ref span, indicating duplication.; Instead of outputting CIGARs for the duplicated units like we did for duplication records now in master pipeline, we output alt haplotype sequence from the evidence contigs we assembled, since we did an experiment work with inverted duplications. Some performance evaluation based on the logs. ```; master.vcf. 10:28:46.262 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6324 variants.; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 237; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/pull/3668:395,Testability,log,logs,395,"Dealing with case when two alignment blocks contain each other in their ref span, indicating duplication.; Instead of outputting CIGARs for the duplicated units like we did for duplication records now in master pipeline, we output alt haplotype sequence from the evidence contigs we assembled, since we did an experiment work with inverted duplications. Some performance evaluation based on the logs. ```; master.vcf. 10:28:46.262 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6324 variants.; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 237; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/pull/3668:1855,Usability,simpl,simple,1855,"iantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known issues__:; 1. Arguably, these calls may not have high confidence since we are likely NOT having the duplicated region fully assembled. But we could develop a filter later and be less stringent in the discovery stage.; 2. The inserted sequence mapping annotation is still an issue we need to iron out, in the sense that when one ref span is a completely enclosed in the other with some bases in the larger ref span uncovered by the the smaller ref span (i.e. a true containment from both boundaries instead of a one-boundary coincidence), there's actually insert sequence between the two copies of the duplicated sequence (this is why alt haplotype sequence is generated rather than CIGARs).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668
https://github.com/broadinstitute/gatk/issues/3669:4502,Availability,down,down,4502,"IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:52:21.917 INFO PrintReads - Done initializing engine; 14:52:22.027 INFO ProgressMeter - Starting traversal; 14:52:22.027 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 14:52:32.033 INFO ProgressMeter - chr17:6779805 0.2 494000 2962814.9; 14:52:42.035 INFO ProgressMeter - chr17:18100301 0.3 1275000 3823661.7; 14:52:52.089 INFO ProgressMeter - chr17:32183301 0.5 2017000 4025814.2; 14:53:02.141 INFO ProgressMeter - chr17:38342966 0.7 2500000 3739436.1; 14:53:12.267 INFO ProgressMeter - chr17:46549838 0.8 3360000 4012818.7; 14:53:22.273 INFO ProgressMeter - chr17:63099258 1.0 4210000 4192879.1; 14:53:30.687 INFO PrintReads - No reads filtered by: WellformedReadFilter; 14:53:30.687 INFO ProgressMeter - chr17:83185333 1.1 5250614 4588427.4; 14:53:30.687 INFO ProgressMeter - Traversal complete. Processed 5250614 total reads in 1.1 minutes.; 14:53:33.576 INFO PrintReads - Shutting down engine; [October 5, 2017 2:53:33 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 1.38 minutes.; Runtime.totalMemory()=8385462272; ```. ## Cloud CRAM; Running just PrintReads without `-L` intervals succeeds.; ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -O HG00190_cram.bam; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -O HG00190_cram.bam; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:8715,Availability,error,error,8715,flater: IntelInflater; 15:05:33.887 INFO PrintReads - GCS max retries/reopens: 20; 15:05:33.887 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:05:33.887 INFO PrintReads - Initializing engine; 15:05:39.011 INFO PrintReads - Done initializing engine; 15:05:39.298 INFO ProgressMeter - Starting traversal; 15:05:39.299 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 15:05:49.302 INFO ProgressMeter - chr1:12666181 0.2 578000 3467306.5; 15:05:59.302 INFO ProgressMeter - chr1:21255922 0.3 1287000 3860613.9; 15:06:09.320 INFO ProgressMeter - chr1:36027022 0.5 2121000 4239032.7; 15:06:19.323 INFO ProgressMeter - chr1:52397728 0.7 3017000 4522786.3; 15:06:29.323 INFO ProgressMeter - chr1:86811190 0.8 4064000 4874460.3; 15:06:39.479 INFO ProgressMeter - chr1:111761145 1.0 5079000 5063808.6; ...; ```. Adding in `-L` causes the command to error despite the presence of the index within the same folder.; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -O HG00190_cram.bam -L chr17; 14:59:15.760 INFO Nat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:11943,Availability,down,down,11943,"gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:59:15.872 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:59:15.873 INFO PrintReads - Deflater: IntelDeflater; 14:59:15.873 INFO PrintReads - Inflater: IntelInflater; 14:59:15.873 INFO PrintReads - GCS max retries/reopens: 20; 14:59:15.873 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:59:15.873 INFO PrintReads - Initializing engine; 14:59:21.404 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:59:21.421 INFO PrintReads - Shutting down engine; [October 5, 2017 2:59:22 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=2129133568; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. Still fails with `-readIndex` specified (.cram.crai OR .crai):; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:12185,Availability,ERROR,ERROR,12185,"MTOOLS : false; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:59:15.873 INFO PrintReads - Deflater: IntelDeflater; 14:59:15.873 INFO PrintReads - Inflater: IntelInflater; 14:59:15.873 INFO PrintReads - GCS max retries/reopens: 20; 14:59:15.873 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:59:15.873 INFO PrintReads - Initializing engine; 14:59:21.404 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:59:21.421 INFO PrintReads - Shutting down engine; [October 5, 2017 2:59:22 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=2129133568; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. Still fails with `-readIndex` specified (.cram.crai OR .crai):; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai \; > -O HG00190_cram.bam \; > ; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:19507,Availability,down,down,19507,"gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:08.250 INFO PrintReads - Deflater: IntelDeflater; 15:00:08.250 INFO PrintReads - Inflater: IntelInflater; 15:00:08.250 INFO PrintReads - GCS max retries/reopens: 20; 15:00:08.250 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:08.250 INFO PrintReads - Initializing engine; 15:00:13.258 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:13.275 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:14 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2233466880; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:19749,Availability,ERROR,ERROR,19749,"MTOOLS : false; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:08.250 INFO PrintReads - Deflater: IntelDeflater; 15:00:08.250 INFO PrintReads - Inflater: IntelInflater; 15:00:08.250 INFO PrintReads - GCS max retries/reopens: 20; 15:00:08.250 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:08.250 INFO PrintReads - Initializing engine; 15:00:13.258 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:13.275 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:14 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2233466880; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_asy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:23666,Availability,down,down,23666,"gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:28.284 INFO PrintReads - Deflater: IntelDeflater; 15:00:28.284 INFO PrintReads - Inflater: IntelInflater; 15:00:28.285 INFO PrintReads - GCS max retries/reopens: 20; 15:00:28.285 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:28.285 INFO PrintReads - Initializing engine; 15:00:33.117 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:33.134 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:34 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2255486976; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; -bash-4.1$ ; ```. ## Confirm all files present in bucket; ```; WMCF9-CB5:newCNV shlee$ gsutil ls gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN*; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.bam.bas; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:23908,Availability,ERROR,ERROR,23908,"Reads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:28.284 INFO PrintReads - Deflater: IntelDeflater; 15:00:28.284 INFO PrintReads - Inflater: IntelInflater; 15:00:28.285 INFO PrintReads - GCS max retries/reopens: 20; 15:00:28.285 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:28.285 INFO PrintReads - Initializing engine; 15:00:33.117 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:33.134 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:34 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2255486976; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; -bash-4.1$ ; ```. ## Confirm all files present in bucket; ```; WMCF9-CB5:newCNV shlee$ gsutil ls gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN*; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.bam.bas; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram; gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:3321,Deployability,patch,patch,3321,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 2:52:10 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:52:10.875 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:52:10.875 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:52:10.875 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:52:10.875 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:52:10.875 INFO PrintReads - Deflater: IntelDeflater; 14:52:10.875 INFO PrintReads - Inflater: IntelInflater; 14:52:10.876 INFO PrintReads - GCS max retries/reopens: 20; 14:52:10.876 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:52:10.876 INFO PrintReads - Initializing engine; 14:52:21.901 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:52:21.917 INFO PrintReads - Done initializing engine; 14:52:22.027 INFO ProgressMeter - Starting traversal; 14:52:22.027 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 14:52:32.033 INFO ProgressMeter - chr17:6779805 0.2 494000 2962814.9; 14:52:42.035 INFO ProgressMeter - chr17:18100301 0.3 1275000 3823661.7; 14:52:52.089 INFO ProgressMeter - chr17:32183301 0.5 2017000 4025814.2; 14:53:02.141 INFO ProgressMeter - chr17:38342966 0.7 2500000 3739436.1; 14:53:12.267 INFO ProgressMeter - chr17:46549838 0.8 3360000 4012818.7; 14:53:22.273 INFO ProgressMeter - chr17:63099258 1.0 4210000 4192879.1; 14:53:30.687 INFO PrintReads - No reads filtered by: WellformedReadFilter; 14:53:30.687 INFO ProgressMeter - chr17:831",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:7865,Deployability,patch,patch,7865,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 3:05:33 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 15:05:33.887 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 15:05:33.887 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:05:33.887 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:05:33.887 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:05:33.887 INFO PrintReads - Deflater: IntelDeflater; 15:05:33.887 INFO PrintReads - Inflater: IntelInflater; 15:05:33.887 INFO PrintReads - GCS max retries/reopens: 20; 15:05:33.887 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:05:33.887 INFO PrintReads - Initializing engine; 15:05:39.011 INFO PrintReads - Done initializing engine; 15:05:39.298 INFO ProgressMeter - Starting traversal; 15:05:39.299 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 15:05:49.302 INFO ProgressMeter - chr1:12666181 0.2 578000 3467306.5; 15:05:59.302 INFO ProgressMeter - chr1:21255922 0.3 1287000 3860613.9; 15:06:09.320 INFO ProgressMeter - chr1:36027022 0.5 2121000 4239032.7; 15:06:19.323 INFO ProgressMeter - chr1:52397728 0.7 3017000 4522786.3; 15:06:29.323 INFO ProgressMeter - chr1:86811190 0.8 4064000 4874460.3; 15:06:39.479 INFO ProgressMeter - chr1:111761145 1.0 5079000 5063808.6; ...; ```. Adding in `-L` causes the command to error despite the presence of the index within the same folder.; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:11645,Deployability,patch,patch,11645,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 2:59:15 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:59:15.872 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:59:15.873 INFO PrintReads - Deflater: IntelDeflater; 14:59:15.873 INFO PrintReads - Inflater: IntelInflater; 14:59:15.873 INFO PrintReads - GCS max retries/reopens: 20; 14:59:15.873 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:59:15.873 INFO PrintReads - Initializing engine; 14:59:21.404 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:59:21.421 INFO PrintReads - Shutting down engine; [October 5, 2017 2:59:22 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=2129133568; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. Still fails with `-readIndex`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:15848,Deployability,patch,patch,15848,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 2:59:57 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:59:57.393 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:59:57.393 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:59:57.393 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:59:57.393 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:59:57.394 INFO PrintReads - Deflater: IntelDeflater; 14:59:57.394 INFO PrintReads - Inflater: IntelInflater; 14:59:57.394 INFO PrintReads - GCS max retries/reopens: 20; 14:59:57.394 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:59:57.394 INFO PrintReads - Initializing engine; ^C-bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:19209,Deployability,patch,patch,19209,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 3:00:08 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:08.250 INFO PrintReads - Deflater: IntelDeflater; 15:00:08.250 INFO PrintReads - Inflater: IntelInflater; 15:00:08.250 INFO PrintReads - GCS max retries/reopens: 20; 15:00:08.250 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:08.250 INFO PrintReads - Initializing engine; 15:00:13.258 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:13.275 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:14 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2233466880; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; ```; -bash-4.1$ /humgen/gsa-h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:23368,Deployability,patch,patch,23368,"udIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 5, 2017 3:00:28 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:28.284 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:28.284 INFO PrintReads - Deflater: IntelDeflater; 15:00:28.284 INFO PrintReads - Inflater: IntelInflater; 15:00:28.285 INFO PrintReads - GCS max retries/reopens: 20; 15:00:28.285 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:28.285 INFO PrintReads - Initializing engine; 15:00:33.117 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:33.134 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:34 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2255486976; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; -bash-4.1$ ; ```. ## Confirm all f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:1354,Performance,Load,Loading,1354,"/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam \; -L chr17; ...; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam -L chr17; 14:52:10.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:52:10 PM EDT] PrintReads --output /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam --intervals chr17 --input /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:5985,Performance,Load,Loading,5985,"alysis_set_plus_decoy_hla.fa \; -O HG00190_cram.bam; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -O HG00190_cram.bam; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -O HG00190_cram.bam; 15:05:33.776 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 3:05:33 PM EDT] PrintReads --output HG00190_cram.bam --input gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --ve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:9747,Performance,Load,Loading,9747,"the index within the same folder.; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -O HG00190_cram.bam -L chr17; 14:59:15.760 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:59:15 PM EDT] PrintReads --output HG00190_cram.bam --intervals chr17 --input gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --sho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:13860,Performance,Load,Loading,13860,"826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai \; > -O HG00190_cram.bam \; > ; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai -O HG00190_cram.bam; 14:59:57.284 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:59:57 PM EDT] PrintReads --output HG00190_cram.bam --input gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --clo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:17203,Performance,Load,Loading,17203,"m \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai -O HG00190_cram.bam -L chr17; 15:00:08.140 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 3:00:08 PM EDT] PrintReads --output HG00190_cram.bam --intervals chr17 --input gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:21367,Performance,Load,Loading,21367,".exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai -O HG00190_cram.bam -L chr17; 15:00:28.170 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 3:00:28 PM EDT] PrintReads --output HG00190_cram.bam --intervals chr17 --input gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:39,Security,access,accessing,39,"For a PrintReads command that requires accessing the index, e.g. when specifying `-L` intervals, running locally works but running on `gs://` CRAM fails even if index is explicitly specified. ## Local run (server); A command that accesses a local CRAM runs fine. ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam \; -L chr17; ...; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam -L chr17; 14:52:10.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:52:10 PM EDT] PrintReads --output /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam --intervals chr17 --input /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/issues/3669:230,Security,access,accesses,230,"For a PrintReads command that requires accessing the index, e.g. when specifying `-L` intervals, running locally works but running on `gs://` CRAM fails even if index is explicitly specified. ## Local run (server); A command that accesses a local CRAM runs fine. ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam \; -L chr17; ...; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam -L chr17; 14:52:10.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:52:10 PM EDT] PrintReads --output /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam --intervals chr17 --input /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669
https://github.com/broadinstitute/gatk/pull/3671:25,Availability,error,error,25,"This PR fixes a critical error that was causing an ""invalid interval"" exception to be thrown while calling imprecise deletion intervals. The problem was a mismatch between the sequence dictionary in the reference and the read metadata's contig ID - contig name mapping. I've modified the code to always use the read metadata when translating the contig ID in `EvidenceTargetLink` intervals into contig names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3671
https://github.com/broadinstitute/gatk/issues/3672:112,Testability,test,tests,112,"Yossi noticed that the result alleles in some of the `AlleleSubsettingUtilsUnitTest.makeUpdatePLsSACsAndADData` tests seem to be incorrect given the PLs and names. https://github.com/broadinstitute/gatk/blob/e919f85b1b9c34a1239c4a3e87db4e1678e58aaf/src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java#L151-L156. After further inspection it looks like the input alleles for the genotypes may also be incorrect. The named pls in the input describe a het-C, but the genotype is given as AA. The output is AA when it seems like it should be AC. . We should figure out if there's something wrong here, or if I'm just misunderstanding something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3672
https://github.com/broadinstitute/gatk/issues/3672:253,Testability,test,test,253,"Yossi noticed that the result alleles in some of the `AlleleSubsettingUtilsUnitTest.makeUpdatePLsSACsAndADData` tests seem to be incorrect given the PLs and names. https://github.com/broadinstitute/gatk/blob/e919f85b1b9c34a1239c4a3e87db4e1678e58aaf/src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java#L151-L156. After further inspection it looks like the input alleles for the genotypes may also be incorrect. The named pls in the input describe a het-C, but the genotype is given as AA. The output is AA when it seems like it should be AC. . We should figure out if there's something wrong here, or if I'm just misunderstanding something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3672
https://github.com/broadinstitute/gatk/issues/3677:175,Usability,Simpl,SimpleVCFHeaderLine,175,Currently GenomicsDB's `GenomicsDBImporter.generateVidMapFromMergedHeader` only includes specific subclasses of `VCFHeaderLine`. It's missing support for `VCFHeaderLine` and `SimpleVCFHeaderLine`. These header lines should be handled and propagated to the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3677
https://github.com/broadinstitute/gatk/issues/3678:1192,Performance,load,loadNextIterator,1192,"ate with an issue with the LocusWalker implementation or elsewhere in the engine:. Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.grow(ArrayList.java:261); at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235); at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227); at java.util.ArrayList.addAll(ArrayList.java:579); at htsjdk.samtools.BAMFileSpan.merge(BAMFileSpan.java:307); at htsjdk.samtools.BAMFileReader.getFileSpan(BAMFileReader.java:903); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:915); at htsjdk.samtools.BAMFileReader.query(BAMFileReader.java:575); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:528); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:400); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:125); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:66); at org.broadinstitute.hellbender.engine.ReadsDataSource.prepareIteratorsForTraversal(ReadsDataSource.java:404); at org.broadinstitute.hellbender.engine.ReadsDataSource.iterator(ReadsDataSource.java:330); at java.lang.Iterable.spliterator(Iterable.java:101); at org.broadinstitute.hellbender.utils.Utils.stream(Utils.java:1055); at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:254); at org.broadinstitute.hellbender.engine.LocusWalker.traverse(LocusWalker.java:157); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLinePr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3678
https://github.com/broadinstitute/gatk/issues/3679:19,Availability,error,error,19,"I've run into this error in the past as well. As far as I can tell, the SparkGenomeReadCounts code is not trying to do anything too funky, so I wonder if this could be a more general htsjdk/engine issue. But I could be wrong. @droazen could you assign someone to help me look into it? Thanks!. org.apache.spark.SparkException: Job aborted due to stage failure: Task 137 in stage 0.0 failed 1 times, most recent failure: Lost task 137.0 in stage 0.0 (TID 137, localhost): java.lang.IllegalArgumentException: Reference name for '858929714' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setReferenceIndex(SAMRecord.java:422); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:87); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.<init>(BAMFileReader.java:1003); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:944); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:174); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:352,Availability,failure,failure,352,"I've run into this error in the past as well. As far as I can tell, the SparkGenomeReadCounts code is not trying to do anything too funky, so I wonder if this could be a more general htsjdk/engine issue. But I could be wrong. @droazen could you assign someone to help me look into it? Thanks!. org.apache.spark.SparkException: Job aborted due to stage failure: Task 137 in stage 0.0 failed 1 times, most recent failure: Lost task 137.0 in stage 0.0 (TID 137, localhost): java.lang.IllegalArgumentException: Reference name for '858929714' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setReferenceIndex(SAMRecord.java:422); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:87); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.<init>(BAMFileReader.java:1003); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:944); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:174); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:411,Availability,failure,failure,411,"I've run into this error in the past as well. As far as I can tell, the SparkGenomeReadCounts code is not trying to do anything too funky, so I wonder if this could be a more general htsjdk/engine issue. But I could be wrong. @droazen could you assign someone to help me look into it? Thanks!. org.apache.spark.SparkException: Job aborted due to stage failure: Task 137 in stage 0.0 failed 1 times, most recent failure: Lost task 137.0 in stage 0.0 (TID 137, localhost): java.lang.IllegalArgumentException: Reference name for '858929714' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setReferenceIndex(SAMRecord.java:422); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:87); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.<init>(BAMFileReader.java:1003); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:944); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:174); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:3811,Energy Efficiency,schedul,scheduler,3811,park.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:3890,Energy Efficiency,schedul,scheduler,3890,rk.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:3969,Energy Efficiency,schedul,scheduler,3969,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4328,Energy Efficiency,schedul,scheduler,4328,la:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4368,Energy Efficiency,schedul,scheduler,4368,); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4466,Energy Efficiency,schedul,scheduler,4466, at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4563,Energy Efficiency,schedul,scheduler,4563,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4814,Energy Efficiency,schedul,scheduler,4814,r.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4894,Energy Efficiency,schedul,scheduler,4894,.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4999,Energy Efficiency,schedul,scheduler,4999,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:5147,Energy Efficiency,schedul,scheduler,5147,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:5235,Energy Efficiency,schedul,scheduler,5235,617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:5332,Energy Efficiency,schedul,scheduler,5332,.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:5427,Energy Efficiency,schedul,scheduler,5427,.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunction,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:5590,Energy Efficiency,schedul,scheduler,5590,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:11642,Energy Efficiency,schedul,scheduler,11642,park.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-Collec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:11721,Energy Efficiency,schedul,scheduler,11721,rk.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:11800,Energy Efficiency,schedul,scheduler,11800,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta \; --binLength 250 \; --keepXYMT false \; --disableToolDefaul,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4091,Performance,concurren,concurrent,4091,rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Opti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4175,Performance,concurren,concurrent,4175,(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:11922,Performance,concurren,concurrent,11922,rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta \; --binLength 250 \; --keepXYMT false \; --disableToolDefaultReadFilters false \; --disableSequenceDictionaryValidation true \; --disableReadFilter NotDuplicateReadFilter \; --output ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:12006,Performance,concurren,concurrent,12006,:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta \; --binLength 250 \; --keepXYMT false \; --disableToolDefaultReadFilters false \; --disableSequenceDictionaryValidation true \; --disableReadFilter NotDuplicateReadFilter \; --output HCC1143_BL.readCounts.tsv \; --writeHdf5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:331,Safety,abort,aborted,331,"I've run into this error in the past as well. As far as I can tell, the SparkGenomeReadCounts code is not trying to do anything too funky, so I wonder if this could be a more general htsjdk/engine issue. But I could be wrong. @droazen could you assign someone to help me look into it? Thanks!. org.apache.spark.SparkException: Job aborted due to stage failure: Task 137 in stage 0.0 failed 1 times, most recent failure: Lost task 137.0 in stage 0.0 (TID 137, localhost): java.lang.IllegalArgumentException: Reference name for '858929714' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setReferenceIndex(SAMRecord.java:422); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:87); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.<init>(BAMFileReader.java:1003); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:944); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:174); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4498,Safety,abort,abortStage,4498,dd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4595,Safety,abort,abortStage,4595,); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/issues/3679:4837,Safety,abort,abortStage,4837,leMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679
https://github.com/broadinstitute/gatk/pull/3680:53,Testability,test,tests,53,- Unclear what is its purpose.; - added and modified tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680
https://github.com/broadinstitute/gatk/issues/3686:10831,Availability,failure,failures,10831,".1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Bl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:18882,Availability,ERROR,ERROR,18882,r id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:24681,Availability,ERROR,ERROR,24681,"cheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28431,Availability,ERROR,ERROR,28431," id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:29151,Availability,failure,failure,29151,"a:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:29208,Availability,failure,failure,29208,"ker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30997,Availability,down,down,30997,"ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31105,Availability,down,down,31105,"er.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31739,Availability,down,down,31739,"9238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31980,Availability,failure,failure,31980,"edulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:32037,Availability,failure,failure,32037,"38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38371,Availability,down,down,38371,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38555,Availability,down,down,38555,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:2963,Deployability,patch,patch,2963," false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 11, 2017 2:19:10 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: 4.beta.5-70-gdc3237e-SNAPSHOT; 14:19:10.289 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:10468,Deployability,Configurat,Configuration,10468,"ck broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31828,Deployability,pipeline,pipelines,31828,"9:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:36810,Deployability,pipeline,pipelines,36810,rk.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:985); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:985); 	at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:800); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.saveAsShardedHadoopFiles(ReadsSparkSink.java:203); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:37916,Deployability,deploy,deploy,37916,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:37953,Deployability,deploy,deploy,37953,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38026,Deployability,deploy,deploy,38026,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38103,Deployability,deploy,deploy,38103,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38175,Deployability,deploy,deploy,38175,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:38245,Deployability,deploy,deploy,38245,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:5454,Energy Efficiency,allocate,allocate,5454,"yStore: MemoryStore started with capacity 530.0 MB; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/11 14:19:11 INFO ui.SparkUI: Started SparkUI at http://10.131.101.159:4040; 17/10/11 14:19:11 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:43567/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507702751615; 17/10/11 14:19:11 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/11 14:19:11 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 17/10/11 14:19:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Clie",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:9009,Energy Efficiency,schedul,scheduler,9009," N/A; 	 ApplicationMaster host: 10.131.101.159; 	 ApplicationMaster RPC port: 0; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: Application application_1507683879816_0006 has started running.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/applicationHistory/application_1507683879816_0006; 17/10/11 14:19:17 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/11 14:19:17 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Bl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:9312,Energy Efficiency,Schedul,SchedulerBackend,9312,"ng.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/applicationHistory/application_1507683879816_0006; 17/10/11 14:19:17 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/11 14:19:17 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:9342,Energy Efficiency,schedul,scheduling,9342,"ng.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/applicationHistory/application_1507683879816_0006; 17/10/11 14:19:17 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/11 14:19:17 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11059,Energy Efficiency,schedul,scheduler,11059,"imated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11160,Energy Efficiency,schedul,scheduler,11160," in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11295,Energy Efficiency,schedul,scheduler,11295,"e0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11422,Energy Efficiency,schedul,scheduler,11422,"adcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11518,Energy Efficiency,schedul,scheduler,11518,"n.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:11607,Energy Efficiency,schedul,scheduler,11607,"at.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/11 14:19:19 INFO spark.Ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:12283,Energy Efficiency,schedul,scheduler,12283,"; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/11 14:19:19 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/11 14:19:23 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35572) with ID 1; 17/10/11 14:19:23 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:12940,Energy Efficiency,schedul,scheduler,12940," INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/11 14:19:19 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/11 14:19:23 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35572) with ID 1; 17/10/11 14:19:23 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:13492,Energy Efficiency,schedul,scheduler,13492,"FO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/11 14:19:19 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/11 14:19:23 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35572) with ID 1; 17/10/11 14:19:23 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:13730,Energy Efficiency,schedul,scheduler,13730,"3 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35572) with ID 1; 17/10/11 14:19:23 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:13851,Energy Efficiency,schedul,scheduler,13851,".ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:13933,Energy Efficiency,schedul,scheduler,13933,"w total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:13996,Energy Efficiency,schedul,scheduler,13996," task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partiti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:14072,Energy Efficiency,schedul,scheduler,14072,"AL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:14134,Energy Efficiency,schedul,scheduler,14134,"point: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetMa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:14812,Energy Efficiency,schedul,scheduler,14812,"va:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:38568 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35572; 17/10/11 14:19:27 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 134 bytes; 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:15094,Energy Efficiency,schedul,scheduler,15094,"er.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:38568 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35572; 17/10/11 14:19:27 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 134 bytes; 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:15599,Energy Efficiency,schedul,scheduler,15599,"19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:38568 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35572; 17/10/11 14:19:27 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 134 bytes; 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:16634,Energy Efficiency,schedul,scheduler,16634,"in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in remov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:16706,Energy Efficiency,schedul,scheduler,16706,"rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSched",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:17052,Energy Efficiency,schedul,scheduler,17052,"dd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:17278,Energy Efficiency,schedul,scheduler,17278,"ionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(Defa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:20098,Energy Efficiency,schedul,scheduler,20098," id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2, com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:21960,Energy Efficiency,schedul,scheduler,21960,"uncher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 1); 17/10/11 14:19:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:46254 with 530.0 MB RAM, BlockManagerId(2, com2, 46254); 17/10/11 14:19:36 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:46254 (size: 32.3 KB, free: 530.0 MB); 17/10/11 14:19:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35590; 17/10/11 14:19:37 WARN scheduler.TaskSetManager: Lost task 0.2 in stage 1.0 (TID 3, com2, executor 2): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:22611,Energy Efficiency,schedul,scheduler,22611,"Master: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 1); 17/10/11 14:19:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:46254 with 530.0 MB RAM, BlockManagerId(2, com2, 46254); 17/10/11 14:19:36 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:46254 (size: 32.3 KB, free: 530.0 MB); 17/10/11 14:19:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35590; 17/10/11 14:19:37 WARN scheduler.TaskSetManager: Lost task 0.2 in stage 1.0 (TID 3, com2, executor 2): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:23647,Energy Efficiency,schedul,scheduler,23647,"n stage 1.0 (TID 3, com2, executor 2): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in remov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:23719,Energy Efficiency,schedul,scheduler,23719,"g.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:24065,Energy Efficiency,schedul,scheduler,24065,"dd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:24291,Energy Efficiency,schedul,scheduler,24291,"ionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(Default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:27111,Energy Efficiency,schedul,scheduler,27111," id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN scheduler.TaskSetManager: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28437,Energy Efficiency,schedul,scheduler,28437," id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:29010,Energy Efficiency,schedul,scheduler,29010,".hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30647,Energy Efficiency,schedul,scheduler,30647," exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30913,Energy Efficiency,monitor,monitor,30913,"utor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=98618",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31515,Energy Efficiency,schedul,scheduler,31515,"code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runComma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33363,Energy Efficiency,schedul,scheduler,33363,006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33403,Energy Efficiency,schedul,scheduler,33403,n exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33502,Energy Efficiency,schedul,scheduler,33502,t org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33600,Energy Efficiency,schedul,scheduler,33600,xecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33854,Energy Efficiency,schedul,scheduler,33854,inerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33935,Energy Efficiency,schedul,scheduler,33935,ger.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$an,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34041,Energy Efficiency,schedul,scheduler,34041,Task.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.Pair,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34191,Energy Efficiency,schedul,scheduler,34191,r.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34280,Energy Efficiency,schedul,scheduler,34280,exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34378,Energy Efficiency,schedul,scheduler,34378,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScop,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34474,Energy Efficiency,schedul,scheduler,34474,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); 	at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:34639,Energy Efficiency,schedul,scheduler,34639,.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:1261,Modifiability,variab,variables,1261,"Running:; spark-submit --master yarn-client --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_2.bam --sparkMaster yarn-client; 14:19:09.870 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:19:10.155 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 11, 2017 2:19:10 PM CST] PrintReadsSpark --output /gatk4/output_2.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 11, 2017 2:19:10 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:1387,Modifiability,config,configured,1387,"Running:; spark-submit --master yarn-client --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_2.bam --sparkMaster yarn-client; 14:19:09.870 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:19:10.155 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 11, 2017 2:19:10 PM CST] PrintReadsSpark --output /gatk4/output_2.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 11, 2017 2:19:10 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:10468,Modifiability,Config,Configuration,10468,"ck broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:1448,Performance,Load,Loading,1448,"onf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_2.bam --sparkMaster yarn-client; 14:19:09.870 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:19:10.155 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 11, 2017 2:19:10 PM CST] PrintReadsSpark --output /gatk4/output_2.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 11, 2017 2:19:10 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: 4.beta.5-70-gdc3237e-SNAPSHOT; 14:19:10.289 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:19:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6898,Performance,queue,queue,6898," 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> mg, PROXY_URI_BASES -> http://mg:8088/proxy/application_1507683879816_0006), /proxy/application_1507683879816_0006; 17/10/11 14:19:15 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter; 17/10/11 14:19:16 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:17 INFO yarn.Client: Applicatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:8063,Performance,queue,queue,8063," user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> mg, PROXY_URI_BASES -> http://mg:8088/proxy/application_1507683879816_0006), /proxy/application_1507683879816_0006; 17/10/11 14:19:15 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter; 17/10/11 14:19:16 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:17 INFO yarn.Client: Application report for application_1507683879816_0006 (state: RUNNING); 17/10/11 14:19:17 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: 10.131.101.159; 	 ApplicationMaster RPC port: 0; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: Application application_1507683879816_0006 has started running.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:16830,Performance,concurren,concurrent,16830,"/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:16915,Performance,concurren,concurrent,16915,"ke.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_0000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:18556,Performance,concurren,concurrent,18556,0/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:18618,Performance,concurren,concurrent,18618,ssfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:18703,Performance,concurren,concurrent,18703,hedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.Con,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:19767,Performance,concurren,concurrent,19767,"; 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2, com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:19829,Performance,concurren,concurrent,19829,"with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2, com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:21",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:19914,Performance,concurren,concurrent,19914,"cutor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2, com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.Container",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:21092,Performance,concurren,concurrent,21092," scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2, com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:21154,Performance,concurren,concurrent,21154,"com2, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35 INFO spark.ExecutorAllocationManager: New executor 2 has regi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:21239,Performance,concurren,concurrent,21239,"g tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 1); 17/10/11 14:19:35 INFO storage.BlockManagerMasterEndpoint: R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:23843,Performance,concurren,concurrent,23843,"/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:23928,Performance,concurren,concurrent,23928,"ke.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:25566,Performance,concurren,concurrent,25566,7/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:25628,Performance,concurren,concurrent,25628,ccessfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:25713,Performance,concurren,concurrent,25713,cutor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:26780,Performance,concurren,concurrent,26780,"at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN scheduler.TaskSetManager: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:26842,Performance,concurren,concurrent,26842,"h a non-zero exit code 50. 17/10/11 14:19:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN scheduler.TaskSetManager: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:21",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:26927,Performance,concurren,concurrent,26927,"hedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 WARN scheduler.TaskSetManager: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.Container",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28105,Performance,concurren,concurrent,28105," scheduler.TaskSetManager: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28167,Performance,concurren,concurrent,28167,"com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in sta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28252,Performance,concurren,concurrent,28252,"g tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30185,Performance,concurren,concurrent,30185,"imes, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30247,Performance,concurren,concurrent,30247,"com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:30332,Performance,concurren,concurrent,30332,"g tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33014,Performance,concurren,concurrent,33014,"imes, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33076,Performance,concurren,concurrent,33076,"com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33161,Performance,concurren,concurrent,33161,g tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:28499,Safety,abort,aborting,28499,"ception exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:29130,Safety,abort,aborted,29130,"a:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31959,Safety,abort,aborted,31959,"edulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33534,Safety,abort,abortStage,33534,il.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33632,Safety,abort,abortStage,33632,java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:33877,Safety,abort,abortStage,33877,apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:3303,Security,Secur,SecurityManager,3303,5-70-gdc3237e-SNAPSHOT; 14:19:10.289 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:3378,Security,Secur,SecurityManager,3378,COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/bloc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:3455,Security,Secur,SecurityManager,3455, PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-3fe99005-cdde-437f-9ca5-cdc7b1b9c057; 17/10/11 14:19:11 INFO storage.MemoryStore: MemoryStore started with capacity 530.0 MB; 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:3472,Security,Secur,SecurityManager,3472, PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-3fe99005-cdde-437f-9ca5-cdc7b1b9c057; 17/10/11 14:19:11 INFO storage.MemoryStore: MemoryStore started with capacity 530.0 MB; 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:3489,Security,authenticat,authentication,3489, PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-3fe99005-cdde-437f-9ca5-cdc7b1b9c057; 17/10/11 14:19:11 INFO storage.MemoryStore: MemoryStore started with capacity 530.0 MB; 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6153,Security,Secur,SecurityManager,6153,"questing a new application from cluster with 2 NodeManagers; 17/10/11 14:19:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6228,Security,Secur,SecurityManager,6228,"12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster reg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6305,Security,Secur,SecurityManager,6305,"er container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6322,Security,Secur,SecurityManager,6322,"er container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:6339,Security,authenticat,authentication,6339,"er container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:12,Testability,test,test,12,"Hi,; when I test the gatk4 command, I encountered some issues, how can I fix it ? . bash-4.2$ ./gatk-launch PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_2.bam -- --sparkRunner SPARK --sparkMaster yarn-client; Using GATK jar /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar; Running:; spark-submit --master yarn-client --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_2.bam --sparkMaster yarn-client; 14:19:09.870 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:19:10.155 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 11, 2017 2:19:10 PM CST] PrintReadsSpark --output /gatk4/output_2.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:9041,Testability,Log,Logging,9041,"rt time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: Application application_1507683879816_0006 has started running.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/applicationHistory/application_1507683879816_0006; 17/10/11 14:19:17 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/11 14:19:17 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO stora",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3686:31337,Usability,clear,cleared,31337,"hreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686
https://github.com/broadinstitute/gatk/issues/3687:50,Deployability,configurat,configuration,50,"Despite that spark supports equals signs in their configuration values the current code in this class does not as it splits the name=value string in all ""="" present resulting in an bad-argument value exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3687
https://github.com/broadinstitute/gatk/issues/3687:50,Modifiability,config,configuration,50,"Despite that spark supports equals signs in their configuration values the current code in this class does not as it splits the name=value string in all ""="" present resulting in an bad-argument value exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3687
https://github.com/broadinstitute/gatk/issues/3688:33,Deployability,pipeline,pipeline,33,"In order for the variant calling pipeline to be able to scale to process the 68K genomes in the next version of gnomAD and beyond, we need to limit the amount of genotype data we localize. For the filtering portion of the pipeline we could greatly improve performance using a ""sites-only"" query from GenomicsDB. The result could be in BCF format (as I believe it is now) and should include the first 8 fields of the VCF line (CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO) but should not return format-level/genotype data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688
https://github.com/broadinstitute/gatk/issues/3688:222,Deployability,pipeline,pipeline,222,"In order for the variant calling pipeline to be able to scale to process the 68K genomes in the next version of gnomAD and beyond, we need to limit the amount of genotype data we localize. For the filtering portion of the pipeline we could greatly improve performance using a ""sites-only"" query from GenomicsDB. The result could be in BCF format (as I believe it is now) and should include the first 8 fields of the VCF line (CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO) but should not return format-level/genotype data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688
https://github.com/broadinstitute/gatk/issues/3688:256,Performance,perform,performance,256,"In order for the variant calling pipeline to be able to scale to process the 68K genomes in the next version of gnomAD and beyond, we need to limit the amount of genotype data we localize. For the filtering portion of the pipeline we could greatly improve performance using a ""sites-only"" query from GenomicsDB. The result could be in BCF format (as I believe it is now) and should include the first 8 fields of the VCF line (CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO) but should not return format-level/genotype data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688
https://github.com/broadinstitute/gatk/pull/3691:302,Deployability,Update,Updated,302,"* Added new option --unfilteredBreakpointEvidenceDir; When set, this option dumps all evidence (even evidence that is; ultimately rejected) in an easy to parse text format. Some additional; info (cigarString, mappingQuality) is stored in ReadEvidence to output; information related to read quality.; * Updated option --readMetadata; When set, will additionaly output the map from contig number to contig; name. Added non-null ParitionBounds to readMetadata in; ReadMetadataTest::testEverything to prevent crash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3691
https://github.com/broadinstitute/gatk/pull/3691:479,Testability,test,testEverything,479,"* Added new option --unfilteredBreakpointEvidenceDir; When set, this option dumps all evidence (even evidence that is; ultimately rejected) in an easy to parse text format. Some additional; info (cigarString, mappingQuality) is stored in ReadEvidence to output; information related to read quality.; * Updated option --readMetadata; When set, will additionaly output the map from contig number to contig; name. Added non-null ParitionBounds to readMetadata in; ReadMetadataTest::testEverything to prevent crash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3691
https://github.com/broadinstitute/gatk/issues/3692:74,Integrability,depend,dependencies,74,The Python scripts called by the PythonScriptExecutor will require python dependencies which can be managed within a conda environment. Is there a way to load the appropriate conda environment from GATK so that users and unit tests can run the PythonScriptExecutor without worrying about wrangling python libraries. @samuelklee @mbabadi @cmnbroad Any ideas?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692
https://github.com/broadinstitute/gatk/issues/3692:154,Performance,load,load,154,The Python scripts called by the PythonScriptExecutor will require python dependencies which can be managed within a conda environment. Is there a way to load the appropriate conda environment from GATK so that users and unit tests can run the PythonScriptExecutor without worrying about wrangling python libraries. @samuelklee @mbabadi @cmnbroad Any ideas?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692
https://github.com/broadinstitute/gatk/issues/3692:226,Testability,test,tests,226,The Python scripts called by the PythonScriptExecutor will require python dependencies which can be managed within a conda environment. Is there a way to load the appropriate conda environment from GATK so that users and unit tests can run the PythonScriptExecutor without worrying about wrangling python libraries. @samuelklee @mbabadi @cmnbroad Any ideas?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692
https://github.com/broadinstitute/gatk/pull/3693:321,Deployability,pipeline,pipeline,321,"Adding an R dependency for a package that improves performance and memory usage for reading large TSV files. This is convenient for generating CNV plots from WGS data. Note: The current CNV plotting code has other issues that make it unsuitable for WGS data; these are addressed in the sl_wgs_acnv dev branch for the new pipeline by new versions of the plotting tools. However, I do not plan on making these fixes to the old versions of the plotting tools. The real purpose of this PR is just to get the additional R dependency merged into master so I can build a new docker for the dev branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3693
https://github.com/broadinstitute/gatk/pull/3693:12,Integrability,depend,dependency,12,"Adding an R dependency for a package that improves performance and memory usage for reading large TSV files. This is convenient for generating CNV plots from WGS data. Note: The current CNV plotting code has other issues that make it unsuitable for WGS data; these are addressed in the sl_wgs_acnv dev branch for the new pipeline by new versions of the plotting tools. However, I do not plan on making these fixes to the old versions of the plotting tools. The real purpose of this PR is just to get the additional R dependency merged into master so I can build a new docker for the dev branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3693
https://github.com/broadinstitute/gatk/pull/3693:517,Integrability,depend,dependency,517,"Adding an R dependency for a package that improves performance and memory usage for reading large TSV files. This is convenient for generating CNV plots from WGS data. Note: The current CNV plotting code has other issues that make it unsuitable for WGS data; these are addressed in the sl_wgs_acnv dev branch for the new pipeline by new versions of the plotting tools. However, I do not plan on making these fixes to the old versions of the plotting tools. The real purpose of this PR is just to get the additional R dependency merged into master so I can build a new docker for the dev branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3693
https://github.com/broadinstitute/gatk/pull/3693:51,Performance,perform,performance,51,"Adding an R dependency for a package that improves performance and memory usage for reading large TSV files. This is convenient for generating CNV plots from WGS data. Note: The current CNV plotting code has other issues that make it unsuitable for WGS data; these are addressed in the sl_wgs_acnv dev branch for the new pipeline by new versions of the plotting tools. However, I do not plan on making these fixes to the old versions of the plotting tools. The real purpose of this PR is just to get the additional R dependency merged into master so I can build a new docker for the dev branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3693
https://github.com/broadinstitute/gatk/pull/3695:77,Availability,redundant,redundant,77,"Remove the code in `org.broadinstitute.hellbender.utils.gene`, because it is redundant with the code in Picard `picard.annotation`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3695
https://github.com/broadinstitute/gatk/pull/3695:77,Safety,redund,redundant,77,"Remove the code in `org.broadinstitute.hellbender.utils.gene`, because it is redundant with the code in Picard `picard.annotation`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3695
https://github.com/broadinstitute/gatk/pull/3696:132,Testability,test,testing,132,"Example tools are not documented features, and are provided for being examples for developers to build their own traversals and for testing purposes. Thus, it is unnecessary to show them in the command line help, which already contains a huge list of tools (GATK, Picard, etc). Although they can still be run from the command line if you know its existence, they won't be shown after #3486.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3696
https://github.com/broadinstitute/gatk/issues/3697:151,Integrability,depend,depending,151,"## Bug Report. ### Affected tool(s); HaplotypeCaller. ### Affected version(s); GATK4.beta5. ### Description ; HaplotypeCaller does not make some calls depending on the padding size around the interval of interest. The variant calls should not be dependent on the interval size. For example,with -ip 50, I get 7 variant calls. But with -ip 150, I get only 2 variant calls. It seems to be an issue with the graph assembly (perhaps due to repeat regions), but adding --allowNonUniqueKmersInRef does not help. In the IGV screenshots below, the top is the original BAM file; the second is the bamout with -ip 50; the third is with -ip 100; the fourth is with -ip 150; the fifth is with -ip 200. <img width=""1440"" alt=""screen shot 2017-10-16 at 12 36 32 pm"" src=""https://user-images.githubusercontent.com/6998669/31624559-1c07304a-b271-11e7-8013-fafc13f928de.png"">. Notice the difference in calls between -ip 50 and -ip 150. The call should be made regardless of -ip. . #### Steps to reproduce; Files are here:; `/humgen/gsa-scr1/schandra/SkyWarrior_HCMissingCalls/GATK_Bugsubmit_10448_haplotypecaller-missing-snp-calls`. Commands:; `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.vcf`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.50.vcf -ip 50`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.100.vcf -ip 100`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.150.vcf -ip 150`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.200.vcf -ip 200`. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697
https://github.com/broadinstitute/gatk/issues/3697:246,Integrability,depend,dependent,246,"## Bug Report. ### Affected tool(s); HaplotypeCaller. ### Affected version(s); GATK4.beta5. ### Description ; HaplotypeCaller does not make some calls depending on the padding size around the interval of interest. The variant calls should not be dependent on the interval size. For example,with -ip 50, I get 7 variant calls. But with -ip 150, I get only 2 variant calls. It seems to be an issue with the graph assembly (perhaps due to repeat regions), but adding --allowNonUniqueKmersInRef does not help. In the IGV screenshots below, the top is the original BAM file; the second is the bamout with -ip 50; the third is with -ip 100; the fourth is with -ip 150; the fifth is with -ip 200. <img width=""1440"" alt=""screen shot 2017-10-16 at 12 36 32 pm"" src=""https://user-images.githubusercontent.com/6998669/31624559-1c07304a-b271-11e7-8013-fafc13f928de.png"">. Notice the difference in calls between -ip 50 and -ip 150. The call should be made regardless of -ip. . #### Steps to reproduce; Files are here:; `/humgen/gsa-scr1/schandra/SkyWarrior_HCMissingCalls/GATK_Bugsubmit_10448_haplotypecaller-missing-snp-calls`. Commands:; `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.vcf`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.50.vcf -ip 50`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.100.vcf -ip 100`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.150.vcf -ip 150`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.200.vcf -ip 200`. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697
https://github.com/broadinstitute/gatk/issues/3698:225,Energy Efficiency,efficient,efficient,225,"We want tasks such as parsing VCF files to be done in Java, rather than in Python, so that we can leverage all the work we do in htsjdk even in tools that call into a `PythonScriptExecutor`. This implies that we need an easy/efficient means of streaming data in and out of the child Python process. Perhaps a ""popen()""-like approach would be good here (or a named FIFO, or protocol buffers...lots of options).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698
https://github.com/broadinstitute/gatk/issues/3698:373,Integrability,protocol,protocol,373,"We want tasks such as parsing VCF files to be done in Java, rather than in Python, so that we can leverage all the work we do in htsjdk even in tools that call into a `PythonScriptExecutor`. This implies that we need an easy/efficient means of streaming data in and out of the child Python process. Perhaps a ""popen()""-like approach would be good here (or a named FIFO, or protocol buffers...lots of options).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698
https://github.com/broadinstitute/gatk/pull/3702:14,Usability,simpl,simple,14,adding a very simple tool to compare two interval list files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702
https://github.com/broadinstitute/gatk/issues/3703:21,Usability,simpl,simply,21,The MAF reader could simply produce a `VariantContext` or something else that can be iterated through via a `Walker`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3703
https://github.com/broadinstitute/gatk/issues/3708:196,Integrability,depend,dependency,196,"There is an existing NIO filesystem provider for Amazon S3 that has been used successfully with GATK4 by at least one user (with some minor tweaks to the engine). We should add the S3 plugin as a dependency, add basic tests for read support, and make whatever changes are needed to get it working.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708
https://github.com/broadinstitute/gatk/issues/3708:184,Modifiability,plugin,plugin,184,"There is an existing NIO filesystem provider for Amazon S3 that has been used successfully with GATK4 by at least one user (with some minor tweaks to the engine). We should add the S3 plugin as a dependency, add basic tests for read support, and make whatever changes are needed to get it working.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708
https://github.com/broadinstitute/gatk/issues/3708:218,Testability,test,tests,218,"There is an existing NIO filesystem provider for Amazon S3 that has been used successfully with GATK4 by at least one user (with some minor tweaks to the engine). We should add the S3 plugin as a dependency, add basic tests for read support, and make whatever changes are needed to get it working.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708
https://github.com/broadinstitute/gatk/issues/3710:181,Security,access,access,181,"Travis is terminating our cron job because there is too much log output. ; It seems to be thousands of repetitions of:. ```; 21:44:23.077 WARN DefaultDocWorkUnitHandler - Could not access the field definition for backtrace while searching for SHOW_HIDDEN, presumably because the field is inaccessible; ```. Possibly related to our recent inclusion of picard in our doc output?. See: https://travis-ci.org/broadinstitute/gatk/jobs/289240692",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710
https://github.com/broadinstitute/gatk/issues/3710:61,Testability,log,log,61,"Travis is terminating our cron job because there is too much log output. ; It seems to be thousands of repetitions of:. ```; 21:44:23.077 WARN DefaultDocWorkUnitHandler - Could not access the field definition for backtrace while searching for SHOW_HIDDEN, presumably because the field is inaccessible; ```. Possibly related to our recent inclusion of picard in our doc output?. See: https://travis-ci.org/broadinstitute/gatk/jobs/289240692",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710
https://github.com/broadinstitute/gatk/pull/3712:27,Deployability,update,updated,27,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712
https://github.com/broadinstitute/gatk/pull/3712:102,Integrability,depend,dependencies,102,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712
https://github.com/broadinstitute/gatk/pull/3712:153,Testability,test,testing,153,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712
https://github.com/broadinstitute/gatk/pull/3712:128,Usability,simpl,simple,128,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712
https://github.com/broadinstitute/gatk/pull/3713:222,Usability,simpl,simplistic,222,Added command line to do a segment union. Inputs:; - exactly two segment files (arbitrary column headers).; - columns of interest. What it does:; - Attempts to find reasonable headers in the TSVs; - Creates instances of a simplistic object that is composed of a mapping for columns and an interval. Note that the columns making up the interval are not in the map.; - Unions the segments and the columns of interest into a new TSV.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3713
https://github.com/broadinstitute/gatk/issues/3714:318,Modifiability,Plugin,PluginManager,318,"The pedigree-checking warning for the PossibleDeNovo annotation is always output because it happens in the constructor, and in GATK4 all the InfoFieldAnnotations get instantiated. It's a little weird to have this warning even when the annotation is not requested. But if this is the cost we pay for getting rid of the PluginManager I will gladly deal with it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3714
https://github.com/broadinstitute/gatk/pull/3715:209,Integrability,message,messages,209,"This change suppresses about 600k of output from the gatkTabComplete task, which should fix #3710 and allow the nightly cron job to complete. Note that this doesn't actually suppress the excessive ""backtrace"" messages we're seeing with the addition of Picard tools when running javadoc using openjdk (see the note in #3710), which we'll need to do separately in Barclay. To test this change, I added a temporary travis matrix entry that runs the target that is causing the cron job to fail (./gradlew bundle). That branch [fails](https://travis-ci.org/broadinstitute/gatk/builds/289636845) the same way as the cron job does without this change, and [succeeds](https://travis-ci.org/broadinstitute/gatk/builds/289569595) with it. But that doesn't guaranty that the cron job will succeed, since cron job does other things (like upload). Finally, note that the gatkDoc gradle task was also setting the verbose flag, but it didn't actually result in verbose output due to gradle/gradle#2354, so I removed that call in this PR as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3715
https://github.com/broadinstitute/gatk/pull/3715:374,Testability,test,test,374,"This change suppresses about 600k of output from the gatkTabComplete task, which should fix #3710 and allow the nightly cron job to complete. Note that this doesn't actually suppress the excessive ""backtrace"" messages we're seeing with the addition of Picard tools when running javadoc using openjdk (see the note in #3710), which we'll need to do separately in Barclay. To test this change, I added a temporary travis matrix entry that runs the target that is causing the cron job to fail (./gradlew bundle). That branch [fails](https://travis-ci.org/broadinstitute/gatk/builds/289636845) the same way as the cron job does without this change, and [succeeds](https://travis-ci.org/broadinstitute/gatk/builds/289569595) with it. But that doesn't guaranty that the cron job will succeed, since cron job does other things (like upload). Finally, note that the gatkDoc gradle task was also setting the verbose flag, but it didn't actually result in verbose output due to gradle/gradle#2354, so I removed that call in this PR as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3715
https://github.com/broadinstitute/gatk/pull/3716:210,Deployability,pipeline,pipeline,210,"All of the Locatable collections associated with a sample and backed by a TSV file (e.g., read-count files, copy-ratio files, segment files, allelic-count files) extend SampleLocatableCollection in the new CNV pipeline. SampleRecordCollection is even more generic, in that the records are not required to be Locatables; this will be used to output posterior summaries for modeling results, for example. Eventually we will want to expand the sample metadata to include a sequence dictionary when appropriate. This will be used to define the ordering in SampleLocatableCollection. For now, we keep lexicographical ordering to be consistent with the old read-count collection, but we should switch this over as soon as possible. @asmirnov239 we will fit your new read-count code into this framework when it's in. @droazen would appreciate any thoughts you might have on whether it's worth using the Tribble framework rather than TableReader/TableWriter for this sort of thing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3716
https://github.com/broadinstitute/gatk/pull/3716:162,Modifiability,extend,extend,162,"All of the Locatable collections associated with a sample and backed by a TSV file (e.g., read-count files, copy-ratio files, segment files, allelic-count files) extend SampleLocatableCollection in the new CNV pipeline. SampleRecordCollection is even more generic, in that the records are not required to be Locatables; this will be used to output posterior summaries for modeling results, for example. Eventually we will want to expand the sample metadata to include a sequence dictionary when appropriate. This will be used to define the ordering in SampleLocatableCollection. For now, we keep lexicographical ordering to be consistent with the old read-count collection, but we should switch this over as soon as possible. @asmirnov239 we will fit your new read-count code into this framework when it's in. @droazen would appreciate any thoughts you might have on whether it's worth using the Tribble framework rather than TableReader/TableWriter for this sort of thing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3716
https://github.com/broadinstitute/gatk/issues/3717:171,Availability,error,error,171,Running in local mode on a large GCE instance when using external evidence (it looks like any attempt to use external evidence will trigger this) results in the following error:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Partition boundaries are not coordinate sorted.; 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.readExternalEvidence(FindBreakpointEvidenceSpark.java:309); 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.getMappedQNamesSet(FindBreakpointEvidenceSpark.java:208); 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:111); 	at org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:79); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3717
https://github.com/broadinstitute/gatk/pull/3718:61,Deployability,integrat,integration,61,Port of the GATK3 Version of CombineGVCFs and its associated integration tests. . Fixes #16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3718
https://github.com/broadinstitute/gatk/pull/3718:61,Integrability,integrat,integration,61,Port of the GATK3 Version of CombineGVCFs and its associated integration tests. . Fixes #16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3718
https://github.com/broadinstitute/gatk/pull/3718:73,Testability,test,tests,73,Port of the GATK3 Version of CombineGVCFs and its associated integration tests. . Fixes #16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3718
https://github.com/broadinstitute/gatk/pull/3722:14,Testability,test,test,14,Added several test files from GATK3 and made sweeping bugfixes for the finalizeRawAnnotations() code for many of the reducible annotation classes. . Fixes #3544,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3722
https://github.com/broadinstitute/gatk/issues/3723:26,Availability,failure,failure,26,Fixes memory leaks due to failure to free C side resources when an index is closed.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3723
https://github.com/broadinstitute/gatk/issues/3724:426,Availability,error,error,426,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:441,Availability,ERROR,ERROR,441,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:884,Availability,down,download,884,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:910,Availability,Down,Downloading,910,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:1031,Availability,avail,available,1031,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:380,Deployability,install,install,380,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:860,Deployability,install,install,860,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:93,Integrability,depend,dependency,93,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:210,Integrability,depend,dependency,210,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:336,Integrability,depend,dependency,336,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:512,Integrability,depend,dependencies,512,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:771,Integrability,depend,dependency,771,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:374,Usability,clear,clear,374,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3724:854,Usability,clear,clear,854,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724
https://github.com/broadinstitute/gatk/issues/3725:32,Deployability,release,release,32,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725
https://github.com/broadinstitute/gatk/issues/3725:222,Deployability,release,release,222,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725
https://github.com/broadinstitute/gatk/issues/3725:6,Testability,test,testing,6,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725
https://github.com/broadinstitute/gatk/issues/3725:301,Testability,test,test,301,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725
https://github.com/broadinstitute/gatk/issues/3725:373,Testability,test,testcases,373,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725
https://github.com/broadinstitute/gatk/pull/3726:40,Availability,down,downstream,40,"…group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726
https://github.com/broadinstitute/gatk/pull/3726:283,Security,validat,validating,283,"…group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726
https://github.com/broadinstitute/gatk/pull/3726:599,Testability,test,testing,599,"…group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726
https://github.com/broadinstitute/gatk/pull/3726:653,Testability,test,test,653,"…group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726
https://github.com/broadinstitute/gatk/pull/3729:488,Availability,avail,available,488,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:304,Energy Efficiency,efficient,efficient,304,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:82,Integrability,depend,depends,82,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:471,Integrability,depend,depending,471,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:397,Modifiability,flexible,flexible,397,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:538,Security,validat,validation,538,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/pull/3729:181,Testability,test,tests,181,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729
https://github.com/broadinstitute/gatk/issues/3730:102,Testability,test,testdata,102,"Paraphrasing an email from Chunyang Bao:. > In the Dockerfile Line 18, the source code is “RUN ln -s /testdata src/test/resources”. And, I just want to know whether it should be “RUN ln -s src/test/resources /testdata”. Does it make sense? If I change this link, I can get more results from the test script (/root/run_unit_tests.sh). Will double check this when I get a chance, but perhaps it will be immediately obvious to @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730
https://github.com/broadinstitute/gatk/issues/3730:115,Testability,test,test,115,"Paraphrasing an email from Chunyang Bao:. > In the Dockerfile Line 18, the source code is “RUN ln -s /testdata src/test/resources”. And, I just want to know whether it should be “RUN ln -s src/test/resources /testdata”. Does it make sense? If I change this link, I can get more results from the test script (/root/run_unit_tests.sh). Will double check this when I get a chance, but perhaps it will be immediately obvious to @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730
https://github.com/broadinstitute/gatk/issues/3730:193,Testability,test,test,193,"Paraphrasing an email from Chunyang Bao:. > In the Dockerfile Line 18, the source code is “RUN ln -s /testdata src/test/resources”. And, I just want to know whether it should be “RUN ln -s src/test/resources /testdata”. Does it make sense? If I change this link, I can get more results from the test script (/root/run_unit_tests.sh). Will double check this when I get a chance, but perhaps it will be immediately obvious to @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730
https://github.com/broadinstitute/gatk/issues/3730:209,Testability,test,testdata,209,"Paraphrasing an email from Chunyang Bao:. > In the Dockerfile Line 18, the source code is “RUN ln -s /testdata src/test/resources”. And, I just want to know whether it should be “RUN ln -s src/test/resources /testdata”. Does it make sense? If I change this link, I can get more results from the test script (/root/run_unit_tests.sh). Will double check this when I get a chance, but perhaps it will be immediately obvious to @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730
https://github.com/broadinstitute/gatk/issues/3730:295,Testability,test,test,295,"Paraphrasing an email from Chunyang Bao:. > In the Dockerfile Line 18, the source code is “RUN ln -s /testdata src/test/resources”. And, I just want to know whether it should be “RUN ln -s src/test/resources /testdata”. Does it make sense? If I change this link, I can get more results from the test script (/root/run_unit_tests.sh). Will double check this when I get a chance, but perhaps it will be immediately obvious to @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730
https://github.com/broadinstitute/gatk/issues/3732:603,Deployability,integrat,integration,603,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:603,Integrability,integrat,integration,603,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:25,Testability,test,test,25,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:58,Testability,test,test,58,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:77,Testability,test,tests,77,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:372,Testability,test,tests,372,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:467,Testability,test,tests,467,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3732:784,Testability,test,tests,784,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732
https://github.com/broadinstitute/gatk/issues/3734:161,Availability,error,error,161,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734
https://github.com/broadinstitute/gatk/issues/3734:262,Integrability,message,message,262,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734
https://github.com/broadinstitute/gatk/issues/3734:197,Security,validat,validation,197,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734
https://github.com/broadinstitute/gatk/issues/3735:147,Availability,error,errors,147,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:543,Availability,ERROR,ERROR,543,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:583,Availability,Error,Error,583,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:594,Availability,Failure,Failure,594,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:841,Deployability,pipeline,pipeline,841,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:1103,Performance,concurren,concurrent,1103,"eems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(Com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:2463,Performance,concurren,concurrent,2463,ute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:2823,Performance,concurren,concurrent,2823,; 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.goog,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:2888,Performance,concurren,concurrent,2888,GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:4611,Performance,concurren,concurrent,4611,_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:4673,Performance,concurren,concurrent,4673,pi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:4758,Performance,concurren,concurrent,4758,.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.Abstra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:807,Security,access,access,807,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:1277,Security,access,access,1277,"ools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:2637,Security,access,access,2637,til.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(H,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:3476,Security,access,access,3476,en; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUni,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:5067,Security,access,access,5067,yHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.ser,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:6610,Security,access,access,6610,PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:505); 	... 12 more; ```. This service account does have access to these files because every shard accesses the same files and most of them succeed and when the same task is rerun it does succeed. @snovod should have any other information you may need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3735:6652,Security,access,accesses,6652,PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:505); 	... 12 more; ```. This service account does have access to these files because every shard accesses the same files and most of them succeed and when the same task is rerun it does succeed. @snovod should have any other information you may need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735
https://github.com/broadinstitute/gatk/issues/3736:136,Testability,test,test,136,"Hi all;; I'm running to a segfault issue with GATK4 beta6 when running GenomicsDBImport on some batches. This is a small self contained test case that demonstrates the problem:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_segfault.tar.gz. When running:; ```; gatk-launch --javaOptions '-Xms1g -Xmx2g' GenomicsDBImport --genomicsDBWorkspace fails_genomicsdb -L chr6:130365070-146544250 --variant NA12878.vcf.gz --variant NA24631.vcf.gz --variant NA24385.vcf.gz; ```; It appears to segfault in jniImportBatch:; ```; Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j com.intel.genomicsdb.GenomicsDBImporter.jniImportBatch(J[J)Z+0; j com.intel.genomicsdb.GenomicsDBImporter.importBatch()Z+160; j org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse()V+301; j org.broadinstitute.hellbender.engine.GATKTool.doWork()Ljava/lang/Object;+12; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool()Ljava/lang/Object;+27; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs()Ljava/lang/Object;+431; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain([Ljava/lang/String;)Ljava/lang/Object;+14; j org.broadinstitute.hellbender.Main.runCommandLineProgram(Lorg/broadinstitute/hellbender/cmdline/CommandLineProgram;[Ljava/lang/String;)Ljava/lang/Object;+20; j org.broadinstitute.hellbender.Main.mainEntry([Ljava/lang/String;)V+19; j org.broadinstitute.hellbender.Main.main([Ljava/lang/String;)V+8; v ~StubRoutines::call_stub; ```; The same command works without the NA24385.vcf.gz sample but it wasn't clear what caused the issue from this input. I'm also seeing similar behavior over a few other regions and guess they're all caused by the same underlying issue. Thanks much for any pointers or ideas and please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736
https://github.com/broadinstitute/gatk/issues/3736:212,Testability,test,testcases,212,"Hi all;; I'm running to a segfault issue with GATK4 beta6 when running GenomicsDBImport on some batches. This is a small self contained test case that demonstrates the problem:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_segfault.tar.gz. When running:; ```; gatk-launch --javaOptions '-Xms1g -Xmx2g' GenomicsDBImport --genomicsDBWorkspace fails_genomicsdb -L chr6:130365070-146544250 --variant NA12878.vcf.gz --variant NA24631.vcf.gz --variant NA24385.vcf.gz; ```; It appears to segfault in jniImportBatch:; ```; Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j com.intel.genomicsdb.GenomicsDBImporter.jniImportBatch(J[J)Z+0; j com.intel.genomicsdb.GenomicsDBImporter.importBatch()Z+160; j org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse()V+301; j org.broadinstitute.hellbender.engine.GATKTool.doWork()Ljava/lang/Object;+12; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool()Ljava/lang/Object;+27; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs()Ljava/lang/Object;+431; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain([Ljava/lang/String;)Ljava/lang/Object;+14; j org.broadinstitute.hellbender.Main.runCommandLineProgram(Lorg/broadinstitute/hellbender/cmdline/CommandLineProgram;[Ljava/lang/String;)Ljava/lang/Object;+20; j org.broadinstitute.hellbender.Main.mainEntry([Ljava/lang/String;)V+19; j org.broadinstitute.hellbender.Main.main([Ljava/lang/String;)V+8; v ~StubRoutines::call_stub; ```; The same command works without the NA24385.vcf.gz sample but it wasn't clear what caused the issue from this input. I'm also seeing similar behavior over a few other regions and guess they're all caused by the same underlying issue. Thanks much for any pointers or ideas and please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736
https://github.com/broadinstitute/gatk/issues/3736:1509,Testability,Stub,StubRoutines,1509,"Hi all;; I'm running to a segfault issue with GATK4 beta6 when running GenomicsDBImport on some batches. This is a small self contained test case that demonstrates the problem:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_segfault.tar.gz. When running:; ```; gatk-launch --javaOptions '-Xms1g -Xmx2g' GenomicsDBImport --genomicsDBWorkspace fails_genomicsdb -L chr6:130365070-146544250 --variant NA12878.vcf.gz --variant NA24631.vcf.gz --variant NA24385.vcf.gz; ```; It appears to segfault in jniImportBatch:; ```; Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j com.intel.genomicsdb.GenomicsDBImporter.jniImportBatch(J[J)Z+0; j com.intel.genomicsdb.GenomicsDBImporter.importBatch()Z+160; j org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse()V+301; j org.broadinstitute.hellbender.engine.GATKTool.doWork()Ljava/lang/Object;+12; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool()Ljava/lang/Object;+27; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs()Ljava/lang/Object;+431; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain([Ljava/lang/String;)Ljava/lang/Object;+14; j org.broadinstitute.hellbender.Main.runCommandLineProgram(Lorg/broadinstitute/hellbender/cmdline/CommandLineProgram;[Ljava/lang/String;)Ljava/lang/Object;+20; j org.broadinstitute.hellbender.Main.mainEntry([Ljava/lang/String;)V+19; j org.broadinstitute.hellbender.Main.main([Ljava/lang/String;)V+8; v ~StubRoutines::call_stub; ```; The same command works without the NA24385.vcf.gz sample but it wasn't clear what caused the issue from this input. I'm also seeing similar behavior over a few other regions and guess they're all caused by the same underlying issue. Thanks much for any pointers or ideas and please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736
https://github.com/broadinstitute/gatk/issues/3736:1610,Usability,clear,clear,1610,"Hi all;; I'm running to a segfault issue with GATK4 beta6 when running GenomicsDBImport on some batches. This is a small self contained test case that demonstrates the problem:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_segfault.tar.gz. When running:; ```; gatk-launch --javaOptions '-Xms1g -Xmx2g' GenomicsDBImport --genomicsDBWorkspace fails_genomicsdb -L chr6:130365070-146544250 --variant NA12878.vcf.gz --variant NA24631.vcf.gz --variant NA24385.vcf.gz; ```; It appears to segfault in jniImportBatch:; ```; Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j com.intel.genomicsdb.GenomicsDBImporter.jniImportBatch(J[J)Z+0; j com.intel.genomicsdb.GenomicsDBImporter.importBatch()Z+160; j org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse()V+301; j org.broadinstitute.hellbender.engine.GATKTool.doWork()Ljava/lang/Object;+12; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool()Ljava/lang/Object;+27; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs()Ljava/lang/Object;+431; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain([Ljava/lang/String;)Ljava/lang/Object;+14; j org.broadinstitute.hellbender.Main.runCommandLineProgram(Lorg/broadinstitute/hellbender/cmdline/CommandLineProgram;[Ljava/lang/String;)Ljava/lang/Object;+20; j org.broadinstitute.hellbender.Main.mainEntry([Ljava/lang/String;)V+19; j org.broadinstitute.hellbender.Main.main([Ljava/lang/String;)V+8; v ~StubRoutines::call_stub; ```; The same command works without the NA24385.vcf.gz sample but it wasn't clear what caused the issue from this input. I'm also seeing similar behavior over a few other regions and guess they're all caused by the same underlying issue. Thanks much for any pointers or ideas and please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736
https://github.com/broadinstitute/gatk/issues/3738:84,Usability,Simpl,SimpleAnnotatedGenomicRegion,84,"- Additionally, we should create a LocatableCollection class rather than using List<SimpleAnnotatedGenomicRegion>. We can probably reuse the SimpleAnnotatedGenomicRegion static parsing methods, but these should be moved to a new class.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3738
https://github.com/broadinstitute/gatk/issues/3738:141,Usability,Simpl,SimpleAnnotatedGenomicRegion,141,"- Additionally, we should create a LocatableCollection class rather than using List<SimpleAnnotatedGenomicRegion>. We can probably reuse the SimpleAnnotatedGenomicRegion static parsing methods, but these should be moved to a new class.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3738
https://github.com/broadinstitute/gatk/pull/3739:59,Availability,error,errors,59,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739
https://github.com/broadinstitute/gatk/pull/3739:230,Availability,error,errors,230,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739
https://github.com/broadinstitute/gatk/pull/3739:7,Testability,test,test,7,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739
https://github.com/broadinstitute/gatk/issues/3740:404,Integrability,depend,dependencies,404,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3740:154,Performance,Perform,PerformSegmentationIntegrationTest,154,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3740:5,Testability,test,tests,5,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3740:83,Testability,test,test,83,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3740:373,Testability,test,tests,373,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3740:490,Testability,test,test,490,"Some tests are failing in my local computer due to a missing R package Concretely, test classes with this problem are:. * `AllelicCNVIntegrationTest`; * `PerformSegmentationIntegrationTest`; * `SNPSegmenterUnitTest`; * `PlotACNVResultsIntegrationTest`; * `PlotSegmentedCopyRatioIntegrationTest`; * `HMMUnitTest`; * `SegmenterUnitTest`. Is there any way to skip/ignore this tests when running locally and dependencies are not found, or to pull the R libraries while running `./gradlew clean test`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740
https://github.com/broadinstitute/gatk/issues/3741:121,Performance,cache,cached,121,"This results in the creation of two FeatureReaders (including GenomicsDBFeatureReaders if the input is GenomicsDB), with cached headers, even if the tool never queries the input directly. It looks like the majority of VariantWalkers don't require this; with the two exceptions of CalculateGenotypePosteriors and VariantFiltration. It should be possible to let the tool itself decide if it needs to query the driving variants, either through an overridable method, or by adding VariantWalker subclass.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3741
https://github.com/broadinstitute/gatk/pull/3742:14,Integrability,depend,dependend,14,"previously we dependend on com.github.fommil.netlib:netlib:all which is a pom only dependency that includes a number of jars containing native code. this caused problems when importing GATK using maven, see #3724. to fix this, I've added the exact versions of the transitive dependencies that we want; an added bonus is that it means we are no longer including native code for systems we don't support, like arm, 32 bit systems, and windows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742
https://github.com/broadinstitute/gatk/pull/3742:83,Integrability,depend,dependency,83,"previously we dependend on com.github.fommil.netlib:netlib:all which is a pom only dependency that includes a number of jars containing native code. this caused problems when importing GATK using maven, see #3724. to fix this, I've added the exact versions of the transitive dependencies that we want; an added bonus is that it means we are no longer including native code for systems we don't support, like arm, 32 bit systems, and windows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742
https://github.com/broadinstitute/gatk/pull/3742:275,Integrability,depend,dependencies,275,"previously we dependend on com.github.fommil.netlib:netlib:all which is a pom only dependency that includes a number of jars containing native code. this caused problems when importing GATK using maven, see #3724. to fix this, I've added the exact versions of the transitive dependencies that we want; an added bonus is that it means we are no longer including native code for systems we don't support, like arm, 32 bit systems, and windows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742
https://github.com/broadinstitute/gatk/issues/3744:381,Security,Hash,HashMap,381,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/issues/3744:422,Security,Hash,HashMap,422,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/issues/3744:300,Testability,test,test,300,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/issues/3744:330,Testability,Test,Test,330,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/issues/3744:348,Testability,test,testGetSortedSampleSet,348,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/issues/3744:788,Testability,test,tests,788,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744
https://github.com/broadinstitute/gatk/pull/3746:113,Testability,log,logic,113,"partially cleanup, partially reminiscent of PR series part 5. Broke into 3 commits, with the first two having no logic change and the last with logic changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3746
https://github.com/broadinstitute/gatk/pull/3746:144,Testability,log,logic,144,"partially cleanup, partially reminiscent of PR series part 5. Broke into 3 commits, with the first two having no logic change and the last with logic changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3746
https://github.com/broadinstitute/gatk/pull/3747:193,Performance,load,loading,193,"This adds --activityProfileOut and --assemblyRegionOut arguments to AssemblyRegionWalker,; allowing assembly regions and supporting activity profile data to be output in a format; suitable for loading in IGV. Mirrors functionality present in GATK 3.x. Resolves #2796",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3747
https://github.com/broadinstitute/gatk/pull/3748:220,Availability,error,error,220,"Noticed some compile warnings in the Travis logs, looks like a funky apostrophe is to blame?. :compileJava/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:511: error: unmappable character for encoding ASCII; // if there???s more than 1 DEL allele then we need to use the best one; ^",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3748
https://github.com/broadinstitute/gatk/pull/3748:44,Testability,log,logs,44,"Noticed some compile warnings in the Travis logs, looks like a funky apostrophe is to blame?. :compileJava/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:511: error: unmappable character for encoding ASCII; // if there???s more than 1 DEL allele then we need to use the best one; ^",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3748
https://github.com/broadinstitute/gatk/issues/3749:533,Testability,test,test,533,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:594,Testability,test,tests,594,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:981,Testability,test,test,981,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:1234,Testability,test,test,1234,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:1295,Testability,test,tests,1295,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:1601,Testability,test,test,1601,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/issues/3749:1627,Testability,test,test,1627,"When having a deletion that spans from before a splice site to after a splice site, Funcotator does not properly render Codon Change or Protein Change. For frame shifts, this is because Funcotator determines if a variant is a frame shift by looking at the number of bases inserted / deleted - if that number is evenly divisble by 3 it is in-frame. Deleted bases beyond the splice site should not be counted for frame shift purposes (in fact, the coding transcript should be used to determine frameshift for deletions). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this (hg19):. `new Object[] { ""PIK3CA"", 3, 178948159, 178948167, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTG"", ""T"", ""g.chr3:178948160_178948167delGAGAGGTG"", ""+"", ""c.2932_2936delGAGAGGTG"", ""c.(2932-2937)gagaggfs"", ""p.ER978fs"" }`. Unfortunately Oncotator also gets this wrong, so the ground truth needs to be changed for this test case. =========. For the non-frame shift case, currently Funcotator treats the bases beyond the end of the splice site as an alternate reference string, and the resulting codon change is wrong (and likely the protein change as well). The following test case (defined in DataProviderForPik3caMnpFullData.java) tests this:. `new Object[] { ""PIK3CA"", 3, 178948159, 178948168, GencodeFuncotation.VariantClassification.SPLICE_SITE, GencodeFuncotation.VariantType.DEL, ""TGAGAGGTGA"", ""T"", ""g.chr3:178948160_178948168delGAGAGGTGA"", ""+"", ""c.2932_2936delGAGAGGTGA"", ""c.(2932-2937)gagagg>g"", ""p.ER978del"" }`. In this case the test can be re-enabled to test the fix for this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3749
https://github.com/broadinstitute/gatk/pull/3751:235,Performance,perform,performing,235,"an edge case where ""=="" is to be distinguished from ""<="" or "">="". The reason is that when two quantities are equal, the value to be deduced from their difference is simply zero and an expensive computation could be avoided (the method performing the expensive computation has a check for such optimization opportunity and caught this).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3751
https://github.com/broadinstitute/gatk/pull/3751:293,Performance,optimiz,optimization,293,"an edge case where ""=="" is to be distinguished from ""<="" or "">="". The reason is that when two quantities are equal, the value to be deduced from their difference is simply zero and an expensive computation could be avoided (the method performing the expensive computation has a check for such optimization opportunity and caught this).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3751
https://github.com/broadinstitute/gatk/pull/3751:215,Safety,avoid,avoided,215,"an edge case where ""=="" is to be distinguished from ""<="" or "">="". The reason is that when two quantities are equal, the value to be deduced from their difference is simply zero and an expensive computation could be avoided (the method performing the expensive computation has a check for such optimization opportunity and caught this).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3751
https://github.com/broadinstitute/gatk/pull/3751:165,Usability,simpl,simply,165,"an edge case where ""=="" is to be distinguished from ""<="" or "">="". The reason is that when two quantities are equal, the value to be deduced from their difference is simply zero and an expensive computation could be avoided (the method performing the expensive computation has a check for such optimization opportunity and caught this).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3751
https://github.com/broadinstitute/gatk/pull/3752:60,Deployability,update,updated,60,"As more and more branches are cleaned up, trunk needs to be updated. This reflects updates to the tree described in #2703",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3752
https://github.com/broadinstitute/gatk/pull/3752:83,Deployability,update,updates,83,"As more and more branches are cleaned up, trunk needs to be updated. This reflects updates to the tree described in #2703",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3752
https://github.com/broadinstitute/gatk/pull/3755:38,Security,validat,validation,38,"This is an implementation of a pileup validation tool. Additionally, some testing utilities for creating reads with variants have been added.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755
https://github.com/broadinstitute/gatk/pull/3755:74,Testability,test,testing,74,"This is an implementation of a pileup validation tool. Additionally, some testing utilities for creating reads with variants have been added.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755
https://github.com/broadinstitute/gatk/issues/3756:59,Integrability,interface,interface,59,We need a file reader that is based on the `java.nio.path` interface that can read lines from a `Path` object. This should wrap `files.lines` and return an `Iterator<String>`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3756
https://github.com/broadinstitute/gatk/issues/3756:123,Integrability,wrap,wrap,123,We need a file reader that is based on the `java.nio.path` interface that can read lines from a `Path` object. This should wrap `files.lines` and return an `Iterator<String>`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3756
https://github.com/broadinstitute/gatk/issues/3757:146,Usability,simpl,simple,146,We need a parser that can read in non-Locatable files. These files will be *sv formatted (e.g. tsv / csv / etc.). This should be based off of the simple `Path` reader in #3756,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3757
https://github.com/broadinstitute/gatk/issues/3759:31,Performance,perform,perform,31,"There are several methods that perform the `String.split` operation in the GATK, two of which claim to be faster than the base Java's `String.split`. Make a unit test to compare the performance of the baseline Java `String.split`, HTSJDK's `ParsingUtils::split` and GATK3's `Utils::split`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3759
https://github.com/broadinstitute/gatk/issues/3759:182,Performance,perform,performance,182,"There are several methods that perform the `String.split` operation in the GATK, two of which claim to be faster than the base Java's `String.split`. Make a unit test to compare the performance of the baseline Java `String.split`, HTSJDK's `ParsingUtils::split` and GATK3's `Utils::split`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3759
https://github.com/broadinstitute/gatk/issues/3759:162,Testability,test,test,162,"There are several methods that perform the `String.split` operation in the GATK, two of which claim to be faster than the base Java's `String.split`. Make a unit test to compare the performance of the baseline Java `String.split`, HTSJDK's `ParsingUtils::split` and GATK3's `Utils::split`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3759
https://github.com/broadinstitute/gatk/issues/3760:307,Deployability,update,updated,307,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760
https://github.com/broadinstitute/gatk/issues/3760:335,Integrability,Interface,Interface,335,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760
https://github.com/broadinstitute/gatk/issues/3760:409,Integrability,interface,interface,409,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760
https://github.com/broadinstitute/gatk/issues/3760:440,Modifiability,inherit,inherit,440,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760
https://github.com/broadinstitute/gatk/issues/3762:40,Testability,test,testing,40,"It is not necessary to be packed in the testing framework, because it is specific for a single tool...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3762
https://github.com/broadinstitute/gatk/issues/3763:21,Integrability,message,message,21,Results in a warning message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763
https://github.com/broadinstitute/gatk/issues/3764:2411,Deployability,pipeline,pipelines,2411,"-a-reference-with-alternate-contigs-like-grch38> for the implications. This section also gives the first hack--remove the `0x1` SAM flag to circumvent the now `MateOnSameContigOrNoMappedMateReadFilter`. ; - The second hack is in the current Mutect2 hands-on tutorial where I have users `--disableReadFilter MateOnSameContigOrNoMappedMateReadFilter`. This latter hack is particularly germane to somatic analyses where there can be many fusion events. The `MateOnSameContigOrNoMappedMateReadFilter` filter asks HaplotypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764
https://github.com/broadinstitute/gatk/issues/3764:2610,Integrability,bridg,bridging,2610,"e I have users `--disableReadFilter MateOnSameContigOrNoMappedMateReadFilter`. This latter hack is particularly germane to somatic analyses where there can be many fusion events. The `MateOnSameContigOrNoMappedMateReadFilter` filter asks HaplotypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature enables is for us to continue discounting read pairs that map across chromosomes while correctly counting read pairs split across primary assembly and ALT contigs. . - Alternatively, or additionally, it might be good to have a stand-alone tool that can change the mate pai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764
https://github.com/broadinstitute/gatk/issues/3764:2742,Usability,simpl,simple,2742,"ypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature enables is for us to continue discounting read pairs that map across chromosomes while correctly counting read pairs split across primary assembly and ALT contigs. . - Alternatively, or additionally, it might be good to have a stand-alone tool that can change the mate pair designations. MergeBamAlignment has some options to change mate pair designations to some extent for other criteria. It may be that adding ALT-aware designations as an additional options to MergeBamAlignment could be useful. In this case, I ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764
https://github.com/broadinstitute/gatk/pull/3766:38,Availability,error,errors,38,We've been encountering transient 403 errors when using GCS NIO.; It seems that some GCS-related service is incorrectly returning 403 in; certain cases where we do actually have permission to access a resource.; This commit moves us to a google-cloud-java snapshot that retries upon; 403 errors:. https://github.com/droazen/google-cloud-java/commit/6d11bef1c81f885c26b2b56c8616b7a705171e4f. Resolves #3735,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766
https://github.com/broadinstitute/gatk/pull/3766:288,Availability,error,errors,288,We've been encountering transient 403 errors when using GCS NIO.; It seems that some GCS-related service is incorrectly returning 403 in; certain cases where we do actually have permission to access a resource.; This commit moves us to a google-cloud-java snapshot that retries upon; 403 errors:. https://github.com/droazen/google-cloud-java/commit/6d11bef1c81f885c26b2b56c8616b7a705171e4f. Resolves #3735,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766
https://github.com/broadinstitute/gatk/pull/3766:192,Security,access,access,192,We've been encountering transient 403 errors when using GCS NIO.; It seems that some GCS-related service is incorrectly returning 403 in; certain cases where we do actually have permission to access a resource.; This commit moves us to a google-cloud-java snapshot that retries upon; 403 errors:. https://github.com/droazen/google-cloud-java/commit/6d11bef1c81f885c26b2b56c8616b7a705171e4f. Resolves #3735,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766
https://github.com/broadinstitute/gatk/pull/3767:70,Availability,down,down,70,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767
https://github.com/broadinstitute/gatk/pull/3767:289,Modifiability,variab,variable,289,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767
https://github.com/broadinstitute/gatk/pull/3767:160,Testability,test,tests,160,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767
https://github.com/broadinstitute/gatk/issues/3768:381,Deployability,release,release,381,"Folks occasionally but consistently ask for this information on the forum and our current answer is that we provide these files as is. For the new GATK4 documentation, which we plan on releasing on January 9th alongside the new GATK4, I think we should aim to be more transparent. . The doc team aims to have select documentation ready by December 13, 2017, in preparation for the release. ### Those involved in the creation of the GRCh38 resource files, could you kindly provide READMEs to place alongside these files? . For example, what were the processing steps used to generate each, what is the original source (version) of the resource used, etc. Thank you. . The files are as follows:; ```; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.64.alt; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768
https://github.com/broadinstitute/gatk/issues/3768:762,Deployability,integrat,integrated,762,"Folks occasionally but consistently ask for this information on the forum and our current answer is that we provide these files as is. For the new GATK4 documentation, which we plan on releasing on January 9th alongside the new GATK4, I think we should aim to be more transparent. . The doc team aims to have select documentation ready by December 13, 2017, in preparation for the release. ### Those involved in the creation of the GRCh38 resource files, could you kindly provide READMEs to place alongside these files? . For example, what were the processing steps used to generate each, what is the original source (version) of the resource used, etc. Thank you. . The files are as follows:; ```; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.64.alt; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768
https://github.com/broadinstitute/gatk/issues/3768:872,Deployability,integrat,integrated,872,"Folks occasionally but consistently ask for this information on the forum and our current answer is that we provide these files as is. For the new GATK4 documentation, which we plan on releasing on January 9th alongside the new GATK4, I think we should aim to be more transparent. . The doc team aims to have select documentation ready by December 13, 2017, in preparation for the release. ### Those involved in the creation of the GRCh38 resource files, could you kindly provide READMEs to place alongside these files? . For example, what were the processing steps used to generate each, what is the original source (version) of the resource used, etc. Thank you. . The files are as follows:; ```; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.64.alt; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768
https://github.com/broadinstitute/gatk/issues/3768:762,Integrability,integrat,integrated,762,"Folks occasionally but consistently ask for this information on the forum and our current answer is that we provide these files as is. For the new GATK4 documentation, which we plan on releasing on January 9th alongside the new GATK4, I think we should aim to be more transparent. . The doc team aims to have select documentation ready by December 13, 2017, in preparation for the release. ### Those involved in the creation of the GRCh38 resource files, could you kindly provide READMEs to place alongside these files? . For example, what were the processing steps used to generate each, what is the original source (version) of the resource used, etc. Thank you. . The files are as follows:; ```; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.64.alt; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768
https://github.com/broadinstitute/gatk/issues/3768:872,Integrability,integrat,integrated,872,"Folks occasionally but consistently ask for this information on the forum and our current answer is that we provide these files as is. For the new GATK4 documentation, which we plan on releasing on January 9th alongside the new GATK4, I think we should aim to be more transparent. . The doc team aims to have select documentation ready by December 13, 2017, in preparation for the release. ### Those involved in the creation of the GRCh38 resource files, could you kindly provide READMEs to place alongside these files? . For example, what were the processing steps used to generate each, what is the original source (version) of the resource used, etc. Thank you. . The files are as follows:; ```; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf; gs://genomics-public-data/resources/broad/hg38/v0/1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz; gs://genomics-public-data/resources/broad/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.64.alt; gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768
https://github.com/broadinstitute/gatk/issues/3769:1461,Availability,avail,available,1461,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:98,Deployability,release,release,98,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:309,Deployability,update,update,309,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:645,Deployability,release,release,645,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:804,Deployability,release,release,804,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:958,Deployability,release,release,958,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:1065,Deployability,release,release,1065,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:1365,Security,validat,validation,1365,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/issues/3769:1442,Testability,benchmark,benchmarking,1442,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769
https://github.com/broadinstitute/gatk/pull/3770:250,Availability,down,down,250,"for multiple alignment fine tuning for ; * sending back some contigs back to the 2 alignment logic tree, as handled by #3752 , and ; * capturing more incomplete picture assemblies, and ; * sending the assembly contig seemingly has a complete picture down the multiple alignment logic tree, which is being finalized. To be merged after #3752 is reviewed. Code for hooking it up exists and is minimal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3770
https://github.com/broadinstitute/gatk/pull/3770:93,Testability,log,logic,93,"for multiple alignment fine tuning for ; * sending back some contigs back to the 2 alignment logic tree, as handled by #3752 , and ; * capturing more incomplete picture assemblies, and ; * sending the assembly contig seemingly has a complete picture down the multiple alignment logic tree, which is being finalized. To be merged after #3752 is reviewed. Code for hooking it up exists and is minimal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3770
https://github.com/broadinstitute/gatk/pull/3770:278,Testability,log,logic,278,"for multiple alignment fine tuning for ; * sending back some contigs back to the 2 alignment logic tree, as handled by #3752 , and ; * capturing more incomplete picture assemblies, and ; * sending the assembly contig seemingly has a complete picture down the multiple alignment logic tree, which is being finalized. To be merged after #3752 is reviewed. Code for hooking it up exists and is minimal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3770
https://github.com/broadinstitute/gatk/issues/3771:61,Usability,Simpl,SimpleIntervalTestFactory,61,The methods in `TargetsToolsTestUtils` (renamed in #3475 to `SimpleIntervalTestFactory`) are better suited to be static methods in `IntervalUtils` taking a dictionary as a parameter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3771
https://github.com/broadinstitute/gatk/issues/3772:220,Deployability,update,update,220,It seems like another R dependency has moved. ; `http://cran.r-project.org/src/contrib/data.table_1.10.4-2.tar.gz` -> `https://cran.r-project.org/src/contrib/Archive/data.table/data.table_1.10.4-2.tar.gz`. We'll need to update our `installRscripts`. We should seriously consider just hosting these files ourselves somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3772
https://github.com/broadinstitute/gatk/issues/3772:232,Deployability,install,installRscripts,232,It seems like another R dependency has moved. ; `http://cran.r-project.org/src/contrib/data.table_1.10.4-2.tar.gz` -> `https://cran.r-project.org/src/contrib/Archive/data.table/data.table_1.10.4-2.tar.gz`. We'll need to update our `installRscripts`. We should seriously consider just hosting these files ourselves somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3772
https://github.com/broadinstitute/gatk/issues/3772:24,Integrability,depend,dependency,24,It seems like another R dependency has moved. ; `http://cran.r-project.org/src/contrib/data.table_1.10.4-2.tar.gz` -> `https://cran.r-project.org/src/contrib/Archive/data.table/data.table_1.10.4-2.tar.gz`. We'll need to update our `installRscripts`. We should seriously consider just hosting these files ourselves somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3772
https://github.com/broadinstitute/gatk/issues/3774:5,Availability,avail,available,5,"I am available to help in this process @jonn-smith. Just to give you an idea of the evolution of tutorials, here are some example tutorials that focus on somatic CNV calling. - Alpha tutorial that Lee wrote:; <https://gatkforums.broadinstitute.org/gatk/discussion/7387/description-and-examples-of-the-steps-in-the-acnv-case-workflow>; - A demo-like tutorial that Sam Lee planned and developed (also Mehrtash was involved so don't be shy about asking around for help) and I encased in writing:; <https://gatkforums.broadinstitute.org/gatk/discussion/9143/how-to-call-somatic-copy-number-variants-using-gatk4-cnv/p1>; - A tutorial to highlight the factors in PoN creation currently used in workshops that I planned, developed and wrote: [GATK4_SomaticCNV_worksheet.pdf](https://github.com/broadinstitute/gatk/files/1435691/GATK4_SomaticCNV_worksheet.pdf). Depending on how much responsibility you want to take (I think it nice for you to post a tutorial on the forum under your name for posterity), you can choose to get my review only or have me help in brainstorming, organizing and/or formatting the content. I have a template available for copy-pasting with formatting elements at <https://gatkforums.broadinstitute.org/dsde/discussion/9140/how-to-tutorial-template-a-la-soo-hee-for-copy-pasting#latest>. Notice this document is only visible to DSDE members and similarly, you can draft a tutorial in private first then move it to a public forum. Here are some steps I go through in developing a tutorial. You may choose to skip certain elements, e.g. example data. I have to say that having example data really helps the users.; - Find small test data to illustrate important features of the tool; ensure data is publically sharable; - Write out commands that include recommended parameters; - Explain the important parameters and the impact of changing them; - Illustrate with results and screenshots; - Get reviewed early by others and incorporate changes; - A section of links to related or help",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774
https://github.com/broadinstitute/gatk/issues/3774:1128,Availability,avail,available,1128,"lable to help in this process @jonn-smith. Just to give you an idea of the evolution of tutorials, here are some example tutorials that focus on somatic CNV calling. - Alpha tutorial that Lee wrote:; <https://gatkforums.broadinstitute.org/gatk/discussion/7387/description-and-examples-of-the-steps-in-the-acnv-case-workflow>; - A demo-like tutorial that Sam Lee planned and developed (also Mehrtash was involved so don't be shy about asking around for help) and I encased in writing:; <https://gatkforums.broadinstitute.org/gatk/discussion/9143/how-to-call-somatic-copy-number-variants-using-gatk4-cnv/p1>; - A tutorial to highlight the factors in PoN creation currently used in workshops that I planned, developed and wrote: [GATK4_SomaticCNV_worksheet.pdf](https://github.com/broadinstitute/gatk/files/1435691/GATK4_SomaticCNV_worksheet.pdf). Depending on how much responsibility you want to take (I think it nice for you to post a tutorial on the forum under your name for posterity), you can choose to get my review only or have me help in brainstorming, organizing and/or formatting the content. I have a template available for copy-pasting with formatting elements at <https://gatkforums.broadinstitute.org/dsde/discussion/9140/how-to-tutorial-template-a-la-soo-hee-for-copy-pasting#latest>. Notice this document is only visible to DSDE members and similarly, you can draft a tutorial in private first then move it to a public forum. Here are some steps I go through in developing a tutorial. You may choose to skip certain elements, e.g. example data. I have to say that having example data really helps the users.; - Find small test data to illustrate important features of the tool; ensure data is publically sharable; - Write out commands that include recommended parameters; - Explain the important parameters and the impact of changing them; - Illustrate with results and screenshots; - Get reviewed early by others and incorporate changes; - A section of links to related or helpful docs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774
https://github.com/broadinstitute/gatk/issues/3774:854,Integrability,Depend,Depending,854,"I am available to help in this process @jonn-smith. Just to give you an idea of the evolution of tutorials, here are some example tutorials that focus on somatic CNV calling. - Alpha tutorial that Lee wrote:; <https://gatkforums.broadinstitute.org/gatk/discussion/7387/description-and-examples-of-the-steps-in-the-acnv-case-workflow>; - A demo-like tutorial that Sam Lee planned and developed (also Mehrtash was involved so don't be shy about asking around for help) and I encased in writing:; <https://gatkforums.broadinstitute.org/gatk/discussion/9143/how-to-call-somatic-copy-number-variants-using-gatk4-cnv/p1>; - A tutorial to highlight the factors in PoN creation currently used in workshops that I planned, developed and wrote: [GATK4_SomaticCNV_worksheet.pdf](https://github.com/broadinstitute/gatk/files/1435691/GATK4_SomaticCNV_worksheet.pdf). Depending on how much responsibility you want to take (I think it nice for you to post a tutorial on the forum under your name for posterity), you can choose to get my review only or have me help in brainstorming, organizing and/or formatting the content. I have a template available for copy-pasting with formatting elements at <https://gatkforums.broadinstitute.org/dsde/discussion/9140/how-to-tutorial-template-a-la-soo-hee-for-copy-pasting#latest>. Notice this document is only visible to DSDE members and similarly, you can draft a tutorial in private first then move it to a public forum. Here are some steps I go through in developing a tutorial. You may choose to skip certain elements, e.g. example data. I have to say that having example data really helps the users.; - Find small test data to illustrate important features of the tool; ensure data is publically sharable; - Write out commands that include recommended parameters; - Explain the important parameters and the impact of changing them; - Illustrate with results and screenshots; - Get reviewed early by others and incorporate changes; - A section of links to related or help",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774
https://github.com/broadinstitute/gatk/issues/3774:1645,Testability,test,test,1645,"lable to help in this process @jonn-smith. Just to give you an idea of the evolution of tutorials, here are some example tutorials that focus on somatic CNV calling. - Alpha tutorial that Lee wrote:; <https://gatkforums.broadinstitute.org/gatk/discussion/7387/description-and-examples-of-the-steps-in-the-acnv-case-workflow>; - A demo-like tutorial that Sam Lee planned and developed (also Mehrtash was involved so don't be shy about asking around for help) and I encased in writing:; <https://gatkforums.broadinstitute.org/gatk/discussion/9143/how-to-call-somatic-copy-number-variants-using-gatk4-cnv/p1>; - A tutorial to highlight the factors in PoN creation currently used in workshops that I planned, developed and wrote: [GATK4_SomaticCNV_worksheet.pdf](https://github.com/broadinstitute/gatk/files/1435691/GATK4_SomaticCNV_worksheet.pdf). Depending on how much responsibility you want to take (I think it nice for you to post a tutorial on the forum under your name for posterity), you can choose to get my review only or have me help in brainstorming, organizing and/or formatting the content. I have a template available for copy-pasting with formatting elements at <https://gatkforums.broadinstitute.org/dsde/discussion/9140/how-to-tutorial-template-a-la-soo-hee-for-copy-pasting#latest>. Notice this document is only visible to DSDE members and similarly, you can draft a tutorial in private first then move it to a public forum. Here are some steps I go through in developing a tutorial. You may choose to skip certain elements, e.g. example data. I have to say that having example data really helps the users.; - Find small test data to illustrate important features of the tool; ensure data is publically sharable; - Write out commands that include recommended parameters; - Explain the important parameters and the impact of changing them; - Illustrate with results and screenshots; - Get reviewed early by others and incorporate changes; - A section of links to related or helpful docs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774
https://github.com/broadinstitute/gatk/pull/3775:142,Performance,Cache,CachedBinarySearchIntervalList,142,"@asmirnov239 I made some additions to your code to add HDF5 writing and make TSV writing consistent. I used an OverlapDetector instead of the CachedBinarySearchIntervalList and I think there was no performance hit. I also went ahead and added HDF5Utils, which has some methods that will be used in later PRs. . Let's consider your first commit reviewed by me; could you take a look at my changes in the second commit?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3775
https://github.com/broadinstitute/gatk/pull/3775:198,Performance,perform,performance,198,"@asmirnov239 I made some additions to your code to add HDF5 writing and make TSV writing consistent. I used an OverlapDetector instead of the CachedBinarySearchIntervalList and I think there was no performance hit. I also went ahead and added HDF5Utils, which has some methods that will be used in later PRs. . Let's consider your first commit reviewed by me; could you take a look at my changes in the second commit?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3775
https://github.com/broadinstitute/gatk/pull/3776:560,Availability,down,down,560,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776
https://github.com/broadinstitute/gatk/pull/3776:325,Energy Efficiency,reduce,reduce,325,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776
https://github.com/broadinstitute/gatk/pull/3776:531,Testability,test,test,531,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776
https://github.com/broadinstitute/gatk/pull/3776:565,Testability,test,testing,565,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776
https://github.com/broadinstitute/gatk/pull/3776:605,Testability,Benchmark,Benchmark,605,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776
https://github.com/broadinstitute/gatk/pull/3779:416,Deployability,integrat,integration,416,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/pull/3779:416,Integrability,integrat,integration,416,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/pull/3779:252,Testability,test,tests,252,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/pull/3779:381,Testability,test,test,381,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/pull/3779:428,Testability,test,tests,428,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/pull/3779:470,Testability,test,tests,470,"First version of Funcotator, a GATK Oncotator analog. ; Fixes #3283. Includes functionality to create annotations from GENCODE for HG19 and; HG38 for MNPs and INDELs in all regions of the genome. NOTE: There are still some INDEL issues, and some INDEL tests are still; commented out. This is very much a work in progress and should still be considered a; BETA tool. Added required test files for Funcotator unit and integration tests to; git lfs. Rebased on master, now tests are GATKBaseTests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3779
https://github.com/broadinstitute/gatk/issues/3783:51,Modifiability,config,config,51,Add the ability (either as command-line options or config file options) for a user to specify default values for certain annotations (i.e. `Center`).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3783
https://github.com/broadinstitute/gatk/issues/3785:160,Modifiability,config,config,160,Need to create a tool that allows a user to import / create a simple delimited data source (i.e. from a given CSV / TSV file). See how Oncotator structured its config files for insights on how to do this. It may be possible to simply reuse that config file format.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785
https://github.com/broadinstitute/gatk/issues/3785:245,Modifiability,config,config,245,Need to create a tool that allows a user to import / create a simple delimited data source (i.e. from a given CSV / TSV file). See how Oncotator structured its config files for insights on how to do this. It may be possible to simply reuse that config file format.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785
https://github.com/broadinstitute/gatk/issues/3785:62,Usability,simpl,simple,62,Need to create a tool that allows a user to import / create a simple delimited data source (i.e. from a given CSV / TSV file). See how Oncotator structured its config files for insights on how to do this. It may be possible to simply reuse that config file format.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785
https://github.com/broadinstitute/gatk/issues/3785:227,Usability,simpl,simply,227,Need to create a tool that allows a user to import / create a simple delimited data source (i.e. from a given CSV / TSV file). See how Oncotator structured its config files for insights on how to do this. It may be possible to simply reuse that config file format.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785
https://github.com/broadinstitute/gatk/issues/3788:243,Integrability,depend,depend,243,"I'm running SelectVariants with an interval list L of 600,000 loci and an excluded interval list XL of 160 loci. Based on restricting L and XL it seems that the runtime scales as |L|x|XL|, which comes out to over an hour. The runtime does not depend at all on the size of the vcf in the -V argument. That is, once traversal begins it's basically instantaneous, but processing the intervals takes forever. Naively, one could make this scale as |L| + |XL| by querying each variant in the input vcf against L and then against XL. For reasons @cmnbroad points out this is not a great solution, but it seems like because (i) L and XL are ordered and (ii) each L overlaps with only a sparse subset of XL and vice versa that this quadratic scaling is not necessary. For my case I can get around this easily by preprocessing V with -XL, then running SelectVariants with -L. @lbergelson was also in this conversation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3788
https://github.com/broadinstitute/gatk/pull/3789:32,Testability,test,tests,32,@magicDGS here you go. All unit tests in SV package now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3789
https://github.com/broadinstitute/gatk/issues/3793:235,Deployability,patch,patch,235,"As discussed internally, we should publish our docker image to GCR in addition to dockerhub, so that dockerhub won't get clobbered by our production users. The GCR repo to use will be provided by @hjfbynara. Once we have it, we should patch `build_docker.sh -p` to push there as well, and update our ""How to release GATK"" wiki article appropriately.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3793
https://github.com/broadinstitute/gatk/issues/3793:289,Deployability,update,update,289,"As discussed internally, we should publish our docker image to GCR in addition to dockerhub, so that dockerhub won't get clobbered by our production users. The GCR repo to use will be provided by @hjfbynara. Once we have it, we should patch `build_docker.sh -p` to push there as well, and update our ""How to release GATK"" wiki article appropriately.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3793
https://github.com/broadinstitute/gatk/issues/3793:308,Deployability,release,release,308,"As discussed internally, we should publish our docker image to GCR in addition to dockerhub, so that dockerhub won't get clobbered by our production users. The GCR repo to use will be provided by @hjfbynara. Once we have it, we should patch `build_docker.sh -p` to push there as well, and update our ""How to release GATK"" wiki article appropriately.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3793
https://github.com/broadinstitute/gatk/pull/3795:49,Availability,error,error,49,- expanding unit tests to actually replicate the error if we have a regression.; - applied fix that sorts the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3795
https://github.com/broadinstitute/gatk/pull/3795:17,Testability,test,tests,17,- expanding unit tests to actually replicate the error if we have a regression.; - applied fix that sorts the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3795
https://github.com/broadinstitute/gatk/issues/3796:419,Testability,test,test,419,"`Utils.split` was found to be much faster (>=2x) than `String.split` (see #3759). . We need to go through and replace all calls to `String.split` with calls to our `Utils.split`. Additionally, we need to find a way to have the compiler throw a warning when any call to `String.split` occurs. This will prevent developers from using this method in the future and cause this change to proliferate. Ideally this is a unit test so that it gets called automatically and prevents the developer from checking in code with `String.split` calls. For clarity, this test should only check classes in the org.broadinstitute.hellbender.* classes, and should exclude tests. It would also be nice to be able to check in derivative projects.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3796
https://github.com/broadinstitute/gatk/issues/3796:555,Testability,test,test,555,"`Utils.split` was found to be much faster (>=2x) than `String.split` (see #3759). . We need to go through and replace all calls to `String.split` with calls to our `Utils.split`. Additionally, we need to find a way to have the compiler throw a warning when any call to `String.split` occurs. This will prevent developers from using this method in the future and cause this change to proliferate. Ideally this is a unit test so that it gets called automatically and prevents the developer from checking in code with `String.split` calls. For clarity, this test should only check classes in the org.broadinstitute.hellbender.* classes, and should exclude tests. It would also be nice to be able to check in derivative projects.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3796
https://github.com/broadinstitute/gatk/issues/3796:653,Testability,test,tests,653,"`Utils.split` was found to be much faster (>=2x) than `String.split` (see #3759). . We need to go through and replace all calls to `String.split` with calls to our `Utils.split`. Additionally, we need to find a way to have the compiler throw a warning when any call to `String.split` occurs. This will prevent developers from using this method in the future and cause this change to proliferate. Ideally this is a unit test so that it gets called automatically and prevents the developer from checking in code with `String.split` calls. For clarity, this test should only check classes in the org.broadinstitute.hellbender.* classes, and should exclude tests. It would also be nice to be able to check in derivative projects.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3796
https://github.com/broadinstitute/gatk/issues/3798:415,Modifiability,refactor,refactored,415,"The script is dangerous in its current state because it uses rm -Rf ${dir} arguments which can result in unwanted deletion if something goes wrong with the input arguments. We should either fix those arguments or remove the necessity for the script to be run with root permissions altogether to avoid any future problems that might arise and make the script safer for users. Additionally, the whole script could be refactored to be cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3798
https://github.com/broadinstitute/gatk/issues/3798:295,Safety,avoid,avoid,295,"The script is dangerous in its current state because it uses rm -Rf ${dir} arguments which can result in unwanted deletion if something goes wrong with the input arguments. We should either fix those arguments or remove the necessity for the script to be run with root permissions altogether to avoid any future problems that might arise and make the script safer for users. Additionally, the whole script could be refactored to be cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3798
https://github.com/broadinstitute/gatk/issues/3798:358,Safety,safe,safer,358,"The script is dangerous in its current state because it uses rm -Rf ${dir} arguments which can result in unwanted deletion if something goes wrong with the input arguments. We should either fix those arguments or remove the necessity for the script to be run with root permissions altogether to avoid any future problems that might arise and make the script safer for users. Additionally, the whole script could be refactored to be cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3798
https://github.com/broadinstitute/gatk/issues/3799:93,Availability,down,down,93,"For compatibility with long reads, if we will become interested in supporting their features down the road. Otherwise, please take this ticket as informational. New aligner by Heng Li, Minimap2, has option to emit `CG` tag containing full CIGAR string for long reads that would have >65535 CIGAR operations. This is for BAM compatibility. My understanding is that in such cases, the CIGAR field would then contain only clipping information. Minimap2 will also have the option to emit a `CS` tag, encoding bases at mismatches and INDELs. This mapper is originally intended for long read mapping, e.g. at the scale of PacBio and Oxford Nanopore (ONT), where it is ~ten times faster than BWA-MEM and other conventional mappers for ~10kb noisy reads. **The mapper is also currently compatible with >100 base reads, either genomic (DNA) or spliced nucleotide (RNA) and for these, is three times faster than BWA-MEM and Bowtie2.** . See <https://github.com/lh3/minimap2> for details and <https://arxiv.org/pdf/1708.01492.pdf> for the preprint.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3799
https://github.com/broadinstitute/gatk/issues/3800:119,Deployability,patch,patches,119,We should revert the change in https://github.com/broadinstitute/gatk/pull/3766 to retry 403s on GCS as soon as Google patches its service to return the correct status code (503) instead of 403. We can do this via a straight-up:; `git revert e11d7b9410e0fcecf2d98c5ac55ce05fad21ee17`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3800
https://github.com/broadinstitute/gatk/pull/3805:430,Availability,avail,available,430,"finally here. closing the main feature requests made in #2703 . Need to wait for #3752 and #3770 . Will generate a separate dummy PR about how to run the whole prototyping holistic SV interpretation tool. Some small patches need to be applied after this PR, basically for dumpster diving into ; * ambiguous events; * events where assembly contigs clearly couldn't tell a complete picture. but all parts of the diving suit are all available after this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805
https://github.com/broadinstitute/gatk/pull/3805:216,Deployability,patch,patches,216,"finally here. closing the main feature requests made in #2703 . Need to wait for #3752 and #3770 . Will generate a separate dummy PR about how to run the whole prototyping holistic SV interpretation tool. Some small patches need to be applied after this PR, basically for dumpster diving into ; * ambiguous events; * events where assembly contigs clearly couldn't tell a complete picture. but all parts of the diving suit are all available after this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805
https://github.com/broadinstitute/gatk/pull/3805:347,Usability,clear,clearly,347,"finally here. closing the main feature requests made in #2703 . Need to wait for #3752 and #3770 . Will generate a separate dummy PR about how to run the whole prototyping holistic SV interpretation tool. Some small patches need to be applied after this PR, basically for dumpster diving into ; * ambiguous events; * events where assembly contigs clearly couldn't tell a complete picture. but all parts of the diving suit are all available after this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805
https://github.com/broadinstitute/gatk/pull/3806:96,Deployability,install,installAll,96,"for demonstrating how to using the prototyping tool. To run the tool:. ```bash; ./gradlew clean installAll. ./gatk-launch SvDiscoverFromLocalAssemblyContigAlignmentsSpark \; -I PATH_TO_LOCAL_ASSEMBLY_SAM \; -O OUTPUT_DIR \; -R PATH_TO_2BIT_REF \; --writeSAM; ```. This will scan through the assembly sam file, search for split alignments and output in a directory several VCF files, each for one raw type of variant.; This does not output VCF records for interpreted complex variant yet (see #3805 ), but put them in a more human-friendly format.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3806
https://github.com/broadinstitute/gatk/issues/3807:507,Availability,error,error,507,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807
https://github.com/broadinstitute/gatk/issues/3807:600,Availability,ERROR,ERROR,600,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807
https://github.com/broadinstitute/gatk/issues/3807:906,Availability,error,error,906,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807
https://github.com/broadinstitute/gatk/issues/3807:1002,Deployability,pipeline,pipelines,1002,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807
https://github.com/broadinstitute/gatk/issues/3807:1169,Deployability,pipeline,pipeline,1169,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807
https://github.com/broadinstitute/gatk/issues/3808:326,Availability,down,downsampling,326,"In looking at Mutect2 for clinical applications, one thing that always seems to come up has to do with the big difference between the ref/alt coverage denoted in the VCF file and what is seen in IGV. For clinical reporting, many labs will provide mutant allele depths, along with the VAF estimate. I understand the purpose of downsampling at stages of the m2 workflow, and I also understand this negatively affects amplicon-based studies. How viable is it to provide more exact (include reads that are high quality but not used during variant determination) estimates of coverage at variant loci, while not substantially increasing runtime? It would be great to get some of our analysts away from always feeling as if they need to visualize calls in IGV... Thanks,; John",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3808
https://github.com/broadinstitute/gatk/pull/3810:66,Deployability,upgrade,upgrade,66,"The GCS ReadUtils tests are failing intermittently on the Barclay upgrade branch, probably due to filename collision when tests are running in parallel on Travis because the tests don't use unique temporary filenames.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3810
https://github.com/broadinstitute/gatk/pull/3810:18,Testability,test,tests,18,"The GCS ReadUtils tests are failing intermittently on the Barclay upgrade branch, probably due to filename collision when tests are running in parallel on Travis because the tests don't use unique temporary filenames.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3810
https://github.com/broadinstitute/gatk/pull/3810:122,Testability,test,tests,122,"The GCS ReadUtils tests are failing intermittently on the Barclay upgrade branch, probably due to filename collision when tests are running in parallel on Travis because the tests don't use unique temporary filenames.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3810
https://github.com/broadinstitute/gatk/pull/3810:174,Testability,test,tests,174,"The GCS ReadUtils tests are failing intermittently on the Barclay upgrade branch, probably due to filename collision when tests are running in parallel on Travis because the tests don't use unique temporary filenames.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3810
https://github.com/broadinstitute/gatk/issues/3811:7,Testability,test,test,7,In the test suite for `GenotypeGVCFs` and `CombineGVCFs` there is some nearly duplicated code related to comparing VCF files intelligently when there exists an expectation that certain fields in the file will vary between runs. Similar functionality exists in for sam file comparison with `org.broadinstitute.hellbender.utils.test.SamAssertionUtils`. Factoring the VCF comparison tests out into a `VCFAssertionUtils` class could help alleviate this code duplication problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3811
https://github.com/broadinstitute/gatk/issues/3811:326,Testability,test,test,326,In the test suite for `GenotypeGVCFs` and `CombineGVCFs` there is some nearly duplicated code related to comparing VCF files intelligently when there exists an expectation that certain fields in the file will vary between runs. Similar functionality exists in for sam file comparison with `org.broadinstitute.hellbender.utils.test.SamAssertionUtils`. Factoring the VCF comparison tests out into a `VCFAssertionUtils` class could help alleviate this code duplication problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3811
https://github.com/broadinstitute/gatk/issues/3811:380,Testability,test,tests,380,In the test suite for `GenotypeGVCFs` and `CombineGVCFs` there is some nearly duplicated code related to comparing VCF files intelligently when there exists an expectation that certain fields in the file will vary between runs. Similar functionality exists in for sam file comparison with `org.broadinstitute.hellbender.utils.test.SamAssertionUtils`. Factoring the VCF comparison tests out into a `VCFAssertionUtils` class could help alleviate this code duplication problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3811
https://github.com/broadinstitute/gatk/pull/3812:20,Availability,error,error,20,"improving gatk, one error message at a time",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3812
https://github.com/broadinstitute/gatk/pull/3812:26,Integrability,message,message,26,"improving gatk, one error message at a time",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3812
https://github.com/broadinstitute/gatk/issues/3813:418,Availability,error,error,418,"We have a problematic read that goes in as cigar `14S45M92S` (or something similar) and turns `137H14S` when clipped by `ReadClipper.hardClipLowQualEnds` `(AssemblyBasedCallerUtils::L73)`. This is because the first 137 are base quality 2. M2 (and HC) fails later on because we miscalculate the start position as -4. This only occurs when a specific interval file is used. When run with `-L chrM`, the we don't get the error, for example. Problematic bam: `/seq/picard_aggregation/RP-1490/WGS/OCB006937/v2/OCB006937.bam`; Read Name: `H3FWGCCXY170920`; Position: chrM:147-146 (this is what I wrote down but I'm not sure if it's right); Reference: `/seq/references/Mus_musculus_assembly10/v0/Mus_musculus_assembly10.fasta` (this is a mouse reference). ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; contig = chrM; start = -4; 	at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); 	at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); 	at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:82); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:242); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:211); 	at org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3813
https://github.com/broadinstitute/gatk/issues/3813:596,Availability,down,down,596,"We have a problematic read that goes in as cigar `14S45M92S` (or something similar) and turns `137H14S` when clipped by `ReadClipper.hardClipLowQualEnds` `(AssemblyBasedCallerUtils::L73)`. This is because the first 137 are base quality 2. M2 (and HC) fails later on because we miscalculate the start position as -4. This only occurs when a specific interval file is used. When run with `-L chrM`, the we don't get the error, for example. Problematic bam: `/seq/picard_aggregation/RP-1490/WGS/OCB006937/v2/OCB006937.bam`; Read Name: `H3FWGCCXY170920`; Position: chrM:147-146 (this is what I wrote down but I'm not sure if it's right); Reference: `/seq/references/Mus_musculus_assembly10/v0/Mus_musculus_assembly10.fasta` (this is a mouse reference). ```; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; contig = chrM; start = -4; 	at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); 	at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); 	at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); 	at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:82); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:242); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:211); 	at org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3813
https://github.com/broadinstitute/gatk/issues/3814:880,Availability,error,error,880,"It looks like we've found a bug in GenomicsDB. We had a project with 26 replicates (same sample in there twice) among another ~1000 samples. Therefore we uniquified the names in the sample map that’s input to TileDB for those 26 samples (i.e. converted them to project.sample instead of just sample) -- but obviously the names in the gvcfs remained unaltered. When we look at the output VCF from GenomicsDB, there's definitely a problem. These 52 samples are the first ones in the list and here's what we see:. The first 26 samples (the first occurrence of the replicates) are fine.; Then the next 24 samples (the second occurrence of the replicates) are all “.:0,0” (i.e. empty) for all columns in the VCF.; Then the next 2 samples (also second occurrences of replicates) are fine. Given that our batch size was 50 when importing into GenomicsDB, this looks suspiciously like an error with the batching. So within a batch it looks like it’s not respecting the renaming somehow?. @kgururaj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814
https://github.com/broadinstitute/gatk/pull/3819:533,Energy Efficiency,reduce,reduces,533,"Closes #3607 ; In cleaning rare or ubiquitous kmers from the list for local assemblies, we now make our min and max counts depend on the measured coverage.; We also count the number of partitions in which a kmer appears, and discard those that appear in too many dispersed locations. This is a big win for keeping the assemblies small and local, and allows us to do more of them (there are fewer ""too bigs"").; Finally, we reorder the assemblies so that we do the big ones first. This keeps us from being hung up on stragglers.; This reduces by a percent or so the number of events called, but preliminary results suggest that these were mostly false positives caused by assembling homologous regions together.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3819
https://github.com/broadinstitute/gatk/pull/3819:123,Integrability,depend,depend,123,"Closes #3607 ; In cleaning rare or ubiquitous kmers from the list for local assemblies, we now make our min and max counts depend on the measured coverage.; We also count the number of partitions in which a kmer appears, and discard those that appear in too many dispersed locations. This is a big win for keeping the assemblies small and local, and allows us to do more of them (there are fewer ""too bigs"").; Finally, we reorder the assemblies so that we do the big ones first. This keeps us from being hung up on stragglers.; This reduces by a percent or so the number of events called, but preliminary results suggest that these were mostly false positives caused by assembling homologous regions together.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3819
https://github.com/broadinstitute/gatk/pull/3820:918,Availability,down,down,918,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:991,Availability,redundant,redundant,991,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:69,Deployability,update,update,69,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:182,Deployability,update,update,182,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:301,Deployability,update,update,301,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1484,Deployability,Update,Updated,1484,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:684,Modifiability,refactor,refactor,684,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:991,Safety,redund,redundant,991,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:820,Testability,test,tests,820,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1064,Testability,test,tests,1064,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1205,Testability,test,tests,1205,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1318,Testability,test,tests,1318,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1396,Testability,test,tests,1396,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1110,Usability,simpl,simply,1110,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/pull/3820:1328,Usability,Simpl,SimpleCountCollection,1328,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820
https://github.com/broadinstitute/gatk/issues/3822:665,Deployability,Pipeline,Pipelines,665,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822
https://github.com/broadinstitute/gatk/issues/3822:544,Energy Efficiency,efficient,efficient,544,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822
https://github.com/broadinstitute/gatk/issues/3822:35,Usability,guid,guidelines,35,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822
https://github.com/broadinstitute/gatk/issues/3822:129,Usability,guid,guidelines,129,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822
https://github.com/broadinstitute/gatk/issues/3823:1731,Availability,error,error,1731,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:215,Deployability,integrat,integration,215,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:247,Deployability,integrat,integration,247,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1165,Deployability,integrat,integration,1165,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1500,Deployability,integrat,integration,1500,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:942,Energy Efficiency,reduce,reduce,942,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:215,Integrability,integrat,integration,215,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:247,Integrability,integrat,integration,247,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1165,Integrability,integrat,integration,1165,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1500,Integrability,integrat,integration,1500,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1870,Modifiability,refactor,refactored,1870,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:227,Testability,test,tests,227,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:259,Testability,test,tests,259,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1177,Testability,test,test,1177,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1512,Testability,test,test,1512,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:1543,Testability,test,tests,1543,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3823:665,Usability,Simpl,SimpleSampleMetadata,665,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823
https://github.com/broadinstitute/gatk/issues/3825:639,Availability,error,error,639,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3825:1130,Availability,error,error,1130,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3825:53,Deployability,pipeline,pipeline,53,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3825:167,Deployability,pipeline,pipeline,167,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3825:140,Usability,simpl,simply,140,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3825:1177,Usability,simpl,simply,1177,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825
https://github.com/broadinstitute/gatk/issues/3826:7,Deployability,pipeline,pipeline,7,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:198,Deployability,pipeline,pipeline,198,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:286,Deployability,Update,Update,286,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:480,Deployability,pipeline,pipelines,480,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:534,Deployability,pipeline,pipeline,534,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:1365,Deployability,Update,Update,1365,"follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---altho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:1616,Deployability,Update,Update,1616,"nges from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be do",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:1802,Deployability,pipeline,pipeline,1802,"this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update Pr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2211,Deployability,Update,Update,2211,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2326,Deployability,install,install---although,2326,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2358,Deployability,install,install,2358,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2445,Deployability,release,release,2445,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2670,Deployability,Update,Update,2670,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2817,Deployability,Update,Update,2817,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:688,Security,expose,exposed,688,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2530,Testability,test,tests,2530,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:901,Usability,simpl,simple,901,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/issues/3826:2484,Usability,clear,clear,2484,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826
https://github.com/broadinstitute/gatk/pull/3827:78,Security,Validat,Validates,78,Test to verify that picard interval lists are handled properly by GATK tools. Validates the fix for https://github.com/broadinstitute/gatk/issues/3555.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3827
https://github.com/broadinstitute/gatk/pull/3827:0,Testability,Test,Test,0,Test to verify that picard interval lists are handled properly by GATK tools. Validates the fix for https://github.com/broadinstitute/gatk/issues/3555.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3827
https://github.com/broadinstitute/gatk/issues/3828:110,Integrability,message,messages,110,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828
https://github.com/broadinstitute/gatk/issues/3828:273,Integrability,message,messages,273,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828
https://github.com/broadinstitute/gatk/issues/3828:342,Integrability,message,message,342,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828
https://github.com/broadinstitute/gatk/issues/3828:306,Testability,log,log,306,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828
https://github.com/broadinstitute/gatk/issues/3830:196,Deployability,patch,patch,196,"This is a difference vs. GATK3, which did include reads with deletions in the isActive pileups for both HaplotypeCaller and Mutect2 ( @davidbenjamin take note ). The fix is trivial -- I'll have a patch submitted later today.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3830
https://github.com/broadinstitute/gatk/pull/3831:179,Deployability,patch,patch,179,"Previously, reads with deletions at the current loci were not being included in; the pileups passed to isActive(), which was a difference vs. the default settings; in GATK3. This patch changes the default to be to include such reads in both; HaplotypeCaller and Mutect2. Resolves #3830",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3831
https://github.com/broadinstitute/gatk/issues/3834:1061,Availability,avail,available,1061,"Inconsistencies applies to GATK 4.beta.6 (observed by forum user) and 3.7 (recapitulated by @sooheelee). The inconsistency is namely in the form of BQ-clipping, e.g. from `AAFFFKKKKKKKKKKKKKKKKKKK` to `AAF55!!5!!!5!!!55!!5!!!!` for read and a supplementary read of the mate that is highlighted in red:. <img width=""1281"" alt=""screenshot 2017-11-14 14 00 00"" src=""https://user-images.githubusercontent.com/11543866/32800037-56ea32ba-c947-11e7-9d4d-b33a3ac5030a.png"">. This particular read pair does not contribute to variant calling. However, I assume there could be scenarios in which such BQ-clipped reads end up counting towards variant calling. - original forum user report for v4.beta.6: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43851#Comment_43851; - original user data bundle: /humgen/gsa-scr1/pub/incoming/BasequalityBug.tar.gz; - Comms recapitulation and observations including for v3.7: https://github.com/broadinstitute/dsde-docs/issues/2661. I also request that GATK4 HaplotypeCaller port the `--emitDroppedReads` option that is available in v3 but not so far in v4. This option allows users to understand why a read may be dropped from HaplotypeCaller consideration.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3834
https://github.com/broadinstitute/gatk/pull/3835:437,Availability,avail,available,437,"I'll be adding documented feature tags to the 57 annotation modules. Before I get to these, I need a new ANNOTATORS category to exist in HelpConstants.java. . I've taken the liberty to name the category ANNOTATORS. Here is the relevant info I added to HelpConstants.java:. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3835
https://github.com/broadinstitute/gatk/pull/3835:286,Modifiability,variab,variable,286,"I'll be adding documented feature tags to the 57 annotation modules. Before I get to these, I need a new ANNOTATORS category to exist in HelpConstants.java. . I've taken the liberty to name the category ANNOTATORS. Here is the relevant info I added to HelpConstants.java:. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3835
https://github.com/broadinstitute/gatk/pull/3835:370,Modifiability,variab,variable,370,"I'll be adding documented feature tags to the 57 annotation modules. Before I get to these, I need a new ANNOTATORS category to exist in HelpConstants.java. . I've taken the liberty to name the category ANNOTATORS. Here is the relevant info I added to HelpConstants.java:. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3835
https://github.com/broadinstitute/gatk/pull/3836:76,Testability,assert,asserts,76,it seems like the only change necessary was in our code; removing pointless asserts; adding tests the deal with renaming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3836
https://github.com/broadinstitute/gatk/pull/3836:92,Testability,test,tests,92,it seems like the only change necessary was in our code; removing pointless asserts; adding tests the deal with renaming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3836
https://github.com/broadinstitute/gatk/pull/3838:387,Performance,optimiz,optimization,387,"Code is polished and is ready for review. Partial TODO list:; - [ ] (ISSUE TO BE MADE) generate denoising sample summary statistics output (distribution of bias factors, HMM likelihoods, distribution of unexplained variance); - [ ] (ISSUE TO BE MADE) generate plots (training history, GC curves, histogram of unexplained variance, histogram of mean bias); - [ ] (ISSUE TO BE MADE) prior optimization based on real data. In addition, I will also make issues for the TODO comments in the code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838
https://github.com/broadinstitute/gatk/issues/3840:4540,Availability,ERROR,ERROR,4540,"ntVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsof",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:4669,Availability,Error,Error,4669," initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySeria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:7962,Availability,down,down,7962,"5); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8207,Availability,failure,failure,8207,"InputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8294,Availability,Error,Error,8294,"dClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.for",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12767,Availability,ERROR,ERROR,12767,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12868,Availability,ERROR,ERROR,12868,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:3369,Deployability,patch,patch,3369,"verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:43:09.993 INFO PrintVariantsSpark - Deflater: IntelDeflater; 19:43:09.993 INFO PrintVariantsSpark - Inflater: IntelInflater; 19:43:09.993 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 19:43:09.993 INFO PrintVariantsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:43:09.993 INFO PrintVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted applicatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8052,Deployability,pipeline,pipelines,8052,"e0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGSchedule",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12394,Deployability,deploy,deploy,12394,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12431,Deployability,deploy,deploy,12431,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12504,Deployability,deploy,deploy,12504,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12581,Deployability,deploy,deploy,12581,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12653,Deployability,deploy,deploy,12653,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:12723,Deployability,deploy,deploy,12723,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:4563,Energy Efficiency,schedul,scheduler,4563,"rintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:5933,Energy Efficiency,schedul,scheduler,5933,avaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6009,Energy Efficiency,schedul,scheduler,6009,ava:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6121,Energy Efficiency,schedul,scheduler,6121,ware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6226,Energy Efficiency,schedul,scheduler,6226,readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6405,Energy Efficiency,schedul,scheduler,6405,rializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8521,Energy Efficiency,schedul,scheduler,8521,"eadObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8561,Energy Efficiency,schedul,scheduler,8561,"ware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8660,Energy Efficiency,schedul,scheduler,8660," 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8758,Energy Efficiency,schedul,scheduler,8758,"TTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9012,Energy Efficiency,schedul,scheduler,9012,adinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9093,Energy Efficiency,schedul,scheduler,9093,e: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9199,Energy Efficiency,schedul,scheduler,9199,ge failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9349,Energy Efficiency,schedul,scheduler,9349,notypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9438,Energy Efficiency,schedul,scheduler,9438,ellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9536,Energy Efficiency,schedul,scheduler,9536,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9632,Energy Efficiency,schedul,scheduler,9632,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); 	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); 	at org.br,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9797,Energy Efficiency,schedul,scheduler,9797,.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); 	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.computePartitionReadExtents(SparkSharder.java:274); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.joi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1336,Modifiability,variab,variables,1336,"tools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --Q",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1462,Modifiability,config,configured,1462,"tools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --Q",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1523,Performance,Load,Loading,1523,"ark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [Novemb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6486,Performance,concurren,concurrent,6486, 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6571,Performance,concurren,concurrent,6571,zer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esot,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6872,Performance,load,loadClass,6872,"e(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are runn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6942,Performance,load,loadClass,6942,"skResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6998,Performance,load,loadClass,6998,"scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8186,Safety,abort,aborted,8186,"InputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8692,Safety,abort,abortStage,8692,"O org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:8790,Safety,abort,abortStage,8790,"0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:9035,Safety,abort,abortStage,9035,park.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:137,Testability,test,test-,137,"PrintVariantsSpark crashes on dataproc with serialization issues. . Ex:. ```; Running:; gcloud dataproc jobs submit spark --cluster gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:845,Testability,test,test-logs,845,"PrintVariantsSpark crashes on dataproc with serialization issues. . Ex:. ```; Running:; gcloud dataproc jobs submit spark --cluster gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:855,Testability,test,test,855,"PrintVariantsSpark crashes on dataproc with serialization issues. . Ex:. ```; Running:; gcloud dataproc jobs submit spark --cluster gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1007,Testability,test,test,1007,"PrintVariantsSpark crashes on dataproc with serialization issues. . Ex:. ```; Running:; gcloud dataproc jobs submit spark --cluster gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1107,Testability,test,test-logs,1107,"ter gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1117,Testability,test,test,1117,"ter gatk-test-8875b999-b609-4a3f-86ea-973b929fe662 --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1819,Testability,test,test-logs,1819,"rhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1829,Testability,test,test,1829,"rhead=600 --jar gs://hellbender-test-logs/test/staging/lb_staging/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:1920,Testability,test,test,1920,"-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:2572,Testability,test,test-,2572,"ntextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:43:09.993 INFO PrintVariantsSpark - Deflater: IntelDeflater; 19:43:09.993 INFO PrintVariantsSpark - Inflater: IntelInflater; 19:43:09.993 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:3666,Testability,log,log,3666,"o8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:43:09.993 INFO PrintVariantsSpark - Deflater: IntelDeflater; 19:43:09.993 INFO PrintVariantsSpark - Inflater: IntelInflater; 19:43:09.993 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 19:43:09.993 INFO PrintVariantsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:43:09.993 INFO PrintVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserializ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:3671,Testability,Log,Logging,3671,"o8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 19:43:09.993 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:43:09.993 INFO PrintVariantsSpark - Deflater: IntelDeflater; 19:43:09.993 INFO PrintVariantsSpark - Inflater: IntelInflater; 19:43:09.993 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 19:43:09.993 INFO PrintVariantsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:43:09.993 INFO PrintVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserializ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:4216,Testability,test,test-,4216,"later: IntelInflater; 19:43:09.993 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 19:43:09.993 INFO PrintVariantsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:43:09.993 INFO PrintVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoft",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3840:6343,Testability,log,logUncaughtExceptions,6343,oftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.O,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840
https://github.com/broadinstitute/gatk/issues/3841:17,Testability,test,test,17,Need to add more test cases in Funcotator for indels to ensure that all corner cases are being met.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3841
https://github.com/broadinstitute/gatk/issues/3842:544,Testability,test,tests,544,"The `Protein Change` strings that `Funcotator` produces need to be reviewed for consistency and correctness across MAF and VCF. The reported positions should be the first position of a protein anomaly/change, but for some indels this is not the case (they are off by 1). . In all current cases (commented out and labeled), this is a non-issue because they are positions where the amino acid is repeated, so a deletion of one or the other is equivalent, however strictly speaking the positions are wrong. This should result in a new set of unit tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3842
https://github.com/broadinstitute/gatk/issues/3845:531,Availability,error,error,531,"I'm using HaplotypeCaller (`gatk-package-4.beta.5`) to analyse the control medulloblastoma sample from the ICGC benchmark https://www.nature.com/articles/ncomms10001. Reads are aligned to `GRCh37` (from the Broad bundle, without decoy sequences) using `bwa mem`. Analysis is performed within the [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen), which splits input into chunks by chromosome for parallelisation. For some reason, the chunk corresponding to the chromosome `GL000216.1` makes HaplotypeCaller crash with the error `IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1`. I isolated the `gatk-launch` command, and narrowed down the reproducible example to these 2 reads:; ```; H239:179:C1K3VACXX:8:2116:11771:72429 161 GL000216.1 19 23 70S31M 4 49141708 0 ATTCCCTTACATTCGGATTGATACTATTAAAATCACTTACTCTTCCTTACATTCCATTCCATCCGGGCTGTTCCATTTCATTCTATTACACTCCACTCAAT ?1:=D>?B?CC:?A,<C;:AEGC<+AC+++2+:3*1:*11999*:099?<?0?99BBG*9?D*?##################################### NM:i:2 MD:Z:25T2C2 AS:i:25 XS:i:20 RG:Z:MB_normal_50x MQ:i:0 ms:i:1911 mc:i:49141802 MC:Z:11S30M5D60M; HWI-7001436:66:C3FYFACXX:5:1216:4411:82080 65 GL000216.1 27 57 101M 9 72653232 0 CATTCTATTACACTCCATTCCATTTCTATCCATTCCATTCCATTCTATTCCATTCCACTTGGGTCGATTCAATTCCATTCCATTCTATCCCTTCCATTCCA CCCFFFFFHHHHHJJJJJIJJJJJJIJJJJHIJJJJJJJJJJJJJJJJJJJJJJJJJIJIJIJGGIJIJJJJJJJJJJJJJJJJJJGJHHHHHHFFFFFFD NM:i:7 MD:Z:24C2T14A16C1T21C4T12 AS:i:66 XS:i:36 RG:Z:MB_normal_50x MQ:i:0 ms:i:3858 mc:i:72653218 MC:Z:14S45M1D33M9; ```; And one nucleotide target region:; ```; GL000216.1 87 88; ```. These BAM and BED files are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:684,Availability,down,down,684,"I'm using HaplotypeCaller (`gatk-package-4.beta.5`) to analyse the control medulloblastoma sample from the ICGC benchmark https://www.nature.com/articles/ncomms10001. Reads are aligned to `GRCh37` (from the Broad bundle, without decoy sequences) using `bwa mem`. Analysis is performed within the [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen), which splits input into chunks by chromosome for parallelisation. For some reason, the chunk corresponding to the chromosome `GL000216.1` makes HaplotypeCaller crash with the error `IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1`. I isolated the `gatk-launch` command, and narrowed down the reproducible example to these 2 reads:; ```; H239:179:C1K3VACXX:8:2116:11771:72429 161 GL000216.1 19 23 70S31M 4 49141708 0 ATTCCCTTACATTCGGATTGATACTATTAAAATCACTTACTCTTCCTTACATTCCATTCCATCCGGGCTGTTCCATTTCATTCTATTACACTCCACTCAAT ?1:=D>?B?CC:?A,<C;:AEGC<+AC+++2+:3*1:*11999*:099?<?0?99BBG*9?D*?##################################### NM:i:2 MD:Z:25T2C2 AS:i:25 XS:i:20 RG:Z:MB_normal_50x MQ:i:0 ms:i:1911 mc:i:49141802 MC:Z:11S30M5D60M; HWI-7001436:66:C3FYFACXX:5:1216:4411:82080 65 GL000216.1 27 57 101M 9 72653232 0 CATTCTATTACACTCCATTCCATTTCTATCCATTCCATTCCATTCTATTCCATTCCACTTGGGTCGATTCAATTCCATTCCATTCTATCCCTTCCATTCCA CCCFFFFFHHHHHJJJJJIJJJJJJIJJJJHIJJJJJJJJJJJJJJJJJJJJJJJJJIJIJIJGGIJIJJJJJJJJJJJJJJJJJJGJHHHHHHFFFFFFD NM:i:7 MD:Z:24C2T14A16C1T21C4T12 AS:i:66 XS:i:36 RG:Z:MB_normal_50x MQ:i:0 ms:i:3858 mc:i:72653218 MC:Z:14S45M1D33M9; ```; And one nucleotide target region:; ```; GL000216.1 87 88; ```. These BAM and BED files are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:4463,Availability,recover,recoverDanglingHeads,4463,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:4612,Availability,error,errorCorrectKmers,4612,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:5279,Availability,error,errorCorrectReads,5279,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:8813,Availability,Avail,Available,8813,"p from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:9365,Availability,down,down,9365,"/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:11865,Availability,error,error,11865,"r.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:82); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:242); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:496); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:254); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:231); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); at org.broadinstitute.hellbender.Main.main(Main.java:239); ```. Attempts with different regions (e.g. neighbouring positions 86 or 88 at this chromosome, or other sets of reads, or taking one of the culprit reads alone) didn't give me the error. Can you suggest what I'm doing wrong?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:7462,Deployability,patch,patch,7462,"help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilter; s false --minimumMappingQuality 20; [16 November 2017 4:51:50 PM] Executing as vlad@spartan.hpc.unimelb.edu.au on Linux 4.13.12-1.el7.elrepo.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b15; Version: 4.beta.5; 16:51:50.648 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:51:50.648 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:51:50.649 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:51:50.649 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:51:50.649 INFO HaplotypeCaller - Deflater: IntelDeflater; 16:51:50.649 INFO HaplotypeCaller - Inflater: IntelInflater; 16:51:50.649 INFO HaplotypeCaller - GCS max retries/reopens: 20; 16:51:50.649 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:51:50.649 INFO HaplotypeCaller - Initializing engine; 16:51:51.056 INFO FeatureManager - Using codec BEDCodec to read file file:///home/vlad/tmp/debug_gatk/bad_87-88.bed; 16:51:51.063 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:275,Performance,perform,performed,275,"I'm using HaplotypeCaller (`gatk-package-4.beta.5`) to analyse the control medulloblastoma sample from the ICGC benchmark https://www.nature.com/articles/ncomms10001. Reads are aligned to `GRCh37` (from the Broad bundle, without decoy sequences) using `bwa mem`. Analysis is performed within the [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen), which splits input into chunks by chromosome for parallelisation. For some reason, the chunk corresponding to the chromosome `GL000216.1` makes HaplotypeCaller crash with the error `IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1`. I isolated the `gatk-launch` command, and narrowed down the reproducible example to these 2 reads:; ```; H239:179:C1K3VACXX:8:2116:11771:72429 161 GL000216.1 19 23 70S31M 4 49141708 0 ATTCCCTTACATTCGGATTGATACTATTAAAATCACTTACTCTTCCTTACATTCCATTCCATCCGGGCTGTTCCATTTCATTCTATTACACTCCACTCAAT ?1:=D>?B?CC:?A,<C;:AEGC<+AC+++2+:3*1:*11999*:099?<?0?99BBG*9?D*?##################################### NM:i:2 MD:Z:25T2C2 AS:i:25 XS:i:20 RG:Z:MB_normal_50x MQ:i:0 ms:i:1911 mc:i:49141802 MC:Z:11S30M5D60M; HWI-7001436:66:C3FYFACXX:5:1216:4411:82080 65 GL000216.1 27 57 101M 9 72653232 0 CATTCTATTACACTCCATTCCATTTCTATCCATTCCATTCCATTCTATTCCATTCCACTTGGGTCGATTCAATTCCATTCCATTCTATCCCTTCCATTCCA CCCFFFFFHHHHHJJJJJIJJJJJJIJJJJHIJJJJJJJJJJJJJJJJJJJJJJJJJIJIJIJGGIJIJJJJJJJJJJJJJJJJJJGJHHHHHHFFFFFFD NM:i:7 MD:Z:24C2T14A16C1T21C4T12 AS:i:66 XS:i:36 RG:Z:MB_normal_50x MQ:i:0 ms:i:3858 mc:i:72653218 MC:Z:14S45M1D33M9; ```; And one nucleotide target region:; ```; GL000216.1 87 88; ```. These BAM and BED files are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:2616,Performance,Load,Loading,2616,iles are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives the following output: ; ```; Using GATK jar /home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar HaplotypeCaller -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --output bad.vcf.gz -I GL000216.1_49-49__84-88__play.bam -L; bad_87-88.bed; 16:51:50.560 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [16 November 2017 4:51:50 PM] HaplotypeCaller --output bad.vcf.gz --intervals bad_87-88.bed --input GL000216.1_49-49__84-88__play.bam --reference /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9; --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 --GVCFGQBands 14 --GVCFGQBands 15 --GVCFGQBands 16 --GVCFGQBands 17 --GVCFGQBands 18 --GVCFGQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBand,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:8332,Performance,Load,Loading,8332,"Inflater; 16:51:50.649 INFO HaplotypeCaller - GCS max retries/reopens: 20; 16:51:50.649 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:51:50.649 INFO HaplotypeCaller - Initializing engine; 16:51:51.056 INFO FeatureManager - Using codec BEDCodec to read file file:///home/vlad/tmp/debug_gatk/bad_87-88.bed; 16:51:51.063 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:8527,Performance,Load,Loading,8527,"hub.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:51:50.649 INFO HaplotypeCaller - Initializing engine; 16:51:51.056 INFO FeatureManager - Using codec BEDCodec to read file file:///home/vlad/tmp/debug_gatk/bad_87-88.bed; 16:51:51.063 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtim",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:8936,Performance,multi-thread,multi-threaded,8936,"ical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:4463,Safety,recover,recoverDanglingHeads,4463,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3845:112,Testability,benchmark,benchmark,112,"I'm using HaplotypeCaller (`gatk-package-4.beta.5`) to analyse the control medulloblastoma sample from the ICGC benchmark https://www.nature.com/articles/ncomms10001. Reads are aligned to `GRCh37` (from the Broad bundle, without decoy sequences) using `bwa mem`. Analysis is performed within the [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen), which splits input into chunks by chromosome for parallelisation. For some reason, the chunk corresponding to the chromosome `GL000216.1` makes HaplotypeCaller crash with the error `IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1`. I isolated the `gatk-launch` command, and narrowed down the reproducible example to these 2 reads:; ```; H239:179:C1K3VACXX:8:2116:11771:72429 161 GL000216.1 19 23 70S31M 4 49141708 0 ATTCCCTTACATTCGGATTGATACTATTAAAATCACTTACTCTTCCTTACATTCCATTCCATCCGGGCTGTTCCATTTCATTCTATTACACTCCACTCAAT ?1:=D>?B?CC:?A,<C;:AEGC<+AC+++2+:3*1:*11999*:099?<?0?99BBG*9?D*?##################################### NM:i:2 MD:Z:25T2C2 AS:i:25 XS:i:20 RG:Z:MB_normal_50x MQ:i:0 ms:i:1911 mc:i:49141802 MC:Z:11S30M5D60M; HWI-7001436:66:C3FYFACXX:5:1216:4411:82080 65 GL000216.1 27 57 101M 9 72653232 0 CATTCTATTACACTCCATTCCATTTCTATCCATTCCATTCCATTCTATTCCATTCCACTTGGGTCGATTCAATTCCATTCCATTCTATCCCTTCCATTCCA CCCFFFFFHHHHHJJJJJIJJJJJJIJJJJHIJJJJJJJJJJJJJJJJJJJJJJJJJIJIJIJGGIJIJJJJJJJJJJJJJJJJJJGJHHHHHHFFFFFFD NM:i:7 MD:Z:24C2T14A16C1T21C4T12 AS:i:66 XS:i:36 RG:Z:MB_normal_50x MQ:i:0 ms:i:3858 mc:i:72653218 MC:Z:14S45M1D33M9; ```; And one nucleotide target region:; ```; GL000216.1 87 88; ```. These BAM and BED files are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845
https://github.com/broadinstitute/gatk/issues/3847:130,Testability,test,test,130,"In <https://github.com/broadinstitute/dsde-docs/issues/2639> we agreed to tag all tools, regardless of status (alpha, deprecated, test tools), so long as straightforward to do so, with the documentedfeature tag. This allows the javaDoc portion of the tooldoc to show up in our forum (gatkDoc). ### Tools missing from gatkDocs that show up in `--list`that we need documentation to show up for this year; - [x] CalculatePulldownPhasePosteriors; - [x] GetSampleName; - [x] PathSeqBuildKmers; - [x] PathSeqBuildReferenceTaxonomy; - [x] PathSeqBwaSpark; - [x] PathSeqFilterSpark; - [x] PathSeqPipelineSpark; - [x] PathSeqScoreSpark; - [x] ASEReadCounter; - [x] CompareBaseQualities; - [x] FixMisencodedBaseQualityReads; - [x] LeftAlignIndels; - [x] RevertBaseQualityScores; - [x] SplitNCigarReads; - [x] UnmarkDuplicates; - [x] DiscoverVariantsFromContigAlignmentsSAMSpark; - [x] FindBadGenomicKmersSpark; - [x] FindBreakpointEvidenceSpark; - [x] StructuralVariationDiscoveryPipelineSpark; - [x] BwaSpark; - [x] MarkDuplicatesSpark; - [x] MeanQualityByCycleSpark; - [x] ParallelCopyGCSDirectoryIntoHDFSSpark; - [x] QualityScoreDistributionSpark; - [x] SortReadFileSpark; - [x] AnnotatePairOrientation; - [x] CountVariants; - [x] GatherVcfsCloud; - [x] GenomicsDBImport; - [x] BwaMemIndexImageCreator; - [x] CompareDuplicatesSpark; - [x] ConvertHeaderlessHadoopBamShardToBam. 32 total. #### Those needing tags within the Picard repo:; - [x] CollectIndependentReplicateMetrics; - [x] CollectWgsMetricsWithNonZeroCoverage; - [x] UmiAwareMarkDuplicatesWithMateCigar; - [x] CrosscheckReadGroupFingerprints; - [x] SetNmAndUqTags; - [x] SimpleMarkDuplicatesWithMateCigar. Also added `@BetaFeature` tag and `(Experimental)` label in summary to first three, given they are currently categorized under ; ```; Alpha Tools: | Tools that are currently UNSUPPORTED until further testing and maturation.; -- | --; ```. ---; ### Tools missing from `--list` that show up in gatkDocs ; - [x] CallCopyRatioSegments `added bet",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3847
https://github.com/broadinstitute/gatk/issues/3847:1860,Testability,test,testing,1860,"s; - [x] GetSampleName; - [x] PathSeqBuildKmers; - [x] PathSeqBuildReferenceTaxonomy; - [x] PathSeqBwaSpark; - [x] PathSeqFilterSpark; - [x] PathSeqPipelineSpark; - [x] PathSeqScoreSpark; - [x] ASEReadCounter; - [x] CompareBaseQualities; - [x] FixMisencodedBaseQualityReads; - [x] LeftAlignIndels; - [x] RevertBaseQualityScores; - [x] SplitNCigarReads; - [x] UnmarkDuplicates; - [x] DiscoverVariantsFromContigAlignmentsSAMSpark; - [x] FindBadGenomicKmersSpark; - [x] FindBreakpointEvidenceSpark; - [x] StructuralVariationDiscoveryPipelineSpark; - [x] BwaSpark; - [x] MarkDuplicatesSpark; - [x] MeanQualityByCycleSpark; - [x] ParallelCopyGCSDirectoryIntoHDFSSpark; - [x] QualityScoreDistributionSpark; - [x] SortReadFileSpark; - [x] AnnotatePairOrientation; - [x] CountVariants; - [x] GatherVcfsCloud; - [x] GenomicsDBImport; - [x] BwaMemIndexImageCreator; - [x] CompareDuplicatesSpark; - [x] ConvertHeaderlessHadoopBamShardToBam. 32 total. #### Those needing tags within the Picard repo:; - [x] CollectIndependentReplicateMetrics; - [x] CollectWgsMetricsWithNonZeroCoverage; - [x] UmiAwareMarkDuplicatesWithMateCigar; - [x] CrosscheckReadGroupFingerprints; - [x] SetNmAndUqTags; - [x] SimpleMarkDuplicatesWithMateCigar. Also added `@BetaFeature` tag and `(Experimental)` label in summary to first three, given they are currently categorized under ; ```; Alpha Tools: | Tools that are currently UNSUPPORTED until further testing and maturation.; -- | --; ```. ---; ### Tools missing from `--list` that show up in gatkDocs ; - [x] CallCopyRatioSegments `added beta tag`; - PlotDenoisedCopyRatios; - PlotModeledSegments. These in fact have the `CommandLineArgumentProperties` and should show up if I build from master. They just don't show up for beta.6. Added `@BetaFeature` tag to CallCopyRatioSegments. ### Tools missing altogether from lists and docs; - [ ] DepthOfCoverage; - [ ] VariantAnnotator; - [ ] CombineGVCFs; - [ ] Funcotator; - there are likely others; we will get to them as they come up",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3847
https://github.com/broadinstitute/gatk/issues/3847:1625,Usability,Simpl,SimpleMarkDuplicatesWithMateCigar,1625,"s; - [x] GetSampleName; - [x] PathSeqBuildKmers; - [x] PathSeqBuildReferenceTaxonomy; - [x] PathSeqBwaSpark; - [x] PathSeqFilterSpark; - [x] PathSeqPipelineSpark; - [x] PathSeqScoreSpark; - [x] ASEReadCounter; - [x] CompareBaseQualities; - [x] FixMisencodedBaseQualityReads; - [x] LeftAlignIndels; - [x] RevertBaseQualityScores; - [x] SplitNCigarReads; - [x] UnmarkDuplicates; - [x] DiscoverVariantsFromContigAlignmentsSAMSpark; - [x] FindBadGenomicKmersSpark; - [x] FindBreakpointEvidenceSpark; - [x] StructuralVariationDiscoveryPipelineSpark; - [x] BwaSpark; - [x] MarkDuplicatesSpark; - [x] MeanQualityByCycleSpark; - [x] ParallelCopyGCSDirectoryIntoHDFSSpark; - [x] QualityScoreDistributionSpark; - [x] SortReadFileSpark; - [x] AnnotatePairOrientation; - [x] CountVariants; - [x] GatherVcfsCloud; - [x] GenomicsDBImport; - [x] BwaMemIndexImageCreator; - [x] CompareDuplicatesSpark; - [x] ConvertHeaderlessHadoopBamShardToBam. 32 total. #### Those needing tags within the Picard repo:; - [x] CollectIndependentReplicateMetrics; - [x] CollectWgsMetricsWithNonZeroCoverage; - [x] UmiAwareMarkDuplicatesWithMateCigar; - [x] CrosscheckReadGroupFingerprints; - [x] SetNmAndUqTags; - [x] SimpleMarkDuplicatesWithMateCigar. Also added `@BetaFeature` tag and `(Experimental)` label in summary to first three, given they are currently categorized under ; ```; Alpha Tools: | Tools that are currently UNSUPPORTED until further testing and maturation.; -- | --; ```. ---; ### Tools missing from `--list` that show up in gatkDocs ; - [x] CallCopyRatioSegments `added beta tag`; - PlotDenoisedCopyRatios; - PlotModeledSegments. These in fact have the `CommandLineArgumentProperties` and should show up if I build from master. They just don't show up for beta.6. Added `@BetaFeature` tag to CallCopyRatioSegments. ### Tools missing altogether from lists and docs; - [ ] DepthOfCoverage; - [ ] VariantAnnotator; - [ ] CombineGVCFs; - [ ] Funcotator; - there are likely others; we will get to them as they come up",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3847
https://github.com/broadinstitute/gatk/issues/3849:193,Availability,DOWN,DOWNSTREAM,193,"Currently `Funcotator` annotates IGR ""other transcripts"" entries as ""IGR_ANNOTATION"". This must be fixed to be correct. The correct format is:. <UPSTREAM GENE NAME>(<# bases away> upstream) : <DOWNSTREAM GENE NAME>(<# bases away> downstream)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3849
https://github.com/broadinstitute/gatk/issues/3849:230,Availability,down,downstream,230,"Currently `Funcotator` annotates IGR ""other transcripts"" entries as ""IGR_ANNOTATION"". This must be fixed to be correct. The correct format is:. <UPSTREAM GENE NAME>(<# bases away> upstream) : <DOWNSTREAM GENE NAME>(<# bases away> downstream)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3849
https://github.com/broadinstitute/gatk/pull/3851:260,Modifiability,plugin,plugins,260,"Note: these are not hooked up to the code anywhere, I have another branch where I am doing the work to plug these in. This also does not currently resolve the equivalent issue to https://github.com/broadinstitute/gatk/issues/3848 but it does add tests to both plugins enforcing what the correct behavior should be. . fixes #3624",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3851
https://github.com/broadinstitute/gatk/pull/3851:246,Testability,test,tests,246,"Note: these are not hooked up to the code anywhere, I have another branch where I am doing the work to plug these in. This also does not currently resolve the equivalent issue to https://github.com/broadinstitute/gatk/issues/3848 but it does add tests to both plugins enforcing what the correct behavior should be. . fixes #3624",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3851
https://github.com/broadinstitute/gatk/issues/3853:166,Deployability,a/b,a/broadinstitute,166,Thank you everyone for your contributions towards this documentation effort. ; Instructions from @vdauwera ~~to follow~~ at [this Google doc](https://docs.google.com/a/broadinstitute.org/document/d/1r1AV4yWP4_vNmniUDR5LojihuggMDI2OnEpfRiYyvdk/edit?usp=sharing); Favorite tool doc examples from @vdauwera NOW in her SOP doc.; Spreadsheet from @sooheelee ~~to be~~ posted [here](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853
https://github.com/broadinstitute/gatk/issues/3853:401,Deployability,a/b,a/broadinstitute,401,Thank you everyone for your contributions towards this documentation effort. ; Instructions from @vdauwera ~~to follow~~ at [this Google doc](https://docs.google.com/a/broadinstitute.org/document/d/1r1AV4yWP4_vNmniUDR5LojihuggMDI2OnEpfRiYyvdk/edit?usp=sharing); Favorite tool doc examples from @vdauwera NOW in her SOP doc.; Spreadsheet from @sooheelee ~~to be~~ posted [here](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853
https://github.com/broadinstitute/gatk/pull/3854:54,Deployability,upgrade,upgrade,54,upgrading to htsjdk 2.13.1; 4 commits; 1. is the bare upgrade to 2.13.0 with deprecations fixed; 2. replacing our custom NON_REF_SYMBOLIC_ALLELE with the newly introduced one in HTSJDK Allele; 3. replacing our ClassFinder with the newly introduced one in htsjdk; 4. update to 2.13.1 which has an important bug fix,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3854
https://github.com/broadinstitute/gatk/pull/3854:266,Deployability,update,update,266,upgrading to htsjdk 2.13.1; 4 commits; 1. is the bare upgrade to 2.13.0 with deprecations fixed; 2. replacing our custom NON_REF_SYMBOLIC_ALLELE with the newly introduced one in HTSJDK Allele; 3. replacing our ClassFinder with the newly introduced one in htsjdk; 4. update to 2.13.1 which has an important bug fix,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3854
https://github.com/broadinstitute/gatk/pull/3858:64,Testability,test,tests,64,"I had to implement a few other features in order to get my unit tests to function properly, so this contains fixes for a few different issues (sorry). Adding in functionality to:. - Only create annotations for a specific set of transcripts via a command-line flag.; - Select the most detailed annotation for a transcript to be in ""cannonical"" or ""best effect"" order. Fixes #3780.; Fixes #3781.; Fixes #3782.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3858
https://github.com/broadinstitute/gatk/issues/3861:21,Testability,test,test,21,Create a large scale test that verifies that the `GenomicsDBImport` sampleMap argument can handle renaming with a large number of files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3861
https://github.com/broadinstitute/gatk/issues/3862:84,Availability,Error,Error,84,If I try to navigate to https://gatk-jenkins.broadinstitute.org/ I get:. ```; Proxy Error. The proxy server received an invalid response from an upstream server.; The proxy server could not handle the request GET /. Reason: Error reading from remote server. Apache Server at gatk-jenkins.broadinstitute.org Port 443; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3862
https://github.com/broadinstitute/gatk/issues/3862:224,Availability,Error,Error,224,If I try to navigate to https://gatk-jenkins.broadinstitute.org/ I get:. ```; Proxy Error. The proxy server received an invalid response from an upstream server.; The proxy server could not handle the request GET /. Reason: Error reading from remote server. Apache Server at gatk-jenkins.broadinstitute.org Port 443; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3862
https://github.com/broadinstitute/gatk/issues/3864:80,Deployability,pipeline,pipelines,80,"In particular, we are a little lax on sequence-dictionary validation in the CNV pipelines. However, it might be that this is a necessary evil---it seems sequence dictionaries are somewhat inconsistent even in datasets such as TCGA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3864
https://github.com/broadinstitute/gatk/issues/3864:58,Security,validat,validation,58,"In particular, we are a little lax on sequence-dictionary validation in the CNV pipelines. However, it might be that this is a necessary evil---it seems sequence dictionaries are somewhat inconsistent even in datasets such as TCGA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3864
https://github.com/broadinstitute/gatk/pull/3866:93,Deployability,install,install,93,This makes the Docker container more interoperable with other GATK containers that might not install to /gatk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866
https://github.com/broadinstitute/gatk/pull/3866:37,Integrability,interoperab,interoperable,37,This makes the Docker container more interoperable with other GATK containers that might not install to /gatk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866
https://github.com/broadinstitute/gatk/pull/3868:253,Availability,repair,repair,253,"Included a test case generated using the buggy version of GenomicsDBImport in which the sample names declared in the file headers did not always match the samples provided to GenomicsDBImport via the sample name map file, and showed that the tool could repair the callset successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3868
https://github.com/broadinstitute/gatk/pull/3868:11,Testability,test,test,11,"Included a test case generated using the buggy version of GenomicsDBImport in which the sample names declared in the file headers did not always match the samples provided to GenomicsDBImport via the sample name map file, and showed that the tool could repair the callset successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3868
https://github.com/broadinstitute/gatk/pull/3869:25,Deployability,update,update,25,It looks like the HTSJDK update branch changed a few engine constants and that wasn't pulled into the combineGVCFs branch before merging.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3869
https://github.com/broadinstitute/gatk/issues/3870:61,Deployability,update,updated,61,"The version of dbSNP at the research bundle is 138 for hg19 (updated 8.12.2013), but the latest dbSNP version is 150: [https://www.ncbi.nlm.nih.gov/projects/SNP/snp_summary.cgi?view+summary=view+summary&build_id=150](url) . Is it going to affect my results much if I use 138 instead of 150?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3870
https://github.com/broadinstitute/gatk/pull/3871:208,Availability,error,error,208,Fix two bugs in multiple alignment assembly contig classification:; 1. arguments passed in wrong order leading to wrong contigs being filtered out and wrong contigs being sent to call variants; 2. copy-paste error in detecting reference order switch between head/tail alignments (predicate essentially always return true). Added tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3871
https://github.com/broadinstitute/gatk/pull/3871:217,Safety,detect,detecting,217,Fix two bugs in multiple alignment assembly contig classification:; 1. arguments passed in wrong order leading to wrong contigs being filtered out and wrong contigs being sent to call variants; 2. copy-paste error in detecting reference order switch between head/tail alignments (predicate essentially always return true). Added tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3871
https://github.com/broadinstitute/gatk/pull/3871:329,Testability,test,tests,329,Fix two bugs in multiple alignment assembly contig classification:; 1. arguments passed in wrong order leading to wrong contigs being filtered out and wrong contigs being sent to call variants; 2. copy-paste error in detecting reference order switch between head/tail alignments (predicate essentially always return true). Added tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3871
https://github.com/broadinstitute/gatk/pull/3872:182,Modifiability,refactor,refactored,182,"This contains the streaming Python executor, implemented by a (Python-independent) StreamingProcessController. The StreamingProcessController, and the existing ProcessController are refactored to use a shared ProcessControllerBase, and changed from using raw Threads and Runnables to using an ExecutorService with Futures and Callables.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3872
https://github.com/broadinstitute/gatk/issues/3874:2099,Energy Efficiency,schedul,scheduler,2099,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:2179,Energy Efficiency,schedul,scheduler,2179,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:2259,Energy Efficiency,schedul,scheduler,2259,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:1347,Integrability,Wrap,WrappingSpliterator,1347,terval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:1689,Integrability,Wrap,WrappingSpliterator,1689,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:1847,Integrability,Wrap,Wrappers,1847,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:1881,Integrability,Wrap,Wrappers,1881,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:2383,Performance,concurren,concurrent,2383,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:2468,Performance,concurren,concurrent,2468,Breakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:237,Security,validat,validateArg,237,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:321,Security,validat,validatePositions,321,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:306,Usability,Simpl,SimpleInterval,306,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:339,Usability,Simpl,SimpleInterval,339,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:404,Usability,Simpl,SimpleInterval,404,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3874:426,Usability,Simpl,SimpleInterval,426,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874
https://github.com/broadinstitute/gatk/issues/3875:313,Safety,avoid,avoid,313,"It seems that the tool `FilterByOrientationBias` has the argument `--artifactModes` which has the command line abbreviation `-A`. Unfortunately this abbreviation collides with the enshrined `-A` abbreviation for `--annotation` for tools that deal with variants. I would propose we change the argument to `-AM` to avoid naming collisions. If we want to make this change, we should probably do it soon before it becomes too painful to reverse.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3875
https://github.com/broadinstitute/gatk/pull/3876:144,Deployability,patch,patches,144,"Previous behavior assumed that the NM tag was the number of substitutions (as would be implied by ""matches or mismatches"" in CIGAR lingo). This patches makes the function correctly account for indels as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3876
https://github.com/broadinstitute/gatk/pull/3877:9,Safety,avoid,avoid,9,So as to avoid a conflict with -A for annotations. closes #3875,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3877
https://github.com/broadinstitute/gatk/issues/3878:1038,Availability,error,error,1038,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:1162,Availability,ERROR,ERROR,1162,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:99,Deployability,pipeline,pipeline,99,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:832,Deployability,pipeline,pipeline,832,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:842,Safety,avoid,avoiding,842,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:1175,Safety,Abort,Aborting,1175,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3878:564,Usability,clear,clearer,564,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878
https://github.com/broadinstitute/gatk/issues/3881:114,Usability,simpl,simpleInterval,114,"I am trying to use GATK source code to get read depth at a base, what should I do? . As far as I know, there is a simpleInterval class I can use to pass the genome region I want to inspect. But I don't know where should I pass the simpleInterval and get the read depth. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3881
https://github.com/broadinstitute/gatk/issues/3881:231,Usability,simpl,simpleInterval,231,"I am trying to use GATK source code to get read depth at a base, what should I do? . As far as I know, there is a simpleInterval class I can use to pass the genome region I want to inspect. But I don't know where should I pass the simpleInterval and get the read depth. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3881
https://github.com/broadinstitute/gatk/issues/3887:67,Performance,Perform,PerformAlleleFractionSegmentation,67,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887
https://github.com/broadinstitute/gatk/issues/3887:102,Performance,Perform,PerformCopyRatioSegmentation,102,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887
https://github.com/broadinstitute/gatk/issues/3887:132,Performance,Perform,PerformJointSegmentation,132,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887
https://github.com/broadinstitute/gatk/issues/3887:342,Security,validat,validation,342,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887
https://github.com/broadinstitute/gatk/issues/3890:138,Testability,test,test,138,"First with a flag in the tool that allows user to choose which code path to use, the existing version or the prototyping version. But the test coverage is still low and should be improved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3890
https://github.com/broadinstitute/gatk/pull/3891:0,Deployability,Update,Updated,0,Updated docs with usage examples and kebabed long args for:; - HaplotypeCaller; - HaplotypeCallerSpark; - CombineGVCFs; - GenomicsDBImport; - GenotypeGVCFs; - VariantFiltration; - ASEReadCounter; - SplitNCigarReads; - CalculateGenotypePosteriors; - VariantRecalibrator; - ApplyVQSR. Elaborated on/fixed docs for:; - InbreedingCoeff; - ExcessHet; - SampleList. Hid GatherTranches. Added a ReadTransformer to SplitNCigarReads to simplify the command from the old RNA best practices (https://software.broadinstitute.org/gatk/documentation/article.php?id=3891) NOTE: this slightly changes the default behavior @vdauwera . Unfortunately I squashed the SplitNCigarReads changes into the doc fixes. :( If that's a problem I can split into two commits.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891
https://github.com/broadinstitute/gatk/pull/3891:427,Usability,simpl,simplify,427,Updated docs with usage examples and kebabed long args for:; - HaplotypeCaller; - HaplotypeCallerSpark; - CombineGVCFs; - GenomicsDBImport; - GenotypeGVCFs; - VariantFiltration; - ASEReadCounter; - SplitNCigarReads; - CalculateGenotypePosteriors; - VariantRecalibrator; - ApplyVQSR. Elaborated on/fixed docs for:; - InbreedingCoeff; - ExcessHet; - SampleList. Hid GatherTranches. Added a ReadTransformer to SplitNCigarReads to simplify the command from the old RNA best practices (https://software.broadinstitute.org/gatk/documentation/article.php?id=3891) NOTE: this slightly changes the default behavior @vdauwera . Unfortunately I squashed the SplitNCigarReads changes into the doc fixes. :( If that's a problem I can split into two commits.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891
https://github.com/broadinstitute/gatk/pull/3892:118,Availability,down,down,118,I'm sick of scrolling to the bottom to find the test report uri.; This saves the pain of having to scroll all the way down.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3892
https://github.com/broadinstitute/gatk/pull/3892:48,Testability,test,test,48,I'm sick of scrolling to the bottom to find the test report uri.; This saves the pain of having to scroll all the way down.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3892
https://github.com/broadinstitute/gatk/pull/3897:264,Deployability,integrat,integration,264,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897
https://github.com/broadinstitute/gatk/pull/3897:264,Integrability,integrat,integration,264,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897
https://github.com/broadinstitute/gatk/pull/3897:276,Testability,test,tests,276,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897
https://github.com/broadinstitute/gatk/pull/3897:141,Usability,Simpl,SimpleKeyXsvFuncotationFactory,141,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897
https://github.com/broadinstitute/gatk/pull/3897:183,Usability,usab,usable,183,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897
https://github.com/broadinstitute/gatk/issues/3898:47,Modifiability,config,config,47,"This codec should check for the existence of a config file next to the specified file which will inform the parser of the columns from which to parse the `contig`, `start`, and `end` locations from columns.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3898
https://github.com/broadinstitute/gatk/issues/3899:200,Availability,avail,available,200,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3899:397,Modifiability,variab,variables,397,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3899:702,Modifiability,variab,variable,702,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3899:162,Testability,test,test,162,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3899:438,Testability,test,tested,438,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3899:342,Usability,simpl,simpler,342,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899
https://github.com/broadinstitute/gatk/issues/3900:1602,Availability,down,downstream,1602,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:2288,Availability,down,downstream,2288,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:1462,Deployability,pipeline,pipeline,1462,"dules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:320,Integrability,depend,dependencies,320,"The current GATK framework is increasing in size and functionality a lot (engine, CNV, different tools, etc.). For example, the gCNV code from #3838, will include a full python framework to be use in conjunction with the GATK CNV code. In gatk3, different artifacts were generated to allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:860,Integrability,depend,dependency,860,"The current GATK framework is increasing in size and functionality a lot (engine, CNV, different tools, etc.). For example, the gCNV code from #3838, will include a full python framework to be use in conjunction with the GATK CNV code. In gatk3, different artifacts were generated to allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:1053,Integrability,interface,interface,1053,"t (engine, CNV, different tools, etc.). For example, the gCNV code from #3838, will include a full python framework to be use in conjunction with the GATK CNV code. In gatk3, different artifacts were generated to allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:1304,Integrability,depend,dependency,1304,"o allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for document",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:1445,Integrability,depend,depending,1445,"dules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:2193,Integrability,depend,dependent,2193,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:2055,Testability,test,testing,2055,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/issues/3900:2087,Testability,test,testing,2087,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900
https://github.com/broadinstitute/gatk/pull/3903:89,Performance,Perform,PerformAlleleFractionSegmentation,89,"This removes the following tools and associated code:. CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper; TargetCoverageSexGenotyper; GermlineCNVCaller; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls. Note that some evaluation code associated with the last two tools was deleted as it was too specific to copy-number tri-state calls. This code could possibly be made more general and reusable, but we can always salvage it from an earlier commit. I also retained various utility classes associated with gCNV (icg, linalg, nd4j, and solver). I have not been careful to delete all test resources, since there are many test resources left dangling by other branches as well. EDIT: I've done this in another PR (#3907). See #3905. Closes #3887.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903
https://github.com/broadinstitute/gatk/pull/3903:124,Performance,Perform,PerformCopyRatioSegmentation,124,"This removes the following tools and associated code:. CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper; TargetCoverageSexGenotyper; GermlineCNVCaller; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls. Note that some evaluation code associated with the last two tools was deleted as it was too specific to copy-number tri-state calls. This code could possibly be made more general and reusable, but we can always salvage it from an earlier commit. I also retained various utility classes associated with gCNV (icg, linalg, nd4j, and solver). I have not been careful to delete all test resources, since there are many test resources left dangling by other branches as well. EDIT: I've done this in another PR (#3907). See #3905. Closes #3887.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903
https://github.com/broadinstitute/gatk/pull/3903:154,Performance,Perform,PerformJointSegmentation,154,"This removes the following tools and associated code:. CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper; TargetCoverageSexGenotyper; GermlineCNVCaller; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls. Note that some evaluation code associated with the last two tools was deleted as it was too specific to copy-number tri-state calls. This code could possibly be made more general and reusable, but we can always salvage it from an earlier commit. I also retained various utility classes associated with gCNV (icg, linalg, nd4j, and solver). I have not been careful to delete all test resources, since there are many test resources left dangling by other branches as well. EDIT: I've done this in another PR (#3907). See #3905. Closes #3887.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903
https://github.com/broadinstitute/gatk/pull/3903:708,Testability,test,test,708,"This removes the following tools and associated code:. CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper; TargetCoverageSexGenotyper; GermlineCNVCaller; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls. Note that some evaluation code associated with the last two tools was deleted as it was too specific to copy-number tri-state calls. This code could possibly be made more general and reusable, but we can always salvage it from an earlier commit. I also retained various utility classes associated with gCNV (icg, linalg, nd4j, and solver). I have not been careful to delete all test resources, since there are many test resources left dangling by other branches as well. EDIT: I've done this in another PR (#3907). See #3905. Closes #3887.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903
https://github.com/broadinstitute/gatk/pull/3903:745,Testability,test,test,745,"This removes the following tools and associated code:. CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper; TargetCoverageSexGenotyper; GermlineCNVCaller; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls. Note that some evaluation code associated with the last two tools was deleted as it was too specific to copy-number tri-state calls. This code could possibly be made more general and reusable, but we can always salvage it from an earlier commit. I also retained various utility classes associated with gCNV (icg, linalg, nd4j, and solver). I have not been careful to delete all test resources, since there are many test resources left dangling by other branches as well. EDIT: I've done this in another PR (#3907). See #3905. Closes #3887.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903
https://github.com/broadinstitute/gatk/issues/3904:22,Testability,test,test,22,"Are some of the FASTA test files misnamed? For example, src/test/resources/large/human_g1k_v37.20.21.fasta seems to only include chr20, but the associated dict and fai include chr21 as well. Is this intentional?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3904
https://github.com/broadinstitute/gatk/issues/3904:60,Testability,test,test,60,"Are some of the FASTA test files misnamed? For example, src/test/resources/large/human_g1k_v37.20.21.fasta seems to only include chr20, but the associated dict and fai include chr21 as well. Is this intentional?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3904
https://github.com/broadinstitute/gatk/issues/3905:291,Availability,echo,echo,291,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21165,Deployability,pipeline,pipeline,21165,org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21264,Deployability,pipeline,pipeline,21264,uality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; sr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29037,Deployability,integrat,integration,29037,s/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29138,Deployability,integrat,integration,29138,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:42462,Deployability,pipeline,pipelines,42462,/PathSeqBuildKmers/exampleFASTA.hss; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/e_coli_k12_mini.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/pipeline_output.bam.splitting-bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSBuildReferenceTaxonomyUtils/test.tar.gz; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSFilter/hg19mini_test_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark/SVBreakpointsTest.assembly.0; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.fastq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.rmdup-contigs.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:56968,Deployability,pipeline,pipeline,56968,urces/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/variantFiltrationInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfMask.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/ad-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; sr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:57087,Deployability,pipeline,pipeline,57087,t/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfMask.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/ad-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:57206,Deployability,pipeline,pipeline,57206,es/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfMask.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/ad-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:65564,Deployability,Update,UpdateVCFSequenceDictionary,65564,rg/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/haploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/selectVariantsInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/test.dup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetra-diploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2DiscordanceConcordance.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleBAM.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleFASTA.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/expected.soap_gatk_annotated.AMD.table; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic_gt.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.noChr_lines.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/V,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:65684,Deployability,Update,UpdateVCFSequenceDictionary,65684,g/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/selectVariantsInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/test.dup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetra-diploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2DiscordanceConcordance.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleBAM.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleFASTA.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/expected.soap_gatk_annotated.AMD.table; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic_gt.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.noChr_lines.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/vcfexample.noSamples.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29037,Integrability,integrat,integration,29037,s/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29138,Integrability,integrat,integration,29138,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30739,Safety,detect,detectcoveragedropout,30739,st/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/ev,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30823,Safety,detect,detectcoveragedropout,30823,st/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/ev,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30932,Safety,detect,detectcoveragedropout,30932,nstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:39469,Security,validat,validation,39469,eq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/repeated_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/validation/nearby_indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chr1.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chrY_Plus.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.intervals; src/test/resources/org/broadinstitute/hellbender/tools/print_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.chr1_1.bam.bai; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:45543,Security,validat,validation,45543,esources/org/broadinstitute/hellbender/tools/spark/sv/utils/SVContext.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:45664,Security,validat,validation,45664,ellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:45792,Security,validat,validation,45792,t/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allele,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60190,Security,Validat,ValidateVariants,60190,eup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60310,Security,Validat,ValidateVariants,60310,pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60421,Security,Validat,ValidateVariants,60421,r20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60524,Security,Validat,ValidateVariants,60524,tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVarian,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60637,Security,Validat,ValidateVariants,60637,org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60774,Security,Validat,ValidateVariants,60774,s/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:60909,Security,Validat,ValidateVariants,60909,/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/vali,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61024,Security,Validat,ValidateVariants,61024,seq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61155,Security,Validat,ValidateVariants,61155,urces/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61266,Security,Validat,ValidateVariants,61266,test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61283,Security,validat,validationExampleBad,61283,test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61376,Security,Validat,ValidateVariants,61376,/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotype,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61393,Security,validat,validationExampleGood,61393,/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotype,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61487,Security,Validat,ValidateVariants,61487,g/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/Calculat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61504,Security,validat,validationExampleRSIDonPositionNotInDBSNP,61504,g/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/Calculat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61618,Security,Validat,ValidateVariants,61618,tute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61635,Security,validat,validationUnusedAllelesBugFix,61635,tute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61737,Security,validat,validation,61737,resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors.vcf; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:61884,Security,validat,validation,61884,roadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testSingleParentFamily_chr1.vcf.idx; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:172,Testability,test,test,172,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:582,Testability,test,test,582,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:658,Testability,test,test,658,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:692,Testability,test,test,692,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:735,Testability,test,test,735,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:782,Testability,test,test,782,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:823,Testability,test,test,823,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:858,Testability,test,test,858,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:898,Testability,test,test,898,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:932,Testability,test,test,932,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:971,Testability,test,test,971,"The following one-liner (which I Googled, so I cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_cov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1028,Testability,test,test,1028," cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1090,Testability,test,test,1090,"led 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1175,Testability,test,test,1175,"urces -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_wo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1251,Testability,test,test,1251,"; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_varian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1300,Testability,test,test,1300,". Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1354,Testability,test,test,1354,"we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bia",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1390,Testability,test,test,1390,"Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_histo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1431,Testability,test,test,1431,"ned if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1510,Testability,test,test,1510,gine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelih,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1592,Testability,test,test,1592,_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1663,Testability,test,test,1663,STA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1787,Testability,test,test,1787,/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:1906,Testability,test,test,1906,fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2024,Testability,test,test,2024,fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_wor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2145,Testability,test,test,2145,p135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2273,Testability,test,test,2273,17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_f,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2410,Testability,test,test,2410,g_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2548,Testability,test,test,2548,urces/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/p,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2672,Testability,test,test,2672,/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2794,Testability,test,test,2794,puts/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:2913,Testability,test,test,2913,/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_fina,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3039,Testability,test,test,3039,_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_fi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3158,Testability,test,test,3158,pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3283,Testability,test,test,3283,on/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3416,Testability,test,test,3416,/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3530,Testability,test,test,3530,ine_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/ta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3644,Testability,test,test,3644,/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/lar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3758,Testability,test,test,3758,rge/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workfl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:3882,Testability,test,test,3882,germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resou,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4012,Testability,test,test,4012,ermline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/larg,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4136,Testability,test,test,4136,mline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4255,Testability,test,test,4255,nv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4373,Testability,test,test,4373,ources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4494,Testability,test,test,4494,e/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.pr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4622,Testability,test,test,4622, src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4674,Testability,test,test,4674,_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f72,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4772,Testability,test,test,4772,rkflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4850,Testability,test,test,4850, src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4928,Testability,test,test,4928,on/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:4990,Testability,test,test,4990,x.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5046,Testability,test,test,5046,est_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5111,Testability,test,test,5111,ients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapie,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5182,Testability,test,test,5182,nputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5271,Testability,test,test,5271,ermline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resource,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5362,Testability,test,test,5362,/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.p,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5458,Testability,test,test,5458,ic_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.dupli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5514,Testability,test,test,5514,ine_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5592,Testability,test,test,5592,ariance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5656,Testability,test,test,5656, src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5732,Testability,test,test,5732,e-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5794,Testability,test,test,5794,orkflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dre,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5871,Testability,test,test,5871,orkflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synth,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5924,Testability,test,test,5924,urces/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:5977,Testability,test,test,5977,test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6030,Testability,test,test,6030,st/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6091,Testability,test,test,6091,rc/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6157,Testability,test,test,6157,ds.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6213,Testability,test,test,6213,.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6269,Testability,test,test,6269,ces/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6325,Testability,test,test,6325,sesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6381,Testability,test,test,6381,12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpReca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6436,Testability,test,test,6436,ng0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/e,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6494,Testability,test,test,6494,/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6565,Testability,test,test,6565,rc/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6636,Testability,test,test,6636,t/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6705,Testability,test,test,6705,rc/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6775,Testability,test,test,6775,resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6845,Testability,test,test,6845,rc/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6913,Testability,test,test,6913,/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:6958,Testability,test,test,6958,src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7010,Testability,test,test,7010, src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7062,Testability,test,test,7062,38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7183,Testability,test,test,7183,1.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-1000002,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7277,Testability,test,test,7277,man_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7352,Testability,test,test,7352,ta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7419,Testability,test,test,7419,/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7483,Testability,test,test,7483,t/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7533,Testability,test,test,7533,m.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7612,Testability,test,test,7612,am.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7697,Testability,test,test,7697,sources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7767,Testability,test,test,7767,resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_ind,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7815,Testability,test,test,7815,s/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7873,Testability,test,test,7873,ynthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:7933,Testability,test,test,7933,t/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8010,Testability,test,test,8010,all-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_va,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8092,Testability,test,test,8092,g19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8225,Testability,test,test,8225,.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8342,Testability,test,test,8342,large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8461,Testability,test,test,8461,sources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8540,Testability,test,test,8540,es_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8624,Testability,test,test,8624,sensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8710,Testability,test,test,8710,d.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8798,Testability,test,test,8798,es/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8880,Testability,test,test,8880,.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:8977,Testability,test,test,8977,resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupport,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9076,Testability,test,test,9076,roadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9171,Testability,test,test,9171,mapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resour,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9261,Testability,test,test,9261,878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9368,Testability,test,test,9368,HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9455,Testability,test,test,9455,itute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9546,Testability,test,test,9546,er/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9636,Testability,test,test,9636,cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9774,Testability,test,test,9774,r/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:9926,Testability,test,test,9926,sources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10061,Testability,test,test,10061,er/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10194,Testability,test,test,10194,cf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10323,Testability,test,test,10323,rg/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10468,Testability,test,test,10468,ndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10610,Testability,test,test,10610,te/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/Mu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10746,Testability,test,test,10746,sources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/e,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10840,Testability,test,test,10840,ationTest_bam_multiple_intervals_with_unmapped.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:10922,Testability,test,test,10922,stitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/reso,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11004,Testability,test,test,11004,m_single_interval.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11087,Testability,test,test,11087,ests/expected_ReadWalkerGCSSupportIntegrationTest_bam_unmapped_only.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11170,Testability,test,test,11170,org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_wholefile.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11271,Testability,test,test,11271,ai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11381,Testability,test,test,11381,_vcf_multiple_intervals.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11503,Testability,test,test,11503,lkerGCSSupportIntegrationTest_vcf_single_interval.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11613,Testability,test,test,11613,CSTests/expected_VariantWalkerGCSSupportIntegrationTest_vcf_wholefile.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/Rea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11735,Testability,test,test,11735,ute/hellbender/engine/GenomicsDBIntegration/tiny.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasource,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11839,Testability,test,test,11839,nder/engine/minimal_bcf_file.bcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_bed_file.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:11943,Testability,test,test,11943,ile.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf3_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12054,Testability,test,test,12054,sources/org/broadinstitute/hellbender/engine/minimal_vcf4_file.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metri,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12157,Testability,test,test,12157,roadinstitute/hellbender/engine/MultiVariantDataSource/baseVariants.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_1_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resour,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12246,Testability,test,test,12246,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12361,Testability,test,test,12361,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12485,Testability,test,test,12485,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12590,Testability,test,test,12590,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12708,Testability,test,test,12708,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12826,Testability,test,test,12826,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:12944,Testability,test,test,12944,oadinstitute/hellbender/engine/MultiVariantDataSource/interleavedVariants_2_WithOverlap.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantDataSource/splitVariants_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/MultiVariantWalkerGroupedOnStart/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13045,Testability,test,test,13045,ne/reads_data_source_test1_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/reads_data_source_test3.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13180,Testability,test,test,13180,bai; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13312,Testability,test,test,13312,sources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/directoryWithNoPartFiles/_SUCCESS; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13443,Testability,test,test,13443,/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13575,Testability,test,test,13575,der/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13712,Testability,test,test,13712,rces/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistribut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13852,Testability,test,test,13852,nk/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:13983,Testability,test,test,13983,.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_qualit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14110,Testability,test,test,14110,isulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14223,Testability,test,test,14223,/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14353,Testability,test,test,14353,trics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resource,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14468,Testability,test,test,14468,lignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resour,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14582,Testability,test,test,14582,s/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14691,Testability,test,test,14691,dinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14805,Testability,test,test,14805,ources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:14933,Testability,test,test,14933,resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15062,Testability,test,test,15062,; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/me,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15172,Testability,test,test,15172,bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15277,Testability,test,test,15277,ginalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15387,Testability,test,test,15387,utionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; sr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15502,Testability,test,test,15502,stributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15603,Testability,test,test,15603,/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15706,Testability,test,test,15706,llectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.tx,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15827,Testability,test,test,15827,ectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:15934,Testability,test,test,15934,trics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16058,Testability,test,test,16058,ender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resourc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16167,Testability,test,test,16167,stitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16247,Testability,test,test,16247,est/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16327,Testability,test,test,16327,id.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/to,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16436,Testability,test,test,16436,Fail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16545,Testability,test,test,16545,t5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16654,Testability,test,test,16654,.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16763,Testability,test,test,16763,il_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16872,Testability,test,test,16872,first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:16981,Testability,test,test,16981,iginalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17090,Testability,test,test,17090,Distribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEU,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17206,Testability,test,test,17206,est/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17322,Testability,test,test,17322,lbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17438,Testability,test,test,17438,/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17554,Testability,test,test,17554,ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17670,Testability,test,test,17670,er/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17774,Testability,test,test,17774,lbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resou,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17878,Testability,test,test,17878,e/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:17975,Testability,test,test,17975,roadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18073,Testability,test,test,18073,ces/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excludi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18185,Testability,test,test,18185,esources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18309,Testability,test,test,18309,/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18434,Testability,test,test,18434,dinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18566,Testability,test,test,18566,ender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18678,Testability,test,test,18678,ellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18790,Testability,test,test,18790,r/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.W,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:18907,Testability,test,test,18907,qsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19024,Testability,test,test,19024,.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19147,Testability,test,test,19147,.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19244,Testability,test,test,19244,m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_qualit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19341,Testability,test,test,19341,rio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19463,Testability,test,test,19463,EUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19604,Testability,test,test,19604,Seq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellben,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19738,Testability,test,test,19738,.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:19876,Testability,test,test,19876,rc/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20008,Testability,test,test,20008,es/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20154,Testability,test,test,20154,ellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20297,Testability,test,test,20297,00.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20447,Testability,test,test,20447,es/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_li,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20591,Testability,test,test,20591,org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20715,Testability,test,test,20715,resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/reso,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20843,Testability,test,test,20843, src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:20964,Testability,test,test,20964,.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21084,Testability,test,test,21084,2878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21183,Testability,test,test,21183,xpected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resourc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21287,Testability,test,test,21287,rg/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbende,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21400,Testability,test,test,21400,ize_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/to,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21502,Testability,test,test,21502,S.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.ba,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21642,Testability,test,test,21642,q.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21734,Testability,test,test,21734,/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21823,Testability,test,test,21823,rces/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:21917,Testability,test,test,21917,ernate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/to,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22016,Testability,test,test,22016,2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22131,Testability,test,test,22131,te.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbende,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22199,Testability,test,test,22199,der/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22271,Testability,test,test,22271,/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22380,Testability,test,test,22380,ces/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipRead,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22465,Testability,test,test,22465,m.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22536,Testability,test,test,22536,q.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22611,Testability,test,test,22611,/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipRea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22705,Testability,test,test,22705,ources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22798,Testability,test,test,22798,urces/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:22898,Testability,test,test,22898,ces/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23006,Testability,test,test,23006,roadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23113,Testability,test,test,23113,es/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23233,Testability,test,test,23233,ai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.cl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23353,Testability,test,test,23353,t/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23468,Testability,test,test,23468,/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/Cl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23583,Testability,test,test,23583,st/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23697,Testability,test,test,23697,adinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23811,Testability,test,test,23811,r/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/res,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:23926,Testability,test,test,23926,ds/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24059,Testability,test,test,24059,TestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/reso,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24192,Testability,test,test,24192,5.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24319,Testability,test,test,24319,src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24446,Testability,test,test,24446,ources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/C,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24574,Testability,test,test,24574,oadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24702,Testability,test,test,24702,ellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24834,Testability,test,test,24834,ipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.with,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:24966,Testability,test,test,24966,clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25081,Testability,test,test,25081,lipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25196,Testability,test,test,25196,hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25311,Testability,test,test,25311,adinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25425,Testability,test,test,25425,urces/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25539,Testability,test,test,25539, src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25656,Testability,test,test,25656,TE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25773,Testability,test,test,25773,T_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25885,Testability,test,test,25885,dsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:25997,Testability,test,test,25997,ngReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26110,Testability,test,test,26110,pingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26222,Testability,test,test,26222,eadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/to,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26351,Testability,test,test,26351,ed.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26429,Testability,test,test,26429,ute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/br,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26502,Testability,test,test,26502,2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.ts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26580,Testability,test,test,26580,d.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/callin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26658,Testability,test,test,26658,itute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26731,Testability,test,test,26731,_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26809,Testability,test,test,26809,ted.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26892,Testability,test,test,26892,lbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:26977,Testability,test,test,26977,ources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coverag,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27063,Testability,test,test,27063,.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27159,Testability,test,test,27159,/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_ge,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27229,Testability,test,test,27229,/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_ge,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27332,Testability,test,test,27332,dinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27435,Testability,test,test,27435,ols/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27536,Testability,test,test,27536,rc/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/covera,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27636,Testability,test,test,27636,roadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/to,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27739,Testability,test,test,27739,count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27843,Testability,test,test,27843,; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:27947,Testability,test,test,27947,es/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28049,Testability,test,test,28049,titute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28150,Testability,test,test,28150,hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28254,Testability,test,test,28254,del/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28345,Testability,test,test,28345,coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28440,Testability,test,test,28440,tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28520,Testability,test,test,28520,tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28632,Testability,test,test,28632,/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28746,Testability,test,test,28746,emodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28867,Testability,test,test,28867,emodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:28953,Testability,test,test,28953,s/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29058,Testability,test,test,29058,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29164,Testability,test,test,29164,coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcov,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29233,Testability,test,test-pulldown-,29233,coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcov,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29258,Testability,test,test,29258,er/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29327,Testability,test,test-pulldown-,29327,er/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29352,Testability,test,test,29352,tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29421,Testability,test,test-pulldown-,29421,tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29446,Testability,test,test,29446,/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29515,Testability,test,test-pulldown-,29515,/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29540,Testability,test,test,29540,el/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29647,Testability,test,test,29647,/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29767,Testability,test,test,29767,odel/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:29887,Testability,test,test,29887,targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/dete,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30007,Testability,test,test,30007,c/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discove,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30126,Testability,test,test,30126,s/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30252,Testability,test,test,30252,llbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30358,Testability,test,test,30358,s/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30469,Testability,test,test,30469,ulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-ca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30592,Testability,test,test,30592,sMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30682,Testability,test,test,30682,st/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/ev,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30766,Testability,test,test,30766,st/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/ev,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30875,Testability,test,test,30875,nstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30954,Testability,test,test,30954,nstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:30992,Testability,test,test,30992,tute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-avera,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31097,Testability,test,test,31097,rg/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31204,Testability,test,test,31204,78.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.out,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31288,Testability,test,test,31288,targetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-count,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31371,Testability,test,test,31371,tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31453,Testability,test,test,31453,rg/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31538,Testability,test,test,31538,ll-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31627,Testability,test,test,31627,some-targets.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31711,Testability,test,test,31711,ctcoveragedropout; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31796,Testability,test,test,31796,tcoveragedropout/HCC1143T-100_27M_37M.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31885,Testability,test,test,31885,der/tools/exome/detectcoveragedropout/test.tn.HCC1143T-100_27M_37M.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:31968,Testability,test,test,31968,rces/org/broadinstitute/hellbender/tools/exome/discover-germline-input-to-xhmm-zscores.pl; src/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32057,Testability,test,test,32057,rc/test/resources/org/broadinstitute/hellbender/tools/exome/discover-germline-xhmm-output-4-6-70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32155,Testability,test,test,32155,70-3-3.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/dummy_cov_profile.txt; src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-count,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32246,Testability,test,test,32246, src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sampl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32341,Testability,test,test,32341,rces/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32440,Testability,test,test,32440,institute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32536,Testability,test,test,32536,hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32633,Testability,test,test,32633,der/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/ge,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32729,Testability,test,test,32729,e/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32825,Testability,test,test,32825,-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:32921,Testability,test,test,32921,f.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exom,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33016,Testability,test,test,33016,rc/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33116,Testability,test,test,33116,ut; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33203,Testability,test,test,33203,src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33305,Testability,test,test,33305,st/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33380,Testability,test,test-targets,33380,st/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33402,Testability,test,test,33402,est/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33477,Testability,test,test-targets,33477,est/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33503,Testability,test,test,33503,ces/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellben,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33578,Testability,test,test-targets-wo-coords,33578,ces/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellben,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33610,Testability,test,test,33610,dinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33721,Testability,test,test,33721,llbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33827,Testability,test,test,33827,te/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33903,Testability,test,test,33903,-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:33978,Testability,test,test,33978,-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34091,Testability,test,test,34091,g/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34194,Testability,test,test,34194,nder/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-pos,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34311,Testability,test,test,34311,r/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34404,Testability,test,test,34404,/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-po,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34507,Testability,test,test,34507,/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
https://github.com/broadinstitute/gatk/issues/3905:34617,Testability,test,test,34617,ools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fraction-transformation.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.di,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905
