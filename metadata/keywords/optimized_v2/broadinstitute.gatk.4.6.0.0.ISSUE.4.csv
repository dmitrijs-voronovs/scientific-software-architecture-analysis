quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"m_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 11:47:51.534 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 11:47:51.534 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 11:47:51.534 INFO IntelPairHmm - Available threads: 16; 11:47:51.534 INFO IntelPairHmm - Requested threads: 4; 11:47:51.534 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 11:47:51.557 INFO ProgressMeter - Starting traversal; 11:47:51.557 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 11:47:52.683 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 11:47:52.683 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 11:47:52.683 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.24 sec; 11:47:52.684 INFO Mutect2 - Shutting down engine; [July 2, 2020 11:47:52 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2511863808; java.lang.IllegalArgumentException: Read bases and read quality arrays aren't the same size: Bases: 38 vs Base Q's: 38 vs Insert Q's: 146 vs Delete Q's: 146.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:734); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.createQualityModifiedRead(PairHMMLikelihoodCalculationEngine.java:205); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.modifyReadQualities(PairHMMLikelihoodCalculationEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:236); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482:4864,down,down,4864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482,1,['down'],['down']
Availability,make task robust to reads and index being in different locations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6900:10,robust,robust,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6900,1,['robust'],['robust']
Availability,"make the ActiveRegion traversal fully respect dcov. I think Mark, in implementing the current scheme, might have been thinking that maintaining the undownsampled reads in memory is actually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active region traversals, and disallow the -dcov argument for active region walkers. Downsampling would then by c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5486,down,downsampling,5486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['down'],['downsampling']
Availability,making constants BQSR_TABLE_LONG_NAME and BQSR_TABLE_SHORT_NAME in StandardArgumentDefinitions; fixing outdated references to -BQSR -> -bqsr in documentation and error messages; fixes #1631,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1633:162,error,error,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1633,1,['error'],['error']
Availability,"mals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs here). Will try to track down the source of the discrepancy. EDIT 3: Added segment union based on single-changepoint detection using kernel segmentation.; - [x] Segment union should be replaced by a proper joint kernel segmentation. EDIT: I've added this, but there could be some minor improvements. Right now, only use one het per copy-ratio interval and throw away those off-target/bin. There are a few percent of targets/bins that have more than one het, and we could potentially rescue the off-target/bin hets as well with some care.; - Old code and models are used for modeling. Since the old allele-fraction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instead of assuming the null hypothesis of het (f = 0.5) and accepting a site when we cannot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:3944,down,down,3944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['down'],['down']
Availability,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3595:210,error,errors,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595,2,['error'],"['error', 'errors']"
Availability,"mand line inside a Nextflow module, it gives a generic error for most of the samples (sometimes all of them, sometimes some of them). ; It looks like a random issue, because if I run the same code outside of Nextflow, it works perfectly on every sample. . I would really appreciate if someone may give me some hints on why this is occurring and, eventually, how to fix it. ## Bug Report. ### Affected tool(s) or class(es); AnalyzeSaturationMutagenesis . ### Affected version(s); gatk4-4.3.0.0. ### Description ; Here it follows the output from Nextflow that appears on screen:. ```; Error executing process > 'gatk_count (gatk)'. Caused by:; Process `gatk_count (gatk)` terminated with an error exit status (247). Command executed:. gatk AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//i ndex/genome.fa --orf 1-5610 -O ./MITE6_P1. Command exit status:; 247. Command output:; (empty). Command error:; WARNING: Not mounting requested bind point (already mounted in container): /home/tigem/f.panariello; Using GATK jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=f alse -Dsamjdk.compression_level=2 -jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//index/genome.fa --orf 1-5610 -O ./MIT E6_P1; 09:36:03.173 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/gatk4-4.3.0.0-0/gatk-package -4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:36:03.397 INFO AnalyzeSaturationMutagenesis - ------------------------------------------------------------; 09:36:03.398 INFO AnalyzeSaturationMutagenesis - The Genome Analysis Toolkit (GATK) v4.3.0.0; 09:36:03.398 INFO AnalyzeSaturationMutagenesis - For suppor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8357:1239,error,error,1239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8357,1,['error'],['error']
Availability,"many methods in MathUtils are redundant with ApacheCommons/Math or JDK. We should remove those methods.; For example, `MathUtils.lnGamma` should be deleted in favor of `Gamma.logGamma' unless there's a severe speed penalty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/400:30,redundant,redundant,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/400,1,['redundant'],['redundant']
Availability,"match for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33544,failure,failure,33544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['failure'],['failure']
Availability,"max"": ""3.457286111111111"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFControlSample/Benchmark/9033775b-223e-4c4a-8dc8-28b281b3f2e1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""102.1011388888889"",; ""NIST evalHCsystemhours"": ""0.20356111111111105"",; ""NIST evalHCwallclockhours"": ""74.47628888888889"",; ""NIST evalHCwallclockmax"": ""4.013952777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFTestSample/Benchmark/79b5d82e-a482-465f-a161-f82a21b0436f/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:22067,error,errors,22067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['error'],['errors']
Availability,"max"": ""3.995058333333333"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFControlSample/Benchmark/670f9cb4-5bb0-48e2-95c9-15a2e1ae7dee/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.23083611111107"",; ""NIST evalHCsystemhours"": ""0.2083694444444444"",; ""NIST evalHCwallclockhours"": ""76.16374166666664"",; ""NIST evalHCwallclockmax"": ""3.743883333333333"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFTestSample/Benchmark/b84fd1b7-a21e-4098-aeaf-05de3b35b2df/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:22043,error,errors,22043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['error'],['errors']
Availability,maybe this will lower failure rates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6087:22,failure,failure,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6087,1,['failure'],['failure']
Availability,"mbda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); > 	at org.broadinstitute.hellbender.Main.main(Main.java:289). For those files experiencing the error, it disappears when disabling the mitochondria mode for `FilterMutectCalls`. I wonder how this problem could be solved so that all VCFs can be filtering in a consistent way, enabling the mitochondria mode. I am happy to share the VCF and reference sequence used it that helps reproducing/solving the issue. Thank you,; Eugenio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:2407,error,error,2407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['error'],['error']
Availability,"mdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:209); at org.broadinstitute.hellbender.Main.main(Main.java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:4543,failure,failure,4543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['failure'],['failure']
Availability,me in java Smith-Waterman : 4695.36 sec ; ; 23:44:30.027 INFO HaplotypeCaller - Shutting down engine ; ; \[2021Âπ¥11Êúà1Êó• ‰∏ãÂçà11Êó∂44ÂàÜ30Áßí\] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 569.97 minutes. ; ; Runtime.totalMemory()=742916096 ; ; htsjdk.samtools.SAMFormatException: Did not inflate expected amount ; ; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147) ; ; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331) ; ; at java.io.DataInputStream.read(DataInputStream.java:149) ; ; at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:421) ; ; at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:394) ; ; at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380) ; ; at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:282) ; ; at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:866) ; ; at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:1005) ; ; at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:840) ; ; at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:834) ; ; at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:802) ; ; at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReade,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:8846,avail,available,8846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['avail'],['available']
Availability,"me.log.txt ; ; Using GATK jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ; ¬†¬†¬†java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp -Xmx3g -jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-packa ; ; ge-4.2.5.0-local.jar HaplotypeCaller -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam -O results/wesep-229191-f.vcf --alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.inter ; ; val\_list -bamout results/wesep-229191-f.variants.bam -G StandardAnnotation -G StandardHCAnnotation --dragen-mode --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params ; ; 22:06:39.332 WARN ¬†GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default ; ; 22:06:39.337 WARN ¬†GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default ; ; 22:06:39.383 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Mar 12, 2022 10:06:39 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 22:06:39.543 INFO ¬†HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.543 INFO ¬†HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; 22:06:39.543 INFO ¬†HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 22:06:39.54",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:4133,Redundant,Redundant,4133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['Redundant'],['Redundant']
Availability,"meAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3189,ERROR,ERROR,3189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,3,['ERROR'],['ERROR']
Availability,"mentations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you to find serious fault with. Note that I punted on adding MultidimensionalKernelSegmenterUnitTest and ModelSegmentsIntegrationTest. Filed #3916. Closes #2858. (FINALLY!); Closes #3825.; Closes #3661.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:2385,fault,fault,2385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['fault'],['fault']
Availability,mention --help in error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1341:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1341,1,['error'],['error']
Availability,"minates-without-an-active-exception). \--. JointGenotyping fails in ImportGvcfs with the c++ error ""terminate called without an active exception"", which occurs when a thread goes out of scope without calling join() or detach(). This occurs when running JointGenotyping on 345 gvcfs created by GATK4 ExomeGermlineSingleSample; the workflow is running on an HPC cluster in Singularity (single node, 32 cores/node, 1002GB node memory) NOTE that I am able to successfully run JointGenotyping on a set of 80 gvcfs, also produced by ExomeGermlineSingleSample, in this HPC/Singularity environment with 248GB memory, 24 cores/node - this doesn't seem to be a resource issue. The only difference appears to be the number of input gvcfs, which is still quite small (345 vs 80). ¬†The number of reader threads for GenomicsDBImport has been hard-coded to 1 because these are exome sequences; scatter count = 10, batch size = 50, gather\_vcfs = false. GenomicsDBImport appears to succeed on all 10 shards but workflow execution fails with exactly the same c++ error, see below. REQUIRED for all errors and issues: ; ; a) GATK version used:¬†v4.2.6.1. b) Exact command used:. java -Dconfig.file=/scratch.global/lee04110/config/sing-cache.conf -jar /home/pankrat2/public/bin/gatk4/cromwell-81.jar run -i /scratch.global/lee04110/config/jg.ca\_defects.json /home/pankrat2/public/bin/gatk4/warp/pipelines/broad/dna\_seq/germline/joint\_genotyping/JointGenotyping.wdl -o¬† <(echo '{""final\_workflow\_outputs\_dir"" : ""/scratch.global/lee04110/tmp\_jg"", ""use\_relative\_output\_paths"" : true, ""workflow-log-temporary"" : true}'). c) Entire program log: (too big to include the whole thing). (From main process stderr, picking from SplitInterval setting status to Done). \[2022-10-18 15:38:20,88\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.SplitIntervalList:NA:1\]: Status change from WaitingForReturnCode to Done. \[2022-10-18 15:38:25,47\] \[info\] WorkflowExecutionActor-9743b28a-3819-49a7-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:1392,error,error,1392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['error'],['error']
Availability,mit/46cd10f8f2130da871da611eb6b48e501eda3cf1?src=pr&el=desc) will **decrease** coverage by `0.001%`.; > The diff coverage is `94.444%`. ```diff; @@ Coverage Diff @@; ## master #5448 +/- ##; ==============================================; - Coverage 87.01% 87.008% -0.001% ; - Complexity 31177 31184 +7 ; ==============================================; Files 1908 1908 ; Lines 144007 144037 +30 ; Branches 15927 15930 +3 ; ==============================================; + Hits 125300 125324 +24 ; - Misses 12950 12955 +5 ; - Partials 5757 5758 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5448?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `81.573% <100%> (+0.041%)` | `159 <1> (+1)` | :arrow_up: |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `100% <100%> (√∏)` | `23 <6> (+2)` | :arrow_up: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `81.818% <100%> (+4.769%)` | `12 <2> (+2)` | :arrow_up: |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `95.745% <80%> (-4.255%)` | `25 <6> (+4)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802:1219,down,downsampling,1219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802,1,['down'],['downsampling']
Availability,mitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.8514933Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8515375Z [done in 2341 ms]; 2022-08-16T22:45:53.8515491Z 1 error; 2022-08-16T22:45:53.8515610Z 101 warnings; 2022-08-16T22:45:53.8515748Z expected [99] but found [1]; 2022-08-16T22:45:53.8515934Z at org.testng.Assert.fail(Assert.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:22275,error,error,22275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"mlzcnt -mrtm -mhle -mrdrnd -mf16c -mfsgsbase -mrdseed -mprfchw -madx -mfxsr -mxsave -mxsaveopt -mavx512f -mno-avx512er -mavx512cd -mno-avx512pf -mno-prefetchwt1 -mclflushopt -mxsavec -mxsaves -mavx512dq -mavx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mclwb -mno-mwaitx -mno-clzero -mpku --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=22528 -mtune=generic -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/numpy/core/include -I/home/tintest/miniconda2/envs/aurexome/include/python3.6m -I/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/theano/gof -L/home/tintest/miniconda2/envs/aurexome/lib -fvisibility=hidden -o /home/tintest/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--3.6.2-64/tmpueark7lw/m421cdb2b133a2578e9a2670dfbb5d33e.so /home/tintest/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--3.6.2-64/tmpueark7lw/mod.cpp -lpython3.6m; ERROR (theano.gof.cmodule): [Errno 12] Cannot allocate memory; Traceback (most recent call last):; File ""/tmp/tintest/cohort_denoising_calling.4390748645603329412.py"", line 143, in <module>; shared_workspace, initial_params_supplier); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/gcnvkernel/tasks/task_cohort_denoising_calling.py"", line 140, in __init__; denoising_model = DenoisingModel(denoising_config, shared_workspace, initial_param_supplier); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/pymc3/model.py"", line 197, in __call__; instance.__init__(*args, **kwargs); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/gcnvkernel/models/model_denoising_calling.py"", line 851, in __init__; observed=shared_workspace.n_st); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/pymc3/distributions/distribution.py"", line 39, in __new__; return model.Var(name, dist, data, total_size); File ""/home/tintest/min",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:63149,ERROR,ERROR,63149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['ERROR'],['ERROR']
Availability,"mmandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx6500m -jar /root/gatk.jar FilterMutectCalls -V gs://fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-MergeVCFs/Abrams_cell-unfiltered.vcf -R gs://fc-0b0cb3ce-e2cb-4aef-a8b2-08e60d78e87c/Canis_lupus_familiaris_assembly3.fasta -O Abrams_cell-filtered.vcf --contamination-table /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-CalculateContamination/contamination.table --tumor-segmentation /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-CalculateContamination/segments.table --ob-priors /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-LearnReadOrientationModel/artifact-priors.tar.gz -stats /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-MergeStats/merged.stats --filtering-stats filtering.stats --min-median-read-position 10; ```. Both of these tests were run on an interval that included a single chromosome (approximately 24Mb). Thank you for your help!. Best,; Kate. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24345/m2-error-with-canine-germline-resource-and-variants-for-contamination-files/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:10319,error,error-with-canine-germline-resource-and-variants-for-contamination-files,10319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['error'],['error-with-canine-germline-resource-and-variants-for-contamination-files']
Availability,"mmit 45058f27aae9c9240a167f126e32a6bddd3353ff; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Nov 8 23:33:51 2023 -0500. conda 23.9.0. commit d95494d282dd42ea3377de6c2d3554a3a5db65e4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 17:04:34 2023 -0400. minor fixes to get ploidy working. commit c6a21f33f1f17b2bc9b878d8d6bfc6d7da784933; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 16:33:22 2023 -0400. truncated normal fixes. commit 81e3fff0a099731730d1657fc12f56abdc2b2927; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 16:03:02 2023 -0400. minor clip fix. commit 2fb94e88ab457ec037d304f7a80384b70a8685cc; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 15:17:06 2023 -0400. use model.rvs_to_values for registry; inference completes but numerical tests seem off!. commit 5d2062f3301f682dbf427d898521ec6da8338944; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 15:03:40 2023 -0400. VarMap and transformed name in register, exact match error to warn. commit 3dca890329396c9afae52aa8779cdfb97c18fa7c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Oct 25 23:28:32 2023 -0400. inference works! oh wow. commit d056855608fdf222a38a25d8de41f11fa1e82c22; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 22:11:30 2023 -0400. past full denoising instantiation and through to first calling epoch before hitting another shape error. commit fcfdb29e79e0652d24a5f509ade6e941f84293c2; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 00:17:46 2023 -0400. revert pytensorf. commit 2ec79b362bdfcd34b3ca1736e6327ecbbe2269ad; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 00:16:04 2023 -0400. HalfFlat typo. commit 6eb1594d62ed62b992db04c523ffc598845d3b4c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 23 23:46:42 2023 -0400. added TODOs for nontrivial changes. commit c01754082991c006c8d56f0027138948d792ce75; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:6770,error,error,6770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['error'],['error']
Availability,"mmm... that said, I think this must fail using the right error message, don't you think? @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500:57,error,error,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500,1,['error'],['error']
Availability,"model-based filtering, etc). If Mutect would employ this naive approach to haplotype calling, I suppose it would end up looking like the ""Platypus"" caller, _which_ again might be suited for our needs, but potentially makes option 3 more appealing. > Option 3 ( i.e. Quick-and-dirty (""FreeBayes-ian"") assembly:. This is interesting and would seem to solve my problems (I believe?) by creating a Haplotype-based, somatic variant caller with the Mutect perks/processing steps/output formats. Again, though, I could see the generation of many candidate haplotypes if things are really messy; however, could you not use a simple ""supporting reads""-based approach for haplotype selection. That would make the likelihood calculations fairly straight-forward. It would undeniably be less-sophisticated than the current De Bruijn Graph/Smith Waterman realignment-based approach but could be better for folks that want more control of the expected behaviors of the tool. > Option 5 (Disable realignment portion of assembly):. I'm going to go out on a limb with this one (feel free to shut this line of thought down quick if I'm really off-base). I've never been able to fully understand the code in the `findBestPaths` method (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L307) and I've had troubles figuring out the details of realignment from the official docs. It could be this part of the assembly process that causes me the most troubles in my pipeline, since this is where the original alignment information can really get disregarded as Mutect2 looks for better understandings of the input alignments. Admittedly, I find this feature to be really neat (particularly for the big ugly INDELs), but again the lose of the original alignment information has been troubling in certain cases. Could there be a potential approach to disabling realignment?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817:1664,down,down,1664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817,2,['down'],['down']
Availability,modify build.gradle to give a reasonable error if R isn't found,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/351:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/351,1,['error'],['error']
Availability,"mon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:12187,ERROR,ERROR,12187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,monCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:13087,ERROR,ERROR,13087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"mory()=3391094784; java.lang.NullPointerException; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:231); at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRenderer.close(VcfOutputRenderer.java:137); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:883); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:970); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. #### Steps to reproduce. Does not work; ```; gatk Funcotator --variant input.vcf.gz --reference /path/to/human_g1k_v37_decoy.fasta --ref-version hg19 --data-sources-path /path/to/funcotator_dataSources.v1.6.20190124s/ --output output.vcf.gz --output-file-format VCF; ```. Works; ```; gatk Funcotator --variant input.vcf.gz --reference /path/to/human_g1k_v37_decoy.fasta --ref-version hg19 --data-sources-path /path/to/funcotator_dataSources.v1.6.20190124s/ --output output.vcf --output-file-format VCF; ```. (note that the `--output` parameter is different). #### Expected behavior; It should either give an error/warning saying outputting compressed VCF output is not supported, or output a compressed VCF like other GATK tools. #### Actual behavior; See examples above",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683:2755,error,error,2755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683,1,['error'],['error']
Availability,"moryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextH",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7160,AVAIL,AVAILABLE,7160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,moving some test utilities from src/test to src/main/ in order to make them available to hellbender-dataflow. removed a method that was only used by dataflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/992:76,avail,available,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/992,1,['avail'],['available']
Availability,moving test utilities to make them available to hellbender-dataflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/992:35,avail,available,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/992,1,['avail'],['available']
Availability,"mp_0003_of_10/cohort-model/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-calls/ --allosomal-contig chrX --allosomal-contig chrY --contig-ploidy-calls /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_ploidy//cohort-calls/ --sample-index 16 --output-genotyped-intervals /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.intervals.vcf --output-genotyped-segments /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.segments.vcf --sequence-dictionary /home/lmbs02/bio/databases/referenses/hg19_37/ucsc/hg19.dict --output-denoised-copy-ratios /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.copy_ratios.tsv `. In the same time, if you use the first 4 or the third and 4 at the same time, an error pops up.; `12:49:08.552 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:49:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.687 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:49:08.687 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:6906,error,error,6906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['error'],['error']
Availability,"mport - Importing batch 5 with 50 samples. 01:50:11.697 INFO¬† GenomicsDBImport - Importing batch 5 with 50 samples. 02:11:57.531 INFO¬† GenomicsDBImport - Importing batch 5 with 50 samples. 02:20:02.171 INFO¬† GenomicsDBImport - Importing batch 5 with 50 samples. 02:35:13.654 INFO¬† GenomicsDBImport - Importing batch 5 with 50 samples. 03:04:30.490 INFO¬† GenomicsDBImport - Importing batch 5 with 50 samples. 03:05:06.171 INFO¬† GenomicsDBImport - Done importing batch 5/7. 03:05:14.150 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 03:08:31.080 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 03:23:52.054 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 03:30:37.049 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 03:43:46.119 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 04:09:27.761 INFO¬† GenomicsDBImport - Importing batch 6 with 50 samples. 04:10:10.953 INFO¬† GenomicsDBImport - Done importing batch 6/7. 04:10:18.233 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 04:13:55.022 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 04:27:28.342 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 04:33:32.781 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 04:44:09.752 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 05:04:33.112 INFO¬† GenomicsDBImport - Importing batch 7 with 45 samples. 05:05:02.272 INFO¬† GenomicsDBImport - Done importing batch 7/7. 05:05:02.299 INFO¬† GenomicsDBImport - Import of all batches to GenomicsDB completed!. 05:05:02.300 INFO¬† GenomicsDBImport - Shutting down engine. \[October 19, 2022 5:05:02 AM GMT\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 506.11 minutes. Runtime.totalMemory()=8653373440. pure virtual method called. terminate called without an active exception<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/297458'>Zendesk ticket #297458</a>)<br> gz#297458</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:21965,down,down,21965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['down'],['down']
Availability,"mtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx7000M -Xms7000M -XX:ParallelGCThreads=2 -jar /shared/ifbstor1/projects/gentaumix/conda/envs/gatk\_4.2.2.0/share/gatk4-4.2.2.0-0/gatk-package-4.2.2.0-local.jar GenotypeGVCFs -R /shared/projects/gentaumix/Ressources/grch38\_BWA\_2/GCA\_000001405.15\_GRCh38\_no\_alt\_plus\_hs38d1\_analysis\_set.fa -V gendb:///tmp/tmp.6QEyWPGpWs/vcf\_database/Interval\_6 -O /tmp/tmp.6QEyWPGpWs/gentaumix\_interval\_6\_raw.vcf.gz -D /shared/projects/gentaumix/Ressources/known\_sites/Homo\_sapiens\_assembly38.dbsnp138.vcf --sequence-dictionary /shared/projects/gentaumix/Ressources/known\_sites/Homo\_sapiens\_assembly38.dict -L /shared/projects/gentaumix/Ressources/interval\_genomicsdbi/temp\_6/interval.interval\_list -G StandardAnnotation -G AS\_StandardAnnotation --merge-input-intervals ; ; 14:17:35.171 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default ; ; 14:17:35.232 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/shared/ifbstor1/projects/gentaumix/conda/envs/gatk\_4.2.2.0/share/gatk4-4.2.2.0-0/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Sep 10, 2021 2:17:35 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:17:35.492 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 14:17:35.492 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.2.0 ; ; 14:17:35.492 INFO GenotypeGVCFs - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:17:35.493 INFO GenotypeGVCFs - Executing as quentin67100@cpu-node-9 on Linux v3.10.0-1160.6.1.el7.x86\_64 amd64 ; ; 14:17:35.493 INFO GenotypeGVCFs - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465:2646,Redundant,Redundant,2646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465,1,['Redundant'],['Redundant']
Availability,"my pipeline(from fastq ) is üëç ; . 1. FastqToSam . 2. ConvertHeaderlessHadoopBamShardToBam. 3. BwaAndMarkDuplicatesPipelineSpark; ; ...... but in the step 3 ÔºàBwaAndMarkDuplicatesPipelineSparkÔºâÔºåthe pipeline crash; ```; Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, com1, executor 1): # **java.lang.IllegalArgumentException: Reference name for '1853452901' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setMateReferenceIndex(SAMRecord.java:506); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:94); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.<init>(BAMFileReader.java:963); at htsjdk.samtools.BAMFileReader.getIterator(BAMFileReader.java:491)**; at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:182); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:211); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:180); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:179); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4179:286,failure,failure,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179,2,['failure'],['failure']
Availability,"n FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line¬† is¬† ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O D1394-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp ; ; 14:50:12.699 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/nativ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:1627,error,error,1627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['error'],['error']
Availability,"n Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.alpha.2-1100-g04dbeb2-SNAPSHOT; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, executor 0): java.lang.IllegalStateException: unread block data;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:4000,ERROR,ERROR,4000,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability,"n port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContext",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7547,AVAIL,AVAILABLE,7547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"n the new syntax:; **********; ********** ValidateSamFile -I concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name UMI-ATT-GAA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 26312, Read name UMI-CCT-TTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 70755, Read name UMI-CAG-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 145082, Read name UMI-AAC-ATG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 181500, Read name UMI-ACT-CTT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186837, Read name UMI-CAA-CTC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186862, Read name UMI-CGC-GCC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186904, Read name UMI-AGG-GTC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186919, Read name UMI-CGC-TGC-0, Zero-length read without FZ, CS ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:1783,avail,available,1783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['avail'],['available']
Availability,"n the stdError exit condition is met (i.e., stdError < (contamination* MIN_RELATIVE_ERROR +MIN_ABSOLUTE_ERROR)), it reports out the contamination and stdError values. The issue is that this stdError exit condition is also met when contamination = 0, because in this case, stdError is also equal to 0, and thus is always less than the minimum value for (contamination * MIN_RELATIVE_ERROR [0.2] + MIN_ABSOLUTE_ERROR [0.001]), which cannot be less than 0.001. . final double stdError = homs.isEmpty() ? 1 : Math.sqrt(homs.stream().mapToDouble(ps -> {; final double d = ps.getTotalCount();; final double f = 1 - oppositeAlleleFrequency.applyAsDouble(ps);; return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);; }).sum()) / totalDepthWeightedByOppositeFrequency;. ** return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);**. Root cause:; At the first MAF iteration where errorDepth is greater than oppositeDepth, contamination is set to ‚Äú0‚Äù (according to the code logic shown below), the function exits the iteration process, and no further MAF thresholds are tested. **contaminationOppositeDepth = Math.max(oppositeDepth - errorDepth, 0);**; **contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency**. Solution proposed:; Currently, when errorDepth is greater than oppositeDepth, the output contamination is reported as **‚Äô0‚Äô contamination**; it seems to us that this should instead be interpreted as **‚Äúunable to calculate contamination‚Äù** because of the high error rate in these pileups. Improvements for current version:; In addition, we suggest calculating all contamination values over all strategies/iterations and outputting the highest contamination value (by MAF and/or strategy, as appropriate), rather than exiting after the first MAF iteration where stdError exit condition is met. ### Description what needs to be added or modified; Please see the code change attached, compare it to 4.2.0.0. The code ou",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177:1811,error,errorDepth,1811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177,1,['error'],['errorDepth']
Availability,"n$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:4965,ERROR,ERROR,4965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['ERROR'],['ERROR']
Availability,"n$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikeliho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:9732,failure,failure,9732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['failure'],['failure']
Availability,"n, in the cloud, I was able to use samtools to decram and index this CRAM file alongside 39 others. On our local server, I cannot get readwalkers PrintReads nor CalculateTargetCoverage to correctly decipher the CRAM. Both tools give the same error. Here is the PrintReads command:; ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch \; PrintReads \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram \; -O HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.bam; ```; And here is the error:; ```; 17:47:15.362 INFO ProgressMeter - chr1:198467627 2.6 8432000 3202552.3; 17:47:25.402 INFO ProgressMeter - chr1:236860077 2.8 10019000 3577916.1; ERROR 2017-06-22 17:47:27 Slice Reference MD5 mismatch for slice 0:248681942-248858764, ATAGCGGTCA...AGTGGCGGTG; 17:47:27.292 INFO CalculateTargetCoverage - Shutting down engine; [June 22, 2017 5:47:27 PM EDT] org.broadinstitute.hellbender.tools.exome.CalculateTargetCoverage done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=10377756672; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248681942, span 176823, expected MD5 4b8526e90896b01860301e5a1ef4988b; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:115); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154:1203,down,down,1203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154,1,['down'],['down']
Availability,"n-us/articles/360035889851--How-to-Install-and-use-Conda-for-GATK4) (conda env create -n gatk4 -f gatkcondaenv.yml). installation was completed as below;. Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117482 sha256=5e0f0b2eb6027268eb5814acd8c8b57d265b7aeb371702c736dd4723aa1beee4; Stored in directory: /tmp/pip-ephem-wheel-cache-gyc4oo9g/wheels/86/46/5d/d5d2d327a9cdc718f906fa1d0cd6e18392bd4eea267f327437; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done. when I started to run this command;. gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf; it gives an error as below;. java.lang.RuntimeException: A required Python package (""gatktool"") could not be imported into the Python environment. This tool requires that the GATK Python environment is properly established and activated. Please refer to GATK README.md file for instructions on setting up the GATK Python environment.; at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.start(StreamingPythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:302); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397:1202,error,error,1202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397,1,['error'],['error']
Availability,n.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 19/02/18 16:58:29 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.Defau,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:5885,ERROR,ERROR,5885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['ERROR'],['ERROR']
Availability,"n/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:1684,Error,Error,1684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['Error'],['Error']
Availability,n/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:20119,error,error,20119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,n/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4389382Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/ma,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:19027,error,error,19027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,n/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8433800Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:21608,error,error,21608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"n/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3823794Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Numb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:5292,error,error,5292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"n: chr3:117,527,190; INFO	2022-05-06 12:14:45	SortVcf	wrote 800,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:134,613,380; INFO	2022-05-06 12:14:45	SortVcf	wrote 825,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:153,780,108; INFO	2022-05-06 12:14:45	SortVcf	wrote 850,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:173,329,831; INFO	2022-05-06 12:14:46	SortVcf	wrote 875,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:192,133,262; [Fri May 06 12:14:46 EDT 2022] picard.vcf.SortVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=2855272448; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp. java.lang.ArrayIndexOutOfBoundsException: 16799; 	at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:102); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:92); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); 	at picard.vcf.SortVcf.writeSortedOutput(SortVcf.java:183); 	at picard.vcf.SortVcf.doWork(SortVcf.java:101); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. #### Expected output. There's almost certainly some format issue with my VCF, but ideally GATK would have a better error message than ArrayIndexOutOfBoundsException.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7838:3163,error,error,3163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7838,1,['error'],['error']
Availability,"n; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:38553,Error,Error,38553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"nEntry()`, distinguishing errors that comes from the user's side regarding some specifications in the tools/framework.; * `CommandLineException` are handled in `parseArgs()`, distinguishing errors that comes from the command line from the user side while parsing. I expect that any command line error that is not `CommandLineParserInternalException ` or `ShouldNeverReachHereException` comes from the user's side. The contract in Barclay says that are `CommandLineException` are _""Exceptions thrown by CommandLineParser implementations.""_, and I think that if other parts of the code (outside arg parsing) is throwing this exception is a bug that does not come from the user. I guess that this is the problematic part.; * Any other `Exception` is thrown in `Main.handleNonUserException()`, which may be caused by non-user exceptions. I propose that `CommandLineException` is handled as currently to separate ""errors that are the user's fault regarding input and/or assumptions"" (`UserException`), ""errors that are the user's fault while providing parameters to the command line"" (`CommandLineException`) and ""errors that are not the user's fault"" (other `Exception`s). Actually, this is reasonable because the exit status is different for any kind of errors in the current `Main`. The only problem that I see with this approach is the silently failing of a ""bug"" in tools/engine code, which can be rethrow easily in `CommandLineProgram.instanceMain`` as following:. ```java; public Object instanceMain(final String[] argv) {; if (!parseArgs(argv)) {; //an information only argument like help or version was specified, just exit; return 0;; }; try {; return instanceMainPostParseArgs();; } catch (CommandLineException e) {; // CommandLineExceptions are suposed to be only thrown while parsing arguments; throw new GATKException(""BUG: CommandLineException outside argument parsing code."", e);; }; }; ```. If you think that this is a good idea, I could implement and workaround parts of the code where th",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161:1397,error,errors,1397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161,6,"['error', 'fault']","['errors', 'fault']"
Availability,"nReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 12:16:43.443 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 12:16:43.452 INFO LearnReadOrientationModel - Shutting down engine; [November 26, 2018 12:16:43 PM EST] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 0.39 minutes.; Runtime.totalMemory()=1543503872; Tool returned:; SUCCESS; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:7352,down,down,7352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['down'],['down']
Availability,nReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.toolin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7275,ERROR,ERROR,7275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,nReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommand,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:10923,ERROR,ERROR,10923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,nReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommand,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:9665,ERROR,ERROR,9665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"nScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.start(StreamingPythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:302); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python -c import gatktool. Stdout: ; Stderr: Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'gatktool'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:198); when I checked gatktool python package, it is installed in the python packages by conda. after activate gatk4 , I checked with pip install gatktool, and it says the package already installed. Anyone experienced this error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397:3570,error,error,3570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397,1,['error'],['error']
Availability,"n_rnaseq/gatk_output/CDL-164-04P/CDL-164-04P-1_0_249250621_genomicsdb; 10:24:57.553 INFO GenomicsDBImport - Vid Map JSON file will be written to CDL-164-04P-1_0_249250621_genomicsdb/vidmap.json; 10:24:57.554 INFO GenomicsDBImport - Callset Map JSON file will be written to CDL-164-04P-1_0_249250621_genomicsdb/callset.json; 10:24:57.554 INFO GenomicsDBImport - Complete VCF Header will be written to CDL-164-04P-1_0_249250621_genomicsdb/vcfheader.vcf; 10:24:57.554 INFO GenomicsDBImport - Importing to array - CDL-164-04P-1_0_249250621_genomicsdb/genomicsdb_array; 10:24:57.554 INFO ProgressMeter - Starting traversal; 10:24:57.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:24:57.971 INFO GenomicsDBImport - Importing batch 1 with 1 samples; Buffer resized from 22726bytes to 32529; Buffer resized from 32529bytes to 32693; Buffer resized from 32693bytes to 32738; Buffer resized from 32738bytes to 32741; Buffer resized from 32741bytes to 32756; Buffer resized from 32756bytes to 32768; Buffer resized from 32768bytes to 32769; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f7288295359, pid=68672, tid=0x00007f72dc187700; #; # JRE version: OpenJDK Runtime Environment (8.0_171-b10) (build 1.8.0_171-b10); # Java VM: OpenJDK 64-Bit Server VM (25.171-b10 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8064358042335455262.so+0x155359] BufferVariantCell::set_cell(void const*)+0x99; #; # Core dump written. Default location: /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/core or core.68672; #; # An error report file with more information is saved as:; # /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/hs_err_pid68672.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:10769,error,error,10769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['error'],['error']
Availability,"na \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.addGivenAlleles(AssemblyBasedCallerUtils.java:350); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:291); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:542); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:240); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:1691,error,error,1691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,1,['error'],['error']
Availability,"nager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS184_1.raw_variants.g.vcf; 11:30:53.894 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS201_1.raw_variants.g.vcf; 11:30:54.000 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS209_1.raw_variants.g.vcf; 11:34:25.030 INFO CombineGVCFs - Done initializing engine; 11:34:25.154 INFO ProgressMeter - Starting traversal; 11:34:25.155 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:34:25.473 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location DS235882:44 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 11:34:25.944 INFO CombineGVCFs - Shutting down engine; [October 26, 2020 11:34:25 AM EDT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 3.59 minutes.; Runtime.totalMemory()=3738173440; java.lang.NumberFormatException: empty String; 	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842); 	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); 	at java.lang.Double.parseDouble(Double.java:538); 	at htsjdk.variant.vcf.VCFUtils.parseVcfDouble(VCFUtils.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:808); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContext.java:180); 	at htsjdk.variant.variantcontext.GenotypesContext.getSampleNames(GenotypesContext.java:646); 	at htsjdk.variant.variantcontext.VariantContex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6913:7146,down,down,7146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913,1,['down'],['down']
Availability,"nager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS184_1.raw_variants.g.vcf; 11:30:53.894 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS201_1.raw_variants.g.vcf; 11:30:54.000 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS209_1.raw_variants.g.vcf; 11:34:25.030 INFO CombineGVCFs - Done initializing engine; 11:34:25.154 INFO ProgressMeter - Starting traversal; 11:34:25.155 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:34:25.473 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location DS235882:44 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 11:34:25.944 INFO CombineGVCFs - Shutting down engine; [October 26, 2020 11:34:25 AM EDT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 3.59 minutes.; Runtime.totalMemory()=3738173440; java.lang.NumberFormatException: empty String; 	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842); 	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); 	at java.lang.Double.parseDouble(Double.java:538); 	at htsjdk.variant.vcf.VCFUtils.parseVcfDouble(VCFUtils.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:808); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContext.java:180); 	at htsjdk.variant.variantcontext.GenotypesContext.getSampleNames(GenotypesContext.java:646); 	at htsjdk.variant.variantcontext.VariantContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444:6909,down,down,6909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444,1,['down'],['down']
Availability,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ‚Äî; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2109,error,error,2109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323,2,['error'],['error']
Availability,"nal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. 21/04/13 07:32:25 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurren",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:11280,failure,failure,11280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['failure'],['failure']
Availability,nal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 21/04/13 07:32:24 ERROR SparkHadoopWriter: Task attempt_20210413073224_0026_r_000000_0 aborted.; 21/04/13 07:32:24 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 105); org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:5485,ERROR,ERROR,5485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['ERROR'],['ERROR']
Availability,"nce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:9194,ERROR,ERROR,9194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['ERROR'],['ERROR']
Availability,"ncher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at htsjdk.samtools.metrics.MetricsFile.loadClass(MetricsFile.java:471); 	at htsjdk.samtools.metrics.MetricsFile.read(MetricsFile.java:353); 	... 8 more; ```. If it is replaced, the tool still errors but with a different error:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:170); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:219); 	at java.util.ArrayList.forEach(ArrayList.java:1249); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:171); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```. It does not matter if I produce the pre-adapter metrics with the latest Picard jar v2.9.2. I get the same error. . I'm using a M2 callset from GATK3. Even so, I don't think I should get the above error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:3981,error,error,3981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,2,['error'],['error']
Availability,ncotationFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GdW5jb3RhdGlvbkZpbHRlci5qYXZh) | `100% <100%> (√∏)` | `8 <4> (+4)` | :arrow_up: |; | [...r/filtrationRules/FilterFuncotationsExacUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GaWx0ZXJGdW5jb3RhdGlvbnNFeGFjVXRpbHMuamF2YQ==) | `81.818% <80.952%> (-0.535%)` | `12 <7> (+5)` | |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | ... and [138 more](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539:3519,down,downsampling,3519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539,1,['down'],['downsampling']
Availability,"nd:54 - Interrupting monitor thread; 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 22:34:48 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:34:48 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:34:48 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:34:49 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:34:49 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:34:49 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:34:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:34:49 INFO SparkContext:54 - Successfully stopped SparkContext; 22:34:49.027 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:34:49 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 3.72 minutes.; Runtime.totalMemory()=3829923840; htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readInteger(IndexStreamBuffer.java:56); at htsjdk.samtools.AbstractBAMFileIndex.readInteger(AbstractBAMFileIndex.java:432); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:272); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(H",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:1809,down,down,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['down'],['down']
Availability,"nd:54 - Interrupting monitor thread; 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 22:45:35 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:45:35 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:45:35 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:45:35 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:45:35 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:45:35 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:45:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:45:35 INFO SparkContext:54 - Successfully stopped SparkContext; 22:45:35.933 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:45:35 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 5.79 minutes.; Runtime.totalMemory()=4147118080; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-423d02dc-cbc1-4c83-907d-ca315ca231bc; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-c035847e-6113-48f1-b5d1-66184925be7d; ```. $ hadoop fs -ls /project/casa/gcad/adsp.cc/sv/*. -rw-r--r-- 3 farrell casa 1684348 2019-06-03 22:34 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.bam.sbi; -rw-r--r-- 3 farrell casa 27494132363 2019-06-03 22:45 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.cram. Writing to a sam worked without triggering error.... ```; 2019-06-03 22:59:08 INFO TaskSet",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:9307,down,down,9307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['down'],['down']
Availability,nd:; `./gatk BaseRecalibratorSpark --tmp-dir /dev/shm/gatktmp/ -I /home/data/WGS/F002/F002.sort.bam -O 1.grp --known-sites /home/data/ref/dbsnp_138.hg19.vcf --known-sites /home/data/ref/1000G_phase1.indels.hg19.sites.vcf --known-sites /home/data/ref/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf -R /home/data/ref/ucsc.hg19.fasta -- --spark-runner SPARK --spark-master local[8] --driver-memory 100G`. Here is the log:. > 19:23:59.384 INFO FeatureManager - Using codec VCFCodec to read file file:///dev/shm/gatktmp/spark-30e238e4-b1b7-41f9-b31e-844f16879051/userFiles-4621c82d-5f86-4b51-9321-ccc84ab49979/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf; 19:23:59.411 INFO BaseRecalibrationEngine - The covariates being used here: ; 19:23:59.411 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 19:23:59.412 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 19:23:59.412 INFO BaseRecalibrationEngine - 	ContextCovariate; 19:23:59.412 INFO BaseRecalibrationEngine - 	CycleCovariate; 18/10/17 19:23:59 ERROR Executor: Exception in task 517.0 in stage 0.0 (TID 517); org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: Cannot read /dev/shm/gatktmp/spark-30e238e4-b1b7-41f9-b31e-844f16879051/userFiles-4621c82d-5f86-4b51-9321-ccc84ab49979/dbsnp_138.hg19.vcf because no suitable codecs found; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:462); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:320); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:300); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:1261,ERROR,ERROR,1261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['ERROR'],['ERROR']
Availability,"ndLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). This request was created from a contribution made by Domniki Manousi on March 07, 2022 12:01 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4556136866843-FindBreakpointEvidenceSpark-sudden-shutdown](https://gatk.broadinstitute.org/hc/en-us/community/posts/4556136866843-FindBreakpointEvidenceSpark-sudden-shutdown). \--. Hi, I am trying to run the tool FindBreakpointEvidenceSpark. I have successfully¬† produced the required kmers and the tool seems to run for several minutes until it finally stops without producing output. I have read in past issues that memory usage might be a problem and have tried to accomodate for it using the -Xmx option.¬†. a) GATK version used: gatk4: 4.2.0.0 through singularity (/cvmfs/singularity.galaxyproject.org/all/gatk4:4.2.0.0--0)¬†. b) Exact command used:¬†. singularity exec /cvmfs/singularity.galaxyproject.org/all/gatk4:4.2.0.0--0 gatk --java-options ""-Xmx75g -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true"" FindBreakpointEvidenceSpark \\ ; ; ¬† ¬†-R /mnt/SCRATCH/domniman/references/ssa\_selected/Simon\_Final2021\_Ssa\_selected.fa -I /mnt/SCRATCH/domniman/2014G\_NO\_Males\_1169\_D03\_RG.bam \\ ; ; ¬† ¬†--aligner-index-image /mnt/SCRATCH/domniman/references/ssa\_selected/Simon\_Final2021\_Ssa\_selected.fa.img \\ ; ; ¬† ¬†--kmers-to-ignore /mnt/users/domniman/ag\_fish/kmers\_to\_ignore.txt -O /mnt/SCRATCH/domniman/assembly.sam \\ ; ; ¬† ¬†--tmp-dir /mnt/SCRATCH/domniman/tmp -L ssa03. Entire error log: ; ; Due to length of the complete log (37.671 lines) I attach it as a separate link: [https://www.dropbox.com/s/n7q5dco4z5t3moz/gatk%20error%20log%20.txt?dl=0](https://www.dropbox.com/s/n7q5dco4z5t3moz/gatk%20error%20log%20.txt?dl=0). Best,. Domniki<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/275546'>Zendesk ticket #275546</a>)<br> gz#275546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7710:2825,error,error,2825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7710,1,['error'],['error']
Availability,"ndelSize >= 212; 16:34:35.876 INFO LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --maxIndelSize >= 216; 16:34:35.877 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --maxIndelSize >= 204; 16:34:35.877 INFO LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --maxIndelSize >= 209; 16:34:35.879 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --maxIndelSize >= 204; 16:34:35.881 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --maxIndelSize >= 207; 16:34:35.914 INFO ProgressMeter - unmapped 0.0 295 168571.4; 16:34:35.914 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 16:34:35.920 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 4:34:35 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; Tool returned:; 0 variants left aligned; ```. md5 of input; ```; WMCF9-CB5:shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 9569730f636c1c27353ab122a3792a14; ```; md5 of GATK3-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_headless.txt ; MD5 (zeta_leftalign_headless.txt) = a9a07f5049188d2e57fc0b653a131887; ```; md5 of GATK4-port-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_ck_3487_headless.txt ; MD5 (zeta_leftalign_ck_3487_headless.txt) = 61a5526841d465b14f5a4f7582d5ae55; ```. The GATK4-port-leftalign retains the same number of records as the input, whereas GATK3-leftalign drops ten. The test data variants run into and overlap each other. Combining the variant calls is a functionality in another tool, CombineVariants. Here, first let's make sure variant representations are le",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:5210,down,down,5210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['down'],['down']
Availability,nder.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:349); at org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark.runTool(ApplyBQSRSpark.java:90); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: java.io.IOException: Stream closed; at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170); at java.io.BufferedInputStream.read(BufferedInputStream.java:336); at java.io.DataInputStream.read(DataInputStream.java:149); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:133); at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:21); ... 22 more; 19/04/28 10:11:25 INFO ShutdownHookManager: Shutdown hook called. Could you please help me to resolve this issue. Thanks In Advance; Fazulur Rehaman. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/23954/stream-closed-error-with-gatk-4-1-1-0/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919:4122,error,error-with-gatk-,4122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919,1,['error'],['error-with-gatk-']
Availability,ndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:365); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:346); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:307); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I ran `java -jar gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar SelectVariants -V gnomADaccuracyTest.noMQinSNPVQSR.SynDip.vcf.gz -O testNoIndex.vcf.gz`. Data is at `/humgen/gsa-hpprojects/dev/gauthier/reblockGVCF` If I remember to pull down the index everything works swimmingly. I'd love for this to either work without an index or fail early with an appropriate message about the index being missing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224:2831,down,down,2831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224,1,['down'],['down']
Availability,"ndler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextH",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:7464,AVAIL,AVAILABLE,7464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ndler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.S",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:7860,AVAIL,AVAILABLE,7860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ndler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextH",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8875,AVAIL,AVAILABLE,8875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"ndler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO C",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9906,AVAIL,AVAILABLE,9906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"ndler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47179,AVAIL,AVAILABLE,47179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,nds 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvc; f-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --g; vcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 -; -gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47; --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands ; 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-re; f-model 10 --disable-optimizations false --dragen-mode false --flow-mode NONE --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quali; ty false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing ; false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --use-flow-aligner-for-stepwise-hc-filtering false --adaptive-pruning false --do-not-recover-dan; gling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 ; --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:4877,recover,recover-dan,4877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,4,"['error', 'recover']","['error-rate', 'recover-all-dangling-branches', 'recover-dan', 'recover-dangling-heads']"
Availability,"ne.CommandLineProgram.runTool(CommandLineProgram.java:147); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:209); at org.broadinstitute.hellbender.Main.main(Main.java:306); Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms200G -Xmx200G -XX:ParallelGCThreads=2 -jar /gatk/gatk-package-4.5.0.0-local.jar BaseRecalibrator -I VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam -O VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.baseRecal.bam -R GRCh38.primary_assembly.genome.fa --known-sites 1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --tmp-dir /tmp --disable-bam-index-caching true. Work dir:; /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/71/ac26344f0e095f7fe77cbb45a334db. Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`. -- Check '.nextflow.log' file for details. ```. I tried to run it like this:; ```; gatk --java-options ""-Xms200G -Xmx200G -XX:ParallelGCThreads=2"" \; BaseRecalibrator \; -I $input_bam \; -O ""${file(input_bam).baseName}.baseRecal.bam"" \; -R $reference \; --known-sites $kg_snp \; --known-sites $kg_indel \; --tmp-dir /tmp \; --disable-bam-index-caching true; ```. but I still get the memory error. I have more memory to use, but it seems very inefficient if I need to go up to 1TB? Why can I not make this run? And is there any alternative when I want to do the MarkDup, SplitCigar, BaseRecal ? . Hope you can help, ; BR, ; Mette",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8726:5601,error,error,5601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8726,1,['error'],['error']
Availability,"ne.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 17/10/18 17:35:58 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.131.101.159, 35676),broadcast_4_piece167,StorageLevel(1 replicas),0,0)); 17/10/18 17:35:58 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.131.101.159, 35676),broadcast_4_piece173,StorageLevel(1 replicas),0,0)); 17/10/18 17:35:58 WARN Executor: Issue communicating with driver in heartbeater; java.lang.NullPointerException; 	at org.apache.spark.storage.BlockManagerMaster.updateBlockInfo(BlockManagerMaster.scala:67); 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$tryToReportBlockStatus(BlockManager.scala:363); 	at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:219); 	at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:217); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:3484,ERROR,ERROR,3484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['ERROR'],['ERROR']
Availability,"ne; 22:13:30.002 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates13996065741193890473.csv'; 22:13:30.002 INFO AnalyzeCovariates - Generating plots file './sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf'; 22:13:30.518 INFO AnalyzeCovariates - Shutting down engine; [August 7, 2023 at 10:13:30 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=113246208; org.broadinstitute.hellbender.utils.R.RScriptExecutorException:; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10708586791705723928';source('/tmp/BQSR.12372590345390592260.R'); /tmp/AnalyzeCovariates13996065741193890473.csv /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_before_recal_data.table /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf; Stdout:; Stderr:; Attaching package: ‚Äògplots‚Äô. The following object is masked from ‚Äòpackage:stats‚Äô:. lowess. Error in names(x) <- value :; 'names' attribute [6] must be the same length as the vector [1]; Calls: source ... finishTable -> .gsa.assignGATKTableToEnvironment -> colnames<-; In addition: Warning messages:; 1: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 2: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 3: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 4: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 5: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; Execution halted. at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8456:3534,mask,masked,3534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8456,1,['mask'],['masked']
Availability,"neGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 12:01:37.108 INFO CombineGVCFs - Start Date/Time: August 24, 202",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:1570,Redundant,Redundant,1570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['Redundant'],['Redundant']
Availability,nerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildCon,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3108,ERROR,ERROR,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"new Germline CNV wdl test are too slow, causing travis failures",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4064:55,failure,failures,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064,1,['failure'],['failures']
Availability,new dangling head recovery leads to array index out of bounds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7085:18,recover,recovery,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7085,1,['recover'],['recovery']
Availability,"nflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /user/yaron/o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3675,ERROR,ERROR,3675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,"nflater; 16:36:22.399 INFO Funcotator - GCS max retries/reopens: 20; 16:36:22.399 INFO Funcotator - Requester pays: disabled; 16:36:22.399 INFO Funcotator - Initializing engine; 16:36:22.624 INFO FeatureManager - Using codec VCFCodec to read file file:///home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz; 16:36:22.842 INFO Funcotator - Done initializing engine; 16:36:22.842 INFO Funcotator - Validating sequence dictionaries...; 16:36:22.856 INFO Funcotator - Processing user transcripts/defaults/overrides...; 16:36:22.857 INFO Funcotator - Initializing data sources...; 16:36:22.859 INFO DataSourceUtils - Initializing data sources from directory: /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s; 16:36:22.871 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 16:36:22.871 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.871 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.891 INFO Funcotator - Shutting down engine; [January 10, 2024 at 4:36:22 PM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; ***********************************************************************. A USER ERROR has occurred: ERROR: Directory contains more than one config file: file:///home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Any guidance to resolve the issue is appreciated.; Thank you!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:4547,down,down,4547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,3,"['ERROR', 'down']","['ERROR', 'down']"
Availability,"ng GATK wrapper script /juffowup/gatk/build/install/gatk/bin/gatk; Running:; /juffowup/gatk/build/install/gatk/bin/gatk HaplotypeCaller -R /juffowup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta -I /juffowup2/malaria/haplotypecaller_arg_testing/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam -O /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz --bam-output /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam -contamination 0 --sample-ploidy 2 --linked-de-bruijn-graph --pileup-detection true --pileup-detection-enable-indel-pileup-calling true --max-reads-per-alignment-start 20 --annotate-with-num-discovered-alleles -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -G StandardAnnotation -G StandardHCAnnotation -ERC GVCF --verbosity INFO; 14:14:15.323 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 14:14:15.328 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 14:14:15.388 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/juffowup/gatk/build/install/gatk/lib/gkl-0.8.11.jar!/com/intel/gkl/native/libgkl_compression.so; 14:14:15.435 INFO HaplotypeCaller - ------------------------------------------------------------; 14:14:15.439 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0-44-g1529aa1-SNAPSHOT; 14:14:15.439 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:14:15.439 INFO HaplotypeCaller - Executing as jonn@dsde-methods-jonn-juffowup on Linux v5.4.0-1104-gcp amd64; 14:14:15.439 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.7+7; 14:14:15.440 INFO HaplotypeCaller - Start Date/Time: July 26, 2023 at 2:14:15 PM UTC; ...; 22:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:1078,Redundant,Redundant,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['Redundant'],['Redundant']
Availability,"ng for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. ```; 1 <?xml version=""1.0"" encoding=""UTF-8""?>; 2 <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; 3 <modelVersion>4.0.0</modelVersion>; 4 ; 5 <!--; 6 This pom is parent for all gatk poms; 7 See also:; 8 http://maven.apache.org/pom.html#Inheritance_v; 9 http://maven.apache.org/guides/introduction/introduction-to-the-pom.html#Project_Inheritance_vs_Project_Aggregation; 10 http://stackoverflow.com/questions",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:1552,ERROR,ERROR,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,3,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"ng monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:264); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22972,down,down,22972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['down'],['down']
Availability,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > ‚Äî; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:923,avail,available,923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725,3,['avail'],['available']
Availability,"ngAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:7859,error,error,7859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,ngGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dangling tails; 11:36:15.932 DEBUG ReadThreadingGraph - Recovered 13 of 31 dangling heads; 11:36:15.995 DEBUG IntToDoubleFunctionCache - cache miss 2401 > 2399 expanding to 4800; 11:36:16.347 DEBUG Mutect2Engine - Active Region chrM:3703-3943; 11:36:16.348 DEBUG Mutect2Engine - Extended Act Region chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Ref haplotype coords chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Haplotype count 254; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:40.673 DEBUG Mutect2 - Processing assembly region at chrM:3944-4243 isActive: false numReads: 2581; 11:36:40.736 DEBUG Mutect2 - Processing assembly region at chrM:4244-4543 isActive: false numReads: 0; 11:36:40.749 DEBUG Mutect2 - Processing assembly region at chrM:4544-4843 isActive: false numReads: 0; 11:36:40.760 DEBUG Mutect2 - Processing assembly region at chrM:4844-5143 isActive: false numReads: 0; 11:36:40.765 DEBUG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:11056,Recover,Recovered,11056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"ngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:34:51.566 INFO IndexFeatureFile - ------------------------------------------------------------; 14:34:51.566 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.2.1.0; 14:34:51.566 INFO IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:34:51.572 INFO IndexFeatureFile - Initializing engine; 14:34:51.572 INFO IndexFeatureFile - Done initializing engine; 14:34:51.674 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 38): ##description: evidence-based annotation of the human genome (GRCh38), version 38 (Ensembl 104), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 14:34:51.676 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 38): ##description: evidence-based annotation of the human genome (GRCh38), version 38 (Ensembl 104), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 14:34:51.679 INFO FeatureManager - Using codec EnsemblGtfCodec to read file file:///home/robby/Tools/NGS/gencode/hg19/gencode.v38lift37.annotation.REORDERED.gtf; 14:34:51.684 INFO ProgressMeter - Starting traversal; 14:34:51.684 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 14:34:51.694 INFO IndexFeatureFile - Shutting down engine; [August 2, 2021 at 2:34:51 PM CEST] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=113246208; java.lang.IllegalArgumentException: Unexpected value: Ensembl_canonical; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureTag.getEnum(GencodeGtfFeature.java:1391); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:197); at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7385:2071,error,errors,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7385,1,['error'],['errors']
Availability,"ngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:53:59.283 INFO IndexFeatureFile - ------------------------------------------------------------; 18:53:59.283 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.2.0.0; 18:53:59.284 INFO IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:53:59.290 INFO IndexFeatureFile - Initializing engine; 18:53:59.290 INFO IndexFeatureFile - Done initializing engine; 18:53:59.417 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 37): ##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 18:53:59.419 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 37): ##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 18:53:59.422 INFO FeatureManager - Using codec EnsemblGtfCodec to read file file:///home/robby/Tools/NGS/gatk-master4_2_src/scripts/funcotator/data_sources/gencode/hg19/gencode.v37lift37.annotation.REORDERED.gtf; 18:53:59.433 INFO ProgressMeter - Starting traversal; 18:53:59.433 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 18:54:01.952 INFO IndexFeatureFile - Shutting down engine; [March 8, 2021 at 6:54:01 PM CET] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=473956352; java.lang.IllegalArgumentException: Unexpected value: MANE_Plus_Clinical; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureTag.getEnum(GencodeGtfFeature.java:1388); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(Genc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134:2308,error,errors,2308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134,1,['error'],['errors']
Availability,"ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/gof/link.py"", line 325, in raise_with_op; reraise(exc_type, exc_value, exc_trace); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/six.py"", line 692, in reraise; raise value.with_traceback(tb); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__; self.fn() if output_subset is None else\; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 963, in rval; r = p(n, [x[0] for x in i], o); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 952, in p; self, node); File ""scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform; NotImplementedError: We didn't implemented yet the case where scan do 0 iteration; Apply node that caused the error: forall_inplace,cpu,scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceDimShuffle{0,2,1}.0, Subtensor{int64:int64:int64}.0, IncSubtensor{InplaceSet;:int64:}.0, Shape_i{0}.0); Toposort index: 95; Inputs types: [TensorType(int64, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(int64, scalar)]; Inputs shapes: [(), (0, 6, 6), (0, 6), (2, 6), ()]; Inputs strides: [(), (288, 8, 48), (48, 8), (48, 8), ()]; Inputs values: [array(0), array([], shape=(0, 6, 6), dtype=float64), array([], shape=(0, 6), dtype=float64), 'not shown', array(6)]; Inputs type_num: [7, 12, 12, 12, 7]; Outputs clients: [[Subtensor{int64:int64:int8}(forall_inplace,cpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282:3256,error,error,3256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282,1,['error'],['error']
Availability,"nnel.read(BlobReadChannel.java:124); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:141); ... 6 more; Caused by: java.io.IOException: Connection closed prematurely: bytesRead = 16777216, Content-Length = 41943040; at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.throwIfFalseEOF(NetHttpResponse.java:202); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:171); at java.io.FilterInputStream.read(FilterInputStream.java:107); at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:638); ... 13 more. Subsequent reruns on 4.0.4.0 yielded only 1 failure out of 3 walkers x 59 samples; no failures were observed on 4.0.9.0 or 4.0.11.0. So the problem is not unique to 4.0.12.0, but the rate of failure is much higher. Additional reruns on 4.0.12.0 suggest that the original failures were not intermittent; one run showed 6/59 samples failing, with many of those having more than one of the 3 walkers fail. Additional reruns with a branch of 4.0.12.0 that reverted to the htsjdk version used in 4.0.11.0 still showed a high rate of failure. There were at least a couple of instances where the same BAM appeared to fail in roughly the same spot as in the 4.0.12.0 runs, and other instances where the same BAM failed in roughly the same spot, only in two different walkers. However, the set of BAMs that failed was not consistent across all runs. Leaving to @droazen to delegate. The FC CNV featured WDL doesn't use NIO yet, but I'm surprised this hasn't cropped up in other WDLs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631:8062,failure,failure,8062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631,5,['failure'],"['failure', 'failures']"
Availability,"nnot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5745,down,downsample,5745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['down'],['downsample']
Availability,nnotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:16078,error,error,16078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,nnotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.8514933Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8515375Z [done in 2341 ms]; 2022-08-16T22:45:53.8515491Z 1 error; 2022-08-16T22:45:53.8515610Z 101 warnings; 2022-08-16T22:45:53.8515748Z expected [99] but found [1]; 2022-08-16T22:45:53.8515934Z at org.testng.Assert.fail(Assert.java:97); 2022-08-16T22:45:53.8516162Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); 2022-08-16T22:45:53.8516413Z at org.testng.Assert.assertEquals(Assert.java:118); 2022-08-16T22:45:53.8516617Z at org.testng.Assert.assertEquals(Assert.java:839); 2022-08-16T22:45:53.8517212Z at org.broadinstitute.hellbender.utils.help.DocumentationGenerationIntegratio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:22624,error,error,22624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be d; isabled with 'optimizer=None'.; HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.executeSegmentGermlineCNVCallsPythonScript(PostprocessGermlineCNVCalls.java:500); at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.generateSegmentsVCFFileFromAllShards(PostprocessGermlineCNVCalls.java:436); at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.traverse(PostprocessGermlineCNVCalls.java:297); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:892); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Let me know what data files we need to look into to figure out the cause of error so I can make them available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:14257,error,error,14257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,2,"['avail', 'error']","['available', 'error']"
Availability,nomicsDBImport - Done importing batch 53/65; 20:18:42.274 INFO ¬†GenomicsDBImport - Done importing batch 54/65; 21:01:51.304 INFO ¬†GenomicsDBImport - Done importing batch 55/65; 21:36:00.458 INFO ¬†GenomicsDBImport - Done importing batch 56/65; 22:08:38.587 INFO ¬†GenomicsDBImport - Done importing batch 57/65; 22:40:44.082 INFO ¬†GenomicsDBImport - Done importing batch 58/65; 23:14:11.202 INFO ¬†GenomicsDBImport - Done importing batch 59/65; 23:48:23.805 INFO ¬†GenomicsDBImport - Done importing batch 60/65; 00:20:35.869 INFO ¬†GenomicsDBImport - Done importing batch 61/65; 00:51:47.408 INFO ¬†GenomicsDBImport - Done importing batch 62/65; 01:25:23.587 INFO ¬†GenomicsDBImport - Done importing batch 63/65; 01:59:03.103 INFO ¬†GenomicsDBImport - Done importing batch 64/65; Using GATK jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) defined in environment variable GATK_LOCAL_JAR; Running:; ¬† ¬† java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx150g -Xms16g -jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) GenomicsDBImport --sample-name-map sample_map.chr3 --genomicsdb-workspace-path genomicsDB.rb.chr3 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --L chr3 --batch-size 50 --bypass-feature-reader --reader-threads 5 --merge-input-intervals --overwrite-existing-genomicsdb-workspace --consolidate; [farrell@scc-hadoop genomicsdb]$ ls genomicsDB.rb.chr3; __tiledb_workspace.tdb ¬†chr3$1$198295559 ¬†vcfheader.vcf ¬†vidmap.json. ```; It never indicates that it imported batch 65/65.¬†No error and the¬†¬†callset.json is missing which we found in chr4 to chr22. ; ¬†¬†; ls genomicsDB.rb.chr4. __tiledb_workspace.tdb ¬†callset.json ¬†chr4$1$190214555 ¬†vcfheader.vcf ¬†vidmap.json,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232:4498,error,error,4498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232,1,['error'],['error']
Availability,non-NAN; 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:1023); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1139,error,errorProbability,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['error'],['errorProbability']
Availability,"not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1878,ERROR,ERROR,1878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 112212, Read name 20GAVAAXX100126:8:1:1429:129840, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 126595, Read name 20FUKAAXX100202:6:46:9311:1219, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ...; ERROR: Read name 20FUKAAXX100202:3:66:14857:5877, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:3:42:3602:56427, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:3:43:9956:132423, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:5:28:11981:2516, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:6:24:17640:150063, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:7:6:14036:136793, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:8:4:15388:58751, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:7:46:18099:135243, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:1:61:19609:50570, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:7:24:21385:130712, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:6:65:2547:48691, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:7:44:20236:184614, Mate not found for paired read; Maximum output of [100] errors reached.; 19:03:47.020 INFO ValidateSamFile - Shutting down engine; [March 9, 2017 7:03:47 PM EST] org.broadinstitute.hellbender.tools.picard.sam.ValidateSamFile done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=1674051584; Tool returned:; false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:3321,ERROR,ERROR,3321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,14,"['ERROR', 'down', 'error']","['ERROR', 'down', 'errors']"
Availability,not exist; 2022-08-16T00:09:07.2547467Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.2647018Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2671678Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:1515,error,error,1515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6548080Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:3168,error,error,3168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"nps.high\_confidence.b37.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file. 19:13:26.973 INFO ASEReadCounter - Done initializing engine. 19:13:26.977 INFO ProgressMeter - Starting traversal. 19:13:26.977 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute. 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835092. 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835132. 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835133. ...¬†. ... ... 19:13:28.229 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29617944. 19:13:28.230 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29618025. 19:13:28.231 INFO ASEReadCounter - 0 read(s) filtered by: ValidAlignmentStartReadFilter. 0 read(s) filtered by: ValidAlignmentEndReadFilter. 0 read(s) filtered by: HasReadGroupReadFilter. 0 read(s) filtered by: MatchingBasesAndQualsReadFilter. 0 read(s) filtered by: SeqIsStoredReadFilter. 51 read(s) filtered by: NotDuplicateReadFilter. 63 read(s) filtered by: NotSecondaryAlignmentReadFilter. 3 read(s) filtered by: MappedReadFilter. 117 total reads filtered. 19:13:28.231 INFO ProgressMeter - 1:29618022 0.0 110019 5264067.0. 19:13:28.231 INFO ProgressMeter - Traversal complete. Processed 110019 total loci in 0.0 minutes. 19:13:28.233 INFO ASEReadCounter - Shutting down engine. \[June 14, 2021 7:13:28 PM UTC\] org.broadinstitute.hellbender.tools.walkers.rnaseq.ASEReadCounter done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=2303197184. output.txt:. contig position variantID refAllele altAllele refCount altCount totalCount lowMAPQDepth lowBaseQDepth rawDepth otherBases improperPairs. Thanks for your help!. Chunyang<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/165377'>Zendesk ticket #165377</a>)<br>gz#165377</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:5880,down,down,5880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['down'],['down']
Availability,"nputStream.<init>(ByteArrayInputStream.java:106); 	at org.broadinstitute.hellbender.engine.AuthHolder.getOfflineAuth(AuthHolder.java:79); 	at org.broadinstitute.hellbender.engine.AuthHolder.makeStorageClient(AuthHolder.java:94); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:177); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [bd000687-f538-4201-b888-668612d46bad] entered state [ERROR] while waiting for [DONE].; ```. =========================. On a third note, if the reference is also provided with a GCS path, we see this:. ```; ***********************************************************************. A USER ERROR has occurred: The specified fasta file (gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.fasta) does not exist. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: A USER ERROR has occurred: The specified fasta file (gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.fasta) does not exist.; 	at org.broadinstitute.hellbender.engine.datasources.ReferenceFileSource.<init>(ReferenceFileSource.java:31); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:49); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:394); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.Com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:8672,ERROR,ERROR,8672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,"nquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GATK CalibrateDragstrModel. ### Affected version(s); - [x] Latest public release version [4.3.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When running CalibrateDragstrModel in parallel mode, the supplied reference isn't detected correctly causing the following error stack trace:. ```bash; Using GATK jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx72g -jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar CalibrateDragstrModel --input input.cram --output input.txt --reference hg38.fa --str-table-path hg38.zip --threads 12 --intervals fasta_bed.bed --tmp-dir .; 10:24:21.117 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:24:21.289 INFO CalibrateDragstrModel - ------------------------------------------------------------; 10:24:21.289 INFO CalibrateDragstrModel - The Genome Analysis Toolkit (GATK) v4.3.0.0; 10:24:21.289 INFO CalibrateDragstrModel -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:1509,error,error,1509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['error'],['error']
Availability,ns does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.8514933Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:21911,error,error,21911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,nsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:10.813 ERROR Executor:91 - Exception in task 16.0 in stage 1.0 (TID 353); org.apache.spark.SparkException: Error communicating with MapOutputTracker; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:104); at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:202); at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:142); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:4081,ERROR,ERROR,4081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['ERROR'],['ERROR']
Availability,"nsferService' on port 44190.; 18/01/09 18:31:06 INFO netty.NettyBlockTransferService: Server created on 192.168.1.4:44190; 18/01/09 18:31:06 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/01/09 18:31:06 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.1.4:44190 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManager: external shuffle service port = 7337; 18/01/09 18:31:06 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60c8909a{/metrics/json,null,AVAILABLE,@Spark}; 18/01/09 18:31:06 INFO scheduler.EventLoggingListener: Logging events to hdfs://tele-1:8020/user/spark/spark2ApplicationHistory/application_1515493209401_0001; 18/01/09 18:31:09 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1515493209401_0001_01_000002 on host: tele-6. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_1515493209401_0001_01_000002; Exit code: 1; Stack trace: ExitCodeException exitCode=1: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.cont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:15758,AVAIL,AVAILABLE,15758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"nsider if this documentation is adequate from the perspective of a technically competent new user reading the documentation that has not seen examples outside of what is shown in the docs. Actually, to be honest, most of the examples out in the wild stick to only the most basic of options, so for more advanced uses it really is pretty unclear what such arguments should be. . This is not a generic please write better documentation (though that's always appreciated). This is particularly about 1) The tool usage format documentation 2) the particular mis-specification for interval formats (maybe some interpretive element of the page drops the ':' and '-', but viewing the source doesn't show any sign of them). For resolving one, I think moving a bit closer to the specifications in Linux man pages would help, but those are far from perfect themselves. . Here, even way back in 2013, Geraldine gives the correct version of the format. ; https://gatkforums.broadinstitute.org/gatk/discussion/3395/interval-file-errors. > Hi Kristine,; > ; > Make sure your intervals list is named with either extension .bed or .list as appropriate; it cannot end in .txt. The program gets confused, thinks header lines are intervals and doesn't parse the file correctly. For the record, the simplest format for intervals (which I prefer, personally) is the \<chr\>:\<start\>-\<stop\> format, which doesn't require a sequence dictionary.; > ; > The intervals list specifies which regions of the genome the analysis will be run on. I can't comment on how it's used in MuTect, but in GATK it's typically used to restrict analysis to exome capture targets, or to particular regions of interest. And confirms shortly after in the same thread that this is referring to the GATK formats described (.list and .intervals): . > Oh, if you have the intervals in that format the extension needs to be .interval_list or .list, not bed. You'll need to change the starting zeroes to ones. Sorry, the formatting requirements are",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639:5045,error,errors,5045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639,1,['error'],['errors']
Availability,nt/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: p,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:7906,error,error,7906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,nt/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: p,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:9944,error,error,9944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"ntBroadcast.scala:293); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 21 more; Caused by: java.lang.UnsupportedOperationException; 	at shaded.cloud_nio.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. [Stage 21:> (0 + 60) / 3539]18/12/21 16:08:30 ERROR org.apache.spark.scheduler.TaskSetManager: Task 26 in stage 21.0 failed 4 times; aborting job; 18/12/21 16:08:30 ERROR org.apache.spark.internal.io.SparkHadoopMapReduceWriter: Aborting job job_20181221160412_0054.; org.apache.spark.SparkException: Job aborted due to stage failure: Task 26 in stage 21.0 failed 4 times, most recent failure: Lost task 26.3 in stage 21.0 (TID 2498, readpipeline-w-4.c.broad-gatk-test.internal, executor 21): java.io.IOException: com.esotericsoftware.kryo.KryoException: java.lang.UnsupportedOperationException; Serialization trace:; requestOptions (com.google.cloud.storage.BlobReadChannel); channel (com.google.cloud.storage.contrib.nio.CloudStorageReadChannel); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); rsFile (htsjdk.samtools.cram.ref.ReferenceSource); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:4776,ERROR,ERROR,4776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['ERROR'],['ERROR']
Availability,"ntVariantsSpark - Initializing engine; 19:43:09.993 INFO PrintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsof",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:4540,ERROR,ERROR,4540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['ERROR'],['ERROR']
Availability,"ntamination file, except allele frequency, and I tried using that simplified VCF both for the germline resource and the variants for contamination file. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(Filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:5730,Error,ErrorProbabilities,5730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Error'],['ErrorProbabilities']
Availability,"ntelPairHmm - Available threads: 2; > 31 15:07:53.224 INFO IntelPairHmm - Requested threads: 4; > 32 15:07:53.224 WARN IntelPairHmm - Using 2 available threads, but 4 were requested; > 33 15:07:53.224 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; > 34 15:07:53.231 WARN Mutect2 - Note that the Mutect2 reference confidence mode is in BETA -- the likelihoods model and output format are subject to change in subsequent versions.; > 35 15:07:53.314 INFO ProgressMeter - Starting traversal; > 36 15:07:53.314 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; > 37 15:07:54.410 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.8392900000000002E-4; > 38 15:07:54.412 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.03020143; > 39 15:07:54.412 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.05 sec; > 40 15:07:54.413 INFO Mutect2 - Shutting down engine; > 41 [June 19, 2023 at 3:07:54 PM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; > 42 Runtime.totalMemory()=285212672; > 43 java.lang.IndexOutOfBoundsException: Index -1 out of bounds for length 1; > 44 at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64); > 45 at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70); > 46 at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:266); > 47 at java.base/java.util.Objects.checkIndex(Objects.java:359); > 48 at java.base/java.util.ArrayList.get(ArrayList.java:427); > 49 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:389); > 50 at java.base/java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:248); > 51 at java.base/java.util.stream.SliceOps$1$1.accept(SliceOps.java:200); > 52 at java.base/java.uti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632:4381,down,down,4381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632,1,['down'],['down']
Availability,"ntextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8609,AVAIL,AVAILABLE,8609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"ntextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8350,AVAIL,AVAILABLE,8350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"ntextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 INFO client.RMProxy: Connecting to ResourceManager at tele-1/192.168.1.4:8032; 18/01/09 18:30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up containe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:10328,AVAIL,AVAILABLE,10328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"ntimes for balanced sharding (#7645); - Wire through GvsExtractCohortFromSampleNames with new prepare/extract [VS-283] (#7654); - Update GvsExtractCallset.wdl (#7678); - cherry pick lb_lfs_force change (#7683); - Tweak ingest messaging and failure mode [VS-267] (#7680); - Additional tweaks for GvsExtractCohortFromSampleNames [VS-283] (#7698); - VS-280 Create a VAT intermediary (#7657); - There something about split intervals [VS-306] (#7694); - VS 284 Add prepare step to Quick Start (#7685); - VS-222 dont hard code the dataset name! (#7704); - fixed bug; added tests (#7717); - Clean up optional and inconsistently named inputs [VS-294] [VS-218] (#7715); - VS-263 notes on ingest and beyond (#7618); - Add task to ExtractCallset that verifies filter_set_name exists in GVS dataset [VS-335] (#7734); - Clean up input json files to reflect changes inputs [VS-337] (#7733); - used constants; implemented non-AS transformation (#7718); - Pass dataset name to gatk ExtractFeatures (#7735); - Add withdrawn and is_control columns [VS-70] [VS-213] (#7736); - Allow interval lists that require the SA to see (#7743); - allow for gatk to be overridden, update with known good jar (#7758); - VS-361 Add GvsWithdrawSamples wdl (#7765); - Extract Performance Improvements (#7686); - Don't put withdrawn sample data in alt_allele table [VS-369] (#7762); - remove PET code (#7768); - Adding AD for scale testing VS 225 add AD (#7713); - Deterministic Sample ID assignments [VS-371] (#7770); - remove R scripts from filtering (#7781); - Remove an old ""temp table"" dataset (#7780); - Clean up LocalizeFile [VS-314] (#7771); - Remove pet code from CreateVariantIngestFiles and friends [VS-375] (#7773); - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:21407,failure,failure,21407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['failure'],['failure']
Availability,"nts (up from 130 for the 100% tumor alone, as above). Using this joint segmentation for subsequent ModelSegments runs:. For the 100% normal, this yields 88 segments (up from 36):; ![N-SJS modeled](https://user-images.githubusercontent.com/11076296/76632024-ebecb300-6518-11ea-89ff-109c97970ef0.png). For the 100% tumor, this yields 166 segments (up from 130):; ![T-SJS modeled](https://user-images.githubusercontent.com/11076296/76632125-13dc1680-6519-11ea-9901-0c78809d08ba.png). I haven't performed detailed validations, but some spot checking suggests that this actually mitigate oversegmentation while still increasing sensitivity to shared events. For example, there is a small 13-bin deletion in chr19 that is found when running the 100% normal alone, but gets broken up into two adjacent deletions when running the 100% tumor alone (probably just due to statistical noise in the copy ratios). When running jointly, the deletion does not get broken up. However, as discussed over Slack, we should probably run some scenarios with simulated data to check behavior---for example, how robust is the joint segmentation to some of the samples being noisy/oversegmented?. There are lots of options for restructuring the workflow. We could potentially modify ModelSegments to take in the denoised copy ratios from the normal, when available, and add modeling of the normal and germline tagging to that tool. Or we could break things up into separate tools. @fleharty any opinions?. Note that another benefit of using this joint segmentation for germline tagging is that common breakpoints will be shared. This obviates the need for a lot of the idiosyncratic code (in the experimental postprocessing tools) that deals with reconciling segmentations and combining breakpoints. In general, I think such code is extremely prone to off-by-one errors and should be avoided, if possible. See https://github.com/broadinstitute/gatk/pull/5450 for a reminder of some of the remaining issues with that workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598764477:1507,robust,robust,1507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598764477,3,"['avail', 'error', 'robust']","['available', 'errors', 'robust']"
Availability,"nts -V INPUT_VCF -R REF -O OUTPUT_VCF. Then, GATK outputs the following:. ```; 18:30:57.468 INFO CNNScoreVariants - Initializing engine; 18:30:57.985 INFO FeatureManager - Using codec VCFCodec to read file ...; 18:30:58.183 INFO IntervalArgumentCollection - Processing 48129895 bp from intervals; 18:30:58.188 INFO CNNScoreVariants - Done initializing engine; 18:31:00.188 INFO CNNScoreVariants - Using key:CNN_1D for CNN architecture:.../1d_cnn_mix_train_full_bn.2560984151625233621.json and weights:.../1d_cnn_mix_train_full_bn.2397909300265264152.hd5; 18:31:19.873 INFO ProgressMeter - Starting traversal; 18:31:19.874 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 18:31:50.095 INFO CNNScoreVariants - Shutting down engine; [2018/04/24 18:31:50 JST] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.88 minutes.; Runtime.totalMemory()=2141716480; ***********************************************************************; A USER ERROR has occurred: A timeout ocurred waiting for output from the remote Python command.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A timeout ocurred waiting for output from the remote Python command.; at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.getAccumulatedOutput(StreamingPythonScriptExecutor.java:219); at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:153); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:260); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:891); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4696:1327,ERROR,ERROR,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4696,1,['ERROR'],['ERROR']
Availability,nts.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(Gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5379,ERROR,ERROR,5379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"nvs/gatk/lib/python3.6/site-packages/theano/gof/link.py"", line 325, in raise_with_op; reraise(exc_type, exc_value, exc_trace); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/six.py"", line 692, in reraise; raise value.with_traceback(tb); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 978, in p; self, node); File ""theano/scan_module/scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform (/home/shlee/.theano/compiledir_Linux-4.13--gcp-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64/scan_perform/mod.cpp:2628); NotImplementedError: We didn't implemented yet the case where scan do 0 iteration; Apply node that caused the error: forall_inplace,cpu,scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceDimShuffle{0,2,1}.0, Subtensor{int64:int64:int64}.0, IncSubtensor{InplaceSet;:int64:}.0, Shape_i{0}.0); Toposort index: 97; Inputs types: [TensorType(int64, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(int64, scalar)]; Inputs shapes: [(), (0, 6, 6), (0, 6), (2, 6), ()]; Inputs strides: [(), (288, 8, 48), (48, 8), (48, 8), ()]; Inputs values: [array(0), array([], shape=(0, 6, 6), dtype=float64), array([], shape=(0, 6), dtype=float64), 'not shown', array(6)]; Outputs clients: [[Subtensor{int64:int64:int8}(forall_inplace,cpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]. HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be d; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:11467,error,error,11467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['error'],['error']
Availability,"nzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.addGivenAlleles(AssemblyBasedCallerUtils.java:350); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:291); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:1249,echo,echo,1249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,1,['echo'],['echo']
Availability,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:2018,down,down,2018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,1,['down'],['down']
Availability,"o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/cram_samtools.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/cram_stats.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/files.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/mFILE.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/open_trace_file.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/pooled_alloc.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/rANS_static.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/sam_header.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/string_alloc.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_libcurl.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_gcs.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_s3.o -Lpysam -L. -Lbuild/lib.macosx-10.7-x86_64-3.6/pysam -Lbuild/lib.macosx-10.7-x86_64-3.6/pysam -L/Users/markw/anaconda/envs/gatk/lib -lz -llzma -lbz2 -lz -lcurl -o build/lib.macosx-10.7-x86_64-3.6/pysam/libchtslib.cpython-36m-darwin.so -dynamiclib -rpath @loader_path -Wl,-headerpad_max_install_names -Wl,-install_name,@rpath/libchtslib.cpython-36m-darwin.so -Wl,-x; gcc: error: @loader_path: No such file or directory; gcc: error: unrecognized command line option ‚Äò-rpath‚Äô; error: command 'gcc' failed with exit status 1. ----------------------------------------; Command ""/Users/markw/anaconda/envs/gatk/bin/python -u -c ""import setuptools, tokenize;__file__='/private/var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-build-aybz1ucp/pysam/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-z_8e2y_r-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-build-aybz1ucp/pysam/. CondaValueError: pip returned an error; ```; This appears to have been an issue with pysam in the past: https://github.com/pysam-developers/pysam/issues/323",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742:2965,error,error,2965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742,5,['error'],['error']
Availability,"o from jar:file:/master/xxxxxxx/local/pckg/python/miniconda3/envs/cerc_prod/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Mon Jun 22 16:48:58 CDT 2020] MergeVcfs --INPUT data/calling/cerc_prod2.SM_V7_1.vcf.gz --INPUT data/calling/cerc_prod2.SM_V7_ZW.vcf.gz --OUTPUT out.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 22, 2020 4:48:58 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Jun 22 16:48:58 CDT 2020] Executing as xxxxxxx@yyyyyy on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Mon Jun 22 16:48:58 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1211105280; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///data/infectious/schistosome/tmp/test%20a/data/calling/cerc_prod2.SM_V7_1.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:2246,avail,available,2246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,1,['avail'],['available']
Availability,"o read file file:///data/users/zhanglei/species/Medicago/result/SRR340097.HC.g.vcf.gz; 18:08:15.044 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340098.HC.g.vcf.gz; 18:08:15.098 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340099.HC.g.vcf.gz; 18:08:15.142 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340100.HC.g.vcf.gz; 18:08:15.183 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340101.HC.g.vcf.gz; 18:08:15.217 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340102.HC.g.vcf.gz; 18:08:15.250 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340103.HC.g.vcf.gz; 18:08:15.277 INFO CombineGVCFs - Shutting down engine; [May 18, 2019 6:08:15 PM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2372403200; java.lang.IllegalArgumentException: Feature inputs must be unique: /data/users/zhanglei/species/Medicago/result/SRR340103.HC.g.vcf.gz; 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$initializeDrivingVariants$0(MultiVariantWalker.java:60); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.initializeDrivingVariants(MultiVariantWalker.java:56); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:47); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:558); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.onStartup(MultiVariantWalker.java:48); 	at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947:3988,down,down,3988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947,1,['down'],['down']
Availability,"o.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:748); 18/04/24 17:42:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:42:11 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:42:11 INFO BlockManager: BlockManager stopped; 18/04/24 17:42:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:42:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:42:11 INFO SparkContext: Successfully stopped SparkContext; 17:42:11.053 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:42:11 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=866648064; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:39074,failure,failure,39074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['failure'],['failure']
Availability,"o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9690,AVAIL,AVAILABLE,9690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46312,AVAIL,AVAILABLE,46312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"oadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 284.6 KB); 16/08/24 14:06:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56998 (size: 23.2 KB, free: 10.4 GB); 16/08/24 14:06:09 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:105; 16/08/24 14:06:10 INFO FileInputFormat: Total input paths to process : 1; 16/08/24 14:06:21 INFO SparkUI: Stopped Spark web UI at http://10.200.98.30:4040; 16/08/24 14:06:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/08/24 14:06:21 INFO MemoryStore: MemoryStore cleared; 16/08/24 14:06:21 INFO BlockManager: BlockManager stopped; 16/08/24 14:06:21 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/08/24 14:06:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/08/24 14:06:21 INFO SparkContext: Successfully stopped SparkContext; 14:06:21.109 INFO SparkGenomeReadCounts - Shutting down engine; [August 24, 2016 2:06:21 PM EDT] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=3192389632; java.lang.IndexOutOfBoundsException; at java.nio.ByteBuffer.wrap(ByteBuffer.java:375); at htsjdk.samtools.BAMRecord.getCigar(BAMRecord.java:246); at org.seqdoop.hadoop_bam.BAMSplitGuesser.guessNextBAMRecordStart(BAMSplitGuesser.java:189); at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:244); at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:159); at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:253); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:120); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:1743,down,down,1743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,1,['down'],['down']
Availability,oadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6973221Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6981573Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7492903Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7498018Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:4773,error,error,4773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,oadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.strea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:1673,Error,Error,1673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['Error'],['Error']
Availability,"object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:255); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:37); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:4082,down,down,4082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['down'],['down']
Availability,"oblem using BaseRecalibratorSpark. The tool fails soon after starting. The same error appears with the same bam file on different machines. Additionally, vanilla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1160,error,error,1160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['error'],['error']
Availability,"obsolete now as we switched to a different strategy: contigs that used to trigger InvDup calls are now classified as ""incomplete"" because the duplicated region could not be inferred reliably from the contig's alignments alone",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3529#issuecomment-383723121:182,reliab,reliably,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3529#issuecomment-383723121,1,['reliab'],['reliably']
Availability,"occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java‚Äô: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java‚Äô: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smith",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:970,Error,Error,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262,1,['Error'],['Error']
Availability,occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2933,ERROR,ERROR,2933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"ockTransferService' on port 43627.; 2019-01-09 13:35:33 INFO NettyBlockTransferService:54 - Server created on scc-hadoop.bu.edu:43627; 2019-01-09 13:35:33 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:43627 with 372.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:34 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53f94afe{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:37 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.204:36598) with ID 2; 2019-01-09 13:35:37 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q20.scc.bu.edu:42946 with 366.3 MB RAM, BlockManagerId(2, scc-q20.scc.bu.edu, 42946, None); 2019-01-09 13:35:39 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.185:34050) with ID 1; 2019-01-09 13:35:39 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q01.scc.bu.edu:41129 with 366.3 MB RAM, BlockManagerId(1, scc-q01.scc.bu.edu, 41129, None); 2019-01-09 13:35:39 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 2019-01-09 13:35:41 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 371.4 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:16536,AVAIL,AVAILABLE,16536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"od and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1360,down,down,1360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,2,['down'],['down']
Availability,"odule = get_module_cache().module_from_key(; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cc.py"", line 48, in get_module_cache; return cmodule.get_module_cache(config.compiledir, init_args=init_args); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1587, in get_module_cache; _module_cache = ModuleCache(dirname, **init_args); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 703, in __init__; self.refresh(); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 794, in refresh; files = os.listdir(root); FileNotFoundError: [Errno 2] No such file or directory: '/spin1/home/linux/sangj2/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.5.1804-Core-x86_64-3.6.2-64/tmpyvtzjxzm'; 00:50:23.369 DEBUG ScriptExecutor - Result: 1; 00:50:23.370 INFO GermlineCNVCaller - Shutting down engine; [October 29, 2019 12:50:23 AM EDT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=2335703040; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-28-1-Test-gCNV_23-40-33/2-Output/8-GATK-Temp/cohort_denoising_calling.7177495255490777642.py --ploidy_calls_path=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-28-1-Test-gCNV_23-40-33/2-Output/1-Contig-Ploidy/14.Contig_Ploidy_Dir/ploidy-calls --output_calls_path=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-28-1-Test-gCNV_23-40-33/2-Output/2-Germline-CNV/14.Germline-CNV/CNV-calls --output_tracking_path=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-28-1-Test-gCNV_23-40-33/2-Output/2-Germline-CNV/14.Germline-CNV/CNV-tracking --modeling_interval_list=/gpfs/gsfs7/users/gatk_users1/0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019:7336,down,down,7336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019,1,['down'],['down']
Availability,"odule>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see description. #### Actual behavior; see description. ----. ## Feature request; - Switch from pymc3/Theano to another framework that offers the same functionality; - Modify the depedencies of gcnvkernel. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3341,error,error,3341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,4,['error'],"['error', 'errors']"
Availability,"of GATK. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I am trying to run GATK and CombineGVCF failed.; I am using the following code:; singularity exec /fs/scratch/PHS0338/appz/GVCF/gatk_latest.sif \; gatk CombineGVCFs -R /users/PHS0338/jpac1984/data/Autosome.fasta \; --variant PA113.vcf.gz --variant PA113corr.vcf.gz --variant PA112.vcf.gz --variant PA112corr.vcf.gz --variant IN33.vcf.gz\; --variant IN33corr.vcf.gz --variant AL82.vcf.gz \; -O test.vcf.gz; It has all the parameters as mentioned in the website: https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs. #### Expected behavior; _Tell us what should happen_; According to the website (https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs) about combineGVCF, it should have worked fine without any problems... I got the following error log:. 20:11:34.701 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 13, 2021 8:11:35 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 20:11:35.527 INFO CombineGVCFs - ------------------------------------------------------------; 20:11:35.527 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 20:11:35.527 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 20:11:35.528 INFO CombineGVCFs - Executing as jpac1984@p0002.ten.osc.edu on Linux v3.10.0-1160.21.1.el7.x86_64 amd64; 20:11:35.529 INFO CombineGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 20:11:35.529 INFO CombineGVCFs - Start Date/Time: June 13, 2021 8:11:34 PM GMT; 20:11:35.529 INFO CombineGVCFs - --",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:1457,error,error,1457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,1,['error'],['error']
Availability,"of reads that overlap genomic bins (the size of which you can select, typically ~100bp-1kb); these counts are used to estimate copy ratio. In contrast, CollectAllelicCounts counts the number of alt and ref bases in the pileup at genomic sites; these allelic counts are used to estimate minor-allele fraction. > how can we understand this, though I know this fucntion has many possiboe inputs.; > but some has only normal inputs, how is related to tunor? thanks a lot. The possible inputs to ModelSegments are `denoised-copy-ratios`, `allelic-counts`, and `normal-allelic-counts`. As alluded to above, you can run either tumor or normal samples as cases. In both scenarios, you would provide denoised copy ratios (generated by running the output of CollectReadCounts through DenoiseReadCounts, using a PoN to denoise if available) to `denoised-copy-ratios` and/or allelic counts (output by CollectAllelicCounts) to `allelic-counts`. Furthermore, when running a tumor case sample, you may additionally provide the allelic counts from a matched normal to `normal-allelic-counts`. Note that the PoN is only used to denoise copy ratios, not allelic counts. So the first example you showed is for running a normal case sample using only denoised copy ratios from the normal:. ```; gatk ModelSegments \; --denoised-copy-ratios normal.denoisedCR.tsv \; --output-prefix normal \; -O output_dir; ```. The second example is for running a tumor case sample using only allelic counts from the tumor:. ```; gatk ModelSegments \; --allelic-counts tumor.allelicCounts.tsv \; --output-prefix tumor \; -O output_dir; ```; Typically you will want to run a tumor case sample with all possible inputs, if available:. ```; gatk ModelSegments \; --denoised-copy-ratios tumor.denoisedCR.tsv \; --allelic-counts tumor.allelicCounts.tsv \; --normal-allelic-counts normal.allelicCounts.tsv \; --output-prefix tumor \; -O output_dir; ```. Hope this helps. If you have additional questions, please feel free to post on the forum!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5404#issuecomment-439184102:3194,avail,available,3194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5404#issuecomment-439184102,1,['avail'],['available']
Availability,"of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't actually think this is a very important use case to support...); - [x] Delete/deprecate/etc. CNN tools/tests as appropriate. Note that this has to be done concurrently, since we remove Tensorflow. @droazen perhaps I can take a first stab at this in a subsequent commit to this PR once more of the gCNV dust settles and/or has undergone a preliminary review? EDIT: Disabled integration/WDL tests. We should add some deprecation messages to the tools---we can note that they should still work in previous environments but will be untested. I might set up a separate PR for deletion, to be done at the appropriate time (but I call dibs on this, can't have @davidbenjamin overtaking my all-time record for number of lines deleted üòõ).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:3323,avail,available,3323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['avail'],['available']
Availability,"ok well this was a draft, but Miguel got here first, so.....; do we want to just shut this all down and skip Validate VDS?. https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/91bc9190-d623-4ce6-8184-b20e5cb622e5. ok I hate this pr---I dont think it makes sense to have a VDS validation script that only produces a VDS if the VDS matches the VCF--that makes it very hard to debug. https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/c27c9bbe-6a01-4639-bdf9-14b00d5dc252",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343:95,down,down,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343,1,['down'],['down']
Availability,"ol behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerSampleHC' is not a valid command.; ***********************************************************************; ./gatk DepthPerAlleleBySample -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerAlleleBySample' is not a valid command.; ***********************************************************************; ./gatk DepthOfCoverage -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:1827,error,errors,1827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,1,['error'],['errors']
Availability,"ol(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	... 5 more. To bring about success I added 4 lines of code : . ```; ln -vs ${ref_fasta} ; ; ln -vs ${ref_fasta_fai} ;; ln -vs ${ref_fasta_dict} ;; FASTA_NAME=`basename ${ref_fasta} `; . ```. Then, instead of --reference ${ref_fasta} in calling gatk-protected, I put --reference $FASTA_NAME and the ""null"" exception went away and the program run successfully. ---. @eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-264264203). per @droazen : @achevali @LeeTL1220 . ---. @LeeTL1220 commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265342816). @eddiebroad Before this gets assigned, what version of gatk-protected are you using?; Assuming that this is a version we built (despite the name ""eddie.jar""): @achevali , can you figure out how you are reporting the error. @droazen are you sure this is not in the engine?. ---. @eddiebroad commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265464665). @LeeTL1220 . The original JAVA JAR where I first observed the ""null"" message I presume was based off commit 3a2bb0d. At the time the project was initiated I think it was the latest commit. The original JAR where the ""null"" message was observed was gatk-protected-all-3a2bb0d-SNAPSHOT-spark_standalone.jar . Because of the ""3a2bb0d"" in the JAR file name is why I presume that it's based off commit 3a2bb0d. . From the gatk-protected repo code (and also ""gatk"" repo) I added some debug/print statements and saved to a differently named JAR ""eddie.jar"" to help me distinguish my hacking from the original JAR. . The JAVA file where I added the most helpful statements was in CommandLineProgram.java which is actually in ""gatk"" repo (not ""gatk-protected"" repo). If I look at a LOG, I c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:3459,error,error,3459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['error'],['error']
Availability,"ol(s) or class(es); TransferReadTags. ### Affected version(s); - [X] Latest public release version [gatk-4.3.0.0]. ### Description ; When traversing the reads in both aligned (target) and unaligned (the one with the desired tag) BAMs an error is thrown complaining about a read `found in the aligned bam is not found in the unmapped bam`. However the reads exists. It looks like the `traverse` function that uses the lexicographic order difference between both query names will find a _negative_ `diff` and assume that the read in the aligned BAM is missing in the uBAM. However, with Illumina read headers it seems almost guaranteed that this is going to be an issue since the y-coord (the last colon-separated field in the header) often has numbers with different number of digits. The lexicographical comparison will fail to adjust when comparing two read names where the length of the read in the target BAM is larger than the length of the read in the uBAM. . This is the `traverse` function that throws the error:; https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L109-L145 . #### Steps to reproduce; Run `TransferReadTags` with an Illumina sequenced aligned BAM. I can provide dummy files if needed, but should be easy to reproduce. The following example should help illustrate the issue:. ```sh; $ /data/reddylab/software/gatk/gatk-4.3.0.0/gatk TransferReadTags \; --output /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam \; --read-tags RX \; --unmapped-sam /data/reddylab/Alex/tmp/TEST_BAM.umi.nsorted.ubam \; --input /data/reddylab/Alex/tmp/TEST_BAM.nsorted.bam; ```. Produces the following output:; ```; Using GATK jar /gpfs/fs1/data/reddylab/software/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:1043,error,error,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['error'],['error']
Availability,"oleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4j.appender.console=org.apache.log4j.ConsoleAppender; log4j.appender.console.target=System.out; log4j.appender.console.layout=org.apache.log4j.PatternLayout; log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1406,ERROR,ERROR,1406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['ERROR'],['ERROR']
Availability,"olean readHasStarted = false;; boolean addedHardClips = false;. while (!cigarStack.empty()) {; final CigarElement cigarElement = cigarStack.pop();. if (!readHasStarted &&; cigarElement.getOperator() != CigarOperator.DELETION &&; cigarElement.getOperator() != CigarOperator.SKIPPED_REGION &&; cigarElement.getOperator() != CigarOperator.HARD_CLIP) {; readHasStarted = true;; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.HARD_CLIP) {; totalHardClip += cigarElement.getLength();; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.DELETION) {; totalHardClip += cigarElement.getLength();; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.SKIPPED_REGION) {; totalHardClip += cigarElement.getLength();; }. if (readHasStarted) {; if (i == 1) {; if (!addedHardClips) {; if (totalHardClip > 0) {; inverseCigarStack.push(new CigarElement(totalHardClip, CigarOperator.HARD_CLIP));; }; addedHardClips = true;; }; inverseCigarStack.push(cigarElement);; } else {; if (!addedHardClips) {; if (totalHardClip > 0) {; cleanCigar.add(new CigarElement(totalHardClip, CigarOperator.HARD_CLIP));; }; addedHardClips = true;; }; cleanCigar.add(cigarElement);; }; }; }; // first pass (i=1) is from end to start of the cigar elements; if (i == 1) {; shiftFromEnd = shift;; cigarStack = inverseCigarStack;; }; // second pass (i=2) is from start to end with the end already cleaned; else {; shiftFromStart = shift;; }; }; }; `. Notice that the variable _shift_ is initialized, but never assigned to again for the duration of the loop. Thus _shiftFromStart_ and _shiftFromEnd_ are always set to zero upon completion of the loop. These values are used by the _applyHardClipBases_ function, which is called in a number of places to hard clip bases from a read, but because of this error, they will always be zeroed out. The function containing the error is in the file ""src/main/java/org/broadinstitute/hellbender/utils/clipping/ClippingOp.java"" line 523",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6130:2226,error,error,2226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6130,2,['error'],['error']
Availability,"om intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:50:19.847 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:50:19.848 INFO IntelPairHmm - Available threads: 48; 14:50:19.848 INFO IntelPairHmm - Requested threads: 4; 14:50:19.848 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:50:19.926 INFO ProgressMeter - Starting traversal; 14:50:19.926 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:50:30.309 INFO ProgressMeter - chr17:740224 0.2 3010 17395.5; 14:50:41.016 INFO ProgressMeter - chr17:1675683 0.4 7020 19973.4; 14:50:51.041 INFO ProgressMeter - chr17:2415218 0.5 10100 19477.4; 14:51:01.041 INFO ProgressMeter - chr17:3591332 0.7 14920 21773.6; 14:51:11.059 INFO ProgressMeter - chr17:4574538 0.9 19100 22412.6; 14:51:21.089 INFO ProgressMeter - chr17:5381890 1.0 22460 22033.3; 14:51:31.097 INFO ProgressMeter - chr17:6474462 1.2 27070 22821.4; 14:51:41.535 INFO ProgressMeter - chr17:7455949 1.4 31150 22902.4; 14:51:51.542 INFO ProgressMeter - chr17:8073825 1.5 33820 22149.2; 14:52:01.549 INFO ProgressMeter - chr17:9138632 1.7 38220 22566.0; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:7110,Avail,Available,7110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678,1,['Avail'],['Available']
Availability,"ombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Numb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:7330,error,error,7330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"omics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgrading to google-cloud-dataflow-java-sdk-all:0.4.150710 (#754), so perhaps this is caused by a version mismatch somewhere. I wrote a small bug-reproducing class, [BadTypeRepro](https://github.com/broadinstitute/hellbender/blob/jp_badtype_repro/src/main/java/org/broadinstitute/hellbender/dev/tools/walkers/bqsr/BadTypeRepro.java), in its eponymous branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/791:2253,error,error,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791,1,['error'],['error']
Availability,"omicsDBImport - Initializing engine; 01:07:02.331 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 01:07:02.702 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 01:07:02.868 INFO IntervalArgumentCollection - Processing 135534747 bp from intervals; 01:07:02.869 INFO GenomicsDBImport - Done initializing engine; 01:07:02.870 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10/callset.json; 01:07:02.870 INFO GenomicsDBImport - Incrementally importing to workspace - /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10; 01:07:02.871 INFO ProgressMeter - Starting traversal; 01:07:02.871 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 01:07:03.006 INFO GenomicsDBImport - Shutting down engine; [August 29, 2020 at 1:07:03 AM HKT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2147483648; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: A130489. Sample was originally in /paedwy/disk1/yangyxt/wes/batch11_13/gvcfs/A130489.HC.g.vcf.gz; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:252); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:13161,down,down,13161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['down'],['down']
Availability,"ommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; sudo apt-get -qq update > /dev/null; sudo apt-get -qq install -y gradle. echo ""Downloading binaries for Spark""; wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.1-bin-hadoop2.6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3467,error,error,3467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['error'],['error']
Availability,"ommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeU",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:4416,error,errors,4416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['error'],['errors']
Availability,"ommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:107); at org.broadinstitute.hellbender.tools.HaplotypeCallerSparkIntegrationTest.testNonStrictVCFModeIsConsistentWithPastResults(HaplotypeCallerSparkIntegrationTest.java:109); Caused by:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; at java.util.ArrayList.sort(ArrayList.java:1464); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerReadThreadingAssemblerArgumentCollection.makeReadThreadingAssembler(HaplotypeCallerReadThreadingAssemblerArgumentCollection.java:37); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerArgumentCollection.createReadThreadingAssembler(AssemblyBasedCallerArgumentCollection.java:36); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.initialize(HaplotypeCallerEngine.java:231); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.<init>(HaplotypeCallerEngine.java:166); at org.broadinstitute.hellbender.tools.Haplot",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:4439,failure,failure,4439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['failure'],['failure']
Availability,ommon.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.8514933Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8515375Z [done in 2341 ms]; 2022-08-16T22:45:53.8515491Z 1 error; 2022-08-16T22:45:53.8515610Z 101 warnings; 2022-08-16T22:45:53.8515748Z expected [99] but found [1]; 2022-08-16T22:45:53.8515934Z at org.testng.Assert.fail(Assert.java:97); 2022-08-16T22:45:53.8516162Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); 2022-08-16T22:45:53.8516413Z at org.testng.Assert.assertEquals(Assert.java:118); 2022-08,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:22457,error,error,22457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"on emitted from ""AD"" field in vcf is much lower than the real depth. I think I have disabled downsampling by set ""--max-reads-per-alignment-start"" to 0. The command line I used is as follow:¬†. gatk¬† Mutect2¬†¬†-R¬† reference.fa¬†¬†-I¬† tumor.bam¬†¬†--panel-of-normals¬† pon.vcf.gz¬† -L¬† target.bed¬†¬†-O¬† sample.snvIndels.vcf¬†¬†--callable-depth¬† 30¬†¬†--f1r2-tar-gz¬† sample.f1r2.tar.gz¬†¬†--min-base-quality-score¬† 25¬† --max-reads-per-alignment-start¬† 0¬† --minimum-allele-fraction¬† 0.002¬†¬†--dont-use-soft-clipped-bases¬†¬†--force-active¬†¬†--mitochondria-mode¬†¬†--enable-all-annotations¬†. For example, a mutated point information in vcf called by GATK4.2.0.0-Mutect2 is:¬†. 1 24868045 . A G . . AC=1;AF=0.500;AN=2;AS\_MQ=60.00;AS\_SB\_TABLE=51,50|46,23;AS\_UNIQ\_ALT\_READ\_COUNT=69;BaseQRankSum=0.561;ClippingRankSum=-1.473;DP=179;ECNT=2;FS=13.849;LikelihoodRankSum=-0.392;MBQ=37,37;MFRL=236,239;MMQ=60,60;MPOS=44;MQ=60.00;MQ0=0;MQRankSum=0.000;NCC=0;NCount=0;OCM=0;PON;POPAF=7.30;REF\_BASES=GCTCAGCAGAACAGACCCAGA;ReadPosRankSum=1.335;SOR=1.545;Samples=HD786\_4-1;TLOD=230.09 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:**101,69**:0.408:170:54,30:45,39:51,50,46,23. But the information of the same point in vcf called by GATK4.1.9.0-Mutect2 **using the same command** is:¬†. 1 24868045 . A G . . AC=1;AF=0.500;AN=2;AS\_MQ=60.00;AS\_SB\_TABLE=299,290|183,155;AS\_UNIQ\_ALT\_READ\_COUNT=328;BaseQRankSum=1.715;ClippingRankSum=-0.613;DP=934;ECNT=2;FS=1.802;LikelihoodRankSum=0.052;MBQ=20,20;MFRL=153,145;MMQ=60,60;MPOS=39;MQ=60.00;MQ0=0;MQRankSum=0.000;NCC=0;NCount=0;OCM=0;PON;POPAF=7.30;REF\_BASES=GCTCAGCAGAACAGACCCAGA;ReadPosRankSum=3.636;SOR=0.837;Samples=HD786\_4-1;TLOD=779.29 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:**589,338**:0.371:927:290,167:293,171:299,290,183,155. This ""580+338"" is exactly the true depth. Is there any other downsampling or filter in GATK4.2.0.0-Mutect2 but not in GATK4.1.9.0-Mutect2?<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/159302'>Zendesk ticket #159302</a>)<br>gz#159302</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7285:2598,down,downsampling,2598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7285,1,['down'],['downsampling']
Availability,on reset; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:562); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:541); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:493); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:451); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:441); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:322); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:249); 	at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:127); 	at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:79); 	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); 	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); 	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:298); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:354); 	at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:3018,avail,available,3018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['avail'],['available']
Availability,"on to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset... REQUIRED for all errors and issues: ; ; a) GATK version used:. GenomicsDBImport: GATK 4.2.4.0. GenotypeGVCFs: GATK 4.2.6.1. b) Exact command used:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR. ¬† ; ; c) Entire program log:. Using GATK jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar. Running:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR. 15:30:47.303 info Nativ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966:1985,ERROR,ERROR,1985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966,1,['ERROR'],['ERROR']
Availability,on.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:13446,ERROR,ERROR,13446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"on.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:12546,ERROR,ERROR,12546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"on: 2.23.0; 16:26:35.423 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:26:35.427 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:26:35.427 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:26:35.427 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:26:35.427 INFO GenotypeGVCFs - Requester pays: disabled; 16:26:35.427 INFO GenotypeGVCFs - Initializing engine; 16:26:37.201 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:26:39.459 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:26:39 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2303197184; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; [ccastane9@andersserver-01 GenomicsDB]$ bash *_genotype.3.sh; Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --genomicsdb-shared-posixfs-optimizati",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:3127,down,down,3127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['down'],['down']
Availability,"on: 2.23.0; 16:27:54.145 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:27:54.146 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:27:54.146 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:27:54.146 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:27:54.146 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:27:54.146 INFO GenotypeGVCFs - Requester pays: disabled; 16:27:54.146 INFO GenotypeGVCFs - Initializing engine; 16:27:55.873 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:27:58.483 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:27:58 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2231894016; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:6482,down,down,6482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['down'],['down']
Availability,"on: 2.23.0; 21:16:35.498 INFO GenotypeGVCFs - Picard Version: 2.22.8; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:16:35.498 INFO GenotypeGVCFs - Deflater: IntelDeflater; 21:16:35.499 INFO GenotypeGVCFs - Inflater: IntelInflater; 21:16:35.499 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 21:16:35.499 INFO GenotypeGVCFs - Requester pays: disabled; 21:16:35.499 INFO GenotypeGVCFs - Initializing engine; 21:16:36.737 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 21:16:38.472 INFO GenotypeGVCFs - Shutting down engine; [January 17, 2021 9:16:38 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2551709696; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839:4595,down,down,4595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839,1,['down'],['down']
Availability,"one importing batch 3/6; 00:53:26.360 INFO GenomicsDBImport - Starting batch input file preload; 00:54:29.501 INFO GenomicsDBImport - Finished batch preload; 00:54:29.502 INFO GenomicsDBImport - Importing batch 4 with 50 samples; 06:31:35.151 INFO ProgressMeter - C1:10577213 1386.8 4 0.0; 06:31:35.152 INFO GenomicsDBImport - Done importing batch 4/6; 06:31:35.152 INFO GenomicsDBImport - Starting batch input file preload; 06:32:34.398 INFO GenomicsDBImport - Finished batch preload; 06:32:34.404 INFO GenomicsDBImport - Importing batch 5 with 50 samples; 11:49:07.726 INFO ProgressMeter - C1:10577213 1704.4 5 0.0; 11:49:07.727 INFO GenomicsDBImport - Done importing batch 5/6; 11:49:07.727 INFO GenomicsDBImport - Starting batch input file preload; 11:49:48.117 INFO GenomicsDBImport - Finished batch preload; 11:49:48.117 INFO GenomicsDBImport - Importing batch 6 with 45 samples; 16:32:47.060 INFO ProgressMeter - C1:10577213 1988.0 6 0.0; 16:32:47.060 INFO GenomicsDBImport - Done importing batch 6/6; 16:32:47.061 INFO ProgressMeter - C1:10577213 1988.0 6 0.0; 16:32:47.062 INFO ProgressMeter - Traversal complete. Processed 6 total batches in 1988.0 minutes.; 16:32:47.062 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 16:32:47.062 INFO GenomicsDBImport - Shutting down engine; [February 29, 2020 4:32:47 PM PST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 1,988.13 minutes.; Runtime.totalMemory()=57266405376; ```; And the SLURM log: ; ```; Name : combine_gvcfs.count=0004; User : sdturner; Partition : med2; Nodes : c6-74; Cores : 21; GPUs : 0; State : COMPLETED; Submit : 2020-02-28T07:24:31; Start : 2020-02-28T07:24:31; End : 2020-02-29T16:32:58; Reserved walltime : 14-00:00:00; Used walltime : 1-09:08:27; Used CPU time : 1-10:10:37; % User (Computation): 89.40%; % System (I/O) : 10.60%; Mem reserved : 80G/node; Max Mem used : 62.43G (c6-74); Max Disk Write : 0.00 (c6-74); Max Disk Read : 307.20K (c6-74); ```; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6487:6471,down,down,6471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6487,1,['down'],['down']
Availability,"one iterations:. 0) Initialize allele frequencies to the mean of the Dirichlet heterozygosity prior; i.e. ~1 for ref, ~1/1000 for each alt, plus any allele counts from the resources. Genotype priors come from the multinomial distribution (one genotype is a draw of 2 alleles) of these allele frequencies.; 1) (E step) genotype posteriors are the product of genotype likelihoods with the priors from step 0). Pseudocounts are the sum of expected posterior allele counts.; 2) (M step) MLE allele frequencies are the mode of the Dirichlet parameterized by the sum of the original step 0) prior+resources pseudocounts with the E step pseudocounts from step 1). Hmmm that does sound a lot like what the code is doing now. I suppose it's defensible after all. ---. @ldgauthier commented on [Thu May 19 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-220347447). So it sounds to me like the action item here is to fix the Dirichlet heterozygosity prior. I like the idea of adding one count for the ref and 1/1000 for each alt (rather than, for example, 1000 for ref and one for alt) so the heterozygosity prior does something in the absence of external resource counts, but doesn't overwhelms them if they are present. @davidbenjamin Can you think of a more rigorous justification for the scaling of counts between sample genotype allele counts and the heterozygosity?. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-260474993). Is this still alive? To be continued in GATK3 or 4?. ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-260646009). You can move to GATK4. ---. @davidbenjamin commented on [Sun Nov 20 2016](https://github.com/broadinstitute/gatk-protected/issues/792#issuecomment-261761138). @vdauwera @ldgauthier the new qual score model does exactly this. IMO we should simply have this CLI use `AlleleFrequencyCalculator`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2918:6253,alive,alive,6253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2918,1,['alive'],['alive']
Availability,"only mode because you don't have a matched normal. We have found that the false positive rate is very reasonable and comparable to other tools for mitochondria (including HaplotypeCaller). Your latter point (we're looking for calls at various allele fractions) is exactly why we chose to use Mutect instead of HaplotypeCaller. 2. I don't think we can currently output bp resolution reference confidence in Mutect2. There is development being done to allow Mutect to output a GVCF (which would give you reference confidence) but this is still a work in progress. You might be able to use the ""Genotype Given Alleles"" argument to force Mutect to output qualities at each base, but I haven't tested this at all. 3. We found that value for --min-pruning by looking at whole genome sequencing data. Both HaplotypeCaller and Mutect do a local reassembly at a potential variant site. This reassembly builds a graph where each path is a potential haplotype. The min-pruning argument tells you how many reads each path needs to have in order to be considered (otherwise it is pruned from the graph). By default this value is 1 which makes sense for 30-60X data, but if your coverage is very high (which it usually is for mitochondria) the graph will be too messy due to errors unless you turn that argument up. Because the depth is so high, you need more evidence to be sure a path in the graph isn't just noise. 4. The ploidy argument isn't used by Mutect2 because it is always looking for variation at arbitrary allele fractions. If you are instead using HaplotypeCaller you would need to change that argument either to 1 (this would only allow you to call HomVar sites) or as high as you need to get desired resolution. In other words if you want to be able to call sites at 1% allele fraction, you will need to set the ploidy argument to 100 if you are running HaplotypeCaller. Mutect2 will look for sites at all allele fractions (both HomVar and low allele fraction sites) without changing that argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-432645864:1342,error,errors,1342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-432645864,1,['error'],['errors']
Availability,"onsolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and https://docs.google.com/presentation/d/1t5WOAEOMp0xAzJgpKbP68BUnclNYfIVRrDSL9wl1-3A/edit?usp=sharing); this entailed running parameter scans using a local Cromwell on my desktop. Probably this optimization work could be redone relatively easily using the Neptune framework put together by @dalessioluca, which was still in development at the time I did this work. Happy to share the resources and scripts I used if we go down this route; they are pretty lightweight. See more discussion starting here: https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566. Alternatively, we could merge this branch to expose the parameters now and punt on consolidating/optimizing them. I'm not completely convinced we should even do the former unless we are going to follow through on the latter, but happy to defer to others. Finally, note also there is one code optimization that I removed, since it makes assumptions on the SW parameter values that might not be valid for non-default values. I'll highlight this with a comment below. We can restore it if we add code to check whether the assumptions hold, but I'd be curious to see in which cases the optimization makes a big difference. See https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707870344.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:2418,down,down,2418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['down'],['down']
Availability,"ontextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandle",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:7197,AVAIL,AVAILABLE,7197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ontextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:6938,AVAIL,AVAILABLE,6938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ontextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:35 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/13 18:11:36 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/13 18:11:36 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8916,AVAIL,AVAILABLE,8916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3823:1731,error,error,1731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823,1,['error'],['error']
Availability,ools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4331864Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4360539Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4368812Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4375980Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4389382Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/mai,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:17567,error,error,17567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,ools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8295684Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8296401Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8377958Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8390248Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8391883Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8406350Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8414536Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8421445Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8433800Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/mai,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:20148,error,error,20148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"opping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36511,failure,failure,36511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['failure'],['failure']
Availability,"or ""terminate called without an active exception"", which occurs when a thread goes out of scope without calling join() or detach(). This occurs when running JointGenotyping on 345 gvcfs created by GATK4 ExomeGermlineSingleSample; the workflow is running on an HPC cluster in Singularity (single node, 32 cores/node, 1002GB node memory) NOTE that I am able to successfully run JointGenotyping on a set of 80 gvcfs, also produced by ExomeGermlineSingleSample, in this HPC/Singularity environment with 248GB memory, 24 cores/node - this doesn't seem to be a resource issue. The only difference appears to be the number of input gvcfs, which is still quite small (345 vs 80). ¬†The number of reader threads for GenomicsDBImport has been hard-coded to 1 because these are exome sequences; scatter count = 10, batch size = 50, gather\_vcfs = false. GenomicsDBImport appears to succeed on all 10 shards but workflow execution fails with exactly the same c++ error, see below. REQUIRED for all errors and issues: ; ; a) GATK version used:¬†v4.2.6.1. b) Exact command used:. java -Dconfig.file=/scratch.global/lee04110/config/sing-cache.conf -jar /home/pankrat2/public/bin/gatk4/cromwell-81.jar run -i /scratch.global/lee04110/config/jg.ca\_defects.json /home/pankrat2/public/bin/gatk4/warp/pipelines/broad/dna\_seq/germline/joint\_genotyping/JointGenotyping.wdl -o¬† <(echo '{""final\_workflow\_outputs\_dir"" : ""/scratch.global/lee04110/tmp\_jg"", ""use\_relative\_output\_paths"" : true, ""workflow-log-temporary"" : true}'). c) Entire program log: (too big to include the whole thing). (From main process stderr, picking from SplitInterval setting status to Done). \[2022-10-18 15:38:20,88\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.SplitIntervalList:NA:1\]: Status change from WaitingForReturnCode to Done. \[2022-10-18 15:38:25,47\] \[info\] WorkflowExecutionActor-9743b28a-3819-49a7-8598-b0c5267647ee \[9743b28a\]: Starting JointGenotyping.ImportGVCFs (10 shards). \[2022-10-18 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:1427,error,errors,1427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['error'],['errors']
Availability,"or.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:44 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:39 INFO TaskSetManager: Starting task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:56:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:35903 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:39 INFO TaskSetManager: Lost task 1.3 in stage 2.0 (TID 10) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 18/04/24 17:56:39 ERROR TaskSetManager: Task 1 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:56:39 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 45.219 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.Contai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:34543,Error,Error,34543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,or: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:8904,error,error,8904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,or: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:10942,error,error,10942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"or; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7032,AVAIL,AVAILABLE,7032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,orEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292). I realize this is a open source project. But I've made copy of the failing VCF available at:; /dsde/working/fleharty/tmp/buggy.vcf; /dsde/working/fleharty/tmp/buggy.vcf.idx. #### Steps to reproduce; gatk VariantAnnotator -V buggy.vcf --resource:gnomad af-only-gnomad.raw.sites.vcf -E gnomad.AF --resource-allele-concordance -O gnomad_annotated.vcf; #### Expected behavior; Should work. #### Actual behavior; Throws exception,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689:3710,avail,available,3710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689,1,['avail'],['available']
Availability,orEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:11335,Error,ErrorProbabilities,11335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['Error'],['ErrorProbabilities']
Availability,"orage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/10/13 18:11:34 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-ea0e0669-2981-4277-80a0-a67eddf1001d; 17/10/13 18:11:34 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/13 18:11:34 INFO util.log: Logging initialized @3816ms; 17/10/13 18:11:34 INFO server.Server: jetty-9.3.z-SNAPSHOT; 17/10/13 18:11:34 INFO server.Server: Started @3902ms; 17/10/13 18:11:34 INFO server.AbstractConnector: Started ServerConnector@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@710ae6a7{/jobs,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b211077{/jobs/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.Servlet",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:5756,AVAIL,AVAILABLE,5756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"ords; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 23:16:27.971 INFO GenotypeGVCFs - Done initializing engine; 23:16:28.168 INFO ProgressMeter - Starting traversal; 23:16:28.169 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 23:20:28.785 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.11700176899999999,Cpu time(s),0.11079876499999991; [January 7, 2020 11:20:29 PM EST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.71 minutes.; Runtime.totalMemory()=2446327808; java.lang.ArrayIndexOutOfBoundsException: 5; 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.generatePL(ReferenceConfidenceVariantContextMerger.java:652); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:543); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); 	at java.util.stream.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357:4708,down,down,4708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357,1,['down'],['down']
Availability,"ords; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 23:16:27.971 INFO GenotypeGVCFs - Done initializing engine; 23:16:28.168 INFO ProgressMeter - Starting traversal; 23:16:28.169 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 23:20:28.785 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.11700176899999999,Cpu time(s),0.11079876499999991; [January 7, 2020 11:20:29 PM EST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.71 minutes.; Runtime.totalMemory()=2446327808; java.lang.ArrayIndexOutOfBoundsException: 5; 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.generatePL(ReferenceConfidenceVariantContextMerger.java:652); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:543); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); 	at java.util.stream.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057:4662,down,down,4662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057,1,['down'],['down']
Availability,"ored as bytes in memory (estimated size 23.6 KB, free 360.5 MB); 19/04/08 19:03:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-xx.xx.xx.xx.ec2.internal:38471 (size: 23.6 KB, free: 365.8 MB); 19/04/08 19:03:27 INFO SparkContext: Created broadcast 4 from newAPIHadoopFile at PathSplitSource.java:96; 19/04/08 19:03:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.9 MB, free 323.6 MB); 19/04/08 19:03:28 INFO SparkUI: Stopped Spark web UI at http://ip-xx.xx.xx.xx.ec2.internal:4040; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Interrupting monitor thread; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Shutting down all executors; 19/04/08 19:03:28 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:17342,down,down,17342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,2,['down'],['down']
Availability,"org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:09 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException; java.util.concurrent.TimeoutException; 	at java.util.concurrent.FutureTask.get(FutureTask.java:205); 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:10 INFO ShutdownHookManager: Shutdown hook called; 18/05/01 14:31:15 INFO ShutdownHookManager: Deleting directory /tmp/abd30/spark-3f28d2e3-59d7-40f9-bba3-42d61eff6c6a; 18/05/01 14:31:20 ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; Using GATK jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar PathSeqPipelineSpark --input /data/shenlab/abd/TCGA_microbiome/tmp_WXS_colorectal_all/TCGA-AH-6643-11A-01D-1826-10_hg19_Illumina_gdc_realn.bam --kmer-file /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.bfi --filter-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.fa.img --microbe-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa.img --microbe-fasta /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa --taxonomy-file /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_taxonomy.db --min-clipped-read-length 50 --scores-output /data/shenlab/abd/TCGA_microbiome/WXS_colorectal_all/out/TCGA-AH-6643-11A-01D-1826-10_hg19_Illumina_gdc_realn.50.scores.txt --output /data/shenlab/abd/TCGA_microbiome/WXS_colorectal_all/out/TCGA-AH-6643-11A-01D-1826-10_hg19_Illumina_gdc_realn.50.pathseq.bam; /var/spool/slurmd/job1619084/slurm_script: line 126: syntax error: unexpected end of file; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:7103,error,error,7103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['error'],['error']
Availability,"org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5932,ERROR,ERROR,5932,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1138,ERROR,ERROR,1138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['ERROR'],['ERROR']
Availability,"org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 18/04/23 20:42:02 INFO DAGScheduler: Job 0 failed: first at ReadsSparkSource.java:221, took 11.814317 s; 18/04/23 20:42:02 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.xx:4040; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defau",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:16709,down,down,16709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,2,['down'],['down']
Availability,"org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 23, 2018 11:06:24 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 73.92 minutes.; Runtime.totalMemory()=10458497024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 27 in stage 15.0 failed 4 times, most recent failure: Lost task 27.3 in stage 15.0 (TID 29483, scc-q15.scc.bu.edu, executor 13): org.broadinstitute.hellbender.exc eptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.Stre",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:4798,failure,failure,4798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['failure'],['failure']
Availability,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2550,Down,Download,2550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,3,"['Down', 'down']","['Download', 'downloadInternal']"
Availability,"org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:6168,error,error,6168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:8206,error,error,8206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4331864Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4360539Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4368812Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4375980Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.43,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:17370,error,error,17370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8294852Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8295684Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8296401Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8377958Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8390248Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8391883Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8406350Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8414536Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8421445Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8433800Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.84,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:19951,error,error,19951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:3663,error,error,3663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"ormation; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b39",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:6907,AVAIL,AVAILABLE,6907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"ormatted the same as the above file. As part of debugging, I tried removing everything from the INFO field of the variants for contamination file, except allele frequency, and I tried using that simplified VCF both for the germline resource and the variants for contamination file. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:5585,error,errorProbability,5585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['error'],['errorProbability']
Availability,"ormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 17:39:56,368 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz ; INFO 17:39:56,373 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 17:39:56,374 HelpFormatter - Date/Time: 2017/08/22 17:39:56 ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,385 GenomeAnalysisEngine - Strictness is SILENT ; INFO 17:39:57,377 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 17:39:58,497 GenomeAnalysisEngine - Preparing for traversal ; INFO 17:39:58,502 GenomeAnalysisEngine - Done preparing for traversal ; INFO 17:39:58,503 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 17:39:58,503 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 17:39:58,503 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 17:39:58,692 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 17:39:58,697 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:3012,Down,Downsampling,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['Down'],['Downsampling']
Availability,"ort 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextH",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7287,AVAIL,AVAILABLE,7287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,ortGVCFs/shard-5/inputs/1422537242/000006KQ0748.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/000006KQ0757.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/000006KQ0775.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/000006KQ0784.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/000006KQ0793.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/000006KQ1479.rb.g.vcf.gz -V /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-5/inputs/1422537242/00000. ...(all the shards fail in the same way). (this is stderr.background for one shard; all 10 shards log the same error). lee04110@ln0005 \[/scratch.global/lee04110/batch\] % cat /scratch.global/lee04110/cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-9/execution/stderr.background¬†. INFO:¬† ¬† Using cached SIF image. INFO:¬† ¬† Using cached SIF image. Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar. Running:. ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms8000m -Xmx25000m -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /gatk/gatk-package-4.2.6.1-local.jar GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-9/inputs/-1806236336/0009-scattered.interval\_list \[...list of input gvcs\]¬†--reader-threads 1 --merge-input-intervals true --consolidate false. Picked up \_JAVA\_OPTIONS: ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:13934,error,error,13934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['error'],['error']
Availability,"orted to GenotypeGVCFs? @vdauwera @vruano ?. ---. @vdauwera commented on [Fri Oct 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-257037491). That sounds like a good idea, @SHuang-Broad . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260456840). @SHuang-Broad @vruano Is this (making the HC allele culling available to GenotypeGVCFs too) still on your radar(s)?. ---. @SHuang-Broad commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260687763). @vdauwera yes it is on mine. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260714842). Are you planning/working on this in GATK3 or GATK4? Would be good to know where the issue should live. . ---. @vdauwera commented on [Wed Feb 08 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-278478318). @SHuang-Broad ping... ---. @SHuang-Broad commented on [Wed Feb 15 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-280102484). @vdauwera sorry this went off my attention for a while. I did attempt to port a similar change a while back, but discovered that it was not so simple: the fix worked in HC code by removing alt alleles looking at the supporting haplotype scores. Such scores are not available in `GenotypeGVCFs` so either we would have to, like Valentin suggested, make sure the tools handle input without PLs, which is a direction that I looked into and found that the pay/cost is not good (if I recall correctly, most of the places that handles the input does not require valid PL but there are several that's difficult to handle). Then I began wondering how the new QUAL calculating method David Benjamin has put in will make such problems obsolete. So I would say if I find time beyond finishing my SV duty, I would chase down if the new QUAL method indeed will resolv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:9595,ping,ping,9595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['ping'],['ping']
Availability,"ory - Creating default GencodeFuncotation on transcript ENST00000377837.5 for problem variant: chr1:6412417-6412418(AT* -> A); 12:22:46.360 INFO ProgressMeter - chr1:7546157 0.2 3000 14771.0; 12:22:56.769 INFO ProgressMeter - chr1:15441040 0.4 6000 15932.0; 12:23:08.615 INFO ProgressMeter - chr1:24268222 0.6 10000 17420.6; 12:23:18.806 INFO ProgressMeter - chr1:32245507 0.7 13000 17475.9; 12:23:29.190 INFO ProgressMeter - chr1:40884137 0.9 16000 17449.2; 12:23:40.060 INFO ProgressMeter - chr1:49383659 1.1 19000 17302.6; 12:23:52.381 INFO ProgressMeter - chr1:59695584 1.3 23000 17645.3; 12:24:03.424 INFO ProgressMeter - chr1:68377682 1.5 27000 18151.3; 12:24:13.590 INFO ProgressMeter - chr1:76887474 1.7 31000 18709.1; 12:24:25.294 INFO ProgressMeter - chr1:85925943 1.9 36000 19438.3; 12:24:35.871 INFO ProgressMeter - chr1:94465524 2.0 40000 19721.1; 12:24:46.052 INFO ProgressMeter - chr1:102403847 2.2 44000 20018.4; 12:24:57.807 INFO ProgressMeter - chr1:111078655 2.4 49000 20468.7; 12:25:09.216 INFO ProgressMeter - chr1:120476481 2.6 53000 20510.4; 12:25:20.032 INFO ProgressMeter - chr1:148975263 2.8 57000 20620.0; 12:25:23.276 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000420382.1 for variant: chr1:151765708-151765710(ATT* -> A): Variant overlaps transcript but is not completely contained within it. Funcotator cannot currently handle this case. Transcript: ENST00000420382.1 Variant: [VC Unknown @ chr1:151765708-151765710 Q. of type=INDEL alleles=[ATT*, A] attr={AS_FilterStatus=weak_evidence, AS_SB_TABLE=[0, 0|0, 0], DP=1, ECNT=1, GERMQ=1, MBQ=[0, 30], MFRL=[0, 325], MMQ=[60, 60], MPOS=29, POPAF=0.839, RPA=[15, 13], RU=T, STR=true, STRQ=93, TLOD=3.31} GT=GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:0,1:0.667:1:0,1:0,0:0,1:0,0,0,1 filters=germline,weak_evidence; 12:25:23.277 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000420382.1 for problem variant: chr1:151765708-151765710(ATT* -> A).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8844:1948,ERROR,ERROR,1948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8844,1,['ERROR'],['ERROR']
Availability,"ory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138); at java.lang.Thread.run(Thread.java:745); 2019-02-17 16:25:50 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-02-17 16:25:50 INFO MemoryStore:54 - MemoryStore cleared; 2019-02-17 16:25:50 INFO BlockManager:54 - BlockManager stopped; 2019-02-17 16:25:50 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-02-17 16:25:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-02-17 16:25:50 INFO SparkContext:54 - Successfully stopped SparkContext; 16:25:50.893 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 17, 2019 4:25:50 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 5.28 minutes.; Runtime.totalMemory()=5059379200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 181 in stage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:47207,failure,failure,47207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['failure'],['failure']
Availability,"oryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6900,AVAIL,AVAILABLE,6900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"oseq-germline-cnv/Monkol_test_pon_raw_cov.tsv -O /home/mehrtash/test_pon_true,true,10_creation --contigAnnotationsTable gs://mb-myoseq-germline-cnv/contig_annots.tsv --sexGenotypeTable gs://mb-myoseq-germline-cnv/test_sex_genotypes.tsv --copyNumberTransitionPriorTable /home/mehrtash/homo_sapiens_germline_HMM_priors.tsv --jobType LEARN_AND_CALL --targets /home/mehrtash/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.tsv --copyRatioUpdate true --gammaUpdate true --logLikelihoodTolThresholdCopyRatioCalling 1e-3 --logLikelihoodTol 1e-7 --gammaSolverNumBisections 15 --gammaSolverRefinementDepth 5 --psiSolverNumBisections 15 --psiSolverRefinementDepth 5 --numLatents 10 --maximumEMIterations 40 --numTargetSpacePartitions 200 --rddCheckpointingInterval 8 --rddCheckpointingPath hdfs://mb-myoseq-germline-cnv-m:8020/users/mehrtash/tmp/test_pon_true,true,10_creation --verbosity INFO --apiKey AIzaSyDu_-7aNIHQvs6Pkh4SW_dqW4DOeu8OTkA --sparkMaster yarn; ```. and this is the error:. ```; usage: gcloud dataproc jobs submit spark --cluster=CLUSTER [optional flags] [-- JOB_ARGS ...]; ERROR: (gcloud.dataproc.jobs.submit.spark) unrecognized arguments:; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true; ,spark.executor.extraJavaOptions=-Dsamjdk.compression_level=1; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ,spark.executor.instances=40,spark.executor.memory=8G,spark.driver.memory=20G,spark.executor.extraJavaOptions=-Dorg.bytedeco.javacpp.maxbytes=10gb; -Dorg.bytedeco.javacpp.maxphysicalbytes=20gb; -Ddtype=double; -Dorg.bytedeco.javacpp.maxretries=100; -XX:+UseParNewGC; -XX:ParallelGCThreads=2; -XX:+UseConcMarkSweepGC; -XX:+CMSParallelRemarkEnabled; -XX:ConcGCThreads=2; -XX:CMSInitiatingOccupancyFraction=65,spark.driver.extraJavaOptions=-Dorg.bytedeco.javacpp.maxbytes=10gb; -Dorg.bytedeco.javacpp.maxphysicalbytes=20gb; -Ddtype=double; -Dorg.bytedeco.javacpp.maxretries=100; -XX:+UseParNewGC; -XX:ParallelGCThreads=2; -XX:+UseConcMarkSweepGC; -XX:+CMSParallelRemarkEnabled",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278726095:2715,error,error,2715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278726095,1,['error'],['error']
Availability,"ositive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be avai",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:2785,avail,available,2785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['avail'],['available']
Availability,"ost:port, mesos://host:port, yarn, or local.; --deploy-mode DEPLOY_MODE Whether to launch the driver program locally (""client"") or; on one of the worker machines inside the cluster (""cluster""); (Default: client).; --class CLASS_NAME Your application's main class (for Java / Scala apps).; --name NAME A name of your application.; --jars JARS Comma-separated list of local jars to include on the driver; and executor classpaths.; ....... **the spark-shell**; bash-4.2$ spark-shell; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Failed to created SparkJLineReader: java.io.IOException: Permission denied; Falling back to SimpleReader.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 1.6.0; /_/. Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_91); Type in expressions to have them evaluated.; Type :help for more information.; Spark context available as sc (master = yarn-client, app id = application_1507683879816_0007).; Wed Oct 11 14:25:24 CST 2017 Thread[main,5,main] java.io.FileNotFoundException: derby.log (Permission denied); ----------------------------------------------------------------; Wed Oct 11 14:25:24 CST 2017:; Booting Derby version The Apache Software Foundation - Apache Derby - 10.11.1.1 - (1616546): instance a816c00e-015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verificat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:1476,avail,available,1476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,1,['avail'],['available']
Availability,"ot a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); 	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1448); 	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1436); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.pathExists(SparkUtils.java:100); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.setHadoopBAMConfigurationProperties(ReadsSparkSource.java:241); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:203); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [da63aa3c-e3bc-4893-9f40-42921719a343] entered state [ERROR] while waiting for [DONE].; ```. to reproduce this error, . ```bash; cd /Users/shuang/GATK/gatk. CLUSTER_NAME=""svdev-caller""; MASTER_NODE=""hdfs://svdev-caller-m:8020""; PROJECT_DIR=""user/shuang/NA12878_PCR-_30X"". ./gatk-launch FindBreakpointEvidenceSpark \; -R ""$MASTER_NODE""/reference/Homo_sapiens_assembly38.fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsForAssembly \; --maxFASTQSize 10000000 \; -- \; --sparkRunner GCS \; --clust",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:4200,ERROR,ERROR,4200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,ot exist; 2022-08-16T00:09:07.4139500Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T00:09:07.4190745Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4198885Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:242: error: cannot find symbol; 2022-08-16T00:09:07.4199424Z @VisibleForTesting; 2022-08-16T00:09:07.4200130Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4200630Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T00:09:07.4211864Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4214985Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.commo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:14775,error,error,14775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,ot exist; 2022-08-16T22:45:53.8135486Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T22:45:53.8163449Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8167163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:245: error: cannot find symbol; 2022-08-16T22:45:53.8167305Z @VisibleForTesting; 2022-08-16T22:45:53.8167581Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8167809Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T22:45:53.8173821Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8175307Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8268598Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.commo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:16813,error,error,16813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2221,avail,available,2221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,2,['avail'],['available']
Availability,"ot sure if this is a bug or something wrong with my bam files. Any help on solving/debugging would be welcomed. Running mutect2 returns >100,000 warnings of more than two reads with the same name found. The bams were processing following best practices. The header of the log file: . Mutect2 -R resources/hg38/genome/d ; 975 efault/genome.fa -L resources/hg38/a.interval_list -I recal/RBL3_diagnostic.bam -I recal/RBL3_germline.bam -I recal/RBL3_diagnostic.bam -I recal/RBL3_relapse1.bam -I recal/RBL ; 976 3_relapse2.bam -I recal/RBL3_PDX.bam -normal RBL3_germline_hg38 --germline-resource resources/hg38/gnomad/af-only-gnomad.hg38.vcf.gz --panel-of-normals resources/hg38/pon/1000 ; 977 g_pon.hg38.vcf.gz --f1r2-tar-gz results/RBL3/f1r2.tar.gz --read-filter NotSupplementaryAlignmentReadFilter --read-filter NotSecondaryAlignmentReadFilter --native-pair-hmm-thre ; 978 ads 20 -O results/RBL3/unfiltered.vcf ; 979 17:07:51.270 WARN GATKReadFilterPluginDescriptor - Redundant enabled filter (NotSecondaryAlignmentReadFilter) is enabled for this tool by default ; 980 17:07:51.313 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/rds/project/rds-cyiwgCzJok8/WES_snakemake/.snakemake/conda/773770bb2edb9f4c58fb17b5017e1f ; 981 be_/share/gatk4-4.5.0.0-0/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so ; 982 17:07:51.633 INFO Mutect2 - ------------------------------------------------------------ ; 983 17:07:51.635 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.5.0.0 ; 984 17:07:51.635 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/ ; 985 17:07:51.635 INFO Mutect2 - Executing as cjs236@cpu-r-25 on Linux v4.18.0-553.16.1.el8_10.x86_64 amd64 ; 986 17:07:51.635 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v17.0.11-internal+0-adhoc..src ; 987 17:07:51.635 INFO Mutect2 - Start Date/Time: August 28, 2024 at 5:07:51 PM BST ; 988 17:07:51.635 INFO Mutect2 - ----------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8966:967,Redundant,Redundant,967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8966,1,['Redundant'],['Redundant']
Availability,"otate - Built for Spark Version: 3.3.1; 16:11:10.076 INFO SVAnnotate - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:11:10.076 INFO SVAnnotate - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:11:10.076 INFO SVAnnotate - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:11:10.076 INFO SVAnnotate - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:11:10.076 INFO SVAnnotate - Deflater: IntelDeflater; 16:11:10.077 INFO SVAnnotate - Inflater: IntelInflater; 16:11:10.077 INFO SVAnnotate - GCS max retries/reopens: 20; 16:11:10.077 INFO SVAnnotate - Requester pays: disabled; 16:11:10.077 INFO SVAnnotate - Initializing engine; 16:11:10.152 INFO FeatureManager - Using codec VCFCodec to read file file:///home/Division/user/2_Exome/snv_GWAS_data/disease_related_SV/test/test.vcf; 16:11:10.251 INFO SVAnnotate - Done initializing engine; 16:11:10.260 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 43): ##description: evidence-based annotation of the human genome (GRCh38), version 43 (Ensembl 109) Continuing, but errors may occur.; 16:11:10.260 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 43): ##description: evidence-based annotation of the human genome (GRCh38), version 43 (Ensembl 109) Continuing, but errors may occur.; 16:11:10.261 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/Division/user/2_Exome/snv_GWAS_data/disease_related_SV/gencode.v43.basic.modified_annotation.gtf; 16:11:10.261 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 43): ##description: evidence-based annotation of the human genome (GRCh38), version 43 (Ensembl 109) Continuing, but errors may occur.; 16:11:21.599 INFO ProgressMeter - Starting traversal; 16:11:21.600 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Va",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1621377138:2973,error,errors,2973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1621377138,1,['error'],['errors']
Availability,"otator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:55:32.063 INFO Funcotator - Deflater: IntelDeflater; 02:55:32.063 INFO Funcotator - Inflater: IntelInflater; 02:55:32.063 INFO Funcotator - GCS max retries/reopens: 20; 02:55:32.063 INFO Funcotator - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 02:55:32.063 WARN Funcotator - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: Funcotator is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 02:55:32.063 INFO Funcotator - Initializing engine; 02:55:32.318 INFO FeatureManager - Using codec VCFCodec to read file file:///export2/liuhw/wes_test/Mutect2_filter/K001137N_somatic_filtered.vcf.gz; 02:55:32.459 INFO Funcotator - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 02:55:32.466 INFO Funcotator - Shutting down engine; [July 12, 2024 2:55:32 AM EDT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148532224; ***********************************************************************. A USER ERROR has occurred: Bad input: ERROR in config file: file:///./software/gatk_Funcotator/funcotator_dataSources.v1.8.hg38.20230908s/gnomAD_exome/hg38/gnomAD_exome.config - src_file does not exist: /./software/gatk_Funcotator/funcotator_dataSources.v1.8.hg38.20230908s/gnomAD_exome/hg38/gs:/broad-public-datasets/funcotator/gnomAD_2.1_VCF_INFO_AF_Only/hg38/gnomad.exomes.r2.1.sites.liftoverToHg38.INFO_ANNOTATIONS_FIXED.vcf.gz. ***********************************************************************; ```; How to solved it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8913:3372,down,down,3372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8913,3,"['ERROR', 'down']","['ERROR', 'down']"
Availability,"ots file '/researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf'; 23:15:31.932 INFO AnalyzeCovariates - Shutting down engine; [January 19, 2020 11:15:31 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2161115136; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.2074992987327687075';source('/tmp/BQSR.6874121927957307421.R'); /tmp/AnalyzeCovariates6611620304443967041.csv /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/IN-PM01004_rmd.recal.bam.recalTable /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf; Stdout: WARNING: ignoring environment value of R_HOME. Stderr: During startup - Warning messages:; 1: Setting LC_CTYPE failed, using ""C"" ; 2: Setting LC_COLLATE failed, using ""C"" ; 3: Setting LC_TIME failed, using ""C"" ; 4: Setting LC_MESSAGES failed, using ""C"" ; 5: Setting LC_MONETARY failed, using ""C"" ; 6: Setting LC_PAPER failed, using ""C"" ; 7: Setting LC_MEASUREMENT failed, using ""C"" ; Error in readRDS(pfile) : ; cannot read workspace version 3 written by R 3.6.0; need R 3.5.0 or newer; Calls: source ... library -> find.package -> lapply -> FUN -> readRDS; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6393:4045,Error,Error,4045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6393,1,['Error'],['Error']
Availability,"otypeCaller - Inflater: IntelInflater; 02:07:51.774 INFO HaplotypeCaller - GCS max retries/reopens: 20; 02:07:51.775 INFO HaplotypeCaller - Requester pays: disabled; 02:07:51.775 INFO HaplotypeCaller - Initializing engine; 02:07:52.246 INFO HaplotypeCaller - Done initializing engine; 02:07:52.303 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 02:07:52.312 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/administrator/IGIB/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 02:07:52.314 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/administrator/IGIB/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 02:07:52.355 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 02:07:52.355 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 02:07:52.356 INFO IntelPairHmm - Available threads: 104; 02:07:52.356 INFO IntelPairHmm - Requested threads: 4; 02:07:52.356 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 02:07:52.408 INFO ProgressMeter - Starting traversal; 02:07:52.408 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 02:07:53.316 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes; 02:07:53.598 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.49244E-4; 02:07:53.598 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.007888748000000001; 02:07:53.598 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 02:07:53.598 INFO HaplotypeCaller - Shutting down engine; [28 November 2019 at 2:07:53 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=8220835840; java.lang.Null",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6292:3478,Avail,Available,3478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6292,1,['Avail'],['Available']
Availability,"oud.auth.service.account.json.keyfile"", gcs_creds);; hdfsBuilderConfSetStr(builder, ""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1826); Caused by: com.google.api.client.http.HttpResponseException: 404 Not Found; {""error"":""invalid_request"",""error_description"":""Service account not enabled on this instance""}; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1072); at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:159); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:493); at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); ... 77 more; [GenomicsDB::",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:1605,Error,Error,1605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['Error'],['Error']
Availability,"ould effectively stall). Therefore we began to --consolidate the workspaces using GenomicsDBImport during the append process. Initially --consolidate worked; however, as @jjfarrell noted, that's memory intensive and once our workspace was a certain size, this basically died again. Therefore we even worked with @nalinigans to their the standalone GenomicsDB consolidate tool. This was a viable way to consolidate the workspaces and we successfully aggregated and consolidated all our data (which took a while). However, these massive, consolidated workspaces seem to choke GenotypeGVCFs. Therefore this process is still basically dead. 3) As I noted above, I'm currently giving up on trying to maintain permanent data in genomicsDB. There's so many advantages to not doing so, and letting the gVCFs exist as the permanent store. Notably, there are many reasons we would want/need to remake a gVCF (like the introduction of reblocking). Whenever any one of the source gVCFs changes, the workspace is basically worthless anyway (which is a massive waste of computation time). We've had great success running each GenotypeGVCFs scattered, where each job runs GenomicsDbImport on-the-fly, to make a transient workspace. I havent heard a GATK reply, but I believe that giving each workspace a sufficient amount of downstream padding (we're using 1000bp) should ensure any variant that begins within the job's interval can be called properly. It does add non-trivial additional computation time to each GenotypeGVCFs job, but we were wasting all sorts of computation time pre-aggregating GenomicsDbImport workspaces. . What we're seeing in option 3 is consistent with some kind of problem in GenotypeGVCFs/SelectVariants when trying to read from GenomicsDB workspaces that have large chromosomes with highly consolidated data. In those workspaces, I was seeing single files with size of >30GB (like PL_var.tdb). I dont know the read pattern of GATK/GenomicsDB, but maybe over-consolidating is deleterious?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1256246852:2096,down,downstream,2096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1256246852,1,['down'],['downstream']
Availability,"ount the fact that targets on different chromosomes are ""infinitely"" separated. Agilent/Ice targets are very unevenly spaced and the distribution of target spacing has a heavy tail, making the matter worse. The regularizer could still be used with certain modifications. Let us define the ""target coverage noise"" for sample s as:. u_{st} = \sum_{\mu} W_{t \mu} z_{s \mu} + m_t. (1) [implementation] First of all, the target coverage noise must be regularized on each contig separately. It doesn't make sense to stack up all targets and take once giant FFT of u_{st}. This can be fixed in the current implementation with little effort. (2) [formal development + implementation] Within each contig, u_{st} must be mapped from target space to genomic position space e.g. via kernel density estimation. It is crucial to take into account the uncertainty in density estimation in the penalty function. For example, if the pre-image of a genomic position $x$ lies at the middle of a certain target $t$, the estimated value is much more reliable than the case where it lies between two largely separated targets. The penalty must be weighted according to the certainty of estimation. (3) [formal development + implementation] once step 1 and 2 are done, the iterative solver code must be updated accordingly. ---. @mbabadi commented on [Fri Sep 09 2016](https://github.com/broadinstitute/gatk-protected/issues/701#issuecomment-246015485). @samuelklee @davidbenjamin @asmirnov239 Let's have a joint meeting at some point to discuss the problem. It is (probably) not too hard to figure out, and it will make our model really shine!. ---. @mbabadi commented on [Tue Sep 13 2016](https://github.com/broadinstitute/gatk-protected/issues/701#issuecomment-246822768). I have some notes written on this which I can discuss tomorrow in the CNV meeting. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/701#issuecomment-249735634). Here's a nice demonstration @asmir",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2892:1293,reliab,reliable,1293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2892,1,['reliab'],['reliable']
Availability,"oups in a SAM/BAM/CRAM file with a single new read group; ApplyBQSR Applies the BQSR table to the input SAM/BAM/CRAM; BaseRecalibrator Generates recalibration table for BQSR; BuildBamIndex Generates a BAM index (.bai) file; CalculateReadGroupChecksum Creates a hash code based on the read groups (RG) in the SAM/BAM/CRAM header; CleanSam Cleans the provided SAM/BAM/CRAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads; ClipReads Clip reads in a SAM/BAM/CRAM file; CompareBaseQualities Compares base qualities of two input SAM/BAM/CRAM files; CompareSAMs Compares two input SAM/BAM/CRAM files; CountBases Count bases in a SAM/BAM/CRAM file; CountReads Count reads in a SAM/BAM/CRAM file; DownsampleSam Down-sample a SAM/BAM file to retain a random subset of the reads; EstimateLibraryComplexity Estimates library complexity from the sequence of read pairs; ExampleReadWalkerWithReference Print reads with reference context; ExampleReadWalkerWithVariants Print reads with overlapping variants; FastqToSam Converts a fastq file to an unaligned SAM/BAM file; FilterReads Creates a new SAM/BAM/CRAM file by including or excluding aligned reads; FixMateInformation Ensure that all mate-pair information is in sync between each read and its mate pair; FixMisencodedBaseQualityReads Fix Illumina base quality scores in a SAM/BAM/CRAM file; FlagStat A reimplementation of the 'samtools flagstat' subcommand; GatherBQSRReports Gathers scattered BQSR recalibration reports into a single file; GatherBamFiles Concatenates one or more BAM files together as efficiently as possible; LeftAlignIndels Left-aligns indels from reads in a SAM/BAM/CRAM file; MarkDuplicates Examines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.; MergeBamAlignment Merges alignment data from a SAM/BAM with data in an unmapped SAM/BAM/CRAM file; MergeSamFiles Merges multiple SAM/BAM files into one file; PrintReads Print reads in the SAM/BAM/CRAM file; Reor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:4270,Down,DownsampleSam,4270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,['Down'],"['Down-sample', 'DownsampleSam']"
Availability,"ource('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.applySegmentation(PerformSegmentation.java:185); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.doWork(PerformSegmentation.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.he",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2578,Error,Error,2578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,1,['Error'],['Error']
Availability,outputting better error messages when command line parsing fails,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/173:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/173,1,['error'],['error']
Availability,"ov 200 -minPruning 4 -o /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/eflynn90-test.vcf -L /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/intervals.vcf -stand_emit_conf 10 -pedValidationType SILENT; ```. ---. @eitanbanks said:. Updated command-line:. ```; java -Xmx6g -jar dist/GenomeAnalysisTK.jar -T HaplotypeCaller -R /humgen/1kg/reference/hs37d5.fasta -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND1/UDP2731_1.forGATK.bam -dcov 200 -minPruning 4 -L 1:14464; ```. I can confirm that it appears that down-sampling is not working for the Haplotype Caller (when run through the Unified Genotyper the down-sampling works just fine).; I see in SAMDataSource line 668 that assumeDownstreamLIBSDownsampling is being set to true. But then it doesn't look like LIBS is actually down-sampling. Don't have time to debug more so passing on to David. ---. @droazen said (over multiple comments):. I am looking into this. LIBS is actually calling into the downsamplers correctly in the test case that Eric provided. You can see this by examining readStates.size() for each locus -- it never exceeds the -dcov target of 200. The problem must lie elsewhere -- I'll continue to step through this in the debugger. [...]. After some more debugging and consultation with Ryan, I've found that DP values exceeding dcov are to be expected given the way the ActiveRegion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and compl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:2094,down,downsamplers,2094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['down'],['downsamplers']
Availability,overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [a85f28df-e6b8-4f64-bafb-c0f195dcd4d5] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:14760,ERROR,ERROR,14760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,2,['ERROR'],['ERROR']
Availability,"ow.readers.bam.BAMIO: No index for gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: Creating SeekableGCSStream: gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: uriToStorageObject mw-pathseq-test/hs37d5cs.reads.sorted.bam=mw-pathseq-test:hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO org.spark_project.jetty.server.ServerConnector: Stopped ServerConnector@5148cf20{HTTP/1.1}{0.0.0.0:4040}; 21:42:54.861 INFO PrintReadsSpark - Shutting down engine; [February 6, 2017 9:42:54 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=573571072; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:376); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:357); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:347); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:6900,Error,Error,6900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['Error'],['Error']
Availability,"p [often](https://gatk.broadinstitute.org/hc/en-us/community/posts/4566282375835-Mutect2-AF-does-not-match-AD-and-DP) in the GATK forum and it feels like having clear documentation around this would be helpful. . My impression is that Mutect2 might be using an AD ""1-read-per-allele"" prior and incorporating that into its reported AF. From the [article on informative reads](https://gatk.broadinstitute.org/hc/en-us/articles/360035532252-Allele-Depth-AD-is-lower-than-expected), once you're at the sample level (FORMAT field), both DP and AD appear to include only informative alleles. It is tempting to think that AF would be computed from them directly (e.g., `AD_alt / DP`, which is equivalent to `AD_alt/[AD_alt+AD_ref]` in the biallelic case since only informative reads are retained). However, as noted in those linked forum posts, Mutect2 (in my case, version 4.2.5.0) does not produce AF values that can be computed from the AD values in that way. Rather, the AF value appears to incorporate a prior.¬†. I investigated this across a range of allele depths in real calls. Here are some examples. The format is:; |AlleleDepthRef,AlleleDepthAlt | DP | AF[provided by Mutect2] | AF[if I calculate it myself]|; | ------- | ------- | ----- | ------- |; | 0,1|1|0.667|1.000 |; | 23,4|27|0.170|0.148 |; | 39,125|164|0.758|0.762 | . The intuition here is that there is a huge discrepancy between the Mutect2 AF and the AF I calculate when AD (or DP) is small (first row), and the error gets smaller as DP increases. The formula that Mutect2 seems to use to compute AF is:. ```py; # Formula that Mutect2 seems to use to calculate AF of the alternative allele in a biallelic scenario; Mutect2_AF = (ADalt+1) / (ADalt+1 + ADref+1). # Which is equivalent to:; Mutect2_AF = (ADalt + 1) / (DP + 2); ```. 1. Is my inference about a prior weight being added by Mutect2 prior to computing AF accurate?; 2. If so, is it intended behavior?; 3. If so, can the VCF header field be a bit more informative about this?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8080:2145,error,error,2145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8080,1,['error'],['error']
Availability,"p from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:8813,Avail,Available,8813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,1,['Avail'],['Available']
Availability,"p(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy), for input source: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz; 	at htsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:97); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:82); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:380); 	... 14 more; Caused by: java.io.FileNotFoundException: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy); 	at java.io.RandomAccessFile.open0(Native Method); 	at java.io.RandomAccessFile.open(RandomAccessFile.java:316); 	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); 	at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); 	at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:111); 	at htsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:94); 	... 17 more; ```. Which doesn't happen when running it without the intervals file. I am using the latest version of GATK4 available in conda.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059:3062,avail,available,3062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059,1,['avail'],['available']
Availability,"p/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletCon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7678,AVAIL,AVAILABLE,7678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"pPartitions$1$$anonfun$apply$23.apply(RDD.scala:796); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; And I notice `gatk/src/main/java/org/broadinstitute/hellbender/utils/bwa/BwaMemAligner.java` doesn't exist, and there is no class file `gatk/build/classes/main/org/broadinstitute/hellbender/utils/bwa/BwaMemAligner.class` either. Is that causing this error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186:4156,error,error,4156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186,1,['error'],['error']
Availability,packaging gatk-launch in our jar so that it's available to downstream projects; some build.gradle refactoring,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1772:46,avail,available,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1772,2,"['avail', 'down']","['available', 'downstream']"
Availability,"park - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.REFERENCE_FASTA : null; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:19:00.371 INFO BaseRecalibratorSpark - Deflater IntelDeflater; 17:19:00.372 INFO BaseRecalibratorSpark - Inflater IntelInflater; 17:19:00.372 INFO BaseRecalibratorSpark - Initializing engine; 17:19:00.372 INFO BaseRecalibratorSpark - Done initializing engine; 17:19:00.872 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java clas; 17:22:09.153 INFO BaseRecalibratorSpark - Shutting down engine; [May 17, 2017 5:22:09 PM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 3.15 min; Runtime.totalMemory()=15504244736; java.lang.ArrayIndexOutOfBoundsException: 1073741865; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:195); at org.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236)atorg.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236)atorg.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236); at org.apache.spark.util.Utils$.tryWithSafeFinally(Uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2732:3280,down,down,3280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2732,1,['down'],['down']
Availability,"park - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5031,ERROR,ERROR,5031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"park web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:28:58 INFO MemoryStore: MemoryStore cleared** ; **20/03/05 09:28:58 INFO BlockManager: BlockManager stopped** ; **20/03/05 09:28:58 INFO BlockManagerMaster: BlockManagerMaster stopped** ; **20/03/05 09:28:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!** ; **20/03/05 09:28:58 INFO SparkContext: Successfully stopped SparkContext** ; **09:28:58.889 INFO PathSeqPipelineSpark - Shutting down engine** ; **[2020ÎÖÑ 3Ïõî 5Ïùº (Î™©) Ïò§Ï†Ñ 9Ïãú 28Î∂Ñ 58Ï¥à] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.25 minutes.** ; **Runtime.totalMemory()=19560660992** ; **org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:42461,failure,failure,42461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability,pe ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin; > /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin (No such file or directory). * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; * ; BUILD FAILED in 761ms; ====================================. How can I build GATK4? . Thanks a lot.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:2452,FAILURE,FAILURE,2452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['FAILURE'],['FAILURE']
Availability,"peline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291). My GATK version is :GATK4.1.2.0; My command is:; /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk --java-options ""-Xmx20G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/home/wuly/source/Homo_sapiens_assembly38.fasta \; -I M1.bam \; --known-sites /data/home/wuly/source/hapmap_3.3.hg38.vcf.gz \; --known-sites /data/home/wuly/source/dbsnp_146.hg38.vcf.gz \; --known-sites /data/home/wuly/source/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; --known-sites /data/home/wuly/source/1000G_phase1.snps.high_confidence.hg38.vcf.gz \; -O M1_recal.table; Then I run the ValidateSamFile to check the BAM file,this is the command : ; /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk --java-options ""-Xmx20G -Djava.io.tmpdir=./"" ValidateSamFile -I M1.bam. And the result is: No errors found; I also tried to use the BAM file before I merge them to run BaseRecalibrator and ValidateSamFile, but I got the same result.Can anybody tell me how solve this problem?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:12139,error,errors,12139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,1,['error'],['errors']
Availability,"pens: 20; > 23 15:07:52.443 INFO Mutect2 - Requester pays: disabled; > 24 15:07:52.443 INFO Mutect2 - Initializing engine; > 25 15:07:52.848 INFO FeatureManager - Using codec VCFCodec to read file file://ref_nobackup/af-only-gnomad.hg38.vcf.gz; > 26 15:07:53.126 INFO Mutect2 - Done initializing engine; > 27 15:07:53.196 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/scicore/soft/apps/GATK/4.4.0.0-GCCcore-10.3.0-Java-17/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 28 15:07:53.201 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/scicore/soft/apps/GATK/4.4.0.0-GCCcore-10.3.0-Java-17/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 29 15:07:53.223 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 30 15:07:53.223 INFO IntelPairHmm - Available threads: 2; > 31 15:07:53.224 INFO IntelPairHmm - Requested threads: 4; > 32 15:07:53.224 WARN IntelPairHmm - Using 2 available threads, but 4 were requested; > 33 15:07:53.224 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; > 34 15:07:53.231 WARN Mutect2 - Note that the Mutect2 reference confidence mode is in BETA -- the likelihoods model and output format are subject to change in subsequent versions.; > 35 15:07:53.314 INFO ProgressMeter - Starting traversal; > 36 15:07:53.314 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; > 37 15:07:54.410 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.8392900000000002E-4; > 38 15:07:54.412 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.03020143; > 39 15:07:54.412 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.05 sec; > 40 15:07:54.413 INFO Mutect2 - Shutting down engine; > 41 [June 19, 2023 at 3:07:54 PM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; > 42 Runtime.totalMem",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632:3537,avail,available,3537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632,1,['avail'],['available']
Availability,"periment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1422,mask,mask,1422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,4,['mask'],['mask']
Availability,"pertiesAreValid(DataSourceUtils.java:841); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.getAndValidateDataSourcesFromPaths(DataSourceUtils.java:216); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:776); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: shaded.cloud_nio.com.google.api.client.http.HttpResponseException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1097); 	at shaded.cloud_nio.com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:197); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:157); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:145); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:91); 	at shaded.cloud_nio.com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:159); 	at shaded.cloud_nio.com.google.cloud.http.CensusHttpModule$CensusHttpRequestInitializer.initialize(CensusHttpModule.java:109); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:88); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientReques",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:9758,error,error,9758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['error'],['error']
Availability,phs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:9068,error,error,9068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,phs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:11106,error,error,11106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"physicalbytes=20gb -Ddtype=double -Dorg.bytedeco.javacpp.maxretries= -XX:+UseParNewGC -XX:ParallelGCThreads=2 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:ConcGCThreads=2 -XX:CMSInitiatingOccupancyFraction=65,spark.driver.extraJavaOptions=Dorg.bytedeco.javacpp.maxbytes=10gb -Dorg.bytedeco.javacpp.maxphysicalbytes=20gb -Ddtype=double -Dorg.bytedeco.javacpp.maxretries= -XX:+UseParNewGC -XX:ParallelGCThreads=2 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:ConcGCThreads=2 -XX:CMSInitiatingOccupancyFraction=65,spark.yarn.; executor.memoryOverhead=12000,spark.yarn.driver.memoryOverhead=12000 --jar /dsde/working/mehrtash/gatk-protected/build/libs/gatk-protected-spark.jar CoverageModellerSparkToggle -I gs://mb-germline-eval-data/TCGA/odd_raw_cov_gc.tsv -O /home/mehrtash/calling__odd_raw_cov_gc__1e-8,70000__on__TCGA_pon_even__true,true,6 -annots gs://mb-germline-eval-data/TCGA/contig_annots.tsv -gen gs://mb-germline-eval-data/TCGA/sex_genotypes.tsv -eventSize 70000 -eventProb 1e-8 --targets /home/mehrtash/agilent_targets_no_xy_padded_annotated_filtered.tsv --modelPath /home/mehrtash/TCGA_pon_even__true,true,6 --jobType CALL_ONLY --copyRatioUpdate true --gammaUpdate true --logLikelihoodTolThresholdCopyRatioCalling 5e-2 --numLatents 6 --maximumEMIterations 20 --numTargetSpacePartitions 200 --rddCheckpointingInterval 2 --rddCheckpointingPath hdfs://mb-germline-1-m:8020/users/mehrtash/tmp/calling__odd_raw_cov_gc__1e-8,70000__on__TCGA_pon_even__true,true,6 --verbosity INFO --apiKey [xxx] --sparkMaster yarn-client`. and the latest Cloud SDK makes the following complaint:; `ERROR: (gcloud.dataproc.jobs.submit.spark) argument --verbosity: Invalid choice: 'INFO'. Did you mean 'info'?`. After changing `info` to `INFO`, we get yet another set of complaints (can not recognize -DGATK_STACKTRACE_ON_USER_EXCEPTION=true and so on). Perhaps putting quotes around `--properties` args fixes it? I haven't tried it (I just rolled back to the older working Cloud SDK v117).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-255508321:2558,ERROR,ERROR,2558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-255508321,1,['ERROR'],['ERROR']
Availability,"pically, SVD is performed on the samples x intervals matrix and the right-singular vectors are taken, which saves some extra computation that is necessary to calculate the left-singular vectors.</s> (EDIT: Actually, looks like Spark's SVD is faster on tall and skinny matrices, which might be due to the fact that the underlying implementation calls Fortran code. I still think that representing samples as row vectors has some benefits, so I've changed things to reflect this; I now just take a transpose before performing the SVD, so that we still operate on the same intervals x samples matrix.) This will also save us some transposing, which we do anyway to make HDF5 writes faster.; - [x] Change HDF5 matrix writing to allow matrices with NxM > MAX_INT, which can be done naively by chunking and writing to multiple HDF5 subdirectories. This will allow for smaller bin sizes. (EDIT: I implemented this in a way that allows one to set the maximum number of values allowed per chunk, so that heap usage can be controlled, but the downside is that this translates into a corresponding limit on the number of columns (i.e., intervals). On the other hand, you could theoretically crank this number up to Integer.MAX_VALUE, as long as you set -Xmx high enough... In practice, it's very unlikely that we'll need to go to bins smaller than a read length.); - [ ] <s>Check that CreatePanelOfNormals works correctly on Spark cluster.</s> Implement Randomized SVD, which should give better performance on large matrices. See https://arxiv.org/pdf/1007.5510.pdf and https://research.fb.com/fast-randomized-svd/. For now, I'll require that the coverage matrix can fit in RAM, but more sophisticated versions of the algorithm could be implemented in the future.; - [ ] Update methods doc. Note that some of the CNV section is out of date and incorrect. In particular, we have been taking in PCOV as input to CreatePanelOfNormals for some time now, but the doc states that we take integer read counts. This alre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:2932,down,downside,2932,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,2,['down'],['downside']
Availability,ping @chandrans,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-386409306:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-386409306,2,['ping'],['ping']
Availability,ping @cwhelan .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3457#issuecomment-327257527:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457#issuecomment-327257527,1,['ping'],['ping']
Availability,"ping @lbergelson if you want to take a look, especially the leftover class for shelling out tasks to cmd line programs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3613#issuecomment-332852084:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3613#issuecomment-332852084,1,['ping'],['ping']
Availability,ping @vdauwera,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-390003142:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-390003142,1,['ping'],['ping']
Availability,ping @vdauwera. Do you know what we need to do to respond to @bbimber's request to take over VariantEval in a separate repo ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101894:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101894,1,['ping'],['ping']
Availability,ping @vruano for reviewing #2512 that fixes this issue,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288289361:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288289361,1,['ping'],['ping']
Availability,"ping? It's been a little while, a review would be nice. If @droazen is busy, perhaps @lbergelson can have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4721#issuecomment-387826797:0,ping,ping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4721#issuecomment-387826797,1,['ping'],['ping']
Availability,"pling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_2005",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3366,ERROR,ERROR,3366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,plotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:9636,error,error,9636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,plotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:11674,error,error,11674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"port 44818.; 17/10/13 18:11:42 INFO netty.NettyBlockTransferService: Server created on 10.131.101.159:44818; 17/10/13 18:11:42 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:44818 with 366.3 MB RAM, BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/13 18:11:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@544300a6{/metrics/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:42 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/spark2ApplicationHistory/application_1507856833944_0003; 17/10/13 18:11:42 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:43 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/13 18:11:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:14422,AVAIL,AVAILABLE,14422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,porter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7145,ERROR,ERROR,7145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,porter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7997,ERROR,ERROR,7997,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"porter] ; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Where:; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1729,ERROR,ERROR,1729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"posterior mode. Getting a few hundred MCMC samples is probably more expensive but roughly comparable. These numbers are manageable but get expensive when we relearn the model at every iteration of segment merging. In my opinion it makes sense to come back to this issue after we have a new segmentation strategy. We'll see how pressing it is then. ---. @samuelklee commented on [Wed Jun 08 2016](https://github.com/broadinstitute/gatk-protected/issues/542#issuecomment-224786950). To clarify, I think this is primarily an issue for WGS, where we have ~1.5 million hets. From the logs in /dsde/working/lichtens/wgs/out_case_chip_wgs/acnv/*out it looks like finding the MLE takes ~10 minutes (which is roughly consistent with your estimate), but 200 MCMC iterations takes ~1 hr. Naive profiling of the AlleleFractionModeller tests suggests that around ~60% CPU is going toward log gammas, so if we can improve on this I think it might be an easy win. But we should perhaps profile more carefully. However, I agree that changing our segmentation is more pressing! Note that oversegmentation (typically 1000+ segments) hurts us by both by increasing the number of MAF parameters and by increasing the number of similar-segment merge iterations required to smooth things (looks like the WGS samples hit the limit of 25 merge iterations = ~25 hrs). Turning off refitting between iterations helps, perhaps at the cost of smoothness of the final result, but you're still looking at 2+ hours for the initial and final fit. Just to note, other possibilities for cutting down the runtime include trimming down the number of hets for WGS, changing similar-segment merging so that we can locally refit only the MAF for the newly created segment, ditching MCMC, etc. @LeeTL1220 can you make the plots for your WGS runs so we can see what these hets look like?. ---. @davidbenjamin commented on [Thu Jun 09 2016](https://github.com/broadinstitute/gatk-protected/issues/542#issuecomment-225074377). Ahhhhh, I get it!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2860:2634,down,down,2634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2860,2,['down'],['down']
Availability,"ppable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</n",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:2177,error,error,2177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,"pping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36760,failure,failure,36760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['failure'],['failure']
Availability,"pping to T = 10^6 causes out of memory. Not sure if this could be naively alleviated by setting theano flags appropriately, but I think we will probably want to minibatch in T instead. Note also that this model uses the exact Poisson likelihood. Composing with an HMM segmentation step, perhaps alternating for a few iterations, would give the gCNV PoN without the Gaussian approximation we use. ---. @samuelklee commented on [Wed May 17 2017](https://github.com/broadinstitute/gatk-protected/issues/1038#issuecomment-302234920). The same run of T = 10^5 and N = 100 took <4 minutes on the gsa5 Tesla K40c GPU---about a 3x speedup over my home CPU. A slightly larger run of T = 1.5 * 10^5 and N = 200 took 10 minutes and 6GB of the GPU's 12GB memory. (I did start running into some weird theano/pymc3 errors when I tried to go bigger, unfortunately.) Moving to the GPU does require a bit of extra configuration but is relatively trivial. The real business goes down in exactly 11 lines of code, which cleanly specify the gCNV probabilistic model for read counts:. ```; with pm.Model() as model:; alpha_u = Uniform(name='alpha_u', lower=alpha_min, upper=alpha_max, shape=D); m_t = Uniform(name='m_t', lower=m_min, upper=m_max, shape=T); psi_t = Uniform(name='psi_t', lower=psi_min, upper=psi_max, shape=T); depth_s = Uniform(name='depth_s', lower=depth_min, upper=depth_max, shape=N); ; z_su = Normal(name='z_us', mu=0., sd=1., shape=(N, D)); W_tu = Normal(name='W_tu', mu=0., sd=1. / sqrt(alpha_u), shape=(T, D)); mu_st = Deterministic(name='mu_st', var=z_su.dot(W_tu.T) + m_t); b_st = Normal(name='b_st', mu=mu_st, sd=sqrt(psi_t), shape=(N, T)); n_ts = Poisson(name='n_ts', mu=depth_s * exp(b_st).T, observed=n_ts_data); ; fit_pm = pm.variational.advi(model=model, n=num_iterations, learning_rate=learning_rate, random_seed=random_seed, eval_elbo=eval_elbo_iterations); ```. @eitanbanks @droazen @lbergelson @LeeTL1220 @ldgauthier @yfarjoun This is just one example of how using recently developed M",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2984:2242,down,down,2242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2984,1,['down'],['down']
Availability,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:2208,error,error,2208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,2,"['error', 'failure']","['error', 'failureMessage']"
Availability,"preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:33,18\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:8:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:33,18\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:7:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:33,19\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:1:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:43,39\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:4:1\]: set -euo pipefail. rm -rf genomicsdb¬†. .... (and so on). singularity exec --containall docker://us.gcr.io/broad-gatk/gatk@sha256:21c3cb43b7d11891ed4b63cc7274f20187f00387cfaa0433b3e7991b5be34dbe \\. ¬† echo ""successfully pulled us.gcr.io/broad-gatk/gatk@sha256:21c3cb43b7d11891ed4b63cc7274f20187f00387cfaa0433b3e7991b5be34dbe!"". singularity exec --containall --bind /scratch.global/lee04110/cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-0:/cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-0 docker://us.gcr.io/broad-gatk/gatk@sha256:21c3cb43b7d11891ed4b63cc7274f20187f00387cfaa0433b3e7991b5be34dbe /bin/bash /cromwell-executions/JointGenotyping/9743b28a-3819-49a7-8598-b0c5267647ee/call-ImportGVCFs/shard-0/execution/script. \[2022-10-18 15:38:47,76\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:5:1\]: job id: 698507. \[2022-10-18 15:38:47,76\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:2:1\]: job id: 698509. \[2022-10-18 15:38:47,76\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:4:1\]: j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:4917,echo,echo,4917,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['echo'],['echo']
Availability,prevent log4j error messages in spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2622:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2622,1,['error'],['error']
Availability,"previously avx code was sometimes included if installDist had been run prior to running sparkJar, now sparkJar will always contain the native code; fixes #1576. also changing download of inteldeflator.so to only happen if it doesn't exist already",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1681:175,down,download,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1681,1,['down'],['download']
Availability,"processGermlineCNVCalls - Requester pays: disabled ; ; 11:04:20.985 INFO PostprocessGermlineCNVCalls - Initializing engine ; ; 11:04:26.627 INFO PostprocessGermlineCNVCalls - Done initializing engine ; ; 11:04:27.492 INFO ProgressMeter - Starting traversal ; ; 11:04:27.492 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 11:04:27.493 INFO ProgressMeter - unmapped 0.0 0 NaN ; ; 11:04:27.493 INFO ProgressMeter - Traversal complete. Processed 0 total records in 0.0 minutes. ; ; 11:04:27.493 INFO PostprocessGermlineCNVCalls - Generating intervals VCF file... ; ; 11:04:27.510 INFO PostprocessGermlineCNVCalls - Writing intervals VCF file to /staging/wes/1\_sample\_20210615/CNV\_calling/genotyped-intervals-case-A210066-vs-v7cohort.vcf.gz... ; ; 11:04:27.510 INFO PostprocessGermlineCNVCalls - Analyzing shard 1 / 1... ; ; 11:04:30.169 INFO PostprocessGermlineCNVCalls - Generating segments... ; ; 11:04:37.131 INFO PostprocessGermlineCNVCalls - Shutting down engine ; ; \[August 30, 2021 11:04:37 AM HKT\] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.27 minutes. ; ; Runtime.totalMemory()=2463105024 ; ; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; ; python exited with 1 ; ; Command Line: python /tmp/segment\_gcnv\_calls.8152704641395924200.py --ploidy\_calls\_path /staging/wes/healthy\_bams\_for\_CNV/using\_v7\_probe/v7\_case\_ploidy/v7\_cases\_ploidy\_1\_sample\_20210615-calls --model\_shards /staging/wes/healthy\_bams\_for\_C ; ; Stdout: 11:04:36.532 INFO segment\_gcnv\_calls - THEANO\_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast\_run,compute\_test\_value=ignore,openmp=true,blas.ldflags=-lmkl\_rt,openmp\_elemwise\_minsize=10 ; ; 11:04:36.532 INFO segment\_gcnv\_calls - Loading ploidy calls... ; ; 11:04:36.533 INFO gcnvkernel.io.io\_metadata - Loading germline contig ploidy and global read depth metadata... ; ; 11:04:36",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444:4533,down,down,4533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444,1,['down'],['down']
Availability,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3478:121,error,error,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478,2,['error'],['error']
Availability,ps://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (√∏)` | :arrow_down: |; | [...plotypecaller/HaplotypeCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJHZW5vdHlwaW5nRW5naW5lLmphdmE=) | `77.536% <0%> (+1.449%)` | `32% <0%> (+1%)` | :arrow_up: |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `79.026% <0%> (+1.498%)` | `65% <0%> (+2%)` | :arrow_up: |; | [...ypecaller/AssemblyBasedCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `90.909% <0%> (+1.818%)` | `67% <0%> (+2%)` | :arrow_up: |; | [...ls/downsampling/AlleleBiasedDownsamplingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvQWxsZWxlQmlhc2VkRG93bnNhbXBsaW5nVXRpbHMuamF2YQ==) | `79.31% <0%> (+2.299%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `89.575% <0%> (+4.054%)` | `151% <0%> (+5%)` | :arrow_up: |; | ... and [2 more](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368157556:3542,down,downsampling,3542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368157556,1,['down'],['downsampling']
Availability,pysam compile failure,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742:14,failure,failure,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742,1,['failure'],['failure']
Availability,"q06.scc.bu.edu, executor 23, partition 178, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Finished task 12.0 in stage 5.0 (TID 957) in 30736 ms on scc-q15.scc.bu.edu (executor 15) (117/189); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Removed taskresult_957 on scc-q15.scc.bu.edu:35739 in memory (size: 5.2 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Lost task 181.3 in stage 5.0 (TID 1139) on scc-q02.scc.bu.edu, executor 24: java.lang.IllegalArgumentException (provided start is negative: -1) [duplicate 3]; 2019-02-17 16:25:50 ERROR TaskSetManager:70 - Task 181 in stage 5.0 failed 4 times; aborting job; 2019-02-17 16:25:50 INFO YarnScheduler:54 - Cancelling stage 5; 2019-02-17 16:25:50 INFO YarnScheduler:54 - Stage 5 was cancelled; 2019-02-17 16:25:50 INFO DAGScheduler:54 - ResultStage 5 (collect at FindBreakpointEvidenceSpark.java:963) failed in 30.887 s due to Job aborted due to stage failure: Task 181 in stage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:39413,failure,failure,39413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['failure'],['failure']
Availability,qYXZh) | `9.091% <9.091%> (√∏)` | `1 <1> (?)` | |; | [...ellbender/tools/walkers/MethylationTypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL01ldGh5bGF0aW9uVHlwZUNhbGxlci5qYXZh) | `95.522% <95.522%> (√∏)` | `11 <11> (?)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | ... and [1227 more](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5762#issuecomment-482191369:3079,down,downsampling,3079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5762#issuecomment-482191369,1,['down'],['downsampling']
Availability,"quified samples. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260475512). @ldgauthier Will this tool be ported to GATK4? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260637796). ¬Ø_(„ÉÑ)_/¬Ø. I wasn't going to port it myself. It's not under active development, but GTEx used it a little in the past. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260713724). Hmm. Who would be the right person to ask whether GTex would need this ported? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260739166). Last I checked, Xiao Li was using the tool for the work he was doing with Ayellet Segre. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260778577). Thanks, I emailed them to ask about their use of the tool. . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-287823398). Response from Xiao Li:. > The ‚ÄúCombineSampleData‚Äù tool is initially developed by Laura to perform integrated variant calling when we have both WES and WGS data for same individuals. Use GTEx release v6 data, we have found that it helps generating better genotype calls and improves calls from older technologies (e.g.: HiSeq2000 vs. HiSeqX, Agilent vs. ICE). In GTEx, all samples will be genotyped with both WGS and WES, and because of this, in our final release next year, we want to use this tool to generate a call set that integrates WGS and WES. Prior to this, we plan to publish this method that we could cite it in the final release paper. I will expect this method very useful for other big consortiums where both WGS and WES are available for same samples. . > Hope you could keep it in GATK.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2485:4750,avail,available,4750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2485,1,['avail'],['available']
Availability,r - 1:7202715 4.0 4191000 1045250.1; 14:26:30.135 INFO ProgressMeter - 1:7440529 4.2 4368000 1045747.5; 14:26:40.182 INFO ProgressMeter - 1:7704929 4.3 4546000 1046412.6; 14:26:50.246 INFO ProgressMeter - 1:7943120 4.5 4721000 1046297.7; 14:27:00.269 INFO ProgressMeter - 1:8191836 4.7 4903000 1047839.9; 14:27:10.295 INFO ProgressMeter - 1:8443081 4.8 5076000 1047407.8; 14:27:20.317 INFO ProgressMeter - 1:8693600 5.0 5267000 1050608.9; 14:27:30.363 INFO ProgressMeter - 1:8947934 5.2 5462000 1054294.3; 14:27:40.417 INFO ProgressMeter - 1:9199287 5.3 5639000 1054360.3; 14:27:50.420 INFO ProgressMeter - 1:9454308 5.5 5811000 1053671.8; 14:28:00.434 INFO ProgressMeter - 1:9724703 5.7 5994000 1054928.8; 14:28:10.442 INFO ProgressMeter - 1:9997608 5.8 6184000 1057329.0; ```. Whereas for the `1:10000000-20000000` interval we reach our max records/minute rate from the beginning and sustain it throughout:. ```; 11:59:25.779 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 11:59:35.800 INFO ProgressMeter - 1:10238878 0.2 179000 1071856.3; 11:59:45.815 INFO ProgressMeter - 1:10479871 0.3 365000 1093032.5; 11:59:55.820 INFO ProgressMeter - 1:10734140 0.5 543000 1084517.8; 12:00:05.862 INFO ProgressMeter - 1:11009535 0.7 720000 1077763.6; 12:00:15.906 INFO ProgressMeter - 1:11266264 0.8 906000 1084445.5; 12:00:25.975 INFO ProgressMeter - 1:11519786 1.0 1088000 1084457.4; 12:00:36.005 INFO ProgressMeter - 1:11779127 1.2 1264000 1079941.9; 12:00:46.045 INFO ProgressMeter - 1:12038732 1.3 1440000 1076420.9; 12:00:56.072 INFO ProgressMeter - 1:12294624 1.5 1617000 1074501.9; 12:01:06.118 INFO ProgressMeter - 1:12547820 1.7 1818000 1087125.5; 12:01:16.130 INFO ProgressMeter - 1:12796451 1.8 2002000 1088526.6; 12:01:26.168 INFO ProgressMeter - 1:13176986 2.0 2170000 1081494.2; ....; etc.; ```. I can only conclude that there's something about the start of chromosome 1 that is slowing HB down. Next step is to profile HB during traversal of that region.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236:4391,down,down,4391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236,1,['down'],['down']
Availability,"r - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.375 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xhgnc_v90_38.hg38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg38/gencode_xhgnc_v90_38.hg38.tsv; > 15:16:57.746 INFO Funcotator - Initializing Funcotator Engine...; > 15:16:57.777 INFO Funcotator - Creating a VCF file for output: file:/home/pkus/mutect_test/filtered_variants/P1.avcf.gz; > 15:16:57.894 INFO ProgressMeter - Starting traversal; > 15:16:57.894 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 15:16:57.979 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; > 15:16:57.981 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; > 15:16:57.991 INFO Funcotator - Shutting down engine; > [July 17, 2020 3:16:57 PM CEST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.31 minutes.; > Runtime.totalMemory()=883949568; > java.lang.IllegalArgumentException: Unexpected value: lncRNA; > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1052); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:753); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); > at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:17161,down,down,17161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['down'],['down']
Availability,"r -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 84.000 40778 40780 35116 1412 0.5373 0.9665 0.6907; None 41994 41994 43760 196 0.4897 0.9954 0.6564; ::::::::::::::; NA12878/O1D1/STANDARD_NGS/summary.txt; ::::::::::::::; Thres",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:1273,avail,availability,1273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566,1,['avail'],['availability']
Availability,"r appears to be related to the reblocking of the gvcfs. ```; gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:105582-211160 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-105582-211160.vcf.gz; 07:46:18.893 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 07:46:18.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 7:46:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:46:19.128 INFO GenotypeGVCFs - ------------------------------------------------------------; 07:46:19.128 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 07:46:19.128 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:46:19.129 INFO GenotypeGVCFs - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 07:46:19.129 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 07:46:19.129 INFO GenotypeGVCFs - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278:1184,Redundant,Redundant,1184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278,1,['Redundant'],['Redundant']
Availability,"r dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA‚Ä¶AAAAAGA sequence in the picture below. . C.3 PairHMM runs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/264:1810,recover,recovered,1810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264,1,['recover'],['recovered']
Availability,"r definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. I am pretty sure that most common germline regions are being blacklisted already. The hotspots addressed in this PR (faux-CNLoH) could be added, but I think we will find new areas and a few of these areas were rather big. I have users that are actively using this from the branch, for reasons other than the faux-CNLoH pruning. Results are improving without an appreciable hit to sensitivity, which we got when using parameters like num_changepoints_penalty_factor. As a compromise, I can always default the CNLoH piece to `false`, since there are other useful changes on this branch. (Users did not have as strong an opinion about the faux-CNLoH pruning, since GISTIC does not use MAF and ABSOLUTE requires a manual review). > simple filtering based on CR-AF as described above could be implemented. If the normal is available, we can make IS_NORMAL calls simply based on the overlap of the ModelSegments posteriors (with corresponding qualities). If not, then some heuristic determination of the normal state from the tumor alone as in Marton's caller could be performed. This would combine the IS_NORMAL calling and filtering steps into one simple tool. The output could be a tagged/filtered ModelSegments .seg file and the corresponding VCF. And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874:2352,avail,available,2352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874,2,['avail'],['available']
Availability,"r directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:12 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:07 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.27, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:56:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.27:46181 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.27:46181 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:56:39 WARN TaskSetManager: Lost task 1.2 in stage 2.0 (TID 9, xx.xx.xx.27, executor 0): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:32072,Error,Error,32072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,r id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 ERROR cluster.YarnScheduler: Lost executor 1 on com2: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:18882,ERROR,ERROR,18882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['ERROR'],['ERROR']
Availability,"r issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls. ### Affected version(s); - gatk-4.1.9.0. ### Description ; When I was running FilterMutectCalls with one of my samples, I got an error as ""Duplicate key"". 14:50:59.201 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.202 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:50:59.202 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:50:59.203 INFO FilterMutectCalls - Executing as mparment@her2-w110 on Linux v5.7.7-1.el7.elrepo.x86_64 amd64; 14:50:59.203 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 14:50:59.203 INFO FilterMutectCalls - Start Date/Time: December 12, 2020 2:50:57 PM CET; 14:50:59.203 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.203 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Version: 2.23.0; 14:50:59.204 INFO FilterMutectCalls - Picard Version: 2.23.3; 14:50:59.204 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:1366,error,error,1366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['error'],['error']
Availability,"r message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 02:08:01.543 INFO GenotypeGVCFs - Start Date/Time: November 6, 2020 2:07:51",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1124,Redundant,Redundant,1124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059,1,['Redundant'],['Redundant']
Availability,"r script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:52:19.131 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:52:18 PM EDT; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:1409,error,error,1409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971,1,['error'],['error']
Availability,"r the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‚Äò1.3.0‚Äô; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ‚ñÜ; 1. ‚îú‚îÄbase::source(""/path/to/rscript.r""); 2. ‚îÇ ‚îú‚îÄbase::withVisible(eval(ei, envir)); 3. ‚îÇ ‚îî‚îÄbase::eval(ei, envir); 4. ‚îÇ ‚îî‚îÄbase::eval(ei, envir); 5. ‚îî‚îÄggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ‚îú‚îÄggplot2::continuous_scale(...); 7. ‚îÇ ‚îî‚îÄggplot2::ggproto(...); 8. ‚îÇ ‚îî‚îÄrlang::list2(...); 9. ‚îî‚îÄscales::seq_gradient_pal(low, high, space); 10. ‚îî‚îÄscales::pal_gradient_n(c(low, high), space = space); 11. ‚îî‚îÄlifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. ‚îî‚îÄlifecycle:::deprecate_stop0(msg); 13. ‚îî‚îÄrlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remotes"", repos=""https://cloud.r-project.org/""); > library(remotes); > install_version(""scales"", version=""1.2.1"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‚Äò1.2.1‚Äô; > quit(); $ gatk VariantRecalibrator [arguments omitted for brevity]; $; ```. #### Expected be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:1250,Error,Error,1250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['Error'],['Error']
Availability,"r thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 0.89 minutes.; Runtime.totalMemory()=881328128; ***********************************************************************. A USER ERROR has occurred: Input files reference and reads have incompatible contigs: No overlapping contigs found.; reference contigs = [chrM, chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chr1_gl000191_random, chr1_gl000192_random, chr4_ctg9_hap1, chr4_gl000193_random, chr4_gl000194_random, chr6_apd_hap1, chr6_cox_hap2, chr6_dbb_hap3, chr6_mann_hap4, chr6_mcf_hap5, chr6_qbl_hap6, chr6_ssto_hap7, chr7_gl000195_random, chr8_gl000196_random, chr8_gl000197_random, chr9_gl000198_random, chr9_gl000199_random, chr9_gl000200_random, chr9_gl000201_random, chr11_gl000202_random, chr17_ctg5_hap1, chr17_gl000203_rand",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:31077,down,down,31077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['down'],['down']
Availability,"r$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:53 INFO TaskSetManager: Lost task 1.1 in stage 2.0 (TID 6) on xx.xx.xx.24, executor 1: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 02:34 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.25, executor 6, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 18/04/24 17:42:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:42:02 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.j",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:32807,Error,Error,32807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Error'],['Error']
Availability,"r,/usr/lib/jvm/java-8-openjdk-amd64/jre/classes,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/zipfs.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/dnsns.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunjce_provider.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/icedtea-sound.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/nashorn.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/java-atk-wrapper.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunec.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunpkcs11.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/cldrdata.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/jaccess.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/localedata.jar,/gatk/gatk-package-unspecified-SNAPSHOT-local.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-testDependencies.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-test.jar]; 2022-08-16T22:45:53.6382333Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6548080Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:2123,error,error,2123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"r-mixed-ploidy-samples/p1); ----------; I'm attempting to call variants on whole genomes for about 500 illumina paired-end samples with varying ploidy (haploid to tetraploid). I'm running a fairly standard uBam to GVCF pipeline with HaplotypeCaller passed the ploidy information (1,2,3, or 4) in -ERC GVCF mode. I then try to collect the GVCFs using GenomicsDBImport in a batch size of 50 and use GenotypeGVCFs on the combined database. My interval list that is passed to GenomicsDBImport is just each chromosome on a separate line. I'm using GATK v4.1.1.0<br />; <br />; Command:<br />; ```<br />; ${GATK_DIR}/gatk GenomicsDBImport \<br />; --java-options ""-Xmx110g -Xms110g"" \<br />; -R ${REF} \<br />; --variant ${FILE_LIST} \<br />; -L ${SCRIPT_DIR}/GATK_Style_Interval.list \<br />; --genomicsdb-workspace-path ${WORK_DIR}/GenomicsDB_20190912 \<br />; --batch-size 50 \<br />; --tmp-dir=${WORK_DIR}/<br />; ```<br />; <br />; GenomicsDBImport appears to run without error, but only shows progress for the first 6000 bp before moving onto the next batch. When I run select variants on the created database, I only get variants up to position 6716 in the first interval. When I try to run GenotypeGVCF on it, I get a strange error:<br />; htsjdk.tribble.TribbleException: Invalid block size -1570639203<br />; <br />; My first assumption is that one of the gvcf's is malformed from HaplotypeCaller failing after the first 6000 bp, but I've verified that the gvcfs have all completed and have 'validated' them with ValidateVariants using GATK v4.1.3.0. When I grep for the particular position in the sample's gvcfs I don't find anything out of the ordinary. I would use CombineGVCFs, but it fails due to trying to combine mixed ploidies. <br />; <br />; Any ideas on troubleshooting or experience with problems like this?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24446/genomicsdbimport-not-completing-for-mixed-ploidy-samples/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:4241,error,error,4241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,1,['error'],['error']
Availability,"r-round 50 --log-emission-sampling-median-rel-error 0.005 --log-emission-sampling-rounds 10 --max-advi-iter-first-epoch 5000 --max-advi-iter-subsequent-epochs 100 --min-training-epochs 10 --max-training-epochs 100 --initial-temperature 2.0 --num-thermal-advi-iters 2500 --convergence-snr-averaging-window 500 --convergence-snr-trigger-threshold 0.1 --convergence-snr-countdown-window 10 --max-calling-iters 10 --caller-update-convergence-threshold 0.001 --caller-internal-admixing-rate 0.75 --caller-external-admixing-rate 1.00 --disable-annealing false. [2019-02-22 23:49:20,42] [info] WorkflowManagerActor WorkflowActor-098a389e-b298-4324-8a8c-9f46f05708b5 is in a terminal state: WorkflowFailedState; [2019-02-22 23:50:01,65] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-02-22 23:50:02,38] [info] Workflow polling stopped; [2019-02-22 23:50:02,48] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-02-22 23:50:02,49] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-02-22 23:50:02,53] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-02-22 23:50:02,53] [info] Aborting all running workflows.; [2019-02-22 23:50:02,53] [info] JobExecutionTokenDispenser stopped; [2019-02-22 23:50:02,53] [info] WorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] WorkflowLogCopyRouter stopped; [2019-02-22 23:50:02,61] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor All workflows finished; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor stopped; [2019-02-22 23:50:02,61] [info] Connection pools shut down; [2019-02-22 23:50:02,61] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting dow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:30689,down,down,30689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,3,['down'],['down']
Availability,"r.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 INFO client.RMProxy: Connecting to ResourceManager at tele-1/192.168.1.4:8032; 18/01/09 18:30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Clien",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:10191,AVAIL,AVAILABLE,10191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,r.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:8245,ERROR,ERROR,8245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,r.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/04/27 18:49:12 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1231); at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229); at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:3797,ERROR,ERROR,3797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['ERROR'],['ERROR']
Availability,r.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); Caused by: org.gradle.api.internal.tasks.compile.CompilationFailedException: Compilation failed; see the compiler error output for details.; at org.gradle.api.internal.tasks.compile.JdkJavaCompiler.execute(JdkJavaCompiler.java:48); at org.gradle.api.internal.tasks.compile.JdkJavaCompiler.execute(JdkJavaCompiler.java:33); at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.delegateAndHandleErrors(NormalizingJavaCompiler.java:104); at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.execute(NormalizingJavaCompiler.java:53); at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.execute(NormalizingJavaCompiler.java:38); at org.gradle.api.internal.tasks.compile.CleaningJavaCompilerSupport.execute(CleaningJavaCompilerSupport.java:35); at org.gradle.api.internal.tasks.compile.CleaningJavaCompilerSupport.execute(CleaningJavaCompilerSupport.java:25); at org.gradle.api.tasks.compile.JavaCompile.performCompilation(JavaCompile.java:189); at org.gradle.api.tasks.compile.JavaCompile.compile(JavaCompile.java:170); at org.gradle.api.tasks.compile.JavaCompil,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:12634,error,error,12634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['error'],['error']
Availability,"r.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); ```. #### Steps to reproduce; These are the arguments I used (the input bam is on the file system):. ```; final String[] args = {; ""-I"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/Filtering/IGV/198489_vs_811158/sorted.mt.1.bam"",; ""-"" + M2ArgumentCollection.TUMOR_SAMPLE_SHORT_NAME, ""198489"",; ""-R"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/MitochondriaOnlyFastas/Homo_sapiens_assembly38.mt_only.fasta"",; ""-O"", outputVcf.getAbsolutePath(),; ""--max-reads-per-alignment-start"", ""0"",; ""-default-af"", ""0"",; ""--initial-tumor-lod"", ""0"",; ""--tumor-lod-to-emit"", ""0"",; ""--min-pruning"", ""10"",; ""--annotation"", ""StrandBiasBySample"",; //""--ignore-itr-artifacts"", ""true"",; };; ```. I tried it with and without `--ignore-itr-artifacts` but got the same error both times. @davidbenjamin Any idea if this is an easy fix?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:5499,error,error,5499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['error'],['error']
Availability,"r.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:82); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:242); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:496); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:221); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:254); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:231); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); at org.broadinstitute.hellbender.Main.main(Main.java:239); ```. Attempts with different regions (e.g. neighbouring positions 86 or 88 at this chromosome, or other sets of reads, or taking one of the culprit reads alone) didn't give me the error. Can you suggest what I'm doing wrong?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:11865,error,error,11865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,1,['error'],['error']
Availability,"r/share/man/man1/git-lfs-smudge.1.gz; git-lfs usr/share/man/man1/git-lfs-standalone-file.1.gz; git-lfs usr/share/man/man1/git-lfs-status.1.gz; git-lfs usr/share/man/man1/git-lfs-track.1.gz; git-lfs usr/share/man/man1/git-lfs-uninstall.1.gz; git-lfs usr/share/man/man1/git-lfs-unlock.1.gz; git-lfs usr/share/man/man1/git-lfs-untrack.1.gz; git-lfs usr/share/man/man1/git-lfs-update.1.gz; git-lfs usr/share/man/man1/git-lfs.1.gz; git-lfs usr/share/man/man5/; git-lfs usr/share/man/man5/git-lfs-config.5.gz; ```. Then I run ; ```; git lfs pull --include src/main/resources/large; ./gradle localJar; ```; then; ```; error transferring ""1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46"": [0] remote missing object 1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46; error transferring ""bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d"": [0] remote missing object bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d; error transferring ""6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c"": [0] remote missing object 6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c; error transferring ""e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6"": [0] remote missing object e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6; error transferring ""4ed7feb0343e9ac03135b1456b2c8d2edab1b359c4950908c4d44152c0634a89"": [0] remote missing object 4ed7feb0343e9ac03135b1456b2c8d2edab1b359c4950908c4d44152c0634a89; error transferring ""eda2517817b23238c2b28f69a1fa39e9b85b45985854f0a5d5508280e76da39e"": [0] remote missing object eda2517817b23238c2b28f69a1fa39e9b85b45985854f0a5d5508280e76da39e; error transferring ""5e69a86f301ab9ab0d507ad7659abb4ad3732382ccbeb714db497e51eb3cf87b"": [0] remote missing object 5e69a86f301ab9ab0d507ad7659abb4ad3732382ccbeb714db497e51eb3cf87b; Failed to fetch some objects from 'file:///startdir/gatk'. ```. #### Expected behavior; can be compiled. #### Actual behavior; see above",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:3565,error,error,3565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,7,['error'],['error']
Availability,"r: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 18/01/09 18:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 18:30:55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7424,AVAIL,AVAILABLE,7424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"r; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.seri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:4532,down,down,4532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['down'],['down']
Availability,"r; 09:55:48.867 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 09:55:48.867 INFO GenotypeGVCFs - Requester pays: disabled; 09:55:48.867 INFO GenotypeGVCFs - Initializing engine; 09:55:49.015 INFO FeatureManager - Using codec VCFCodec to read file file:///share/org/YZWL/yzwl_hanxt/leizhou/variant/H-4/H-4.g.vcf.gz; 09:55:49.190 INFO GenotypeGVCFs - Done initializing engine; 09:55:49.215 INFO ProgressMeter - Starting traversal; 09:55:49.216 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:55:49.310 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr1_1-157403528:5512 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:55:49.336 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1_1-157403528:5512 and possibly subsequent; at least 10 samples must have called genotypes; 09:55:50.064 INFO GenotypeGVCFs - Shutting down engine; [September 3, 2024 at 9:55:50 AM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1241513984; java.lang.RuntimeException: Invalid deflate block found.; at com.intel.gkl.compression.IntelInflater.inflateNative(Native Method); at com.intel.gkl.compression.IntelInflater.inflate(IntelInflater.java:176); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:145); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:561); at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:543); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:479); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:469); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:3287,down,down,3287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['down'],['down']
Availability,"rFuncotations - Done initializing engine ; ; 02:00:35.260 INFO ¬†ProgressMeter - Starting traversal ; ; 02:00:35.261 INFO ¬†ProgressMeter - ¬† ¬† ¬† ¬†Current Locus ¬†Elapsed Minutes ¬† ¬†Variants Processed ¬†Variants/Minute ; ; 02:00:35.262 INFO ¬†FilterFuncotations - Starting pass 0 through the variants ; ; 02:00:35.778 ERROR FuncotationMap - Keys: ¬†Gencode\_34\_hugoSymbol, Gencode\_34\_ncbiBuild, Gencode\_34\_chromosome, Gencode\_34\_start, Gencode\_34\_end, Gencode\_34\_variantClassification, Gencode\_34\_secondaryVariantClassification, Gencode\_34\_variantType, Gencode\_34\_refAllele, Gencode\_34\_tumorSeqAllele1, Gencode\_34\_tumorSeqAllele2, Gencode\_34\_genomeChange, Gencode\_34\_annotationTranscript, Gencode\_34\_transcriptStrand, Gencode\_34\_transcriptExon, Gencode\_34\_transcriptPos, Gencode\_34\_cDnaChange, Gencode\_34\_codonChange, Gencode\_34\_proteinChange, Gencode\_34\_gcContent, Gencode\_34\_referenceContext, Gencode\_34\_otherTranscripts, ACMGLMMLof\_LOF\_Mechanism, ACMGLMMLof\_Mode\_of\_Inheritance, ACMGLMMLof\_Notes, ACMG\_recommendation\_Disease\_Name, ClinVar\_VCF\_AF\_ESP, ClinVar\_VCF\_AF\_EXAC, ClinVar\_VCF\_AF\_TGP, ClinVar\_VCF\_ALLELEID, ClinVar\_VCF\_CLNDISDB, ClinVar\_VCF\_CLNDISDBINCL, ClinVar\_VCF\_CLNDN, ClinVar\_VCF\_CLNDNINCL, ClinVar\_VCF\_CLNHGVS, ClinVar\_VCF\_CLNREVSTAT, ClinVar\_VCF\_CLNSIG, ClinVar\_VCF\_CLNSIGCONF, ClinVar\_VCF\_CLNSIGINCL, ClinVar\_VCF\_CLNVC, ClinVar\_VCF\_CLNVCSO, ClinVar\_VCF\_CLNVI, ClinVar\_VCF\_DBVARID, ClinVar\_VCF\_GENEINFO, ClinVar\_VCF\_MC, ClinVar\_VCF\_ORIGIN, ClinVar\_VCF\_RS, ClinVar\_VCF\_SSR, ClinVar\_VCF\_ID, ClinVar\_VCF\_FILTER, LMMKnown\_LMM\_FLAGGED, LMMKnown\_ID, LMMKnown\_FILTER ; ; 02:00:35.778 ERROR FuncotationMap - Values: ¬†, , , , , , , , , , , , , , , , , , , , , , , , , , , , false, ,¬† ; ; 02:00:35.793 INFO ¬†FilterFuncotations - Shutting down engine ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:5142,ERROR,ERROR,5142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['ERROR'],['ERROR']
Availability,rM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dangling tails; 11:36:15.932 DEBUG ReadThreadingGraph - Recovered 13 of 31 dangling heads; 11:36:15.995 DEBUG IntToDoubleFunctionCache - cache miss 2401 > 2399 expanding to 4800; 11:36:16.347 DEBUG Mutect2Engine - Active Region chrM:3703-3943; 11:36:16.348 DEBUG Mutect2Engine - Extended Act Region chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Ref haplotype coords chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Haplotype count 254; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:40.673 DEBUG Mutect2 - Processing assembly region at chrM:3944-4243 isActive: false numReads: 2581; 11:36:40.736 DEBUG Mutect2 - Processing assembly region at chrM:4244-4543 isActive: false numReads: 0; 11:36:40.749 DEBUG Mutect2 - Processing assembly region at chrM:4544-4843 isActive: false numReads: 0; 11:36:40.760 DEBUG Mutect2 - Processing assembl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:10983,Recover,Recovered,10983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"rMutectCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:03:49.970 INFO FilterMutectCalls - Deflater: IntelDeflater ; ; 11:03:49.971 INFO FilterMutectCalls - Inflater: IntelInflater ; ; 11:03:49.971 INFO FilterMutectCalls - GCS max retries/reopens: 20 ; ; 11:03:49.971 INFO FilterMutectCalls - Requester pays: disabled ; ; 11:03:49.971 INFO FilterMutectCalls - Initializing engine ; ; 11:03:50.504 INFO FeatureManager - Using codec VCFCodec to read file file:///home/lqh/somatic\_mutation/Mutect2/test.vcf.gz ; ; 11:03:50.696 INFO FilterMutectCalls - Done initializing engine ; ; 11:03:50.840 INFO ProgressMeter - Starting traversal ; ; 11:03:50.840 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 11:03:50.841 INFO FilterMutectCalls - Starting pass 0 through the variants ; ; 11:03:51.014 INFO FilterMutectCalls - Shutting down engine ; ; \[June 4, 2021 11:03:51 AM CST\] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.19 minutes. ; ; Runtime.totalMemory()=625999872 ; ; java.lang.NumberFormatException: **For input string: ""167|35|14""** ; ; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ; ; at java.lang.Integer.parseInt(Integer.java:580) ; ; at java.lang.Integer.valueOf(Integer.java:766) ; ; at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:288) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Collections$2.tryAdvance(Collections.java:4717) ; ; at java.util.Collections$2.forEachRemaining(Collections.java:4725) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:5592,down,down,5592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['down'],['down']
Availability,"rUn_KI270374v1, chrUn_KI270372v1, chrUn_KI270373v1, chrUn_KI270375v1, chrUn_KI270371v1, chrUn_KI270448v1, chrUn_KI270521v1, chrUn_GL000195v1, chrUn_GL000219v1, chrUn_GL000220v1, chrUn_GL000224v1, chrUn_KI270741v1, chrUn_GL000226v1, chrUn_GL000213v1, chrUn_KI270743v1, chrUn_KI270744v1, chrUn_KI270745v1, chrUn_KI270746v1, chrUn_KI270747v1, chrUn_KI270748v1, chrUn_KI270749v1, chrUn_KI270750v1, chrUn_KI270751v1, chrUn_KI270752v1, chrUn_KI270753v1, chrUn_KI270754v1, chrUn_KI270755v1, chrUn_KI270756v1, chrUn_KI270757v1, chrUn_GL000214v1, chrUn_KI270742v1, chrUn_GL000216v2, chrUn_GL000218v1, chrEBV]; features contigs = [X, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]"". The VCF that I have uses just numbers for chromosomes, whereas the reference genome uses chr1, chr2, etc. Both naming conventions are valid. This is a 4.3 VCF. I have read https://gatk.broadinstitute.org/hc/en-us/articles/360035891131-Errors-about-input-files-having-missing-or-incompatible-contigs and this seems to be the same issue, but I believe there should be a translation that happens, e.g. 1 -> chr1 or the reverse as well. #### Steps to reproduce; Ran the following command using a VCF and reference file that I have:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.2.0-local.jar LeftAlignAndTrimVariants --max-indel-length 500 --max-leading-bases 2000 --dont-trim-alleles false --verbosity DEBUG --variant <input vcf file> --output /data/<vcf_output> --reference /data/<reference file> --split-multi-allelics true. #### Expected behavior; I would expect GATK to be able to translate 1 -> chr1, 2 -> chr2, etc. since both naming conventions are valid according to the VCF spec http://samtools.github.io/hts-specs/VCFv4.3.pdf. When running the same exact command on a VCF file that uses chr1, chr2, etc. as the naming convention the command runs su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:4202,Error,Errors-about-input-files-having-missing-or-incompatible-contigs,4202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['Error'],['Errors-about-input-files-having-missing-or-incompatible-contigs']
Availability,r] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InPr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:6092,ERROR,ERROR,6092,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,r] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:11981,ERROR,ERROR,11981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,r] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.se,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:10723,ERROR,ERROR,10723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,radle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.pr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:12530,ERROR,ERROR,12530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,radle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:11272,ERROR,ERROR,11272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,radle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:12715,ERROR,ERROR,12715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,radle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:11457,ERROR,ERROR,11457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"rageImpl.get(StorageImpl.java:238); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:497); at htsjdk.samtools.util.IOUtil.assertPathsAreReadable(IOUtil.java:525); at picard.fingerprint.CrosscheckFingerprints.doWork(CrosscheckFingerprints.java:449); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Bucket is requester pays bucket but no user project provided."",; ""reason"" : ""required""; } ],; ""message"" : ""Bucket is requester pays bucket but no user project provided.""; }; at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:150); at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:451); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1089); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7489:2008,error,errors,2008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7489,1,['error'],['errors']
Availability,"rated native PairHMM implementation ; 18:15:23.671 INFO ProgressMeter - Starting traversal ; 18:15:23.671 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute ; 18:15:26.788 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1:30191420 and possibly subsequent; at least 10 samples must have called genotypes ; 18:15:27.190 WARN DepthPerSampleHC - Annotation will not be calculated at position chr1:30477350 and possibly subsequent; genotype for sample B00I9EL is not called; 18:15:35.547 INFO ProgressMeter - chr1:32128426 0.2 40 202.1 ; 18:15:48.416 INFO ProgressMeter - chr1:36398656 0.4 80 194.0 ; 18:15:51.025 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.012874514 ; 18:15:51.026 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5.818477527000001; 18:15:51.026 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1.35 sec ; 18:15:51.027 INFO HaplotypeCaller - Shutting down engine ; [November 24, 2022 6:15:51 PM CET] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3212836864 ; java.lang.ArrayIndexOutOfBoundsException ; at java.util.Arrays.copyOfRange(Arrays.java:3521) ; at org.broadinstitute.hellbender.tools.walkers.annotator.TandemRepeat.getNumTandemRepeatUnits(TandemRepeat.java:54) ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer.trim(AssemblyRegionTrimmer.java:189); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:655); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:271); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200) ; at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173) ; at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106:6090,down,down,6090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106,1,['down'],['down']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-01T15:19:15.189684"",; ""created_by"": null,; ""finished_at"": ""2022-06-01T15:58:08.310876"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1143792534:9950,error,errors,9950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1143792534,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-01T17:59:13.998312"",; ""created_by"": null,; ""finished_at"": ""2022-06-01T18:32:08.316695"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1143995846:9950,error,errors,9950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1143995846,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-13T20:49:22.040855"",; ""created_by"": null,; ""finished_at"": ""2022-06-13T21:28:19.122154"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1154457285:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1154457285,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-13T20:50:21.938934"",; ""created_by"": null,; ""finished_at"": ""2022-06-13T21:28:19.925729"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1154457293:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1154457293,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-14T15:54:21.685372"",; ""created_by"": null,; ""finished_at"": ""2022-06-14T16:26:19.183470"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1155423814:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1155423814,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-06-14T16:42:21.893697"",; ""created_by"": null,; ""finished_at"": ""2022-06-14T17:12:19.188417"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1155478613:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1155478613,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-07-11T19:00:58.009539"",; ""created_by"": null,; ""finished_at"": ""2022-07-11T19:35:55.716418"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1180788391:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1180788391,1,['error'],['errors']
Availability,"rated.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2022-07-22T17:02:00.286664"",; ""created_by"": null,; ""finished_at"": ""2022-07-22T17:17:56.932848"",; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192782831:10123,error,errors,10123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192782831,1,['error'],['errors']
Availability,"rather than this:. ```; A USER ERROR has occurred: Input files reference and reads have incompatible contigs: Dictionary reference is missing contigs found in dictionary reads.; reference contigs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, X, Y, MT, GL000207.1, GL000226.1, GL000229.1, GL000231.1, GL000210.1, GL000239.1, GL000235.1, GL000201.1, GL000247.1, GL000245.1, GL000197.1, GL000203.1, GL000246.1, GL000249.1, GL000196.1, GL000248.1, GL000244.1, GL000238.1, GL000202.1, GL000234.1, GL000232.1, GL000206.1, GL000240.1, GL000236.1, GL000241.1, GL000243.1, GL000242.1, GL000230.1, GL000237.1, GL000233.1, GL000204.1, GL000198.1, GL000208.1, GL000191.1, GL000227.1, GL000228.1, GL000214.1, GL000221.1, GL000209.1, GL000218.1, GL000220.1, GL000213.1, GL000211.1, GL000199.1, GL000217.1, GL000216.1, GL000215.1, GL000205.1, GL000219.1, GL000224.1, GL000223.1, GL000195.1, GL000212.1, GL000222.1, GL000200.1, GL000193.1, GL000194.1, GL000225.1, GL000192.1]; reads contigs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, X, Y, MT, GL000207.1, GL000226.1, GL000229.1, GL000231.1, GL000210.1, GL000239.1, GL000235.1, GL000201.1, GL000247.1, GL000245.1, GL000197.1, GL000203.1, GL000246.1, GL000249.1, GL000196.1, GL000248.1, GL000244.1, GL000238.1, GL000202.1, GL000234.1, GL000232.1, GL000206.1, GL000240.1, GL000236.1, GL000241.1, GL000243.1, GL000242.1, GL000230.1, GL000237.1, GL000233.1, GL000204.1, GL000198.1, GL000208.1, GL000191.1, GL000227.1, GL000228.1, GL000214.1, GL000221.1, GL000209.1, GL000218.1, GL000220.1, GL000213.1, GL000211.1, GL000199.1, GL000217.1, GL000216.1, GL000215.1, GL000205.1, GL000219.1, GL000224.1, GL000223.1, GL000195.1, GL000212.1, GL000222.1, GL000200.1, GL000193.1, GL000194.1, GL000225.1, GL000192.1, NC_007605]; ```. it would be more friendly to say `contig NC_007605 is missing from the reference`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1289:31,ERROR,ERROR,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1289,1,['ERROR'],['ERROR']
Availability,rator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.broadinstitute.hellbender.Main.main(Main.java:292); > Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error); > at org.sqlite.core.DB.newSQLException(DB.java:909); > at org.sqlite.core.DB.newSQLException(DB.java:921); > at org.sqlite.core.DB.throwex(DB.java:886); > at org.sqlite.core.NativeDB.prepare_utf8(Native Method); > at org.sqlite.core.NativeDB.prepare(NativeDB.java:127); > at org.sqlite.core.DB.prepare(DB.java:227); > at org.sqlite.jdbc3.JDBC3Statement.executeQuery(JDBC3Statement.java:81); > at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotationsOnVariant(CosmicFuncotationFactory.java:288); > ... 26 more. Is it another typo?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:19900,error,error,19900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,2,['error'],['error']
Availability,rc/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4331864Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4360539Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4368812Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:17000,error,error,17000,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,rc/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8284709Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8288203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8294852Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8295684Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8296401Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8377958Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8390248Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8391883Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8406350Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8414536Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:19581,error,error,19581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"rc/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB. 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; #; # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x1a9401]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. [hs_err_pid2425.log.txt](https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt). @yfarjoun Is this similar to the crash you saw a while back?. ---. @yfarjoun commented on [Wed Aug 31 2016](https://github.com/broadinstitute/gatk-protected/issues/659#issuecomment-243946864). no. this is different. On Wed, Aug 31, 2016 at 3:27 PM, Louis Bergelson notifications@github.com; wrote:. > I got a segfault while running CreatePanelOfNormalsIntegrationTest.; > Subsequent runs were unable to reproduce it.; > ; > 18:03:07.573 WARN TaskSetManager:70 - Stage 181 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:1414,error,error,1414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability,"rceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:14064,error,errors,14064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['error'],['errors']
Availability,"rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11382,down,down,11382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['down'],['down']
Availability,"rdinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.run(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:13150,ERROR,ERROR,13150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"re: . ```; java.lang.AssertionError: Failed Matching VCF and MAF fields:; 	VCF (Gencode_43_variantClassification): 	RNA[0]	RNA[1]	RNA[2]	RNA[3]	RNA[4]	RNA[5]	RNA[6]	RNA[7]	RNA[8]	RNA[9]	RNA[10]; 	MAF (Variant_Classification): 	LINCRNA[0]	LINCRNA[1]	LINCRNA[2]	LINCRNA[3]	LINCRNA[4]	LINCRNA[5]	LINCRNA[6]	LINCRNA[7]	LINCRNA[8]	LINCRNA[9]	LINCRNA[10]; ----; 	VCF (Gencode_43_otherTranscripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[13]	PIK3CA_ENST00000643187.1_INTRON/PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; 	MAF (Other_Transcripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[13]	PIK3CA_ENST00000643187.1_INTRON|PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; ----; ```. Its unclear what is the most correct output rendering between the LINCRNA vs RNA for this specific transcript, its worth investigating and adding more robust gencodev43 tests to funcotator in case this is a real issue and not just a mismatch in the testing framework.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9013:2108,robust,robust,2108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9013,1,['robust'],['robust']
Availability,"re; Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.5.0.0-local.jar CombineGVCFs -R ./test/test.fna -V ./gvcf_all.list -L NC_038255.2 -O ./NC_038255.2.merged.g.vcf.gz; total 2.3G; '""-rw-rw-rw- 1 root root¬† 3.6K Dec 13 23:32 GATKConfig.EXAMPLE.properties""; drwxr-xr-x 2 root root¬† 4.0K Mar 13 06:26 GCF_000004515.6_Glycine_max_v4.0; '""-rw-r--r-- 1 root root¬† 1.6G Mar 13 06:47 NC_038255.2.merged.g.vcf.gz""; '""-rw-r--r-- 1 root root¬†¬† 24K Mar 13 06:47 NC_038255.2.merged.g.vcf.gz.tbi""; '""-rw-rw-rw- 1 root root¬†¬† 40K Dec 13 23:32 README.md""; '""-rwxrwxrwx 1 root root¬†¬† 21K Dec 13 23:32 gatk""; '""-rw-rw-rw- 1 root root 1016K Dec 13 23:32 gatk-completion.sh""; '""-rw-rw-rw- 1 root root¬† 422M Dec 13 23:32 gatk-package-4.5.0.0-local.jar""; '""-rw-rw-rw- 1 root root¬† 320M Dec 13 23:32 gatk-package-4.5.0.0-spark.jar""; lrwxrwxrwx 1 root root¬†¬†¬† 36 Dec 13 23:33 gatk-spark.jar -> /gatk/gatk-package-4.5.0.0-spark.jar; lrwxrwxrwx 1 root root¬†¬†¬† 36 Dec 13 23:33 gatk.jar -> /gatk/gatk-package-4.5.0.0-local.jar; '""-rw-rw-rw- 1 root root¬† 117K Dec 13 23:32 gatkPythonPackageArchive.zip""; '""-rw-rw-rw- 1 root root¬† 4.2K Dec 13 23:32 gatkcondaenv.yml""; '""-rw-r--r-- 1 root root¬†¬†¬† 53 Dec 13 23:37 gatkenv.rc""; '""-rw-r--r-- 1 root root¬† 2.3K Mar 13 06:26 gvcf_all.list""; '""-rw-r--r-- 1 root root¬†¬† 866 Dec 13 23:33 run_unit_tests.sh""; drwxrwxrwx 5 root root¬† 4.0K Dec 13 23:32 scripts; '""-rw-r--r-- 1 root root¬† 1.3K Mar 13 06:26 wgs_jcalling_combine_gvcf_job.sh""; Filesystem¬†¬†¬†¬†¬† Size¬† Used Avail Use% Mounted on; overlay¬†¬†¬†¬†¬†¬†¬†¬† 100G¬†¬† 13G¬†¬† 88G¬† 13% /; tmpfs¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† 64M¬†¬†¬†¬† 0¬†¬† 64M¬†¬† 0% /dev; tmpfs¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† 7.7G¬†¬†¬†¬† 0¬† 7.7G¬†¬† 0% /sys/fs/cgroup; /dev/nvme0n1p1¬† 100G¬†¬† 13G¬†¬† 88G¬† 13% /etc/hosts; shm¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† 64M¬†¬†¬†¬† 0¬†¬† 64M¬†¬† 0% /dev/shm; wgs-pipeline¬†¬†¬† 1.0P¬†¬†¬†¬† 0¬† 1.0P¬†¬† 0% /mnt. Thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735:28247,Avail,Avail,28247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735,1,['Avail'],['Avail']
Availability,read downsampling (+ commandline options),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/64:5,down,downsampling,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/64,1,['down'],['downsampling']
Availability,readingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling tails; 11:55:47.346 DEBUG ReadThreadingGraph - Recovered 6 of 47 dangling heads; 11:55:47.787 DEBUG Mutect2Engine - Active Region chrM:9302-9584; 11:55:47.792 DEBUG Mutect2Engine - Extended Act Region chrM:9202-9684; 11:55:47.796 DEBUG Mutect2Engine - Ref haplotype coords chrM:9202-9684; 11:55:47.800 DEBUG Mutect2Engine - Haplotype count 128; 11:55:47.803 DEBUG Mutect2Engine - Kmer sizes count 0; 11:55:47.807 DEBUG Mutect2Engine - Kmer sizes values []; 12:05:48.002 DEBUG Mutect2 - Processing assembly region at chrM:9585-9884 isActive: false numReads: 125080; 12:05:51.435 DEBUG Mutect2 - Processing assembly region at chrM:9885-10184 isActive: false numReads: 0; 12:05:51.448 DEBUG Mutect2 - Processing assembly region at chrM:10185-10484 isActive: false numReads: 0; 12:05:51.460 INFO ProgressMeter - chrM:10185 30.2 40 1.3; 12:05:51.465 DEBUG Mutect2 - Processing assembly region at chrM:10485-10784 isActive: false numReads: 0; 12:05:51.476 DEBUG Mutect2 - Processing as,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:17251,Recover,Recovered,17251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"records; 21:02:11.780 info NativeGenomicsDB - pid=19608 tid=19609 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 21:02:11.780 info NativeGenomicsDB - pid=19608 tid=19609 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 21:02:17.065 INFO GenotypeGVCFs - Done initializing engine; 21:02:17.110 INFO ProgressMeter - Starting traversal; 21:02:17.111 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:02:45.390 INFO ProgressMeter - Chr1:369351 0.5 1000 2121.8; 21:03:16.132 INFO ProgressMeter - Chr1:505230 1.0 2000 2033.2; 21:03:29.421 INFO ProgressMeter - Chr1:575285 1.2 3000 2489.3; ... (continued for more than 1000 lines); 21:49:51.317 INFO ProgressMeter - Chr1:3713346 47.6 242000 5087.2; 21:50:06.596 INFO ProgressMeter - Chr1:3718941 47.8 244000 5102.0; [TileDB::ReadState] Error: Cannot read tile from file; Memory map error.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ReadState] Error: Cannot read tile from file; Memory map error; Using GATK jar /home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx800G -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /mnt/d/Share/SYJ/liulan/ref/genome.fa -V gendb:///mnt/d/Share/SYJ/liulan/DBI -O /mnt/d/Share/SYJ/liulan/sortbam/combDBI.vcf.gz --tmp-dir /mnt/d/Share/SYJ/liulan/NOHUP/tmp; ```. I have tried to change -Xmx to 20G and 100G, etc. But all processes stop running at Variants Processed 244000.; Could you tell me",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8302:4348,Error,Error,4348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8302,2,"['Error', 'error']","['Error', 'error']"
Availability,redentials(ServiceOptions.java:277); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:252); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:3500,down,down,3500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['down'],['down']
Availability,reduce non-deterministic WDL test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4129:34,failure,failures,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4129,1,['failure'],['failures']
Availability,ree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `81.573% <100%> (+0.041%)` | `159 <1> (+1)` | :arrow_up: |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `100% <100%> (√∏)` | `23 <6> (+2)` | :arrow_up: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `81.818% <100%> (+4.769%)` | `12 <2> (+2)` | :arrow_up: |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `95.745% <80%> (-4.255%)` | `25 <6> (+4)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...itute/hellbender/utils/report/GATKReportTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydFRhYmxlLmphdmE=) | `70.412% <0%> (-0.265%)` | `67% <0%> (√∏)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802:1855,down,downsampling,1855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802,1,['down'],['downsampling']
Availability,"reedingCoeff - InbreedingCoeff will not be calculated at position 1A:219798 and possibly subsequent; at least 10 samples must have called genotypes ; ; 14:28:47.373 INFO ProgressMeter - 1A:568402 0.4 1000 2590.3 ; ; 14:28:57.413 INFO ProgressMeter - 1A:44165059 0.6 255000 460815.6 ; ; 14:29:07.419 INFO ProgressMeter - 1A:78552884 0.7 435000 604040.8 ; ; 14:29:25.201 INFO ProgressMeter - 1A:137636565 1.0 670000 659113.6 ; ; 14:29:35.211 INFO ProgressMeter - 1A:278089494 1.2 994000 839988.2 ; ; 14:29:45.226 INFO ProgressMeter - 1A:317697103 1.4 1162000 860570.8 ; ; 14:30:01.906 INFO ProgressMeter - 1A:363225043 1.6 1347000 827260.1 ; ; 14:30:12.084 INFO ProgressMeter - 1A:441459399 1.8 1676000 932198.7 ; ; 14:30:22.093 INFO ProgressMeter - 1A:466677934 2.0 1835000 933976.9 ; ; 14:30:38.874 INFO ProgressMeter - 1A:495722203 2.2 1996000 889324.5 ; ; 14:30:48.882 INFO ProgressMeter - 1A:536558193 2.4 2320000 962176.5 ; ; 14:30:49.143 INFO GenotypeGVCFs - Shutting down engine ; ; GENOMICSDB\_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),84.09050524498751,Cpu time(s),59.479603645012425 ; ; \[July 7, 2021 2:30:49 PM IDT\] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 2.45 minutes. ; ; Runtime.totalMemory()=12867076096 ; ; java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:142) ; ; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106) ; ; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129) ; ; at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177) ; ; at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:233) ; ; at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.closeTool(GenotypeGVCFs.java:295) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1064) ; ; at org.broadinst",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:6115,down,down,6115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,1,['down'],['down']
Availability,reliability,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7310:0,reliab,reliability,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7310,1,['reliab'],['reliability']
Availability,removing deprecated genomes in the cloud docker image that was causing test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8891:76,failure,failures,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8891,1,['failure'],['failures']
Availability,"removing redundant builds:; we will now have:; openJDK builds for cloud, integration, and unit tests; docker builds for integration and unit tests; an oracleJDK build for integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2770:9,redundant,redundant,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2770,1,['redundant'],['redundant']
Availability,removing the non-docker unit and integration test matrix entries because; they were redundant with the docker ones,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2804:84,redundant,redundant,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2804,1,['redundant'],['redundant']
Availability,removing the redundant command line parse exception,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/197:13,redundant,redundant,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/197,1,['redundant'],['redundant']
Availability,removing two redundant travis matrix entries to save vms,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2804:13,redundant,redundant,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2804,1,['redundant'],['redundant']
Availability,removing uncessary gradle download,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/547:26,down,download,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/547,1,['down'],['download']
Availability,"rencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:994); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). I don't really know how to fix it. ValidateVariants gives no errors, and I am able to perform variant selection, e.g.:. gatk-4.0.5.1/gatk SelectVariants -R data/genome.fasta -V variants/6753_12-15-2015_first_pass_raw.vcf -select 'vc.getGenotype(""6753_12-15-2015"").getAD().1/vc.getGenotype(""6753_12-15-2015"").getDP() > 0.9 ' -output variants/6753_12-15-2015_first_pass_filtered.vcf. with no problems. Insights would be gratefully appreciated.; Thanks!; Gavin. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/12223/java-lang-numberformatexception-when-trying-to-perform-variantfiltration/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4921:7469,error,errors,7469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4921,1,['error'],['errors']
Availability,"rently attempting to use on a computing cluster without spark enabled. . Command line used:; gatk/gatk-4.1.0.0/gatk StructuralVariationDiscoveryPipelineSpark \; -I $CRAM \; -R $Hg38 \; --aligner-index-image reference.fasta.Hg38.img \; --kmers-to-ignore kmers_to_ignore_hg38.txt \; --contig-sam-file aligned_contigs.sam \; -O ${base}_GATK_SV_output.vcf . **Error Log**:; 19/02/01 21:28:27 INFO TaskSetManager: Starting task 700.0 in stage 5.0 (TID 4405, localhost, executor driver, partition 700, PROCESS_LOCAL, 4940 bytes); 19/02/01 21:28:27 INFO Executor: Running task 700.0 in stage 5.0 (TID 4405); 19/02/01 21:28:27 INFO TaskSetManager: Finished task 668.0 in stage 5.0 (TID 4373) in 37331 ms on localhost (executor driver) (669/741); 19/02/01 21:28:27 INFO BlockManagerInfo: Removed taskresult_4373 on 10.120.16.54:34926 in memory (size: 1645.1 KB, free: 15.8 GB); 19/02/01 21:28:27 INFO NewHadoopRDD: Input split: file: /cram8/1-00004__CG0000-1789.GMKF2.cram:23488102400+33554432; 19/02/01 21:28:28 ERROR Executor: Exception in task 698.0 in stage 5.0 (TID 4403); **java.lang.IllegalArgumentException: provided start is negative: -24**; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterato",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5647:1142,ERROR,ERROR,1142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5647,1,['ERROR'],['ERROR']
Availability,"replying for @bbimber : we made a smaller test case on 4.2.6.0, and get the error: ""Genotype has no likelihoods:"" ..., the error does not occur without --force-output-intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7933#issuecomment-1188489162:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7933#issuecomment-1188489162,2,['error'],['error']
Availability,report errors to github comment,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247:7,error,errors,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247,1,['error'],['errors']
Availability,"rested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global genomics community and provide you with the latest technology for managing your genomic data. We have lots of other projects on the way, and look forward to supporting you. . Accordingly, we should remove our code that uses them. Unfortunately, this means we'll only have a single implementation of `GATKRead` which is unfortunate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:1679,robust,robust,1679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,1,['robust'],['robust']
Availability,return more useful error messages from RScriptExecutor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/223:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/223,1,['error'],['error']
Availability,"rg.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:255); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:37); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.Comm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:4341,ERROR,ERROR,4341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:7563,ERROR,ERROR,7563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,2,['ERROR'],['ERROR']
Availability,"rg.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:9444,down,down,9444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['down'],['down']
Availability,"rg.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest > testRequirePythonEnvironment FAILED; java.lang.NullPointerException: Cannot invoke ""Object.getClass()"" because the return value of ""java.lang.RuntimeException.getCause()"" is null; at org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest.testRequirePythonEnvironment(StreamingPythonExecutorIntegrationTest.java:34); ```. Error messages in another test case:; ```; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0xE2) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0x80) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0x99) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; ```. This test is skipped without any apparent reason:; ```; Running Test: Test method loadIndex(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > loadIndex FAILED; java.lang.UnsatisfiedLinkError: 'boolean org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createReferenceIndex(java.lang.S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:1234,error,error,1234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['error'],['error']
Availability,rg.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2233,ERROR,ERROR,2233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,rg.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.inte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:12166,ERROR,ERROR,12166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,rg.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.se,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:10908,ERROR,ERROR,10908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,rg/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:3483,error,error,3483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,rget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3494,ERROR,ERROR,3494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"riants - Built for Spark Version: 2.4.5; 08:37:42.996 INFO NVScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 08:37:42.996 INFO NVScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 08:37:42.996 INFO NVScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 08:37:42.996 INFO NVScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:37:42.996 INFO NVScoreVariants - Deflater: IntelDeflater; 08:37:42.996 INFO NVScoreVariants - Inflater: IntelInflater; 08:37:42.996 INFO NVScoreVariants - GCS max retries/reopens: 20; 08:37:42.996 INFO NVScoreVariants - Requester pays: disabled; 08:37:42.996 WARN NVScoreVariants - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: NVScoreVariants is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 08:37:42.996 INFO NVScoreVariants - Initializing engine; 08:37:43.031 INFO NVScoreVariants - Shutting down engine; [August 29, 2023 8:37:43 AM GMT] org.broadinstitute.hellbender.tools.walkers.vqsr.NVScoreVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=2123366400; java.lang.RuntimeException: A required Python package (""scorevariants"") could not be imported into the Python environment. This tool requires that the GATK Python environment is properly established and activated. Please refer to GATK README.md file for instructions on setting up the GATK Python environment.; 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:228); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.NVScoreVariants.onStartup(NVScoreVariants.java:108); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8501:2278,down,down,2278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8501,1,['down'],['down']
Availability,"riants-6-12-18.sorted_liftover_b38.corrected.vcf; 06:42:41.663 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/gencode.v34.annotation.REORDERED.gtf -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 06:42:41.663 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 06:42:41.665 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; 06:42:41.665 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 06:42:41.666 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; 06:42:41.691 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/gencode.v34.pc_transcripts.fa -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 06:42:46.805 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/clinvar_20180429_hg38.vcf -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 06:42:46.805 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar_VCF : 100000; 06:42:46.807 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 06:42:46.951 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/clinvar_20180429_hg38.vcf -> file:///dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:7150,error,errors,7150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['error'],['errors']
Availability,"right now you get this which is bogus on many levels (duplicated and confusing categories, confusing tool names etc). We need to put more order into this. @vdauwera can you help come up with a better scheme of how to organize tools?; Compare to the ADAM project (much much smaller scope of course but very clean UI: https://github.com/bigdatagenomics/adam). ```; /gatk-launch --list; Running:; /Users/akiezun/IdeaProjects/gatk/build/install/gatk/bin/gatk --help; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Copy Number Analysis: Tools to analyze copy number data.; CalculateTargetCoverage Count overlapping reads target by target. --------------------------------------------------------------------------------------; Fasta: Tools for analysis and manipulation of files in fasta format; CreateSequenceDictionary Creates a dict file from reference sequence in fasta format; NormalizeFasta Normalizes lines of sequence in a fasta file to be of the same length. --------------------------------------------------------------------------------------; Intervals: Tools for processing intervals and associated overlapping records; BedToIntervalList Converts a BED file to an Picard Interval List; ExampleIntervalWalker Print intervals with optional contextual data; IntervalListTools General tool for manipulating interval lists; LiftOverIntervalList Lifts over an interval list between genome builds. --------------------------------------------------------------------------------------; QC: Tools for Diagnostics and Quality Control; AnalyzeCovariates Tool to analyze and evaluate base recalibration tables for BQSR; CalculateHsMetrics Produces Hybrid Selection-specific metrics for a SAM/BAM file; CollectAlignmentSummaryMetrics Produces from a SAM/BAM/CRAM file containing summary alignment metrics; CollectBaseDistributionByCycle Produces metrics about nucleotide distribution per cycle in a SAM/BAM/CRAM fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:491,Avail,Available,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,1,['Avail'],['Available']
Availability,"ription. **(Background)**; I've spent a lot of time working with Mutect2 in the past year (I've built a whole workflow centered around this tool). But, while I recognize that the internal reassembly feature leads to ""best-in-class"" results in terms of calling variants, for my purposes it generally just creates headaches since it makes interpreting (certain) calls and verifying (certain) base-level behaviors/expectations very difficult (even when looking at the bamout and assembly logs). Moreover, while we know our alignment process isn't perfect, we think it's appropriate for our purposes, and we would gladly accept the loss of a few calls to be able to have more control over the expected behaviors. With that, I purpose a ""--skip-assembly"" flag that would cause the Mutect2/HaplotypeCaller engine to use the original alignment information to determine the haplotypes. . All that said, I imagine this could be a niche feature request, so I've spent some time digging through the source code trying to see if there could be a quick fix that could be made available to whatever group of developers would want this. It seemed like there could be another conditional branched added here (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L159) to build a `resultSet` based on a non-assembly based approach. However, I'm not certain how using the original alignment information would affect the statistics employed for genotyping the candidate haplotypes, so I'm starting to back off implementing a custom fix and hoping the experts can help (or at least explain to me why this feature is not currently possible OR if there is a way that I can access this behavior that I'm missing). Thank you for the consideration. **(TL;DR)**; Introduce a `--skip-assembly` option that would cause the Mutect2/HaplotypeCaller engine to use the original alignm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064:1150,avail,available,1150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064,1,['avail'],['available']
Availability,"rk Version: 2.4.5 ; ; 01:03:32.955 INFO GetPileupSummaries - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 01:03:32.955 INFO GetPileupSummaries - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SA MTOOLS : false ; ; 01:03:32.955 INFO GetPileupSummaries - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_S AMTOOLS : true ; ; 01:03:32.956 INFO GetPileupSummaries - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_T RIBBLE : false ; ; 01:03:32.956 INFO GetPileupSummaries - Deflater: IntelDeflater ; ; 01:03:32.956 INFO GetPileupSummaries - Inflater: IntelInflater ; ; 01:03:32.956 INFO GetPileupSummaries - GCS max retries/reopens: 20 ; ; 01:03:32.956 INFO GetPileupSummaries - Requester pays: disabled ; ; 01:03:32.956 INFO GetPileupSummaries - Initializing engine ; ; 01:03:33.330 INFO FeatureManager - Using codec VCFCodec to read file file:///ga tk/my\_data/wgs\_processing\_facilitating\_data/hg38\_to\_hg19/lifted\_small\_exac\_commo n\_3.hg19.vcf.gz ; ; 01:03:33.395 INFO GetPileupSummaries - Shutting down engine ; ; \[September 12, 2021 1:03:33 AM GMT\] org.broadinstitute.hellbender.tools.walkers. contamination.GetPileupSummaries done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=462946304 ; ; java.lang.IllegalArgumentException: Dictionary cannot have size zero ; ; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798) ; ; at org.broadinstitute.hellbender.utils.MRUCachingSAMSequenceDictionary.< init>(MRUCachingSAMSequenceDictionary.java:35) ; ; at org.broadinstitute.hellbender.utils.GenomeLocParser.<init>(GenomeLocP arser.java:78) ; ; at org.broadinstitute.hellbender.utils.GenomeLocParser.<init>(GenomeLocP arser.java:62) ; ; at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArg umentCollection.getTraversalParameters(IntervalArgumentCollection.java:180) ; ; at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArg umentCollection.getIntervals(IntervalArgumentCollection.java:111) ; ; at org.broadinstitute.hellbender.engine.GATKTool.i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7479:4684,down,down,4684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7479,1,['down'],['down']
Availability,rk.SparkSharder.shard(SparkSharder.java:108); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:127); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:154); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:56); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [654b5b8e01de4c60bd87d941d4ec8831] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:13806,ERROR,ERROR,13806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,2,['ERROR'],['ERROR']
Availability,"rk.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5744,ERROR,ERROR,5744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['ERROR'],['ERROR']
Availability,"rk/bwa/BwaSpark.java#L47) launches `BwaSparkEngine` as follows:. ```; final BwaSparkEngine engine = new BwaSparkEngine(bwaArgs.numThreads, bwaArgs.fixedChunkSize, referenceFileName);; ```. and launches the alignment as follows:. ```; final JavaRDD<GATKRead> reads = engine.alignWithBWA(ctx, unalignedReads, readsHeader);; ```. That in turn calls the `align()` method within [BwaSparkEngine.java](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L72):. ```; final JavaRDD<String> samLines = align(shortReadPairs);; ```. which then instantiates a new [BwaMem](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L101) object:. ```; final BwaMem mem = new BwaMem(index);; ```. Since the BWA implementation at [lindenb/jbwa](https://github.com/lindenb/jbwa) is basically a direct call to Heng's BWA as a library, the BWA option for verbosity is set by the `-v` argument as noted [here](http://bio-bwa.sourceforge.net/bwa.shtml#3):. ```; -v INT Control the verbose level of the output. This option has not been fully supported ; throughout BWA. Ideally, a value 0 for disabling all the output to stderr; 1 for ; outputting errors only; 2 for warnings and errors; 3 for all normal messages; 4 or ; higher for debugging. When this option takes value 4, the output is not SAM. [3] ; ```. This is used in Heng's [bwamem.c](https://github.com/lh3/bwa/blob/5961611c358e480110793bbf241523a3cfac049b/bwamem.c#L1224-L1226) file - and several other places - which generates the printout you see, as follows:. ```; if (bwa_verbose >= 3); fprintf(stderr, ""[M::%s] Processed %d reads in %.3f CPU sec, %.3f real sec\n"", __func__, n, cputime() - ctime, realtime() - rtime);; }; ```. So I would just adjust the verbosity via the arguments to the level that is preferable. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398:1571,error,errors,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398,2,['error'],['errors']
Availability,rker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:3565,ERROR,ERROR,3565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,rker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.FailureHandlingDispatch.dispatch(FailureHandlingDispatch.java:29); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.dispatchMessages(AsyncDispatch.java:132); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.access$000(AsyncDispatch.java:33); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch$1.run(AsyncDispatch.java:72); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 2 more,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:15039,ERROR,ERROR,15039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,8,"['ERROR', 'Failure']","['ERROR', 'FailureHandlingDispatch']"
Availability,"rkflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced with an older version of GATK. ; ; Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. ; ; There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. Another question is related to the fasta file:. I downloaded the reference data in the link of [https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37](https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37)¬†, when I noticed that this is an old database, I have already generated GVCF files. It seems like GenotypeGVCFs does not understand the FAI index file. error informaion; ================. \[E::fai\_read\] Could not understand FAI /home/users/nus/bizszl/scratch/WES-new/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta.fai line 1 ; ; \[E::fai\_load3\] Failed to read FASTA index /home/users/nus/bizszl/scratch/WES-new/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta.fai. FAI file; ========. 1 dna:chromosome chromosome:GRCh37:1:1:249250621:1 249250621 52 60 61 ; ; 2 dna:chromosome chromosome:GRCh37:2:1:243199373:1 243199373 253404903 60 61 ; ; 3 dna:chromosome chromosome:GRCh37:3:1:198022430:1 198022430 500657651 60 61 ; ; 4 dna:chromosome chromosome:GRCh37:4:1:191154276:1 191154276 701980507 60 61 ; ; 5 dna:chromosome chromosome:GRCh37:5:1:180915260:1 180915260 896320740 60 61. If I use the latest fasta data provided by the GATK team [https://console.cloud.google.com/storage/browser/gcp-public-data--broad-references/hg19/v0;tab=objects?prefix=&forceOnObjectsSortingFiltering=false](https://console.cloud.google.com/storage/browser/gcp-public-data--broad-re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:6903,error,error,6903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['error'],['error']
Availability,rnal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:8430,ERROR,ERROR,8430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,roadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:451); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:439); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:775); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [91a5d7391a4647a89e50717b96eb50e0] entered state [ERROR] while waiting for [DONE]. ```. #### Steps to reproduce; Run a tool in the following way. ```; gatk ToolNameSpark \; -I hdfs://path/to/bam/test.bam \; -L hdfs://path/to/interval/file/interval.bed \; -O hdfs://path/to/output \; ....; ```. #### Expected behavior; Intervals to be parsed correctly. #### Actual behavior; Engine tries to interpret the file name as an actual interval.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4852:3127,ERROR,ERROR,3127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4852,2,['ERROR'],['ERROR']
Availability,roadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); srun: error: her2-w110: task 0: Exited with exit code 3. #### Steps to reproduce. cd /software/gatk-4.1.9.0. srun ./gatk FilterMutectCalls -R /CECI/proj/iribhm/tc_phylogeny/genome/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta -V /workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S5_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T4_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:5584,error,error,5584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['error'],['error']
Availability,"roazen/google-cloud-java/tree/dr_all_nio_fixes. 18:58:01.494 INFO HaplotypeCaller - Initializing engine. 18:58:02.043 INFO HaplotypeCaller - Done initializing engine. 18:58:02.053 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output. 18:58:02.053 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output. 18:58:02.886 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/bigdata/operations/pkgadmin/opt/linux/centos/7.x/x86_64/pkgs/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar!/com/intel/gkl/native/libgkl_utils.so. 18:58:02.888 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/bigdata/operations/pkgadmin/opt/linux/centos/7.x/x86_64/pkgs/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so. 18:58:02.932 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM. 18:58:02.933 INFO IntelPairHmm - Available threads: 8. 18:58:02.933 INFO IntelPairHmm - Requested threads: 4. 18:58:02.933 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. 18:58:02.986 INFO ProgressMeter - Starting traversal. 18:58:02.987 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute. 18:58:12.992 INFO ProgressMeter - chr1:6969901 0.2 23290 139712.1. 18:58:22.989 INFO ProgressMeter - chr1:13470130 0.3 44960 134866.5. 18:58:32.991 INFO ProgressMeter - chr1:21393130 0.5 71370 142721.0. INFO 18:58:37,986 HelpFormatter - ---------------------------------------------------------------------------------- . INFO 18:58:37,989 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.8-0-ge9d806836, Compiled 2017/07/28 21:26:50 . INFO 18:58:37,989 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute . INFO 18:58:37,989 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk . INFO 18:58:37,989 HelpFormatt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4788:3938,Avail,Available,3938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4788,1,['Avail'],['Available']
Availability,"rocess still running with top. Do you know what could be causing the problem ? Could it be related to -ERC BP_RESOLUTION ? I used to use -ERC GVCF before but I would rather keep the information of the coverage for post filtering, and I am not sure how to use --GVCFGQBands to match my criteria for coverage filtering. Thanks a lot for your help !. Edit: sorry with the latest version of gatk I get a new message error :; ```; 08:22:54.446 INFO ProgressMeter - NC_016854.1:20000 0.2 20000 87450.8; 08:23:04.942 INFO ProgressMeter - NC_016854.1:58000 0.4 58000 143694.8; 08:25:25.155 INFO ProgressMeter - NC_016854.1:82000 2.7 82000 29921.4; 08:25:35.161 INFO ProgressMeter - NC_016854.1:100000 2.9 100000 34396.6; 08:28:02.395 INFO ProgressMeter - NC_016854.1:102000 5.4 102000 19025.7; 08:28:13.248 INFO ProgressMeter - NC_016854.1:140000 5.5 140000 25261.3; 08:28:24.027 INFO ProgressMeter - NC_016854.1:175000 5.7 175000 30585.2; 08:46:13.574 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),29.232685148998623,Cpu time(s),29.09919726900138; [February 28, 2018 8:46:13 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 23.59 minutes.; Runtime.totalMemory()=5588910080; Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator$CombinedPoolLikelihoods.getLikelihoodOfConformation(GeneralPloidyExactAFCalculator.java:61); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.computeLofK(GeneralPloidyExactAFCalculator.java:283); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.calculateACConformationAndUpdateQueue(GeneralPloidyExactAFCalculator.java:187); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.fastCombineMultiallelicPool(GeneralPl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:2701,down,down,2701,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['down'],['down']
Availability,rocessing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dan,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:10072,Recover,Recovered,10072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"rogram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: java.net.UnknownHostException: cngb-nas-f17-1: cngb-nas-f17-1: Name or service not known; 	at java.base/java.net.InetAddress.getLocalHost(InetAddress.java:1631); 	at org.apache.spark.util.Utils$.findLocalInetAddress(Utils.scala:891); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress$lzycompute(Utils.scala:884); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress(Utils.scala:884); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.util.Utils$.localHostName(Utils.scala:941); 	at org.apache.spark.internal.config.package$.<init>(package.scala:204); 	at org.apache.spark.internal.config.package$.<clinit>(package.scala); 	... 12 more; Caused by: java.net.UnknownHostException: cngb-nas-f17-1: Name or service not known; 	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method); 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:924); 	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1504); 	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:843); 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1494); 	at java.base/java.net.InetAddress.getLocalHost(InetAddress.java:1626); 	... 21 more; ```. #### Steps to reproduce; On a Linux machine without _Hadoop_, run `java -jar ../gatk-package-4.1.0.0-local.jar CreateReadCountPanelOfNormals --input in.counts.hdf5 --output out.pon.hdf5` locally. #### Expected behavior; Produce *out.pon.hdf5*. #### Actual behavior; Exit with error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:5263,error,error,5263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['error'],['error']
Availability,"rogram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the database for these chromosomes (still using the same scripts as other chromosomes where variant calling was successful) to see if perhaps something went wrong during the initial database creation. I still received this error when I was trying to call variants. ; What is most confusing to me is that this issue isn't happening for every chromosome, just the first 3. Any advice to get over this hump is greatly appreciated, and let me know if there is more information you need to help trouble shoot. . Thanks, ; Caitlin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:6402,error,error,6402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['error'],['error']
Availability,"rogram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:107); at org.broadinstitute.hellbender.tools.HaplotypeCallerSparkIntegrationTest.testNonStrictVCFModeIsConsistentWithPastResults(HaplotypeCallerSparkIntegrationTest.java:109); Caused by:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; at java.util.ArrayList.sort(ArrayList.java:1464); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerReadThreadingAssemblerArgumentCollection.makeReadThreadingAssembler(HaplotypeCallerReadThreadingAssemblerArgumentCollection.java:37); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerArgumentCollection.createReadThreadingAssembler(AssemblyBasedCallerArgumentCollection.java:36); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.initialize(HaplotypeCallerEngine.java:231); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.<init>(HaplotypeCallerEng",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:4382,failure,failure,4382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['failure'],['failure']
Availability,"root@ab23aa1f82e3 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 20, 2017 2:22:06 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 3.65 minutes.; Runtime.totalMemory()=4188012544; htsjdk.samtools.SAMFormatException: Did not inflate expected amount; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:537); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:519); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:3939,avail,available,3939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['avail'],['available']
Availability,rovider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:9688,ERROR,ERROR,9688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,rovider; hdfs.jsr203.HadoopFileSystemProvider; ```. So it looks like the service loader file is being created correctly. I tried to reproduce on GCS by running (essentially the same as @vdauwera's command.). ```; time ./gatk-launch ApplyBQSRSpark \; -I gs://hellbender/test/resources/benchmark/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R gs://gatk-legacy-bundles/b37/human_g1k_v37.2bit \; -O gs://gatk-demo-tom/TEST/gatk4-spark/recalibrated.bam \; -bqsr gs://gatk-demo/TEST/gatk4-spark/recalibration.table \; -apiKey $GOOGLE_APPLICATION_CREDENTIALS \; -- \; --sparkRunner GCS \; --cluster cluster-tom \; --num-executors 40 \; --executor-cores 4 \; --executor-memory 10g; ```. But I got another error earlier on. Any ideas what this could be? (I can see the input bam with `gsutil cp`). ```; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://hellbender/test/resources/benchmark/CEUTrio.HiSeq.WEx.b37.NA12892.bam; Caused by:Error reading null at position 0; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:376); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:357); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:347); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676:1152,Error,Error,1152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676,1,['Error'],['Error']
Availability,"rox=|851|0|0;AS_RAW_BaseQRankSum=|||;AS_RAW_MQ=0.00|12289.00|0.00|0.00;AS_RAW_MQRankSum=|||;AS_RAW_ReadPosRankSum=|||;AS_SB_TABLE=0,0|1,4|0,0|0,0;AS_VarDP=0|26|1|0;DP=49;QUALapprox=853;RAW_GT_COUNT=0,0,1;RAW_MQandDP=144241,49;VarDP=27	GT:AD:DP:GQ:PL:SB	1/2:0,26,1,0:27:2:853,2,347,878,0,989,875,282,907,1161:0,0,1,4; ```. When merged into a GenomicsDB, they give an empty element in the allele-specific array fields such as `AS_RAW_MQ` and `AS_SB_TABLE`:. ```; chr7 2377548 . A G,*,<NON_REF> . . AS_QUALapprox=|338|0|0;AS_RAW_BaseQRankSum=|1.000,1||;AS_RAW_MQ=35536.000|25290.000||0.000;AS_RAW_MQRankSum=|-0.800,1||;AS_RAW_ReadPosRankSum=|-2.300,1||;AS_SB_TABLE=3,7|0,8||0,0;AS_VarDP=10|10|0|0;BaseQRankSum=1.006;DP=71;MQRankSum=-0.752;QUALapprox=338;RAW_GT_COUNT=0,1,0;RAW_MQandDP=72828,22;ReadPosRankSum=-2.285;VarDP=20 GT:AD:GQ:PL:SB:D; P ./.:10,10,0,0:99:338,0,387,341,416,762,341,416,762,762:3,7,0,8:20 ./.:0,0,26,0:2:853,875,1161,2,282,347,875,1161,282,1161:0,0,1,4:27; ```. Which leads to a GnarlyGenotyper error:. ```; gatk GnarlyGenotyper -R Homo_sapiens_assembly38.fasta -O gnarlied.vcf.gz --only-output-calls-starting-in-intervals --keep-all-sites -V gendb.gs://mybucket/genomicsdbs/interval_20_outof_50 -L 0020-scattered.interval_list; <...>; java.lang.IllegalStateException: Something went wrong:; 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:147); 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:78); 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:298); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(Re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7483:2147,error,error,2147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7483,1,['error'],['error']
Availability,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:2674,avail,available,2674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,3,"['avail', 'error']","['available', 'error']"
Availability,"rrupting monitor thread; 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-05-19 19:09:41 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-05-19 19:09:41 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-19 19:09:41 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-19 19:09:41 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-19 19:09:41 INFO BlockManager:54 - BlockManager stopped; 2019-05-19 19:09:41 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-19 19:09:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-19 19:09:41 INFO SparkContext:54 - Successfully stopped SparkContext; 19:09:41.578 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 19, 2019 7:09:41 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 44.89 minutes.; Runtime.totalMemory()=21646802944; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam; at htsjdk.samtools.SAMFileWriterFactory.makeSAMWriter(SAMFileWriterFactory.java:356); at htsjdk.samtools.SAMFileWriterFactory.makeSAMOrBAMWriter(SAMFileWriterFactory.java:437); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVFileUtils.writeSAMFile(SVFileUtils.java:29); at org.broadinstitute.hellbender.tools.spark.sv.evidence.AlignedAssemblyOrExcuse.writeAssemblySAMFile(AlignedAssemblyOrExcuse.java:336); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:199); at org.broadinst",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:4541,down,down,4541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,2,['down'],['down']
Availability,"rs specific to PGEN extract. ### Large scale testing; All of my testing (with the exception of some very small scale stuff early on) has been done in the [GVS_AoU_PGEN_Extract_Development Terra workspace](https://app.terra.bio/#workspaces/allofus-drc-prod-auxiliary/GVS_AoU_PGEN_Extract_Development) and using data from the GVS Delta callset (aou-genomics-curation-prod.aou_wgs_fullref_v2). My test process (for the majority of tests) has been as follows:. 1. Select a list of sample names from aou_wgs_fullref_v2.sample_info (excluding control samples and sample 3224672 because of the data issue mentioned [here](https://broadinstitute.slack.com/archives/CJRLP6ZSA/p1699026273329339)).; 2. Use that list as an input to GvsPrepareRangesCallset to create a cohort of test data in a separate BigQuery dataset (aou-genomics-curation-prod.klydon_pgen_extract_test).; 3. Run GvsExtractCallsetPgen on the newly created cohort. (I would just run GvsExtractCallsetPgenMerged, but I like using Workflow Dashboard to monitor how the job is going and dig into it if there are any failures. Workflow Dashboard doesn't seem to let you dig into individual tasks for workflows with sub-workflows, so it wouldn't allow me to look at individual shards running ExtractTask if I ran GvsExtractCallsetPgenMerged. Job Manager would be an alternative for this, but it seems to be pretty much unusable for even moderately-sized jobs.); 4. Run GvsExtractCallset on the newly created cohort, making sure to use the same parameters, including scatter count. This will generate VCF files that we can use to compare to the PGEN files created during the previous step for validation.; 5. Run GvsExtractCallsetPgenMerged with the same parameters used to run GvsExtractCallsetPgen in Step 3. This will use call-caching for the extract steps and then merge the PGEN files by chromosome. (Running it this way is maybe not the ideal way to do this, but it's what I've been doing for reasons described in the parenthetical in Step 3).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:10454,failure,failures,10454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['failure'],['failures']
Availability,rs/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: packag,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:8282,error,error,8282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,rs/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: packag,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:10320,error,error,10320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"rsed the test log and found the relevant part (for ID `685190392835`). ```; ""gce"":{. ""instance"":{; ""attributes"":{; ""startup-script"":""#!/usr/bin/env bash\necho poweroff | at now + 130 minutes\ncat > ~travis/.ssh/authorized_keys <<EOF\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDdzVnIEg2ribEvhEvFjR9IFPAkIVtQwZhlgUAHu1BgjBugFRiqg3eaPMOeOuIZBvzwoyotHIVp3XvAfivGyCW4Ke7+2cqlcX1L8kcmoWLm2fdLGlLr/lZnAjQtexMC76uLtR8udqWA0e2sqrSJs4H/blOQmHWPrl/VSG7daoVptzqXihRmXN+/Huo7mTxAjTUEjk4IOBn7sv7G5qLrEPv78AJIZhWHdhUTGLvx+YpzQvX8pE53TMi9W4ovkZTCwhSO3WYyBOY7H1xjeYb9XWTeP563Du1b0JMpQgtFLQUVXio9NzXZE55ovvGDRSLds+VfPsv4G/Whhq76dEZ+wZO3\n\nEOF\n""; },; ""cpuPlatform"":""Intel Haswell"",; ""description"":""Travis CI python test VM"",; ""disks"":[{""deviceName"":""persistent-disk-0"",""index"":0,""mode"":""READ_WRITE"",""type"":""PERSISTENT""}],; ""hostname"":""testing-gce-ec8614d2-40a2-4138-801e-d42d811590a2.c.travis-ci-prod-2.internal"",; ""id"":8221730359445041428,; ""image"":"""",; ""licenses"":[{""id"":""1000010""}],; ""machineType"":""projects/685190392835/machineTypes/n1-standard-2"",; ""maintenanceEvent"":""NONE"",; ""networkInterfaces"":[{""accessConfigs"":[{""externalIp"":""104.198.203.242"",""type"":""ONE_TO_ONE_NAT""}],""forwardedIps"":[],""ip"":""10.128.0.163"",""network"":""projects/685190392835/networks/default""}],; ""scheduling"":{""automaticRestart"":""TRUE"",""onHostMaintenance"":""MIGRATE"",""preemptible"":""FALSE""},; ""serviceAccounts"":{; ""685190392835-compute@developer.gserviceaccount.com"":{; ""aliases"":[""default""],; ""email"":""685190392835-compute@developer.gserviceaccount.com"",; ""scopes"":[""https://www.googleapis.com/auth/userinfo.email"",; ""https://www.googleapis.com/auth/devstorage.full_control"",; ""https://www.googleapis.com/auth/compute""]; },; ""default"":{; ""aliases"":[""default""],; ""email"":""685190392835-compute@developer.gserviceaccount.com"",; ""scopes"":[""https://www.googleapis.com/auth/userinfo.email"",; ""https://www.googleapis.com/auth/devstorage.full_control"",; ""https://www.googleapis.com/auth/compute""]}; },; ""tags"":[""testing""],; ""virtualClock"":{""driftToken"":""1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-513242018:1576,mainten,maintenanceEvent,1576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-513242018,1,['mainten'],['maintenanceEvent']
Availability,"rsion: 2.17.2; 00:17:06.848 INFO IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:06.850 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:06.850 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:17:06.855 INFO IndexFeatureFile - Inflater: IntelInflater; 00:17:06.856 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:17:06.858 INFO IndexFeatureFile - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 00:17:06.859 INFO IndexFeatureFile - Initializing engine; 00:17:06.860 INFO IndexFeatureFile - Done initializing engine; 00:17:07.292 INFO FeatureManager - Using codec VCFCodec to read file file://bad.vcf; 00:17:07.310 INFO IndexFeatureFile - Shutting down engine; [January 26, 2018 12:17:07 AM GMT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=512229376; java.lang.IllegalStateException: the progress meter has not been started yet; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.engine.ProgressMeter.stop(ProgressMeter.java:230); at org.broadinstitute.hellbender.utils.codecs.ProgressReportingDelegatingCodec.isDone(ProgressReportingDelegatingCodec.java:104); at htsjdk.tribble.index.IndexFactory$FeatureIterator.readNextFeature(IndexFactory.java:522); at htsjdk.tribble.index.IndexFactory$FeatureIterator.<init>(IndexFactory.java:440); at htsjdk.tribble.index.IndexFactory.createDynamicIndex(IndexFactory.java:326); at org.broadinstitute.hellbender.tools.IndexFeatureFile.createAppropriateIndexInMemory(IndexFeatureFile.java:122); at org.broadinstitute.hellbender.tools.IndexFeatureFile.doWork(IndexFeatureFile.java:71); at org.broadin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:2676,down,down,2676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['down'],['down']
Availability,"rsion: 2.17.2; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:29:01.393 INFO GenomicsDBImport - Deflater: IntelDeflater; 19:29:01.393 INFO GenomicsDBImport - Inflater: IntelInflater; 19:29:01.393 INFO GenomicsDBImport - GCS max retries/reopens: 20; 19:29:01.393 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:29:01.393 INFO GenomicsDBImport - Initializing engine; 19:29:23.214 INFO IntervalArgumentCollection - Processing 1000000 bp from intervals; 19:29:23.216 INFO GenomicsDBImport - Done initializing engine; 19:29:23.332 INFO GenomicsDBImport - Shutting down engine; [January 10, 2018 7:29:23 PST PM] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=2804940800; Exception in thread ""main"" java.lang.ExceptionInInitializerError; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteOrCreateWorkspace(GenomicsDBImport.java:706); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:448); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:891); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124:2247,down,down,2247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124,1,['down'],['down']
Availability,"rsion: 2.24.1; 19:10:31.439 INFO CalculateContamination - Picard Version: 2.25.4; 19:10:31.439 INFO CalculateContamination - Built for Spark Version: 2.4.5; 19:10:31.439 INFO CalculateContamination - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:10:31.439 INFO CalculateContamination - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:10:31.439 INFO CalculateContamination - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:10:31.439 INFO CalculateContamination - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:10:31.439 INFO CalculateContamination - Deflater: IntelDeflater; 19:10:31.439 INFO CalculateContamination - Inflater: IntelInflater; 19:10:31.439 INFO CalculateContamination - GCS max retries/reopens: 20; 19:10:31.439 INFO CalculateContamination - Requester pays: disabled; 19:10:31.439 INFO CalculateContamination - Initializing engine; 19:10:31.439 INFO CalculateContamination - Done initializing engine; 19:10:31.451 INFO CalculateContamination - Shutting down engine; [March 6, 2022 7:10:31 PM CST] org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: there is no such column: contig; 	at org.broadinstitute.hellbender.utils.tsv.DataLine.columnIndex(DataLine.java:483); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:452); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:581); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:193); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:188); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.fetchNextRecord(TableReader.java:364); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.access$200(TableReader.java:99); 	at org.broadinstitute.hellbender.utils",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707:3063,down,down,3063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707,1,['down'],['down']
Availability,"rstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5749,ERROR,ERROR,5749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"rt**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----; I am getting error while implementing docker images of GATK4 into variant calling workflow. As I connect the images into the WDL script, it first time run properly but as a streamlined input for next step the previous output is not visible...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5906:2292,error,error,2292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5906,1,['error'],['error']
Availability,"rted o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-pa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9004,AVAIL,AVAILABLE,9004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,rter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:6606,ERROR,ERROR,6606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"run this. ```; ./gatk-launch CountReads -I fred; ```. and get this. ```; ***********************************************************************; A USER ERROR has occurred: Couldn't read file /Users/akiezun/IdeaProjects/gatk/fred. Error was: Cannot read non-existent file: /Users/akiezun/IdeaProjects/gatk/fred. ***********************************************************************; Exception in thread ""main"" java.lang.NullPointerException; at org.broadinstitute.hellbender.Main.main(Main.java:93); ```. this is bogus - I don't want any NPEs here",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1598:153,ERROR,ERROR,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1598,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"run(Thread.java:745). Container exited with a non-zero exit code 1. 18/01/09 18:31:21 INFO storage.BlockManagerMaster: Removal of executor 9 requested; 18/01/09 18:31:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 9; 18/01/09 18:31:21 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 0.89 minutes.; Runtime.totalM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:30274,down,down,30274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['down'],['down']
Availability,"rvletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9533,AVAIL,AVAILABLE,9533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"ry for the especially large size on this PR. **PathSeqBuildKmers tool**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently well; - Sequence duplicates are removed. Other:; -Fixed bugginess in very large LongBloomFilters by changing a size variable f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:1187,mask,mask,1187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['mask'],['mask']
Availability,ry$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3308,ERROR,ERROR,3308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,ryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 21/04/13 07:32:24 ERROR SparkHadoopWriter: Task attempt_20210413073224_0026_r_000000_0 aborted.; 21/04/13 07:32:24 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 105); org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:5388,ERROR,ERROR,5388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['ERROR'],['ERROR']
Availability,"s - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:13:30.506 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:13:30.506 INFO FilterMutectCalls - Deflater: IntelDeflater; 17:13:30.506 INFO FilterMutectCalls - Inflater: IntelInflater; 17:13:30.506 INFO FilterMutectCalls - GCS max retries/reopens: 20; 17:13:30.506 INFO FilterMutectCalls - Requester pays: disabled; 17:13:30.506 INFO FilterMutectCalls - Initializing engine; 17:13:30.997 INFO FeatureManager - Using codec VCFCodec to read file file:///data-ddn/home/anthony/sbx/mutect2/work/ea/18e314102728d4b34b636b04f1f897/her2-crefix-unfiltered.vcf; 17:13:31.136 INFO FilterMutectCalls - Done initializing engine; 17:13:31.285 INFO ProgressMeter - Starting traversal; 17:13:31.286 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:13:31.286 INFO FilterMutectCalls - Starting first pass through the variants; 17:13:31.570 INFO FilterMutectCalls - Shutting down engine; [February 17, 2019 5:13:31 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=845676544; java.lang.NumberFormatException: For input string: "".""; 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Integer.parseInt(Integer.java:569); 	at java.lang.Integer.valueOf(Integer.java:766); 	at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:287); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Collections$2.tryAdvance(Collections.java:4717); 	at java.util.Collections$2.forEachRemaining(Collections.java:4725); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:2824,down,down,2824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['down'],['down']
Availability,"s - Inflater: IntelInflater; 14:21:35.554 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 14:21:35.555 INFO PostprocessGermlineCNVCalls - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:21:35.556 WARN PostprocessGermlineCNVCalls -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PostprocessGermlineCNVCalls is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:21:35.557 INFO PostprocessGermlineCNVCalls - Initializing engine; 14:21:35.976 INFO FeatureManager - Using codec BEDCodec to read file file:///bettik/tintest/NTM/bam/1-3-9-17-Y-M/Refseq_GrCh38_1-3-9-17-Y-M.bed; 14:21:36.034 INFO IntervalArgumentCollection - Processing 251589470 bp from intervals; 14:21:38.716 INFO PostprocessGermlineCNVCalls - Done initializing engine; 14:21:38.879 INFO PostprocessGermlineCNVCalls - Shutting down engine; [August 1, 2018 2:21:38 PM CEST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2267545600; java.lang.IllegalArgumentException: The specified allosomal contigs must be contained in the SAM sequence dictionary of the call-set (specified allosomal contigs: [Y], all contigs: [chr9, chr7, chr8, chr5, chr6, chr3, chr21, chr4, chr22, chr1, chr2, chr20, chrY, chrX, chr10, chr11, chr12, chr13, chrM, chr18, chr19, chr14, chr15, chr16, chr17]); at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722); at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:277); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:992); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231:4651,down,down,4651,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231,1,['down'],['down']
Availability,"s are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be available, as it is in this workflow (tumor-only would require some work to identify the normal state, as mentioned previously). I'd rather just roll that, evaluate it, and merge it instead. Key here is that we sidestep the deficiencies of the current CR-only caller, which also shares the blame for this ""CNLOH"" issue (since these events aren't called in the normal and don't become candidates for tagging, as currently implemented). > And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me. I've already expanded the scope of https://github.com/broadinstitute/gatk/issues/4115 to include this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:3807,avail,available,3807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['avail'],['available']
Availability,"s fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits before we start the first review cycle:. 1. A single commit containing the unmodified GATK3 source (unmodified with the exception that if a file is renamed for GATK4, its helpful to rename the GATK3 version in this commit so it's easy to compare in the next commit). This commit doesn't have to compile or run - its just to make the review process easier for us, and will be deleted at some point. I can help with how to get this into your branch if you like.; 2. Your modified GATK3 tests in a single commit. This will also be removed before merge.; 3. A single commit with all of your ""minimal"" changes for the port, including the real, new tests. This should compile, and tests should pass on CI with pretty high code coverage. This is what we'll iterate on. After that, its really helpful to have only a single new commit for each review iteration (you can create as many commits as you want as you work, but squash the new commits down before submitting). Just don't squash or rebase anything thats already been pushed up to the repo. Also, note that most of the GATK engine team is out for a few weeks, so progress may be slow in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:3156,down,down,3156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['down'],['down']
Availability,"s must have called genotypes; 09:01:33.373 WARN DepthPerSampleHC - Annotation will not be calculated at position 1A:1702502 and possibly subsequent; genotype for sample SRR9851087 is not called; 09:01:33.374 WARN StrandBiasBySample - Annotation will not be calculated at position 1A:1702502 and possibly subsequent; genotype for sample SRR9851087 is not called; 09:01:36.316 INFO ProgressMeter - 1A:2054431 0.2 7310 43025.3; 09:01:46.831 INFO ProgressMeter - 1A:3580946 0.3 12960 37547.1; 09:01:56.858 INFO ProgressMeter - 1A:4888859 0.5 17840 34824.5; 09:02:07.416 INFO ProgressMeter - 1A:7184455 0.7 26090 37907.7; 09:02:17.850 INFO ProgressMeter - 1A:9469826 0.9 34580 40109.0; 09:02:28.162 INFO ProgressMeter - 1A:11632942 1.0 42480 41082.5; 09:02:38.391 INFO ProgressMeter - 1A:12861813 1.2 47220 39203.0; 09:02:48.460 INFO ProgressMeter - 1A:15373965 1.4 56590 41236.8. 09:20:43.520 INFO ProgressMeter - 1A:536836177 19.3 1951140 101147.8; 09:20:44.715 INFO HaplotypeCaller - Shutting down engine; [February 8, 2023 at 9:20:44 AM CST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 19.31 minutes.; Runtime.totalMemory()=1811939328; java.lang.ArrayIndexOutOfBoundsException: Index 32770 out of bounds for length 32770; at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:142); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:233); at org.broadinstitute.hellbender.utils.variant.writers.GVCFWriter.close(GVCFWriter.java:71); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.closeTool(HaplotypeCaller.java:277); at org.broadinstitute.hellbender.engine.GATKTool.doWork(G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192:5479,down,down,5479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192,1,['down'],['down']
Availability,"s on the versions tested. This does not occur with version 4.1.4.1 where the program manages to process and output the entire VCF. Upon further testing, it seems that the FORMAT field AF causes the problem as removing it from the following test record solves the problem:. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:AF:DP	1/2:0,5,5:0.500,0.500:10; ```. vs. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:DP	1/2:0,5,5:10; ```. The output for GATK 4.1.4.1 or when the AF field is removed looks like this:; ```; chr1	10027	.	A	C	.	PASS	.	GT:AD:DP	./.:0,5:10; chr1	10027	.	A	G	.	PASS	.	GT:AD:DP	./.:0,5:10; ```. #### Steps to reproduce; ```; $gatk/gatk LeftAlignAndTrimVariants -R $reference --split-multi-allelics -V test.input.vcf -O test.output.vcf; ```. #### Expected behavior; LeftAlignAndTrimVariants should be able to split multiallelic records in a VCF to two separate records as in GATK version 4.1.4.1. The AF field is removed from the 4.1.4.1 output, however. #### Actual behavior; GATK fails at a multiallelic record with the following error (GATK 4.2.0.0):; ```; java.lang.IllegalArgumentException: the range size cannot be negative; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:107); 	at org.broadinstitute.hellbender.utils.IndexRange.<init>(IndexRange.java:67); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitASSBTable(GATKVariantContextUtils.java:1533); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitSomaticVariantContextToBiallelics(GATKVariantContextUtils.java:1501); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants.apply(LeftAlignAndTrimVariants.java:225); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferenceP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7211:1318,error,error,1318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7211,1,['error'],['error']
Availability,s specifically from the GCS access in `CloudStorageReadChannel.fetchSize()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:234); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:78); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:68); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:304); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:265); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at htsjdk.samtools.seekablestream.SeekablePathStream.<init>(SeekablePathStream.java:41); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:101); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:270). [2:58] ; From stdout:. [2:58] ; 15:55:58.059 INFO GenomicsDBImport - Done importing batch 19/444; 15:56:21.780 INFO GenomicsDBImport - Shutting down engine; code: 503; message: 503 Service Unavailable; reason: null; location: null; retryable: false; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:2188,down,down,2188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,1,['down'],['down']
Availability,"s the available number of bins to represent the variations in the CDF in the most accurate way. Here's what I had written earlier:; ```; def get_counts_summary(counts, lo_cutoff=0.01, hi_cutoff=0.99, num_divisions=50):; sorted_counts = np.sort(counts); num_points = len(counts); lo_index = int(np.floor(lo_cutoff * num_points)); hi_index = min(int(np.ceil(hi_cutoff * num_points)), num_points - 1); lo_count = sorted_counts[lo_index]; hi_count = sorted_counts[hi_index]; abscissa_indices = np.round(np.linspace(lo_index, hi_index, num=num_divisions + 1)).astype(int); abscissa = np.asarray([sorted_counts[idx] for idx in abscissa_indices]); abscissa_counts = abscissa_indices[1:] - abscissa_indices[0:-1]; collapsed_abscissa, collapsed_abscissa_counts = collapse_abscissa_triplets(abscissa, abscissa_counts); return collapsed_abscissa, collapsed_abscissa_counts. def collapse_abscissa_triplets(abscissa, abscissa_counts):; if len(abscissa) < 3:; return abscissa, abscissa_counts; else:; pos = 0; collapsed_abscissa = [abscissa[pos]]; collapsed_abscissa_counts = []; while pos < len(abscissa) - 1:; first = abscissa[pos]; last = abscissa[pos + 1]; count = abscissa_counts[pos]; if first != last:; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += 1; else:; j = 1; while pos + j + 1 < len(abscissa):; if abscissa[pos + j + 1] == last:; count += abscissa_counts[pos + j]; j += 1; else:; break; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += j; return np.asarray(collapsed_abscissa), np.asarray(collapsed_abscissa_counts); ```; Here, `get_counts_summary` returns a tuple of `(abscissa, occurrences)`. The summary is interpreted as follows: there are `occurrences[m]` bins with counts >= `abscissa[m]` and <= `abscissa[m+1]`, for `m = 0, ...`, up to `num_divisions` (but could be smaller if some of the redundant abscissa are collapsed). In the PyMC3 code, we could evaluate the `NegativeBinomial` the the midpoint of `abscissa[m]` and `abscissa[m+1]`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049:1996,redundant,redundant,1996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049,1,['redundant'],['redundant']
Availability,s$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.NumberFormatException: empty String; 	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842); 	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); 	at java.lang.Double.parseDouble(Double.java:538); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_RMSMappingQuality.parseRawDataString(AS_RMSMappingQuality.java:172); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_RMSMappingQuality.finalizeRawData(AS_RMSMappingQuality.java:196); 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:137); 	... 23 more; ```. GenotypeGVCFs throws a similar error but with the `AS_SB_TABLE` field.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7483:5286,error,error,5286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7483,1,['error'],['error']
Availability,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:3948,Down,Downloads,3948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,2,['Down'],['Downloads']
Availability,"s-include-non-variant-sites](https://gatk.broadinstitute.org/hc/en-us/community/posts/6808932798363-Monomorphic-sites-after-GenotypeGVCFs-include-non-variant-sites). \--. Hello,. I am using GATKv4.2.6.1 and GATK best practices. I performed joint genotyping of a multi-sample GVCF with GenotypeGVCFs. Because I am doing a population genetic analysis I am very interested in obtaining high confidence monomorphic sites, so I included the option --include-non-variant-sites. In the output VCF, however, I find that there are 3 types of monomorphic sites, for example:. #CHROM¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† POS¬† ID¬†¬† REF¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† ALT¬†¬† QUAL¬†¬†¬†¬† FILTER. HiC\_scaffold\_493 ¬† ¬†961 ¬† ¬†. ¬† ¬†A ¬† ¬† ¬† ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† . ¬† ¬† ¬† ¬†. ¬† ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† . ; ; HiC\_scaffold\_493 ¬† ¬†962 ¬† ¬†. ¬† ¬†ATCTCCCC ¬† ¬†. ¬† ¬† ¬† ¬†7.65 ¬† ¬†¬†¬†¬† LowQual ; ; HiC\_scaffold\_493 ¬† ¬†963 ¬† ¬†. ¬† ¬†T ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† . ¬† ¬† ¬† ¬†180.56 ¬† ¬†. I am not sure what the differences between those 3 types of monomorphic sites are. I tracked down those positions in the input GVCF and they look like this:. #CHROM¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† ¬† ¬† ¬† POS¬† ID¬†¬†¬†¬† REF¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† ALT¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† QUAL¬†¬†¬†¬† FILTER. HiC\_scaffold\_493 ¬† ¬† ¬† ¬†961 ¬† ¬† . ¬† ¬† ¬† A ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†¬† <NON\\\_REF> ¬† ¬† ¬†¬† . ¬† ¬† ¬†¬†¬†¬†¬†¬† .¬† ; ; HiC\_scaffold\_493 ¬† ¬† ¬† ¬†962 ¬† ¬† . ¬† ¬† ¬† ATCTCCCC ¬† ¬† ¬† A,<NON\\\_REF> ¬† ¬† . ¬† ¬† ¬†¬†¬†¬†¬†¬† . ; ; HiC\_scaffold\_493 ¬† ¬† ¬† ¬†963 ¬† ¬† . ¬† ¬† ¬† T ¬† ¬† ¬† ¬† ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \*,<NON\\\_REF> ¬† ¬† . ¬† ¬† ¬†¬†¬†¬†¬†¬† . I assume that in the GVCF, position 962 had some evidence of the presence of an alternative allele (A) but it was so poor (QUAL < 30) that it was discarded and the position was deemed as monomorphic in the VCF (LowQual). But what about position 963? There was some evidence of a deletion (\*) as alternative allele in the GVCF but it got discarded in the VCF despite QUAL = 180.56?. Also, why does position 961 has no QUAL score at all? In fact, these are results from a small scaffold with 1,000 bp, of which 789 monomorphic sites have no QUAL score at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8030:1183,down,down,1183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8030,1,['down'],['down']
Availability,s.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(Execut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:6411,ERROR,ERROR,6411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,s.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecuto,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:4857,ERROR,ERROR,4857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,s.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.B,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7631,ERROR,ERROR,7631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96; 10:33:09.126 INFO MemoryStore - Block broadcast_1 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:09.142 INFO MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:09.144 INFO BlockManagerInfo - Added broadcast_1_piece0 in me",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47875,AVAIL,AVAILABLE,47875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9408,AVAIL,AVAILABLE,9408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from ne",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47511,AVAIL,AVAILABLE,47511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9148,AVAIL,AVAILABLE,9148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"s.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3474,ERROR,ERROR,3474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,"s.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 07:33:15.362 INFO FilterMutectCalls - Deflater: IntelDeflater. 07:33:15.362 INFO FilterMutectCalls - Inflater: IntelInflater. 07:33:15.363 INFO FilterMutectCalls - GCS max retries/reopens: 20. 07:33:15.363 INFO FilterMutectCalls - Requester pays: disabled. 07:33:15.363 INFO FilterMutectCalls - Initializing engine. 07:33:16.008 INFO FeatureManager - Using codec VCFCodec to read file file:///nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz. 07:33:16.053 INFO IntervalArgumentCollection - Processing 16569 bp from intervals. 07:33:16.059 INFO FilterMutectCalls - Done initializing engine. 07:33:16.157 INFO ProgressMeter - Starting traversal. 07:33:16.157 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. 07:33:16.158 INFO FilterMutectCalls - Starting pass 0 through the variants. 07:33:17.341 INFO FilterMutectCalls - Finished pass 0 through the variants. 07:33:17.404 INFO FilterMutectCalls - Shutting down engine. [September 20, 2020 7:33:17 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:4281,down,down,4281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['down'],['down']
Availability,s.Utils.validateArg(Utils.java:728); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:86); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:48); 	at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); 	at org.broadinstitute.hellbender.transformers.ReadTransformer$$Lambda$107/1786040872.apply(Unknown Source); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.fillDownsampledReadsCache(ReadsDownsamplingIterator.java:69); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.advanceToNextRead(ReadsDownsamplingIterator.java:55); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.<init>(ReadsDownsamplingIterator.java:34); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:149); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:109); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:282); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:993); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:1392,down,downsampling,1392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['down'],['downsampling']
Availability,s; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG ReadThreadingGraph - Recovered 6 of 14 dangling heads; 12:09:10.602 DEBUG Mutect2Engine - Active Region chrM:13637-13936; 12:09:10.608 DEBUG Mutect2Engine - Extended Act Region chrM:13537-14036; 12:09:10.613 DEBUG Mutect2Engine - Ref haplotype coords chrM:13537-14036; 12:09:10.617 DEBUG Mutect2Engine - Haplotype count 128; 12:09:10.621 DEBUG Mutect2Engine - Kmer sizes count 0; 12:09:10.625 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:51.290 DEBUG Mutect2 - Processing assembly region at chrM:13937-13944 isActive: true numReads: 54773; 12:13:53.989 DEBUG ReadThreadingGraph - Recovered 29 of 59 dangling tails; 12:13:54.004 DEBUG ReadThreadingGraph - Recovered 0 of 35 dangling heads; 12:13:54.432 DEBUG Mutect2Engine - Active Region chrM:13937-13944; 12:13:54.440 DEBUG Mutect2Engine - Extended Act Region chrM:13837-14044; 12:13:54.447 DEBUG Mutect2Engine - Ref haplotype coords chrM:13837-14044; 12:13:54.452 DEBUG Mutect2Engine - Haplotype count 128; 12:13:54.456 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:54,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:20203,Recover,Recovered,20203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"s; 16:27:48.951 INFO GenomicsDBImport - Initializing engine; 16:28:03.989 INFO IntervalArgumentCollection - Processing 29812 bp from intervals; 16:28:03.994 INFO GenomicsDBImport - Done initializing engine; Created workspace /humgen/gsa-hpprojects/dev/gauthier/reblockGVCF/forkTest; 16:28:04.155 INFO GenomicsDBImport - Vid Map JSON file will be written to forkTest/vidmap.json; 16:28:04.155 INFO GenomicsDBImport - Callset Map JSON file will be written to forkTest/callset.json; 16:28:04.156 INFO GenomicsDBImport - Complete VCF Header will be written to forkTest/vcfheader.vcf; 16:28:04.156 INFO GenomicsDBImport - Importing to array - forkTest/genomicsdb_array; 16:28:04.158 INFO ProgressMeter - Starting traversal; 16:28:04.158 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 16:28:05.198 INFO GenomicsDBImport - Starting batch input file preload; 16:29:23.571 INFO GenomicsDBImport - Finished batch preload; 16:48:46.140 INFO GenomicsDBImport - Shutting down engine; [May 4, 2018 4:48:46 PM EDT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 20.96 minutes.; Runtime.totalMemory()=22281715712; java.util.concurrent.CompletionException: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582); at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157); Caused by: java.lang.OutOfMemoryError: Java heap space; at com.intel.genomicsdb.importe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388079572:3239,down,down,3239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388079572,1,['down'],['down']
Availability,sBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.la,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7877,ERROR,ERROR,7877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,sDBFeatureReader(FeatureDataSource.java:463); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:365); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291); at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:726); at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: vector::_M_default_append; at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:460); ... 13 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918:4761,Error,Error,4761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918,1,['Error'],['Error']
Availability,"sDBImport: ; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms2G -Xmx20G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --genomicsdb-workspace-path 007_Database_DBImport_VCFref/database_interval_9 --sample-name-map sample_name_map --intervals 006_IntervalsSplit_DBImport_VCFref/interval_9.list --reader-threads 5 --batch-size 60 --tmp-dir TMPDIR --max-num-intervals-to-import-in-parallel 3 --merge-input-intervals`. GenotypeGVCFs:; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000_DataLinks/000_RefSeq/Cliv2.1_genomic.fasta --intervals 006_IntervalsSplit_DBImport_VCFref/interval_9.list --force-output-intervals PigeonBatch4/008_RawVcfGz/MergeVcf/pigeonBatch1234_filtered.vcf.gz -V gendb://007_Database_DBImport_VCFref/database_interval_9 -O 008_RawVcfGz_DBImport_VCFref/001_DividedIntervals/interval_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR`. #### **User Description of the Issue:**; ""I'm using the GenotypeGVCFs function based on GenomicsDBImport database. I've divided the reference into 50 intervals. Some intervals seems ok, but some reports error as following. I used a VCF file in ""--force-output-intervals"" for down stream analysis. I've never seen this error without ""--force-output-intervals"". I've searched for the error message and changed my GATK version to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset..."". @droazen and @samuelklee , any insight on this?. Thank you,. Anthony",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938:4952,ERROR,ERROR,4952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938,6,"['ERROR', 'down', 'error']","['ERROR', 'down', 'error']"
Availability,"schemes. Is that really necessary?. Anyway, the pom.xml is broken:. ```; >>> Preparing source in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1 ...; Equivalent maven command; mvn -Dmaven.repo.local=/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/.m2/repository verify '-Ddisable.shadepackage'; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. ```; 1 <?xml version=""1.0"" encoding=""UTF-8""?>; 2 <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:1217,error,error,1217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"scovered by feeding the tool with coverage data on autosomes + X chromosome (no Y chromosome). Since the X chr in XX samples has 2x ploidy of X in XY samples, one expects the tool to be able to make the correct inference. However, the tool genotyped all samples as XX (see the attached figure -- left: autosome+X+Y, right:autosome+X). ![unnamed](https://cloud.githubusercontent.com/assets/15305869/26426249/ce3ffb68-40a5-11e7-8002-6ea4f8513eea.png). A naive calculation of the relative X ploidy, i.e. calculating X_pcov = (X_total_read_counts / autosome_total_read_count) for all samples, performing a 2-mean clustering, and dividing the X_pcov by the lower ploidy cluster mean reveals that indeed, the X conting has twice more coverage on _average_ in XX samples:; ![image](https://cloud.githubusercontent.com/assets/15305869/26426348/2b2d6982-40a6-11e7-8eca-e93916bfc80c.png). Further investigation shows that the wrong behavior of TargetCoverageSexGenotyper stems from the lack of robustness of Poisson regression to outliers: there are a number of targets in the X contig with anomalously high coverage (200x median!). In the absence of Y coverage data (and bias adjustment), higher ploidy genotypes are always favored (in this case, XX). Solution: either filter read counts for outliers before calculating Poisson log likelihoods, or simply use the naive median-based ploidy estimates and perform genotyping on the estimated ploidies (rather than target-resolved read counts). The latter is proven to be robust to outliers. Update: it turns out that the issue can be fixed by simply taking into account bait count as a multiplicative bias. Otherwise, the distribution of raw read counts is multimodal and far from Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516437/54da4930-4254-11e7-9093-5e5fe1e0e28e.png). Correcting for bait count yields a neat over-dispersed Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516442/68d9ba4c-4254-11e7-82f0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3015:1191,robust,robustness,1191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3015,1,['robust'],['robustness']
Availability,sdGlwbGVQYXNzUmVhZFdhbGtlci5qYXZh) | `0% <0%> (√∏)` | `0 <0> (?)` | |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `84.141% <100%> (-3.415%)` | `80 <0> (-22)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-498815356:2404,down,downsampling,2404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-498815356,1,['down'],['downsampling']
Availability,"se(CalibrateDragstrModel.java:159); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Expected behavior. Runs to completed and writes out model file. #### Actual behavior; _Tell us what happens instead_. The following error occurs....; ```; 13:55:33.396 INFO ProgressMeter - Starting traversal; 13:55:33.396 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:55:42.364 INFO CalibrateDragstrModel - Shutting down engine; [April 4, 2021 1:55:42 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2384986112; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:16960,down,down,16960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['down'],['down']
Availability,"seArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); Caused by: java.lang.ClassNotFoundException: gatk.analysis.artifacts.SequencingArtifactMetrics$PreAdapterDetailMetrics; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at htsjdk.samtools.metrics.MetricsFile.loadClass(MetricsFile.java:471); 	at htsjdk.samtools.metrics.MetricsFile.read(MetricsFile.java:353); 	... 8 more; ```. If it is replaced, the tool still errors but with a different error:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:170); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:219); 	at java.util.ArrayList.forEach(ArrayList.java:1249); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:171); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:2436,error,errors,2436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,2,['error'],"['error', 'errors']"
Availability,"seReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:08:45.223 INFO DenoiseReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:08:45.223 INFO DenoiseReadCounts - Deflater: IntelDeflater; 20:08:45.223 INFO DenoiseReadCounts - Inflater: IntelInflater; 20:08:45.223 INFO DenoiseReadCounts - GCS max retries/reopens: 20; 20:08:45.223 INFO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:3922,Error,Error,3922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['Error'],['Error']
Availability,"section of the gatkcondaenv.yml. removes it and install numpy-1.18.1. see relevant part of conda env create -n gatk -f gatk-4.1.4.0/gatkcondaenv.yml 2>&1 | tee log; NB full log is attached : [log.txt](https://github.com/broadinstitute/gatk/files/4091802/log.txt). ```; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in ind = [slice(None), 0]; arr[ind] should be changed to a tuple, e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:1169,Down,Downloading,1169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['Down'],['Downloading']
Availability,"seeing an error, please provide(REQUIRED) :; a) GATK version used: 4.1.8.1; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \; -jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \; ASEReadCounter \; -L scattered.interval_list \; -R Homo_sapiens_assembly19.fasta \; -V 1000G_phase1.snps.high_confidence.b37.vcf.gz \; -I downsample_10k.bam \; -O output.txt --verbosity INFO . c) Entire error log:; 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/broad/software/free/Linux/redhat_7_x86_64/pkgs/gatk_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 14, 2021 7:13:26 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------; 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1; 19:13:26.218 INFO ASEReadCounter - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:13:26.219 INFO ASEReadCounter - Executing as cbao@uger-c009.broadinstitute.org on Linux v3.10.0-1160.15.2.el7.x86_64 amd64; 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_181-b13; 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC; 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------; 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------; 19:13:26.220 INFO ASEReadCounter - HTSJD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7314:1303,error,error,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7314,1,['error'],['error']
Availability,"seems like it should be easy to have a GATK tool called GetFileIndexName that will return the name in a way that can be used in scripting...so that the task could look something like. ```wdl; input {; String output_arg; }. command {; output_index=$(gatk GetFileIndexName -I ~{output_arg} ); echo $output_index > index_name.txt. gatk ActualToolName -V output_arg ; }. output {; File output_file = output_arg; File output_index = read_string(""index_name.txt""); }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736915683:291,echo,echo,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736915683,1,['echo'],['echo']
Availability,"segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S5_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T4_segments.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S5_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T4_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S5_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T4_contamination.table -ob-priors /workdir/mparment/data/process/A2683/PTC2_read-orientation-model.tar.gz -O /workdir/mparment/data/process/A2683/PTC2_filtered.vcf.gz. #### Actual behavior; It look like this error: https://github.com/broadinstitute/gatk/issues/3018. I followed GATK's good practice rules and I use Mutect2 in ""multisample"" mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:8376,error,error,8376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['error'],['error']
Availability,"segments:¬† ; ; 12:37:55.535 INFO ¬†FuncotateSegments - ¬†Gencode 34 CANONICAL ; ; 12:37:55.542 INFO ¬†FuncotatorEngine - VCF sequence dictionary detected as B37 in HG19 annotation mode. ¬†Performing conversion. ; ; 12:37:55.542 WARN ¬†FuncotatorEngine - WARNING: You are using B37 as a reference. ¬†Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. ¬†There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO ¬†ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO ¬†ProgressMeter - ¬† ¬† ¬† ¬†Current Locus ¬†Elapsed Minutes ¬† ¬†Features Processed ¬†Features/Minute ; ; 12:37:56.198 WARN ¬†FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]! ¬†Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO ¬†FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ; ¬† ¬† at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ; ¬† ¬† at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ; ¬† ¬† at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ; ¬† ¬† at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ; ¬† ¬† at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ; ¬† ¬† at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2059,down,down,2059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['down'],['down']
Availability,"semblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3823794Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:5821,error,error,5821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"seq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_RNAseq.R; ```; library(Rsubread); library(Biostrings); set.seed(strtoi(snakemake@wildcards[[""sample""]])). fasta = readDNAStringSet(snakemake@input[[1]]). expr = matrix(1, ncol=1, nrow=length(fasta)). simReads(transcript.file=snakemake@input[[1]], expression.levels=expr,; output.prefix=snakemake@params[[1]], library.size=100000, simulate.sequencing.error=TRUE); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:3754,down,download,3754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,2,"['down', 'error']","['download', 'error']"
Availability,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:1848,heartbeat,heartbeat,1848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,3,"['failure', 'heartbeat']","['failureShutdownDuration', 'heartbeat', 'heartbeatInterval']"
Availability,"server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://githu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:11815,ERROR,ERROR,11815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unkn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:12907,ERROR,ERROR,12907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,setDeprecationLogger.execute(ResetDeprecationLogger.java:26); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:10794,ERROR,ERROR,10794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,setDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:9536,ERROR,ERROR,9536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,setting RScriptExecutor to output useful messages on failure,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/237:53,failure,failure,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237,1,['failure'],['failure']
Availability,"shard-12910/inputs/-724059439/P0000992.b37.counts.hdf5 --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/1773956498/P0001010.b37.counts.hdf5 --contig-ploidy-calls contig-ploidy-calls-dir --interval-merging-rule OVERLAPPING_ONLY --output out --output-prefix csi_batch1-4_wes_gcnv_pon --verbosity DEBUG --p-alt 1e-6 --p-active 1e-2 --cnv-coherence-length 10000.0 --class-coherence-length 10000.0 --max-copy-number 5 --max-bias-factors 5 --mapping-error-rate 0.01 --interval-psi-scale 0.001 --sample-psi-scale 0.0001 --depth-correction-tau 10000.0 --log-mean-bias-standard-deviation 0.1 --init-ard-rel-unexplained-variance 0.1 --num-gc-bins 20 --gc-curve-standard-deviation 1.0 --copy-number-posterior-expectation-mode HYBRID --enable-bias-factors true --active-class-padding-hybrid-mode 50000 --learning-rate 0.05 --adamax-beta-1 0.9 --adamax-beta-2 0.99 --log-emission-samples-per-round 50 --log-emission-sampling-median-rel-error 0.005 --log-emission-sampling-rounds 10 --max-advi-iter-first-epoch 5000 --max-advi-iter-subsequent-epochs 100 --min-training-epochs 10 --max-training-epochs 100 --initial-temperature 2.0 --num-thermal-advi-iters 2500 --convergence-snr-averaging-window 500 --convergence-snr-trigger-threshold 0.1 --convergence-snr-countdown-window 10 --max-calling-iters 10 --caller-update-convergence-threshold 0.001 --caller-internal-admixing-rate 0.75 --caller-external-admixing-rate 1.00 --disable-annealing false. [2019-02-22 23:49:20,42] [info] WorkflowManagerActor WorkflowActor-098a389e-b298-4324-8a8c-9f46f05708b5 is in a terminal state: WorkflowFailedState; [2019-02-22 23:50:01,65] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-02-22 23:50:02,38] [info] Workflow polling stopped; [2019-02-22 23:50:02,48] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-02-22 23:50:02,49] [info] Shutting down WorkflowLogCopyRou",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:29833,error,error,29833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['error'],['error']
Availability,"should contain A element(s).; In file/stream ""2105614020_IVRN_stream"", at contig ""chr14"", position 60604048, for sample ""Einstein"", the field AF has 3 elements; expected 2; Using GATK jar /gatk/gatk-package-4.2.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms8g -jar /gatk/gatk-package-4.2.3.0-local.jar GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-SplitIntervalList/glob-d928cd0f5fb17b6bd5e635f48c18ccfb/0073-scattered.interval_list --sample-name-map sample_name_map --reader-threads 5 --merge-input-intervals --consolidate. </p>; </details>. #### Steps to reproduce; Run ReblockGVCF with Dragen 3.6.3 gvcf output. #### Expected behavior; Do the parse as expected. #### Actual behavior; You can see below 2 different examples that return the same error.; <br>-- First; * Dragen output; ```; chr14 60604048 . TCACACACACACA TCACACA,T,<NON_REF> 135.20 PASS DP=44;MQ=250.00;MQRankSum=1.636;ReadPosRankSum=1.540;FractionInformativeReads=0.818;R2_5P_bias=0.000 GT:AD:AF:DP:F1R2:F2R1:GQ:PL:SPL:ICNT:GP:PRI:SB:MB 1/1:1,34,1,0:0.944,0.028,0.000:36:1,20,1,0:0,14,0,0:82:140,88,0,967,86,138,935,101,985,948:255,0,220:0,29:1.3520e+02,8.5204e+01,0.0000e+00,4.5000e+02,8.5278e+01,1.3828e+02,4.5000e+02,1.3246e+02,4.5000e+02,4.5000e+02:0.00,2.00,5.00,2.00,4.00,5.00,34.77,36.77,36.77,37.77:1,0,18,17:1,0,22,13; ```; * ReblockGVCF (4.2.3.0) output; ```; chr14 60604048 . TCACACA T,<NON_REF> 135.20 . AS_QUALapprox=|140|0;AS_VarDP=1|34|0;DP=44;MQ=250.00;MQRankSum=1.636;QUALapprox=140;RAW_GT_COUNT=0,0,1;RAW_MQandDP=2750000,44;ReadPosRankSum=1.540;VarDP=35 GT:AD:AF:DP:F1R2:F2R1:GQ:ICNT:MB:PL:PRI:SB:SPL 1/1:1,34,0:0.944,0.028,0.000:36:1,20,1,0:0,14,0,0:88:0,29:1,0,22,13:140,88,0,935,101,948:0.00,2.00,5.00,2.00,4.00,5.00,34.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:5474,error,error,5474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,1,['error'],['error']
Availability,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617,2,['error'],['error']
Availability,"sites annotated with PLs forced to true for reference-model confidence output; 22:42:22.734 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 22:42:22.734 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 22:42:22.734 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Users/nhomer/miniconda3/envs/bfx/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; 22:42:22.748 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 22:42:22.748 WARN IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation; 22:42:22.748 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 22:42:22.751 WARN GATKVariantContextUtils - Can't determine output variant file format from output file extension ""bam"". Defaulting to VCF.; 22:42:22.776 INFO ProgressMeter - Starting traversal; 22:42:22.777 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010f47efd3, pid=96919, tid=0x0000000000002303; #; # JRE version: OpenJDK Runtime Environment (8.0_192-b01) (build 1.8.0_192-b01); # Java VM: OpenJDK 64-Bit Server VM (25.192-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman4496658849792952100.dylib+0x1fd3] _Z22smithWatermanBackTrackP10dnaSeqPairiiiiPii+0x3c3; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /private/tmp/hs_err_pid96919.log; #; # If you would like to submit a bug report, please visit:; # http://www.azulsystems.com/support/; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-667631737:4395,error,error,4395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-667631737,2,['error'],['error']
Availability,"skBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7033,AVAIL,AVAILABLE,7033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"skBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6773,AVAIL,AVAILABLE,6773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"sks.task_case_denoising_calling - Loading the model and updating the instantiated model and workspace...; 10:20:25.005 INFO gcnvkernel.io.io_commons - Reading model parameter values for ""log_mean_bias_t""... Stderr: Traceback (most recent call last):; File ""/media/Data/tmp/case_denoising_calling.3564509013495540802.py"", line 201, in <module>; shared_workspace, initial_params_supplier, args.input_model_path); File ""/usr/BioinfSoftware/Anaconda/3-2020.11/envs/gatk4.3.0.0/lib/python3.6/site-packages/gcnvkernel/tasks/task_case_denoising_calling.py"", line 128, in __init__; self.continuous_model_approx, input_model_path)(); File ""/usr/BioinfSoftware/Anaconda/3-2020.11/envs/gatk4.3.0.0/lib/python3.6/site-packages/gcnvkernel/io/io_denoising_calling.py"", line 93, in __call__; self.input_path, self.denoising_model_approx, self.denoising_model); File ""/usr/BioinfSoftware/Anaconda/3-2020.11/envs/gatk4.3.0.0/lib/python3.6/site-packages/gcnvkernel/io/io_commons.py"", line 471, in read_mean_field_global_params; ""expected: {2}"".format(var_name, var_mu.shape, vmap.shp); AssertionError: Loaded mean for ""log_mean_bias_t"" has an unexpected shape; loaded: (11903,), expected: (11901,). at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:351); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289) ```. Can you give me some hint where this error comes from? ; Thanks in advanve; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:9679,error,error,9679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['error'],['error']
Availability,"so from jar:file:/master/xxxxxxx/local/pckg/python/miniconda3/envs/cerc_prod/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Mon Jun 22 17:06:37 CDT 2020] MergeVcfs --INPUT data/calling/erc_prod2.SM_V7_1.vcf.gz --INPUT data/calling/cerc_prod2.SM_V7_ZW.vcf.gz --OUTPUT out.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 22, 2020 5:06:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Jun 22 17:06:37 CDT 2020] Executing as xxxxxxx@yyyyyy on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Mon Jun 22 17:06:37 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=1249378304; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.samtools.SAMException: Cannot read non-existent file: file:///data/infectious/schistosome/tmp/test%20a/data/calling/erc_prod2.SM_V7_1.vcf.gz; at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:498); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:485); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:173); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Mai",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:6087,avail,available,6087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,1,['avail'],['available']
Availability,"sorry, just realized the `N`s are masked! Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7009#issuecomment-748203463:34,mask,masked,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7009#issuecomment-748203463,1,['mask'],['masked']
Availability,"spark complains but non-spark does not. ```; CollectQualityYieldMetricsSpark --output a.metrics --useOriginalQualities true --reference src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta --input src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram --disableSequenceDictionaryValidation false. org.broadinstitute.hellbender.exceptions.UserException$IncompatibleSequenceDictionaries: A USER ERROR has occurred: Input files reference and reads have incompatible contigs: Found contigs with the same name but different lengths:; contig reference = 1 / 1000000; contig reads = 1 / 249250621.; reference contigs = [1]; reads contigs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, X, Y, MT, GL000207.1, GL000226.1, GL000229.1, GL000231.1, GL000210.1, GL000239.1, GL000235.1, GL000201.1, GL000247.1, GL000245.1, GL000197.1, GL000203.1, GL000246.1, GL000249.1, GL000196.1, GL000248.1, GL000244.1, GL000238.1, GL000202.1, GL000234.1, GL000232.1, GL000206.1, GL000240.1, GL000236.1, GL000241.1, GL000243.1, GL000242.1, GL000230.1, GL000237.1, GL000233.1, GL000204.1, GL000198.1, GL000208.1, GL000191.1, GL000227.1, GL000228.1, GL000214.1, GL000221.1, GL000209.1, GL000218.1, GL000220.1, GL000213.1, GL000211.1, GL000199.1, GL000217.1, GL000216.1, GL000215.1, GL000205.1, GL000219.1, GL000224.1, GL000223.1, GL000195.1, GL000212.1, GL000222.1, GL000200.1, GL000193.1, GL000194.1, GL000225.1, GL000192.1, NC_007605]; ```. Once fixed, reenable 2 tests in CollectQualityYieldMetricsSparkIntegrationTest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1262:475,ERROR,ERROR,475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1262,1,['ERROR'],['ERROR']
Availability,spark error due to missing cloud storage enum DURABLE_REDUCED_AVAILABILITY,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:6,error,error,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['error'],['error']
Availability,"spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); ... 24 more; 05:12:04.045 INFO HaplotypeCallerSpark - Shutting down engine; [May 18, 2017 5:12:04 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 131.63 minutes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGSch",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:6365,failure,failure,6365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['failure'],['failure']
Availability,"specops issue #273: https://github.com/broadinstitute/dsp-spec-ops/issues/273. - renamed `ngs_cohort_extract.py` -> `create_cohort_extract_data_table.py`; - run the script in a WDL (GvsPrepareCallset.wdl); - use a custom docker - include script for creating and pushing this docker to gcr.io; - enable running as a SA - this has been tested in Terra and works as expected. if using a dataset that requires SA access and the user does not provide a working SA key, they get this error: `User does not have bigquery.jobs.create permission in project specops-variantstore-sa-tests.`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7200:478,error,error,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7200,1,['error'],['error']
Availability,src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3823794Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:4382,error,error,4382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7498018Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7502319Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol;,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:6529,error,error,6529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ```. FreeBSD 11.2 amd64",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:2851,error,error,2851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,3,['error'],['error']
Availability,"ssignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1204,ERROR,ERROR,1204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['ERROR'],['ERROR']
Availability,"ssing / not called genotypes (`./.`). These variants seem to have coverages that are good enough to successfully call variants ‚Äî and, genotypes are called at these sites as hom refs (`0/0`) when we run these ***same samples*** through the ***same pipeline*** (WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7)) ***without the reblocking step***. . It also seems as if we lose the PL field for these variants when working with reblocked gvcfs (which could explain why GenotypeGVCF isn‚Äôt giving us calls for these variants). I've heard that support for hom-refs with no PLs was implemented in CombineGVCFs as of Sept 2021, but I'm still seeing the issue with CombineGVCFs 4.3.0.0. To provide more info:. - We are seeing these issues regardless of if reblocked gvcfs are analyzed together with or separate from non-reblocked gvcfs. (For reference, the downstream steps in our pipeline are GenomicsDBImport & GenotypeGVCFs, but we‚Äôre seeing the same results with CombineGVCFs & GenotypeGVCFs on a smaller set of test gvcfs.); - I have a test set of samples that I've run with and without ReblockGVCF, and have used CombineGVCFs 4.3.0.0 & GenotypeGVCFs 4.3.0.0, and we're still seeing this issue.; - I have rerun ReblockGVCF including the `--allow-missing-home-ref-data` and `--all-site-pls` flags, but neither of these seem to solve the issue either. . #### Steps to reproduce. Run WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7) pipeline. With the relocked gvcfs, run CombineGVCFs, then GenotypeGVCFs. ; Running WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7) pipeline ***but skipping the reblocking step*** and running CombineGVCFs and GenotypeGVCFs results in these same variants being called as hom-ref (which makes me think that reblocking is messing these up someh",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8208:1445,down,downstream,1445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8208,1,['down'],['downstream']
Availability,"ssion.so from jar:file:/home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar!/com/intel/gkl/native/libgkl_compression.so; 21:10:43.152 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:10:43.153 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.5.2; 21:10:43.153 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:10:44.334 INFO GenotypeGVCFs - Initializing engine; 21:10:44.849 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vojta/dokumenty/fakulta/botanika/arabidopsis/samples/lib_2018_06/4_joined/rad34test.comb2.raw.vcf.gz; 21:10:44.979 INFO GenotypeGVCFs - Done initializing engine; 21:10:45.057 INFO ProgressMeter - Starting traversal; 21:10:45.057 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:10:45.344 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 21:10:47.780 INFO GenotypeGVCFs - Shutting down engine; [2. ƒçervence 2018 21:10:47 CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=501219328; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 6.911788849595091E-17,NaN; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.getLog10PNonRef(AlleleFrequencyCalculator.java:143); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:255); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinsti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:1589,down,down,1589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928,1,['down'],['down']
Availability,"ssion.so from jar:file:/home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:45:47.648 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:45:47.649 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.5.2; 22:45:47.649 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:45:47.800 INFO GenotypeGVCFs - Initializing engine; 22:45:48.331 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vojta/dokumenty/fakulta/botanika/arabidopsis/samples/lib_2018_06/4_joined/rad34test.comb2.raw.vcf.gz; 22:45:48.467 INFO GenotypeGVCFs - Done initializing engine; 22:45:48.555 INFO ProgressMeter - Starting traversal; 22:45:48.556 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 22:45:51.038 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 22:45:51.045 INFO GenotypeGVCFs - Shutting down engine; [2. ƒçervence 2018 22:45:51 CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=528482304; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 6.911788849595091E-17,NaN; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.getLog10PNonRef(AlleleFrequencyCalculator.java:143); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:255); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinsti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-401933028:1452,down,down,1452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-401933028,1,['down'],['down']
Availability,ssorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2371,error,error,2371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['error'],['error']
Availability,"ssuecomment-260687763). @vdauwera yes it is on mine. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260714842). Are you planning/working on this in GATK3 or GATK4? Would be good to know where the issue should live. . ---. @vdauwera commented on [Wed Feb 08 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-278478318). @SHuang-Broad ping... ---. @SHuang-Broad commented on [Wed Feb 15 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-280102484). @vdauwera sorry this went off my attention for a while. I did attempt to port a similar change a while back, but discovered that it was not so simple: the fix worked in HC code by removing alt alleles looking at the supporting haplotype scores. Such scores are not available in `GenotypeGVCFs` so either we would have to, like Valentin suggested, make sure the tools handle input without PLs, which is a direction that I looked into and found that the pay/cost is not good (if I recall correctly, most of the places that handles the input does not require valid PL but there are several that's difficult to handle). Then I began wondering how the new QUAL calculating method David Benjamin has put in will make such problems obsolete. So I would say if I find time beyond finishing my SV duty, I would chase down if the new QUAL method indeed will resolve all these, and that will definitely happen in GATK 4. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-281073466). Ah, interesting, thanks Steve. Do you have any sense of when you might be able to look further into this? This is not to pressure you, just to estimate the roadmap/timeline. An order of magnitude (weeks, months, more) would be fine. . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-287838044). I'm going to move this issu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:10001,avail,available,10001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['avail'],['available']
Availability,"st$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 21 more; Caused by: java.lang.UnsupportedOperationException; 	at shaded.cloud_nio.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. [Stage 21:> (0 + 60) / 3539]18/12/21 16:08:30 ERROR org.apache.spark.scheduler.TaskSetManager: Task 26 in stage 21.0 failed 4 times; aborting job; 18/12/21 16:08:30 ERROR org.apache.spark.internal.io.SparkHadoopMapReduceWriter: Aborting job job_20181221160412_0054.; org.apache.spark.SparkException: Job aborted due to stage failure: Task 26 in stage 21.0 failed 4 times, most recent failure: Lost task 26.3 in stage 21.0 (TID 2498, readpipeline-w-4.c.broad-gatk-test.internal, executor 21): java.io.IOException: com.esotericsoftware.kryo.KryoException: java.lang.UnsupportedOperationException; Serialization trace:; requestOptions (com.google.cloud.storage.BlobReadChannel); channel (com.google.cloud.storage.contrib.nio.CloudStorageReadChannel); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); rsFile (htsjdk.samtools.cram.ref.ReferenceSource); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.lambda$save$bddeb71b$1(AnySamSinkM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:4995,failure,failure,4995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['failure'],['failure']
Availability,st'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1433,ERROR,ERROR,1433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,st; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z sr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:2207,error,error,2207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,st; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the ST,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:3860,error,error,3860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:56:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49966 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49966 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:56:07 WARN TaskSetManager: Lost task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:29475,Error,Error,29475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"station and have allocated about 30GB to Docker. . Mystery 1: I get a warning on some commands that it is unable to determine whether it is running on google. Related to the Funcotator issue perhaps if it can‚Äôt determine where it is running it crashes out?. . Mystery 2: CollectAllelicCounts crashes with a java memory error. The -Xmx5g is several multiples of the recommendation. . gatk --java-options ""-Xmx5g"" CollectAllelicCounts -L mydata/refs/hg19_intervals.interval_list -I mydata/P50513/Tumor_P50513_2.bam -R mydata/refs/Homo_sapiens_assembly19.fasta -O mydata/P50513/P50513_Tumor.allelicCounts.tsv . . 20:31:39.543 INFO ProgressMeter - 1:169308662 59.1 85227000 1443218.8. 20:32:01.576 INFO ProgressMeter - 1:169321662 59.4 85240000 1434518.9. 20:32:22.203 INFO ProgressMeter - 1:169334662 59.8 85253000 1426484.3. 20:32:43.007 INFO ProgressMeter - 1:169341665 60.1 85260000 1418372.5. 20:33:04.435 INFO ProgressMeter - 1:169350665 60.5 85269000 1410144.2. 20:33:29.473 INFO CollectAllelicCounts - Shutting down engine. [October 5, 2019 8:33:29 PM UTC] org.broadinstitute.hellbender.tools.copynumber.CollectAllelicCounts done. Elapsed time: 60.94 minutes. Runtime.totalMemory()=5,285,347,328. . . Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded. . . at java.util.Collections.unmodifiableList(Collections.java:1287). at htsjdk.samtools.Cigar.getCigarElements(Cigar.java:54). at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.getCigarElements(SAMRecordToGATKReadAdapter.java:336). at org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary$ReadLengthEqualsCigarLengthReadFilter.test(ReadFilterLibrary.java:217). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.he",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777:1152,down,down,1152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777,1,['down'],['down']
Availability,"sted number of threads: 12; 10:24:22.008 INFO CalibrateDragstrModel - Done initializing engine; 10:24:22.008 INFO ProgressMeter - Starting traversal; 10:24:22.008 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 10:24:32.859 INFO ProgressMeter - chr1:26000000 0.2 59038 326477.4; 10:24:42.867 INFO ProgressMeter - chr1:83000000 0.3 184245 529998.1; 10:24:52.965 INFO ProgressMeter - chr1:137193529 0.5 306766 594565.4; 10:25:03.307 INFO ProgressMeter - chr1:193193529 0.7 428759 622924.6; 10:25:13.318 INFO ProgressMeter - chr2:3237107 0.9 564835 660497.0; 10:25:23.358 INFO ProgressMeter - chr2:57237107 1.0 681209 666219.1; 10:25:33.392 INFO ProgressMeter - chr2:109237107 1.2 799610 672091.8; 10:25:44.527 INFO ProgressMeter - chr2:177512416 1.4 930822 676805.6; 10:25:54.821 INFO ProgressMeter - chr2:237512416 1.5 1069999 691712.8; 10:26:04.863 INFO ProgressMeter - chr3:54999378 1.7 1197525 698570.8; 10:26:09.642 INFO CalibrateDragstrModel - Shutting down engine; [January 2, 2023 at 10:26:09 AM GMT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 1.81 minutes.; Runtime.totalMemory()=47647293440; java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490); at java.base/java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:600); at java.base/java.util.concurrent.ForkJoinTask.get(ForkJoinTask.java:1006); at org.broadinstitute.hellbender.utils.Utils.runInParallel(Uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:5281,down,down,5281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['down'],['down']
Availability,"stering block manager 172.20.19.130:43279 with 1076.2 GiB RAM, BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45354,AVAIL,AVAILABLE,45354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"stitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```; I downloaded the file from gnomAD repository (""All chromosomes VCF""), but had to do some changes, as follow:; 1. Lifted over to hg19, by using [b37tohg19.chain](https://github.com/broadgsa/gatk/blob/master/public/chainFiles/b37tohg19.chain) by using:; ```; sudo java -jar /picard-2.21.3/picard.jar LiftoverVcf I=gnomad.exomes.r2.1.1.sites.vcf.bgz \; O=gnomad.exomes_hg19.r2.1.1.sites.vcf.bgz \; CHAIN=b37tohg19.chain REJECT=rejected_variants.vcf \; R=/reference/hg19/hg19.fa \; ALLOW_MISSING_FIELDS_IN_HEADER=true \; MAX_RECORDS_IN_RAM=100000; ```; 2. Got rid of the [chrN_random tables](http://genome.ucsc.edu/FAQ/FAQdownloads#download10) by manually deleting them from the header of ```ExAC_hg19.r1.sites.vep.vcf.gz``` and creating a new file with just the new header, ```header_hg19_Ion.vcf```; and. 3. Fixed the header by using:; ```; java -jar picard.jar FixVcfHeader I=/gatk_data/reference/gnomAD/gnomad.exomes_hg19.r2.1.1.sites.vcf.bgz \; O=/gatk_data/reference/gnomAD/gnomad.exomes_hg19_Ion.r2.1.1.sites.vcf.bgz \; HEADER=/gatk_data/reference/gnomAD/header_hg19_Ion.vcf \; MAX_RECORDS_IN_RAM=70000; ```. I am bit lost on where the error might be, Any help is greatly appreciated.; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568:4226,error,error,4226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568,1,['error'],['error']
Availability,"stitute/hellbender/gcnvkernel/structs/metadata.py#L177); [gcnvkernel metadata.py SampleMetadataCollection class](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/metadata.py#L215); [gcnvkernel model_denoising_calling.py](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py); [gcnvkernel io_metadata.py write_sample_coverage_metadata function](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py#L16); [theano scan_op.py](https://github.com/Theano/Theano/blob/master/theano/scan_module/scan_op.py). ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm getting a strange error (see below) when running a nf-core module test. I am using test files, which are obviously smaller as for short testing times i.e. the provided bam file only provides mapped reads for a small section of the genome. #### Steps to reproduce; Run the following to create and interactive container and mount the required zip folder ([gatk_test.tar.gz](https://github.com/broadinstitute/gatk/files/10022295/gatk_test.tar.gz)):; ```docker run -it -v /path/to/gatk_test_dir:/mnt/gatk_test broadinstitute/gatk bash```; If you bash the `gatk_germlinecnvcaller.sh` within the provided zip folder in a gatk4 Docker container. #### Expected behavior; gatk GermlineCNVCaller should run as expected. #### Actual behavior; ```TypeError: ('The following error happened while compiling the node', forall_inplace,cpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0, IncSubtensor{InplaceSet;:int64:}.0, Elemwise{mul,no_inplace}.0, Subtensor{int64::}.0, Elemwise{sub,no",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097:1211,error,error,1211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097,1,['error'],['error']
Availability,"stitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:6916,error,error,6916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,stitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4375980Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4389382Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:18854,error,error,18854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,stitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8421445Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8433800Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVC,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:21435,error,error,21435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,stitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArg,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:3844,error,error,3844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,stitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4360539Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4368812Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4375980Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4389382Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:18480,error,error,18480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,stitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8406350Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8414536Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/FlowBasedHMMEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8421445Z src/main/java/org/broadinstitute/hellbender/utils/read/FlowBasedKeyCodec.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8433800Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotato,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:21061,error,error,21061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:775); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. #### Steps to reproduce; In the scripts/spark_eval directory, run; ```; NUM_WORKERS=20 nohup ./run_gcs_cluster.sh copy_genome_to_hdfs_on_gcs.sh genome_reads-pipeline_hdfs.sh &; ```. #### Expected behavior; The tool should run without error. #### Actual behavior; The tool exits with the above error about 30 mins into the run.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:3034,error,error,3034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,2,['error'],['error']
Availability,"successful run:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/649ee4c9-1afc-473b-b460-2fc88d5f49d4. failing run with the bug:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/f1c952fc-7f05-4468-ae20-1c1cc5b9bf38. AC is:. Cohort builder subcohort extract in AoU and our extract workflow work with both VETS and VQSR callsets, including past callsets. (Note--I did not test in AoU, just on quickstart since the issue doesn't seem to be permission or scale related--see failure reproduced above). Full extract with past callset & VQSR; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/649ee4c9-1afc-473b-b460-2fc88d5f49d4. Subcohort extract with past callset & VQSR. Full extract with new callset & VETS; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/50ef3073-f618-42ee-b207-73712a783a8a; (note this failed but only on one of the 4 runs and it's based on query cost). <img width=""1202"" alt=""Screenshot 2023-08-25 at 1 22 58 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/39468ed8-fe2b-4bf8-9326-3bfcf6dabbb1"">. Kevin is able to run latest extract on Delta (still waiting on Kevin, but otherwise the above are all set). note that there was briefly no ""score"" col but I dont _think_ we need to be backwards compatible for that as there was no release",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8488:544,failure,failure,544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8488,1,['failure'],['failure']
Availability,surpressing tool output statement if the tool returned null; exiting with 1 if the tool threw an error. should fix #341 and #342 . @vruano Please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/343:97,error,error,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/343,1,['error'],['error']
Availability,sy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:13844,ERROR,ERROR,13844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,syncSAMFileWriter.java:38); at htsjdk.samtools.util.AbstractAsyncWriter.close(AbstractAsyncWriter.java:89); at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.close(SAMFileGATKReadWriter.java:26); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:193); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1053); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: htsjdk.samtools.util.RuntimeIOException: Write error; BinaryCodec in writemode; streamed file (filename not available); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:222); at htsjdk.samtools.util.BlockCompressedOutputStream.writeGzipBlock(BlockCompressedOutputStream.java:451); at htsjdk.samtools.util.BlockCompressedOutputStream.deflateBlock(BlockCompressedOutputStream.java:415); at htsjdk.samtools.util.BlockCompressedOutputStream.write(BlockCompressedOutputStream.java:305); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:212); at htsjdk.samtools.BAMRecordCodec.encode(BAMRecordCodec.java:168); at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:134); ... 12 more; Caused by: java.io.IOException: Stale file handle; at java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method); at java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62); at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:115); at java.base/sun.nio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:60190,error,error,60190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,2,"['avail', 'error']","['available', 'error']"
Availability,"t (which happens to be supported by all haplotypes present) falls outside of our active region in the padding then we try to draw the variant span based on the first 4 haplotypes by the rules of haplotype expansion we end up making our trimming span `chr#:###326-###555` (note ###555 falls inside the span the 5th haplotype). When we go to trim all of our variant haplotypes (which happen to all have variant #5) they run into this code inside `Haplotype.trim()`:; ```; // note: the following returns null if the bases covering the ref interval start or end in a deletion.; final byte[] newBases = AlignmentUtils.getBasesCoveringRefInterval(newStart, newStop, getBases(), 0, getCigar());. if ( newBases == null || newBases.length == 0 ) { // we cannot meaningfully chop down the haplotype, so return null; return null;; }; ```; For all of our variant haplotypes at this site we find deletions at the end base and throw the whole haplotypes away when we try to trim it. In this particular case it meant we lost real variants in the previous 4 haplotypes as a result. I propose remedying this in one of two ways:; 1) Allow `AlignmentUtils.getBasesCoveringRefInterval()` to return partially spanning haplotypes when there are potentially 'shorter' than the reference haplotype span (this could easily cause all sorts of errors as the later code might not account for those mismatches. ; 2) Make `AlignmentUtils.getBasesCoveringRefInterval()` cheat and paste reference bases at the front or back of the haplotype to make it square with the reference offsets (we should never call or worry about deletions at the ends of haplotypes anyway) ; 3) Try to catch this edge case at the `AssemblyRegionTrimmer.trim()` stage, try to make the trimmer aware that there might be deletions overlapping its boundaries and expand them until there are no more overlaps. . This is a very unlikely case I suspect but it could cost us some sensitivity in noisy low complexity regions. @davidbenjamin what are your thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7137:2159,error,errors,2159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7137,1,['error'],['errors']
Availability,t 128; 11:39:08.001 DEBUG Mutect2Engine - Kmer sizes count 0; 11:39:08.002 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:12.623 DEBUG Mutect2 - Processing assembly region at chrM:7772-8071 isActive: false numReads: 359; 11:39:12.636 INFO ProgressMeter - chrM:7772 3.5 30 8.5; 11:39:12.638 DEBUG Mutect2 - Processing assembly region at chrM:8072-8371 isActive: false numReads: 0; 11:39:27.522 DEBUG IntToDoubleFunctionCache - cache miss 9173 > 5354 expanding to 10710; 11:39:31.241 DEBUG Mutect2 - Processing assembly region at chrM:8372-8671 isActive: false numReads: 0; 11:39:43.892 DEBUG Mutect2 - Processing assembly region at chrM:8672-8829 isActive: false numReads: 148658; 11:39:47.277 DEBUG IntToDoubleFunctionCache - cache miss 92836 > 47638 expanding to 95278; 11:40:02.830 DEBUG Mutect2 - Processing assembly region at chrM:8830-9129 isActive: true numReads: 296990; 11:41:56.997 DEBUG ReadThreadingGraph - Recovered 7 of 8 dangling tails; 11:41:57.047 DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:15528,Recover,Recovered,15528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"t I filter snp.raw.vcf with `VariantFiltration` command below: ; `gatk-4.1.2.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/"" VariantFiltration -R genome.fa -V snp_rmnan.raw.vcf --filter-expression ""QUAL < 30.0 || QD < 2.0 || FS > 60.0 || MQ < 40.0 || SOR > 4.0 || ReadPosRankSum < -8.0"" --filter-name ""my_snp_filter"" --missing-values-evaluate-as-failing true -O snp_rmnan.raw.vcf.tmp.vcf `. This command runs successfully. But when I'm using `SelectVariants` command to extact the filtered site:; `gatk-4.1.2.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/"" SelectVariants -R genome.fa -V snp_rmnan.raw.vcf.tmp.vcf --exclude-filtered -O snp_rmnan.raw.vcf.filter.vcf `. I get this java ERROR below, even without the wrong line number and do not know how to deal with it......... o(‚ï•Ôπè‚ï•)oÔºåThank you very much!. ~~~; 11:15:52.195 INFO ProgressMeter - Chr01:15144308 19.9 541000 27161.2; 11:16:04.187 INFO ProgressMeter - Chr01:15388212 20.1 547000 27189.6; 11:16:12.515 INFO SelectVariants - Shutting down engine; [May 9, 2019 11:16:12 AM CST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 20.37 minutes.; Runtime.totalMemory()=2814377984; java.lang.NumberFormatException: For input string: ""1,0""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:734); at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:132); at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); at htsjdk.variant.variantcontext.LazyGenotypesContext.getGenotypes(LazyGenotypesContext.java:148); at htsjdk.variant.variantcontext.GenotypesContext.iterator(GenotypesContext.java:465); at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants.initalizeAlleleAnyploidIndicesCache(SelectVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5929:1003,down,down,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5929,1,['down'],['down']
Availability,t exist; 2022-08-16T00:09:07.2647018Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2671678Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:1679,error,error,1679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,t exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z sr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:2383,error,error,2383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,t exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6548080Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:3332,error,error,3332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,t exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable char,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:4036,error,error,4036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"t is shallow copied.; if (value) {; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.enable"", ""true"");; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.json.keyfile"", gcs_creds);; hdfsBuilderConfSetStr(builder, ""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1826); Caused by: com.google.api.client.http.HttpResponseException: 404 Not Found; {""error"":""invalid_request"",""error_description"":""Service account not enabled on this instance""}; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1072); at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:159); at com.google.api.client.auth.oauth2.Credential.refreshToken(Creden",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:1576,error,error,1576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['error'],['error']
Availability,t oAB.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at oAB.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at oAB.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:706); 	at oAB.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at oAB.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at oAB.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseAABs(CommandLineProgram.java:191); 	at oAB.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at oAB.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at oAB.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at oAB.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.IOException: GenomicsDB JNI Error: GenomicsDBConfigException : Syntax error in JSON file /data/xxxxxx/ABchroneALL/callset.json; 	at oAB.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at oAB.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at oAB.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at oAB.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at oAB.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at oAB.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. #GenotypeGVCF working when only six samples are imported in GenomicsDB; gatk GenotypeGVCFs -R Reference/File_S16_uT_chromosomes.fasta -V gendb://GenomicsDB_wd -O test_chromosome_1_6_samples.vcf; Using GATK jar /data/xxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:11984,Error,Error,11984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,2,"['Error', 'error']","['Error', 'error']"
Availability,"t org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11678,failure,failure,11678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['failure'],['failure']
Availability,"t org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:4791,down,down,4791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['down'],['down']
Availability,"t org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbend",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:4974,down,down,4974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['down'],['down']
Availability,"t org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Based on the discussion around #4963 and the [test VCF](https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/testGenotypeGivenAllelesMode_givenAlleles.vcf), I gather that this is intended to work without error. I was trying to figure out how these cases differed from the spanning deletion in the aforementioned test VCF. One thing I noticed was that these two problematic cases have the SNP at the very last base of the spanning deletion. I'm just speculating here, but maybe it is related to an off-by-one bug of some sort? . I am testing with v. 4.0.9.0.; I also tried with v. 4.0.5.1 which does not crash, but rather prints the warnings discussed in #4963:; `00:02:10.995 WARN HaplotypeCallerEngine - Multiple valid VCF records detected in the alleles input file at site 22:16137302-16137302, only considering the first record`; `00:03:08.220 WARN HaplotypeCallerEngine - Multiple valid VCF records detected in the alleles input file at site 22:16464051-16464051, only considering the first record`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:5091,error,error,5091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['error'],['error']
Availability,t org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:5036,ERROR,ERROR,5036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13577,error,error,13577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,2,['error'],['error']
Availability,"t org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); Caused by: com.intel.genomicsdb.GenomicsDBException: Could not load genomicsdb native library; 	at com.intel.genomicsdb.GenomicsDBImporter.<clinit>(GenomicsDBImporter.java:72); 	... 37 more; ```. if you dig into it more you get down to the following error:; ```; /private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib: dlopen(/private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib, 1): ; Library not loaded: /opt/local/lib/libuuid.16.dylib; Referenced from: /private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib; Reason: image not found; ```. It seems like there is a dylib included correctly in the jar, but it's looking for libuuid.16.dylib at runtime. libuuid.16.dylib needs to be statically linked into the GenomicsDB lib.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062:3232,down,down,3232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062,2,"['down', 'error']","['down', 'error']"
Availability,t&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkxpa2VsaWhvb2RzLmphdmE=) | `100.000% <0.000%> (√∏)` | |; | [...s/solver/SynchronizedUnivariateSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlclVuaXRUZXN0LmphdmE=) | | |; | [...bender/utils/solver/RobustBrentSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXJVbml0VGVzdC5qYXZh) | | |; | [...ute/hellbender/utils/solver/RobustBrentSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXIuamF2YQ==) | | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlclNwZWNpZmljYXRpb25zLmphdmE=) | | |; | [...der/utils/solver/SynchronizedUnivariateSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988:3820,Robust,RobustBrentSolver,3820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988,1,['Robust'],['RobustBrentSolver']
Availability,"t-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz; 14:13:54.570 INFO FeatureManager - Using codec IntervalListCodec to read file gs://fc-secure-76d1542e-1c49-4411-8268-e41e92f9f311/729d209c-0ef4-409f-b3af-2e84ff45ee36/omics_mutect2/16911ef5-efb2-4e12-86f2-f3d5a54b28c0/call-mutect2/Mutect2/4e4a27e2-6c57-40e9-8ddc-1024bdcc50c1/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list; 14:13:55.076 INFO IntervalArgumentCollection - Processing 308828640 bp from intervals; 14:13:55.233 INFO Mutect2 - Done initializing engine; 14:13:56.023 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:13:56.039 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:13:56.116 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:13:56.122 INFO IntelPairHmm - Available threads: 1; 14:13:56.123 INFO IntelPairHmm - Requested threads: 4; 14:13:56.123 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 14:13:56.127 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:13:56.302 WARN Mutect2 - Note that the Mutect2 reference confidence mode is in BETA -- the likelihoods model and output format are subject to change in subsequent versions.; 14:13:56.492 INFO ProgressMeter - Starting traversal; 14:13:56.493 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:14:08.796 INFO ProgressMeter - chr1:16085 0.2 60 292.6; 14:14:09.377 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.008674977; 14:14:09.378 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.28976746200000003; 14:14:09.378 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1.41 sec; 14:14:09.384 INFO Mutect2 - Shutting down engine; [May 13, 20",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:3647,Avail,Available,3647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['Avail'],['Available']
Availability,"t.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; 21/04/13 07:32:25 INFO DAGScheduler: Job 2 failed: runJob at SparkHadoopWriter.scala:78, took 0.365288 s; 21/04/13 07:32:25 ERROR SparkHadoopWriter: Aborting job job_20210413073224_0026.; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:13875,ERROR,ERROR,13875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['ERROR'],['ERROR']
Availability,"t2Engine.callRegion(Mutect2Engine.java:251); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```; I downloaded the file from gnomAD repository (""All chromosomes VCF""), but had to do some changes, as follow:; 1. Lifted over to hg19, by using [b37tohg19.chain](https://github.com/broadgsa/gatk/blob/master/public/chainFiles/b37tohg19.chain) by using:; ```; sudo java -jar /picard-2.21.3/picard.jar LiftoverVcf I=gnomad.exomes.r2.1.1.sites.vcf.bgz \; O=gnomad.exomes_hg19.r2.1.1.sites.vcf.bgz \; CHAIN=b37tohg19.chain REJECT=rejected_variants.vcf \; R=/reference/hg19/hg19.fa \; ALLOW_MISSING_FIELDS_IN_HEADER=true \; MAX_RECORDS_IN_RAM=100000; ```; 2. Got rid of the [chrN_random tables](http://genome.ucsc.edu/FAQ/FAQdownloads#download10) by manually deleting them from the header of ```ExAC_hg19.r1.sites.vep.vcf.gz``` and creating a new file with just the new header, ```header_hg19_Ion.vcf```; and. 3. Fixed the header by using:; ```; java -jar picard.jar FixVcfHeader I=/gatk_data/reference/gnomAD/gnomad.exomes_hg19.r2.1.1.sites.vcf.bgz \; O=/gatk_data/reference/gnomAD/gnomad.exomes_hg19_Ion.r2.1.1.sites.vcf.bgz \; HEADER=/gatk_data/referen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568:3089,down,downloaded,3089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568,1,['down'],['downloaded']
Availability,t; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4331864Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:16625,error,error,16625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"t; > 12:28:28.866 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 12:28:31.215 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/hgnc_download_Nov302017.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/hgnc/hg38/hgnc_download_Nov302017.tsv; > 12:28:31.563 INFO Funcotator - Initializing Funcotator Engine...; > 12:28:31.593 INFO Funcotator - Creating a VCF file for output: file:/home/pkus/mutect_test/filtered_variants/P1.avcf.gz; > 12:28:31.731 INFO ProgressMeter - Starting traversal; > 12:28:31.731 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 12:28:31.969 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; > 12:28:31.975 INFO Funcotator - Shutting down engine; > [July 21, 2020 12:28:31 PM CEST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.26 minutes.; > Runtime.totalMemory()=2200961024; > org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: NCRNA00115; > at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotationsOnVariant(CosmicFuncotationFactory.java:320); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:245); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:173); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:17023,down,down,17023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['down'],['down']
Availability,tCollection - Processing 170805979 bp from intervals; 10:29:22.613 INFO Mutect2 - Done initializing engine; 10:29:22.622 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:29:22.688 INFO ProgressMeter - Starting traversal; 10:29:22.688 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:29:32.698 INFO ProgressMeter - 6:378640 0.2 1420 8512.3; 10:29:42.723 INFO ProgressMeter - 6:1034304 0.3 3810 11410.0; 10:29:52.736 INFO ProgressMeter - 6:1705479 0.5 6270 12520.4; 10:30:02.745 INFO ProgressMeter - 6:2543064 0.7 9270 13885.2; 10:30:12.776 INFO ProgressMeter - 6:3144654 0.8 11520 13799.7; 10:30:22.791 INFO ProgressMeter - 6:3912571 1.0 14330 14305.4; 10:30:32.792 INFO ProgressMeter - 6:4678136 1.2 17120 14652.7; 10:30:42.803 INFO ProgressMeter - 6:5436632 1.3 19900 14903.6; 10:30:52.831 INFO ProgressMeter - 6:6213304 1.5 22710 15116.0; 10:31:02.837 INFO ProgressMeter - 6:7019025 1.7 25670 15379.2; 10:31:12.906 INFO ProgressMeter - 6:7571523,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7032:4189,Avail,Available,4189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032,1,['Avail'],['Available']
Availability,"tConfiguration$0(LoggerContext.java:620); at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660); at org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:620); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:699); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:716); at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1; Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.6.1-local.jar -version; ```. This request was created from a contribution made by Pryce Turner on July 29, 2022 03:44 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--Could-not-determine-local-host-name-#community\_comment\_7692552841755](https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:1615,failure,failure,1615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['failure'],['failure']
Availability,"tFiltration - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 12:01:06.399 INFO VariantFiltration - Start Date/Time: November 15, 2020 12:01:06 MST PM; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - HTSJDK Version: 2.23.0; 12:01:06.400 INFO VariantFiltration - Picard Version: 2.22.8; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:01:06.400 INFO VariantFiltration - Deflater: IntelDeflater; 12:01:06.400 INFO VariantFiltration - Inflater: IntelInflater; 12:01:06.400 INFO VariantFiltration - GCS max retries/reopens: 20; 12:01:06.400 INFO VariantFiltration - Requester pays: disabled; 12:01:06.400 INFO VariantFiltration - Initializing engine; 12:01:06.830 INFO FeatureManager - Using codec VCFCodec to read file file:///work/mtgraovac_lab/matthew/c_elegans/COOVAR/VCFS/haplotypecaller.vcf; 12:01:06.851 INFO VariantFiltration - Done initializing engine; 12:01:06.928 INFO ProgressMeter - Starting traversal; 12:01:06.928 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:01:07.147 INFO ProgressMeter - unmapped 0.0 926 253698.6; 12:01:07.147 INFO ProgressMeter - Traversal complete. Processed 926 total variants in 0.0 minutes.; 12:01:07.172 INFO VariantFiltration - Shutting down engine; [November 15, 2020 12:01:07 MST PM] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=209715200. ```. However, the same record remains in the output file, despite it's `MQ=30.51`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6960:3782,down,down,3782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960,1,['down'],['down']
Availability,"tHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:7328,AVAIL,AVAILABLE,7328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"tHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7944,AVAIL,AVAILABLE,7944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"tHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47400,AVAIL,AVAILABLE,47400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"tPercentileThreshold 2.5 --truncatePercentileThreshold 0.1 --numberOfEigensamples auto --noQC false --dryRun false --sparkMaster local[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [June 23, 2017 6:54:00 PM UTC] Executing as root@b4f42b5ba157 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_91-8u91-b14-1~bpo8+1-b14; Version: 4.alpha.2-1134-ga9d9d91-SNAPSHOT; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; [June 23, 2017 6:54:09 PM UTC] org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormals done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=1400373248; ***********************************************************************. A USER ERROR has occurred: Bad input: The number of zeros per count column is too large resulting in all count columns to be dropped. ***********************************************************************; Use -DSTACK_TRACE_ON_USEREXCEPTION to print the stack trace.; ```. I am running the tool with parameters that should be the standard, i.e. with QC, unlike the settings in our repo's WDL scripts ([WDL](https://github.com/broadinstitute/gatk/blob/502fd4119ebde964d24d39aafd1b7346ac5d84d5/scripts/cnv_wdl/somatic/cnv_somatic_panel_workflow.wdl#L137), [JSON](https://github.com/broadinstitute/gatk/blob/56e6baa79b4e56ebee5fb8d2b2288373a4269fa8/scripts/cnv_cromwell_tests/somatic/cnv_somatic_panel_wes_workflow.json#L9)). The command I use is:; ```; 	command {; 	/usr/shlee/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch \; 		--javaOptions ""-Xmx16g"" \; 		CreatePanelOfNormals \; 	-I ${combined_coverage} \; 	-O ${basename}.pon ${additional_options} \; 	--disableSpark; 	}; ```. Where there are no additional options. ---; The coverage counts were processed with",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3163:2306,ERROR,ERROR,2306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163,1,['ERROR'],['ERROR']
Availability,"tPileupSummaries -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GetPileupSummaries is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:35:17.121 INFO GetPileupSummaries - Initializing engine; 14:35:17.456 INFO FeatureManager - Using codec VCFCodec to read file file:///gatk/data/gnomad/vcf/genomes/liftover_grch38/gnomad.b38.biallelic_only.concat.sorted.filtered.vcf.gz; 14:35:17.586 INFO FeatureManager - Using codec VCFCodec to read file file:///gatk/data/gnomad/vcf/genomes/liftover_grch38/gnomad.b38.biallelic_only.concat.sorted.filtered.vcf.gz; 16:39:08.359 INFO IntervalArgumentCollection - Processing 236373212 bp from intervals; 16:41:01.520 INFO GetPileupSummaries - Done initializing engine; 16:41:01.521 INFO ProgressMeter - Starting traversal; 16:41:01.521 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; 02:44:42.116 INFO GetPileupSummaries - Shutting down engine; [April 25, 2019 2:44:42 AM UTC] org.broadinstitute.hellbender.tools.walkers.contamination.GetPileupSummaries done. Elapsed time: 729.42 minutes.; Runtime.totalMemory()=23243784192; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.grow(ArrayList.java:265); at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239); at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231); at java.util.ArrayList.add(ArrayList.java:462); at htsjdk.samtools.BinningIndexContent.getChunksOverlapping(BinningIndexContent.java:131); at htsjdk.samtools.CachingBAMFileIndex.getSpanOverlapping(CachingBAMFileIndex.java:75); at htsjdk.samtools.BAMFileReader.getFileSpan(BAMFileReader.java:935); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:952); at htsjdk.samtools.BAMFileReader.query(BAMFileReader.java:612); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5918:3150,down,down,3150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5918,1,['down'],['down']
Availability,"tPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-890235307]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:179); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 50 more; ```. I'll rerun without using NIO for the dbsnp vcf and I'll try to look through the other 7 error messages to see if anything is different from those above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:15790,error,error,15790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,1,['error'],['error']
Availability,tReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: org.broadinstitute.hellbender.exceptions.UserException: Failed to create reader from gs://fc-c64a0fcd-fb30-4a7e-bdc6-3c09a9286941/f6aeb0ce-044a-4b36-a5f0-d3fda62252a5/ReblockGVCF/66c24439-cfeb-4b85-bc02-aefe693177b6/call-GenotypeGVCF/NWD197223.vcf.gz; 	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); 	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); 	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: org.broadinstitute.hellbender.exceptions.UserException: Failed to create reader from gs://fc-c64a0fcd-fb30-4a7e-bdc6-3c09a9286941/f6aeb0ce-044a-4b36-a5f0-d3fda62252a5/ReblockGVCF/66c24439-cfeb-4b85-bc02-aefe693177b6/call-GenotypeGVCF/NWD197223.vcf.gz; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.lambda$getFeatureReadersInParallel$601(GenomicsDBImport.java:605); 	at java.util.LinkedHashMap.forEach(LinkedHashMap.java:684); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReadersInParallel(GenomicsDBImport.java:600); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.createSampleToReaderMap(GenomicsDBImport.java:491); 	at com.intel.genomicsdb.importer.GenomicsDBImporter.lambda$null$2(GenomicsDBImporter.java:602); 	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590); 	... 3 more; Caused by: java.util.concurrent.ExecutionException: org.broadinstitute,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423:1267,Error,Error,1267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423,2,"['Error', 'Failure']","['Error', 'Failure']"
Availability,"tUtils.java:103); ... 16 more. 01:44 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:39 INFO TaskSetManager: Starting task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:56:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:35903 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:39 INFO TaskSetManager: Lost task 1.3 in stage 2.0 (TID 10) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 18/04/24 17:56:39 ERROR TaskSetManager: Task 1 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:56:39 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 45.219 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:34996,failure,failure,34996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['failure'],['failure']
Availability,"t_gatk_variantEval.txt`. I got the following error; ```; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: VariantEval is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:37:10.767 INFO VariantEval - Initializing engine; 14:37:11.138 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/justinzhang/daiichi/SimpleExample.vcf.gz; 14:37:11.268 INFO VariantEval - Done initializing engine; 14:37:11.278 INFO VariantEval - Creating 3 combinatorial stratification states; 14:37:11.281 INFO ProgressMeter - Starting traversal; 14:37:11.282 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:37:11.454 INFO ProgressMeter - unmapped 0.0 250 87719.3; 14:37:11.454 INFO ProgressMeter - Traversal complete. Processed 250 total variants in 0.0 minutes.; 14:37:11.454 INFO VariantEval - Finalizing variant report; 14:37:11.455 INFO VariantEval - Shutting down engine; [October 11, 2019 2:37:11 PM EDT] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=386924544; **java.lang.NullPointerException**; 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.getnProcessedLoci(VariantEval.java:822); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.CountVariants.finalizeEvaluation(CountVariants.java:184); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.onTraversalSuccess(VariantEval.java:709); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1050); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Mai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6212:1057,down,down,1057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6212,1,['down'],['down']
Availability,"t` without the lfs files, an error code is thrown from within BWA causing the test suite to fail. . Error and Stack Trace:. ...; 11:54:40.426 [ERROR] [system.err] [bwt_restore_sa] SA-BWT inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1041,ERROR,ERROR,1041,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"ta--broad-references/hg38/v0/Homo_sapiens_assembly38.{} | \; gsutil -m cp -I .; ```. Run FastqToSam with the `-SORT_ORDER ""unsorted""` option:; ```; gatk-4.2.1.0/gatk \; FastqToSam \; -FASTQ R1.fastq.gz \; -FASTQ2 R2.fastq.gz \; -OUTPUT unmapped.bam \; -SAMPLE_NAME SM \; -SORT_ORDER ""unsorted""; ```; Notice the option `-SORT_ORDER ""unsorted""` which prevents the tool from resorting the reads which can add both computational and storage requirements. Aligned the data with bwa:; ```; gatk-4.2.1.0/gatk \; SamToFastq \; -INPUT unmapped.bam \; -FASTQ /dev/stdout \; -INTERLEAVE true | \; bwa mem -K 100000000 -p -v 3 -t 16 -Y Homo_sapiens_assembly38.fasta /dev/stdin | \; samtools view -1 - > aligned.unmerged.bam; ```. Merge unmapped and aligned BAMs:; ```; gatk-4.2.1.0/gatk \; MergeBamAlignment \; -ALIGNED_BAM aligned.unmerged.bam \; -UNMAPPED_BAM unmapped.bam \; -OUTPUT aligned.unsorted.bam \; -SORT_ORDER ""unsorted"" \; -REFERENCE_SEQUENCE \; Homo_sapiens_assembly38.fasta; ```. This produces the error:; ```; java.lang.IllegalStateException: Aligned record iterator (NB500989:333:HKYJNAFX2:1:11101:10000:1915) is behind the unmapped reads (NB500989:333:HKYJNAFX2:1:11101:24447:1024); 	at picard.sam.AbstractAlignmentMerger.mergeAlignment(AbstractAlignmentMerger.java:557); 	at picard.sam.SamAlignmentMerger.mergeAlignment(SamAlignmentMerger.java:186); 	at picard.sam.MergeBamAlignment.doWork(MergeBamAlignment.java:368); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:308); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:37); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Despite the fact that option `-SORT_ORDER ""unsorted""` is being used and the two BAM files have the reads in the same order:; ```; $ samtools view unmapped.b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:2960,error,error,2960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,1,['error'],['error']
Availability,"taflow.readers.bam.SeekableGCSStream: Creating SeekableGCSStream: gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:53 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: uriToStorageObject mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai=mw-pathseq-test:hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.BAMIO: No index for gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: Creating SeekableGCSStream: gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: uriToStorageObject mw-pathseq-test/hs37d5cs.reads.sorted.bam=mw-pathseq-test:hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO org.spark_project.jetty.server.ServerConnector: Stopped ServerConnector@5148cf20{HTTP/1.1}{0.0.0.0:4040}; 21:42:54.861 INFO PrintReadsSpark - Shutting down engine; [February 6, 2017 9:42:54 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=573571072; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:376); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:357); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:6528,down,down,6528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['down'],['down']
Availability,"tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5568,ERROR,ERROR,5568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6920,ERROR,ERROR,6920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:7010,ERROR,ERROR,7010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:7100,ERROR,ERROR,7100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:7190,ERROR,ERROR,7190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:7280,ERROR,ERROR,7280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8363,ERROR,ERROR,8363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8453,ERROR,ERROR,8453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,taminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:6466,Error,ErrorProbabilities,6466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Error'],['ErrorProbabilities']
Availability,taminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:2020,Error,ErrorProbabilities,2020,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['Error'],['ErrorProbabilities']
Availability,"tarted o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 INFO client.RMProxy: Connecting to ResourceManager at tele-1/192.168.1.4:8032; 18/01/09 18:30:57 INFO yarn.Client: Requesti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9936,AVAIL,AVAILABLE,9936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"tations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 09:01:26.067 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to -0.0 for reference-model confidence output; 09:01:26.067 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 09:01:26.077 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ywt/anaconda3/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:01:26.078 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ywt/anaconda3/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:01:26.089 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:01:26.089 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:01:26.090 INFO IntelPairHmm - Available threads: 36; 09:01:26.090 INFO IntelPairHmm - Requested threads: 4; 09:01:26.090 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:01:26.121 INFO ProgressMeter - Starting traversal; 09:01:26.121 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 09:01:26.406 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position 1A:145 and possibly subsequent; at least 10 samples must have called genotypes; 09:01:33.373 WARN DepthPerSampleHC - Annotation will not be calculated at position 1A:1702502 and possibly subsequent; genotype for sample SRR9851087 is not called; 09:01:33.374 WARN StrandBiasBySample - Annotation will not be calculated at position 1A:1702502 and possibly subsequent; genotype for sample SRR9851087 is not called; 09:01:36.316 INFO ProgressMeter - 1A:2054431 0.2 7310 43025.3; 09:01:46.831 INFO ProgressMeter - 1A:3580946 0.3 12960 37547.1; 09:01:56.858 INFO ProgressMeter - 1A:4888",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192:4014,Avail,Available,4014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192,1,['Avail'],['Available']
Availability,te VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 01:30:20.227 INFO GenomicsDBImport - Shutting down engine; [10 December 2021 01:30:20 UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 7.76 minutes.; Runtime.totalMemory()=16078340096; ```. #### Steps to reproduce. Not sure if it reproducible with any particular imput... it seems that one has to simulate the IO errors for example by using a nearly full storage for the output or create so,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:4581,error,error,4581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['error'],['error']
Availability,"te(ResolveCachingStateStep.java:90); at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:48); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:69); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/usr/bin/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973:12449,error,error,12449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973,2,['error'],['error']
Availability,"te). Strands of the intervals indicate whether the distal target intervals are; * upstream or downstream of their proposed breakpoints: true indicates that the breakpoint is upstream of the interval; * start position; false indicates that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstream of the interval end. . - I created `StrandedInterval` mostly just as a data container since I was often passing around an interval and an associated strand, and using them in conjunction with the `PairedStrandedIntervalTree` data structure. My goal with those was to have them be utility classes that could be used by anyone without regards to the particular mechanics of imprecise evidence clustering I've implemented here. I'd prefer to put the definition of how we're interpreting the interval and strand in our logic classes (`BreakpointEvidence`, `EvidenceTargetLink`, and EvidenceTargetLinkClusterer`). Does that make sense?. - A ""distal target region"" can be represented by a `StrandedInterval`. So can the original, proximal (non-distal) location of the breakpoint evidence. An `EvidenceTargetLink` has the two `StrandedInterval` objects representing the proximal and distal loca",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:1992,down,downstream,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,2,['down'],['downstream']
Availability,te/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1375,avail,available,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['avail'],['available']
Availability,tect2 - Processing assembly region at chrM:13945-14244 isActive: false numReads: 54745; 12:13:56.962 DEBUG Mutect2 - Processing assembly region at chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false numReads: 0; 12:13:57.009 DEBUG Mutect2 - Processing assembly region at chrM:15445-15744 isActive: false numReads: 0; 12:13:57.027 INFO ProgressMeter - chrM:15445 38.3 60 1.6; 12:13:57.035 DEBUG Mutect2 - Processing assembly region at chrM:15745-15960 isActive: false numReads: 14; 12:13:57.047 DEBUG Mutect2 - Processing assembly region at chrM:15961-16230 isActive: true numReads: 30; 12:13:57.055 DEBUG ReadThreadingGraph - Recovered 1 of 1 dangling tails; 12:13:57.063 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 12:13:57.096 DEBUG ReadThreadingGraph - Recovered 3 of 3 dangling tails; 12:13:57.106 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling heads; 12:13:57.464 DEBUG Mutect2Engine - Active Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter ; 0 read(s) filtered by: NonChimericOriginalAli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:22274,Recover,Recovered,22274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"tect2/vcf --f1r2-tar-gz f1r2.tar.gz --native-pair-hmm-threads 4 --bam-output tumor.recalibrated.realigned.bam --add-output-sam-program-record false -bam-output. The log of the command that generated the error was :. Using GATK jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar. Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar FilterAlignmentArtifacts --variant tumor.recalibrated.filtered.vcf --input tumor.recalibrated.realigned.bam --reference /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/genome/Homo_sapiens.UCSC.hg38.fa --bwa-mem-index-image /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/bwa_index_img/Homo_sapiens.UCSC.hg38.img --output tumor.recalibrated.filtered2.vcf --bam-output tumor.recalibrated.realigned2.bam --verbosity ERROR --tmp-dir TMP --QUIET true. 14:38:44.077 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_utils.so. 14:38:44.103 INFO SmithWatermanAligner - AVX accelerated SmithWaterman implementation is not supported, falling back to the Java implementation. java.lang.IllegalArgumentException: Program record with group id HalpotypeBAMWriter already exists in SAMFileHeader!. at htsjdk.samtools.SAMFileHeader.addProgramRecord(SAMFileHeader.java:202). at htsjdk.samtools.SAMTextHeaderCodec.parsePGLine(SAMTextHeaderCodec.java:158). at htsjdk.samtools.SAMTextHeaderCodec.decode(SAMTextHeaderCodec.java:107). at htsjdk.samtools.SAMFileHeader.clone(SAMFileHeader.java:398). at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriterFromFactory(ReadUtils.java:1215). at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriter(ReadUtils.java:1163). at org.broadinstitute.he",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6287:1624,ERROR,ERROR,1624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6287,1,['ERROR'],['ERROR']
Availability,"ted o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-pac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9265,AVAIL,AVAILABLE,9265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-05-04T18:26:42.379437"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535220790:10803,error,errors,10803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535220790,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-05-12T15:09:42.984289"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1545896607:10803,error,errors,10803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1545896607,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-05-15T22:38:43.733338"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1548708498:10803,error,errors,10803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1548708498,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-05-16T17:15:43.799702"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550066071:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550066071,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-06-02T17:26:47.097005"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574076227:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574076227,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-08-18T19:32:11.841274"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684352689:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684352689,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-08-21T22:38:12.285936"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687151782:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687151782,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-12-09T01:13:16.103312"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1848056937:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1848056937,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-12-09T19:10:16.577710"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1848617792:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1848617792,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-12-18T13:56:16.652540"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1860567595:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1860567595,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2023-12-18T13:57:17.644601"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1860569901:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1860569901,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-01-02T16:15:20.291629"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1874234666:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1874234666,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-01-09T19:30:21.598706"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1883655550:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1883655550,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-01-17T15:15:22.890873"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1896021617:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1896021617,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-01-18T17:19:23.445107"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1898900961:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1898900961,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-01-19T16:18:28.029576"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1900708597:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1900708597,1,['error'],['errors']
Availability,"ted.NIST_evalRuntimeSummaries"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_runtimes"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcf"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_evalVcfIndex"": ""test_output:VariantCallingCarrotOrchestrated.NIST_output_vcf_index"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthLabel"": ""HG002_GRCh38_GIAB"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcf"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz"",; ""BenchmarkVCFsHeadToHeadOrchestrated.NIST_truthVcfIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HG002_GRCh38_GIAB_1_22_v4.2.1_benchmark.broad-header.vcf.gz.tbi"",; ""BenchmarkVCFsHeadToHeadOrchestrated.hapMap"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.haplotype_database.txt"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refDict"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.dict"",; ""BenchmarkVCFsHeadToHeadOrchestrated.refIndex"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta.fai"",; ""BenchmarkVCFsHeadToHeadOrchestrated.reference"": ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/Homo_sapiens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": null,; ""eval_cromwell_job_id"": null,; ""created_at"": ""2024-06-05T12:54:29.059343"",; ""created_by"": null,; ""finished_at"": null,; ""results"": null,; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2149793367:10761,error,errors,10761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2149793367,1,['error'],['errors']
Availability,ted.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL. Command exit status:; 3. Command output:; (empty). Command error:; 23:21:52.354 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:22:02.735 INFO ProgressMeter - chr6:1162012 0.2 25000 144494.8; 23:22:12.789 INFO ProgressMeter - chr6:2449556 0.3 53000 155623.0; 23:22:23.019 INFO ProgressMeter - chr6:3663394 0.5 82000 160448.7; 23:22:33.257 INFO ProgressMeter - chr6:4991347 0.7 112000 164291.1; 23:22:43.683 INFO ProgressMeter - chr6:6325045 0.9 141000 164832.0; 23:22:53.824 INFO ProgressMeter - chr6:7646289 1.0 171000 166913.4; 23:23:03.973 INFO ProgressMeter - chr6:9029926 1.2 200000 167553.3; 23:23:14.220 INFO ProgressMeter - chr6:10374988 1.4 229000 167835.2; 23:23:24.322 INFO ProgressMeter - chr6:11782077 1.5 259000 168971.8; 23:23:34.465 INFO ProgressMeter - chr6:13360174 1.7 290000 170404.5; 23:23:44.556 INFO ProgressMeter - chr6:14757971 1.9 319000 170585.2; 23:23:54.657 INFO ProgressMeter - chr6:16217652 2.0 350000 171704.7; 23:24:04.905 INFO ProgressMeter - chr6:17737681 2.2 381000 172461.9; 23:24:15.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:2186,error,error,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['error'],['error']
Availability,"telInflater; 15:46:27.296 INFO BaseRecalibrator - GCS max retries/reopens: 20; 15:46:27.296 INFO BaseRecalibrator - Requester pays: disabled; 15:46:27.297 INFO BaseRecalibrator - Initializing engine; 15:46:28.062 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/dbsnp_146.hg38.vcf; 15:46:28.075 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf; 15:46:28.127 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:46:28.213 INFO BaseRecalibrator - Done initializing engine; 15:46:28.216 INFO BaseRecalibrator - Shutting down engine; [2021Âπ¥1Êúà8Êó• ‰∏ãÂçà03Êó∂46ÂàÜ28Áßí] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.52 minutes.; Runtime.totalMemory()=1488977920; ***********************************************************************. A USER ERROR has occurred: Number of read groups must be >= 1, but is 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Number of read groups must be >= 1, but is 0; 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.<init>(BaseRecalibrationEngine.java:96); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.onTraversalStart(BaseRecalibrator.java:144); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7031:4031,ERROR,ERROR,4031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031,1,['ERROR'],['ERROR']
Availability,"ten to gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/callset.json; 14:26:53.640 INFO GenomicsDBImport - Complete VCF Header will be written to gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/vcfheader.vcf; 14:26:53.640 INFO GenomicsDBImport - Importing to workspace - gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50; 14:26:56.113 INFO GenomicsDBImport - Starting batch input file preload; 14:26:57.968 INFO GenomicsDBImport - Finished batch preload; 14:26:57.968 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 15:59:12.833 INFO GenomicsDBImport - Done importing batch 5/6; 15:59:12.833 INFO GenomicsDBImport - Starting batch input file preload; 15:59:13.218 INFO GenomicsDBImport - Finished batch preload; 15:59:13.218 INFO GenomicsDBImport - Importing batch 6 with 14 samples; [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB, try increasing TILEDB_UPLOAD_BUFFER_SIZE to at least 5MB path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (gzip_write_buffer) Cannot write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (write_buffer) Cannot compress and/or write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; 16:39:59.490 INFO GenomicsDBImport - Done importing batch 6/6; 16:40:00.293 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 16:40:00.293 INFO GenomicsDBImport - Shutting down engine; [January 27, 2022 at 4:40:00 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 133.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:5811,Error,Error,5811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,1,['Error'],['Error']
Availability,"ter'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:2440,ERROR,ERROR,2440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['ERROR'],['ERROR']
Availability,ter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:3361,ERROR,ERROR,3361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"ter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. 21/04/13 07:32:25 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:61",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:11337,failure,failure,11337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['failure'],['failure']
Availability,"ter: IntelDeflater; 12:01:18.571 INFO ¬†GenotypeGVCFs - Inflater: IntelInflater; 12:01:18.571 INFO ¬†GenotypeGVCFs - GCS max retries/reopens: 20; 12:01:18.571 INFO ¬†GenotypeGVCFs - Requester pays: disabled; 12:01:18.571 INFO ¬†GenotypeGVCFs - Initializing engine; 12:01:19.353 INFO ¬†GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 12:01:33.262 INFO ¬†NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field InbreedingCoeff ¬†- the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO ¬†NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAC ¬†- the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO ¬†NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAF ¬†- the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.288 INFO ¬†GenotypeGVCFs - Shutting down engine; [March 1, 2024 at 12:01:33 PM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.25 minutes.; Runtime.totalMemory()=1130364928; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. ¬†; content of my callset.json file:. {""callsets"": [{""sample_name"": ""ERR318225"",""row_idx"": 223,""idx_in_file"": 0,""stream_name"": ""ERR318225_stream""},{""sample_name"": ""ERR318226"",""row_idx"": 224,""idx_in_file"": 0,""stream_name"": ""ERR318226_stream""},{""sample_name"": ""ERR4133262"",""row_idx"": 225,""idx_in_file"": 0,""stream_name"": ""ERR4133262_stream""},{""sample_name"": ""ERR4133361"",""row_idx"": 226,""idx_in_file"": 0,""stream_name"": ""ERR4133361_stream""},{""sample_name"": ""ERR4133400"",""row_idx"": 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:4986,down,down,4986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['down'],['down']
Availability,ter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.run(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; Use `git lfs logs last` to view the log.; portage$ cat /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; git-lfs/2.3.4 (GitHub; linux amd64; go 1.10); git version 2.16.3. $ git-lfs pull --include src/main/re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:14431,ERROR,ERROR,14431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,ter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InPr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:6944,ERROR,ERROR,6944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,ternal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:5888,ERROR,ERROR,5888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,ternal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:11460,ERROR,ERROR,11460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,ternal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:10202,ERROR,ERROR,10202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"ters/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annot",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:7523,error,error,7523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"ters/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annot",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:9561,error,error,9561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,tervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR. ¬† ; ; c) Entire program log:. Using GATK jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar. Running:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR. 15:30:47.303 info NativeGenomicsDB - pid=135716 tid=135717 No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records. 15:30:47.303 info NativeGenomicsDB - pid=135716 tid=135717 No valid combination operation found for INFO field HaplotypeScore - the field will NOT be part of INFO fields in the generated VCF records. 15:30:47.303 info NativeGenomicsDB - pid=135716 tid=135717 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records. 15:30:47.303 info NativeGenomicsDB - pid=135716 tid=135717 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records. 15:30:47.303 info NativeGenomicsDB - pid=135716 tid=135717 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO f,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966:2897,ERROR,ERROR,2897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966,1,['ERROR'],['ERROR']
Availability,"test version of GATK, it seems like there are no other solutions. I was wondering that how do I fix the issues with GATK 4.0.3.0? Does anyone have a better solution?. I also tried GenotypeGVCFs in GATK 4.2.1.0, but there is a problem in terms of MQ calculation. So I think it's better to stick to the same GATK version in the whole workflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced with an older version of GATK. ; ; Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. ; ; There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. Another question is related to the fasta file:. I downloaded the reference data in the link of [https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37](https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37)¬†, when I noticed that this is an old database, I have already generated GVCF files. It seems like GenotypeGVCFs does not understand the FAI index file. error informaion; ================. \[E::fai\_read\] Could not understand FAI /home/users/nus/bizszl/scratch/WES-new/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta.fai line 1 ; ; \[E::fai\_load3\] Failed to read FASTA index /home/users/nus/bizszl/scratch/WES-new/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta.fai. FAI file; ========. 1 dna:chromosome chromosome:GRCh37:1:1:249250621:1 249250621 52 60 61 ; ; 2 dna:chromosome chromosome:GRCh37:2:1:243199373:1 243199373 253404903 60 61 ; ; 3 dna:chromosome chromosome:GRCh37:3:1:198022430:1 198022430 500657651 60 61 ; ; 4 dna:chromosome chromosome:GRCh37:4:1:191154276:1 191154276 701980507 60 61 ; ; 5 dna:chromosome chromosom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:6557,down,downloaded,6557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['down'],['downloaded']
Availability,tests using the commandline. Removing error codes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/76:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/76,1,['error'],['error']
Availability,"tf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 15:16:54.876 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/achilles_lineage_results.import.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/achilles/hg38/achilles_lineage_results.import.txt; > 15:16:54.881 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:14549,error,errors,14549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['error'],['errors']
Availability,"th_HC/bams/IND2/UDP3478_1.forGATK.bam -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND3/UDP4031_1.forGATK.bam -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND4/UDP4032_1.forGATK.bam -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND5/UDP4033_1.forGATK.bam -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND6/UDP4573_1.forGATK.bam -dcov 200 -minPruning 4 -o /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/eflynn90-test.vcf -L /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/intervals.vcf -stand_emit_conf 10 -pedValidationType SILENT; ```. ---. @eitanbanks said:. Updated command-line:. ```; java -Xmx6g -jar dist/GenomeAnalysisTK.jar -T HaplotypeCaller -R /humgen/1kg/reference/hs37d5.fasta -I /humgen/gsa-scr1/vdauwera/userfiles/Downsampling_with_HC/bams/IND1/UDP2731_1.forGATK.bam -dcov 200 -minPruning 4 -L 1:14464; ```. I can confirm that it appears that down-sampling is not working for the Haplotype Caller (when run through the Unified Genotyper the down-sampling works just fine).; I see in SAMDataSource line 668 that assumeDownstreamLIBSDownsampling is being set to true. But then it doesn't look like LIBS is actually down-sampling. Don't have time to debug more so passing on to David. ---. @droazen said (over multiple comments):. I am looking into this. LIBS is actually calling into the downsamplers correctly in the test case that Eric provided. You can see this by examining readStates.size() for each locus -- it never exceeds the -dcov target of 200. The problem must lie elsewhere -- I'll continue to step through this in the debugger. [...]. After some more debugging and consultation with Ryan, I've found that DP values exceeding dcov are to be expected given the way the ActiveRegion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the un",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:1651,down,down-sampling,1651,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,2,['down'],['down-sampling']
Availability,"the current repo we are using seems to be down, changing to a different one to unblock us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3443:42,down,down,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443,1,['down'],['down']
Availability,"the first commit is the fix, the second is a deliberate test failure so we can validate that the fix works when the tests fail",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5108:61,failure,failure,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5108,1,['failure'],['failure']
Availability,the following:. ```; 2022-08-16T00:09:07.2545204Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2547467Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.2647018Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2671678Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:1336,error,error,1336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"the google genomics API has deprecated all the features we were using,; this includes the reference lookup api, and the google Read data types. removing all google genomics related dependencies; * replacing com.google.cloud.genomics:gatk-tools-java:1.1 with gov.nist.math.jama:gov.nist.math.jama:1.1.1; 	we rely on this transitive dependency, making it a direct dependency instead; * remove com.google.apis:google-api-services-genomics:v1-rev527-1.22.0; * remove com.google.cloud.genomics:google-genomics-utils:v1-0.10. * delete ReferenceAPISource and tests; * delete GoogleGenomicsReadToGATKReadAdapter and tests; * delete CigarConversionUtils and tests. * update other classes to remove references to these types; * improve an error message",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4266:729,error,error,729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4266,1,['error'],['error']
Availability,"the invalid reads strikes back - i got this when running the ReadsPipelineSpark on qurynamesorted file `hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam`:. ```; Job aborted due to stage failure: Task 47 in stage 2.0 failed 4 times, most recent failure: Lost task 47.3 in stage 2.0 (TID 680, dataflow05.broadinstitute.org): java.lang.IllegalArgumentException: ; Invalid interval. Contig:20 start:62720124 end:62720123; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:34); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:46); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.lambda$join$3d1c3858$1(BroadcastJoinReadsWithVariants.java:27); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:28); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1560:210,failure,failure,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1560,2,['failure'],['failure']
Availability,the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeEx,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:1876,Failure,Failure,1876,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['Failure'],['Failure']
Availability,"there is one bug commented out in ValidateSamFileIntegrationTest. The issue is https://github.com/samtools/htsjdk/issues/369, the fix is in https://github.com/samtools/htsjdk/pull/368. SamFileValidator throws NPE on a CRAM file with an invalid sort order. Once that fix is available we can uncomment the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1138:273,avail,available,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138,1,['avail'],['available']
Availability,"there was a memory overflow error (either using -Xmx20G/100G/800G with 1TB of physical memory). The same memory error can occur in CombineGVCFs, so I select GenomicsDBImport for genome-merging. This is the code when using GenomicsDBImport, completed successfully.; ```; gatk GenomicsDBImport \; -R $path1/ref/genome.fa --java-options ""-Xmx100g -Xms80g"" \; $(for i in $(ls $path1/sortbam/2/*.g.vcf.gz); do echo ""--variant $i""; done) \; $(for i in $(ls $path1/sortbam/4/*.g.vcf.gz); do echo ""--variant $i""; done) \; $(for i in $(ls $path1/sortbam/6/*.g.vcf.gz); do echo ""--variant $i""; done) \; --genomicsdb-workspace-path $path1/DBI \; --tmp-dir $path1/NOHUP/tmp --intervals $path1/chr.list; ```; But when I run the following **GenotypeGVCFs code**: ; ```; gatk --java-options '-Xmx800G -DGATK_STACKTRACE_ON_USER_EXCEPTION=true' GenotypeGVCFs \; -R $path1/ref/genome.fa -V gendb://$path1/DBI \; -O $path1/sortbam/combDBI.vcf.gz --tmp-dir $path1/NOHUP/tmp. ```; **It warns**: [TileDB::ReadState] Error: Cannot read tile from file; Memory map error. ```; 21:02:06.717 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 29, 2023 9:02:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:02:06.864 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:02:06.864 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 21:02:06.864 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:02:06.864 INFO GenotypeGVCFs - Executing as wtc@PC10-7742 on Linux v4.4.0-19041-Microsoft amd64; 21:02:06.864 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_121-b15; 21:02:06.865 INFO GenotypeGVCFs - Start Date/Time: April 29, 2023 9:02:06 PM CST; 21:02:06.86",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8302:1073,Error,Error,1073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8302,2,"['Error', 'error']","['Error', 'error']"
Availability,there's some highly redundant code in those classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1882:20,redundant,redundant,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1882,1,['redundant'],['redundant']
Availability,"this PR:; - changes CreateVariantIngestFiles to name the output files in a predictable way - i.e. rather than using a sample_id, it uses the name of the input gvcf. e.g. `pet_001_NA12878.tsv` becomes `pet_001_NA12878.haplotypeCalls.reblocked.vcf.gz.tsv`; - added a test in CreateVariantIngestFilesIntegrationTest to assert that the files are named as expected. - changes the GvsImportGenomes.wdl to:; - check whether, for the given input gvcf file and for each of pet, vet, and sample_info, the output TSV already exists somewhere in the output directory. it checks subdirectories.; - if the output TSV exists in a `set_X` subdirectory, we move that file back into the parent directory so that subsetting works as desired when we get to LoadTables; - if the output TSV exists in a `done` subdirectory, we exit with an error. notes:; - this does not check whether the sample is in the same table_id (e.g. pet_001 versus pet_002). this has been tested as follows:; - ran once with an `exit 1` before bq load, to simulate generating TSVs and putting them into set_X subdirectories and then exiting, simulating a permissions or other bq issue; - removed LOCKFILE, removed exit before bq load, then ran again - TSVs were not regenerated, the existing ones were moved into the parent directory and loaded properly into bq; - then ran again with the same samples - as expected, errored out because the TSVs already existed in a `done` folder",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7226:818,error,error,818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7226,2,['error'],"['error', 'errored']"
Availability,"this bam file has no reads: `src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CollectInsertSizeMetrics/insert_size_metrics_test.bam`. the cram file also has no reads ``src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CollectInsertSizeMetrics/insert_size_metrics_test.cram`. but the corresponding sam file has 52 reads: `src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CollectInsertSizeMetrics/insert_size_metrics_test.sam`. However `CollectInsertSizeMetricsTest` does not catch this and incorrectly reports that the test successfully passed. The issue comes from using only a for loop for asserts (the for loop executes 0 times on this file and so it thinks everything is great). The task here is to:; - fix the test to catch this error, then; - fix the bam file to not have this problem, then; - check and fix all other tests that use the same testing pattern (using the forloop). I suggest switching to using actual files for such tests (as done in `MeanQualityByCycleIntegrationTest`) to avoid such problems in the future",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1512:798,error,error,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1512,1,['error'],['error']
Availability,this includes `SeekableStream.available()`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4350:30,avail,available,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350,1,['avail'],['available']
Availability,this is enabled for the driving variants of VariantWalker as well as any auxiliary FeatureInput. a genomicsdb workspace is referenced by putting the loader.json that was used to create the arrays as well as a query.json into a directory; this is then specified with a url of the form gendb://path/to/directory; i.e; /myfiles/mygendbfiles/loader.json; /myfiles/mygendbfiles/query.json. ```; SomeVariantWalker -V gendb:///myfiles/mygendbfiles; ```. FeatureWalker isn't yet wired to support gendb urls; performance is untested. invalid input files are likely to result in Segfaults or non-helpful errors. resolves #1647,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1975:594,error,errors,594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1975,1,['error'],['errors']
Availability,this is now available on cran again,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8048:12,avail,available,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8048,1,['avail'],['available']
Availability,"this should fix #3724, I've tested it locally by building a maven project with the following pom; ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk-downstream-test</artifactId>; <packaging>jar</packaging>; <version>1.0-SNAPSHOT</version>; <name>gatk-downstream-test</name>; <url>http://maven.apache.org</url>; <repositories>; <repository>; <snapshots />; <id>snapshots</id>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-15-g62e339f-SNAPSHOT</version>; </dependency>; <dependency>; <groupId>junit</groupId>; <artifactId>junit</artifactId>; <version>3.8.1</version>; <scope>test</scope>; </dependency>; </dependencies>; </project>; ```. This didn't build correctly with the current gatk, but builds with this patch, (note that the snapshot version will be different if you download and build this yourself). @Vzzarr Is it possible for you to build this locally and test it with your project?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340:399,down,downstream-test,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340,3,['down'],"['download', 'downstream-test']"
Availability,this should stop the timeout errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1322:29,error,errors,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1322,1,['error'],['errors']
Availability,"this used to lead to complaints when building on some machines ""error: unmappable character for encoding ASCII"". for @davidadamsphd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1011:64,error,error,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1011,1,['error'],['error']
Availability,this was made redundant by #3353,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2804#issuecomment-317848172:14,redundant,redundant,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2804#issuecomment-317848172,1,['redundant'],['redundant']
Availability,"til.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41567.; 18/03/07 20:31:40 INFO netty.NettyBlockTransferService: Server created on 10.48.225.55:41567; 18/03/07 20:31:40 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.48.225.55:41567 with 8.4 GB RAM, BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d9cf71d{/metrics/json,null,AVAILABLE}; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.186:36002) with ID 8; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.196:45956) with ID 2; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q02.scc.bu.edu:37393 with 25.4 GB RAM, BlockManagerId(8, scc-q02.scc.bu.edu, 37393, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.197:57832) with ID 3; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q12.scc.bu.edu:36422 with 25.4 GB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 36422, None); 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q13.scc.bu.edu:42480 with 25.4 GB RAM, BlockManagerId(3, scc-q13.scc.bu.edu, 424",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:1603,AVAIL,AVAILABLE,1603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['AVAIL'],['AVAILABLE']
Availability,"tion --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6790:1610,down,down,1610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790,1,['down'],['down']
Availability,"tion ; I think there's a problem with the StrandOddsRatio (SOR) annotation and the `--map-mnp-distance` flag. I'm looking at a small region of NA24143 (one of the GIAB samples). There's a pair of SNPs in very close proximity. When called without the MNP output I get a pair of variants as follows (some info removed for clarity), coordinates are HG19:. ```; chr4 5743509 . C T 5903.03 . FS=0.000;QD=25.36;SOR=9.825 GT:AD:DP:GQ:PL 1/1:0,135:135:99:5917,406,0; chr4 5743512 . T C 2766.60 . FS=0.000;QD=21.12;SOR=0.983 GT:AD:DP:GQ:PL 0/1:57,74:131:99:2774,0,2060; ```. I'm trying to get permission to share the BAM over this region, but the key information is that every single read that spans or is in proximity to these variants is on the R strand. There is zero F strand coverage. This seems reasonable. It's a bit odd to me that the first SNP which is hom-var has a SOR value of 9.825, but it's homozygous so it's more or less irrelevant. Looking at the code, I think the problem here is that the code avoids divide-by-zero errors by adding pseudo-counts of `1.0` to the table, which for homozygous variants with no coverage on one strand creates a weird situation. I think it would be better to just detect if _all_ coverage is on one strand and short-circuit the calculation, but I digress. The real problem comes when running with `--max-mnp-distance 5`. Then I get this single variant:. ```; chr4 5743509 . CTAT TTAC,TTAT 5506.10 . FS=0.000;QD=25.36;SOR=9.750 GT:AD:DP:GQ:PL 1/2:0,74,56:130:99:5523,2213,2060,3016,0,2774; ```. Now I have a het variant with an SOR of 9.75. This seems really wrong to me - note how FS is 0.0. Again all coverage of all alleles is on one strand. And the het SNP that forms part of this MNP had an SOR of 0.983 when called independently. Since the first SNP is hom-var and the second is het, I would have expected the SOR value for the MNP call to closely mirror that of the het SNP. My suspicion is that what's going on here is probably that the calculation is bein",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5698:1258,error,errors,1258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698,1,['error'],['errors']
Availability,"tion true --disableAllReadFilters true --fixedChunkSize 100000 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [September 17, 2016 12:08:44 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.2-45-ga30af5a-SNAPSHOT; 12:08:44.930 INFO BwaSpark - Defaults.BUFFER_SIZE : 131072; 12:08:44.930 INFO BwaSpark - Defaults.COMPRESSION_LEVEL : 1; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_INDEX : false; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_MD5 : false; 12:08:44.930 INFO BwaSpark - Defaults.CUSTOM_READER_FACTORY : ; 12:08:44.930 INFO BwaSpark - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 12:08:44.930 INFO BwaSpark - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 12:08:44.930 INFO BwaSpark - Defaults.REFERENCE_FASTA : null; 12:08:44.930 INFO BwaSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 12:08:44.930 INFO BwaSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:08:44.930 INFO BwaSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:08:44.931 INFO BwaSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:08:44.931 INFO BwaSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 12:08:44.931 INFO BwaSpark - Deflater IntelDeflater; 12:08:44.931 INFO BwaSpark - Initializing engine; 12:08:44.931 INFO BwaSpark - Done initializing engine; 12:08:45.439 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:08:47.488 INFO BwaSpark - Shutting down engine; [September 17, 2016 12:08:47 PM EDT] org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=499646464. ---. null. ---",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408:2887,down,down,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408,1,['down'],['down']
Availability,"tion.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:6359,failure,failures,6359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['failure'],['failures']
Availability,tion: class LoggingUtils; 2022-08-16T00:09:07.4137968Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.4139500Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T00:09:07.4190745Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4198885Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:242: error: cannot find symbol; 2022-08-16T00:09:07.4199424Z @VisibleForTesting; 2022-08-16T00:09:07.4200130Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4200630Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T00:09:07.4211864Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4214985Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:14615,error,error,14615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,tion: class LoggingUtils; 2022-08-16T22:45:53.8134767Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.8135486Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T22:45:53.8163449Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8167163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:245: error: cannot find symbol; 2022-08-16T22:45:53.8167305Z @VisibleForTesting; 2022-08-16T22:45:53.8167581Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8167809Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T22:45:53.8173821Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8175307Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:16653,error,error,16653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,tionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7458,ERROR,ERROR,7458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,tionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8391,ERROR,ERROR,8391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,tionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7539,ERROR,ERROR,7539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"tionTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	at org.broadinstitute.hellbender.utils.io.IOUtils.deleteRecursively(IOUtils.java:1061); 	at org.broadinstitute.hellbender.utils.io.DeleteRecursivelyOnExitPathHook.runHooks(DeleteRecursivelyOnExitPathHook.java:56); 	at java.lang.Thread.run(Thread.java:748); Results: FAILURE (1604 tests, 1603 successes, 1 failures, 0 skipped); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:3126,FAILURE,FAILURE,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414,2,"['FAILURE', 'failure']","['FAILURE', 'failures']"
Availability,"tional-arguments](https://gatk.broadinstitute.org/hc/en-us/community/posts/4405983290395-run-into-PythonScriptExecutorException-when-executing-PostprocessGermlineCNVCalls-about-positional-arguments). \--. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.2.2.0 ; ; b) Exact command used:. ${gatk} PostprocessGermlineCNVCalls \\. \--model-shard-path ${gCNV\_model\_prefix}-model \\. \--calls-shard-path ${gCNV\_case\_prefix}-calls \\. \--allosomal-contig chrX --allosomal-contig chrY \\. \--contig-ploidy-calls ${ploidy\_case\_prefix}-calls \\. \--sample-index ${sample\_index} \\. \--output-denoised-copy-ratios ${cnv\_dir}/${sampleID}.sample\_${sample\_index}.denoised\_copy\_ration.tsv \\. \--output-genotyped-intervals ${cnv\_dir}/genotyped-intervals-case-${sampleID}-vs-${probe}cohort.vcf.gz \\. \--output-genotyped-segments ${cnv\_dir}/genotyped-segments-case-${sampleID}-vs-${probe}cohort.vcf.gz \\. \--sequence-dictionary ${ref\_gen}/ucsc.hg19.dict. c) Entire error log:. 11:04:20.841 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/yangyxt/software/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 30, 2021 11:04:20 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:04:20.983 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------ ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.2.2.0 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Executing as yangyxt@paedyl02 on Linux v3.10.0-1160.11.1.el7.x86\_64 amd64 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Serve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444:1261,error,error,1261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444,1,['error'],['error']
Availability,"tionally, this PR adds branch filters to the dockstore.yml file that will help with development. The filter for each workflow indicates which branch(es) will show up for that workflow in dockstore. If we don't include these filters, dockstore will run checks of ALL workflows on ALL branches, which causes timeouts. We could remove these filters later (before merging to master) or not, but for now this could help us develop on ah_var_store. Note that we'll need to add feature branches to that file as we work on them. This workflow was tested in Terra and the upload succeeded. Also confirmed that if one file fails, the entire process throws an error code (i.e. -m flag will not cause failures to silently pass) - in example below, `test_file_list.txt` was a list of 6 files, including 1 file that did not exist.; ```; ‚ûú cat test_file_list.txt | gsutil cp -I gs://dsp-fieldeng-dev/test_cp/; Copying file://test1.txt [Content-Type=text/plain]...; Copying file://test2.txt [Content-Type=text/plain]...; Copying file://test3.txt [Content-Type=text/plain]...; CommandException: No URLs matched: test4.txt; ‚ûú cat test_file_list.txt | gsutil -m cp -I gs://dsp-fieldeng-dev/test_cp/; If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o ""GSUtil:parallel_process_count=1""`. Note that multithreading is still available even if you disable multiprocessing. CommandException: No URLs matched: test4.txt; Copying file://test1.txt [Content-Type=text/plain]...; Copying file://test5.txt [Content-Type=text/plain]...; Copying file://test2.txt [Content-Type=text/plain]...; Copying file://test3.txt [Content-Type=text/plain]...; Copying file://test6.txt [Content-Type=text/plain]...; - [5/5 files][ 37.0 B/ 37.0 B] 100% Done; Operation completed over 5 objects/37.0 B.; CommandException: 1 file/object could not be transferred.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7104:1588,avail,available,1588,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7104,1,['avail'],['available']
Availability,"tire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5960,down,downsample,5960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['down'],['downsample']
Availability,"titute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:168) ; ; at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:139) ; ; at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.executeSegmentGermlineCNVCallsPythonScript(PostprocessGermlineCNVCalls.java:739) ; ; at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.generateSegmentsVCFFileFromAllShards(PostprocessGermlineCNVCalls.java:485) ; ; at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalSuccess(PostprocessGermlineCNVCalls.java:456) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1089) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ; at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) ; ; at org.broadinstitute.hellbender.Main.main(Main.java:289) ; ; Using GATK jar /home/yangyxt/software/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/yangyxt/software/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar Po. If not an error, choose a category for your question(REQUIRED): ; ; a)How do I (......)? ; ; b) What does (......) mean? ; ; c) Why do I see (......)? ; ; d) Where do I find (......)? ; ; e) Will (......) be in future releases?<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/181533'>Zendesk ticket #181533</a>)<br>gz#181533</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444:7870,error,error,7870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444,1,['error'],['error']
Availability,"tive Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter ; 0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter ; 0 read(s) filtered by: GoodCigarReadFilter ; 0 read(s) filtered by: WellformedReadFilter ; 0 total reads filtered; 12:13:58.943 INFO ProgressMeter - chrM:15445 38.3 63 1.6; 12:13:58.946 INFO ProgressMeter - Traversal complete. Processed 63 total regions in 38.3 minutes.; 12:13:59.105 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.7153035790000002; 12:13:59.110 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1084.6708644550001; 12:13:59.114 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 54.84 sec; 12:13:59.118 INFO Mutect2 - Shutting down engine; [May 31, 2021 12:13:59 PM EDT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 38.32 minutes.; Runtime.totalMemory()=18715508736; ```. From the log, we see that Mutect2 finished in 40 minutes. In the meanwhile the `g.vcf`, `g.vcf.idx` and `g.vcf.stats` files are generated and contain non-empty contents. However, the program keeps running for hours and still has not finished. Therefore I wonder if Mutect2 is stuck with some post-processing that is less documented. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:23971,down,down,23971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['down'],['down']
Availability,tive: false numReads: 0; 11:36:40.771 INFO ProgressMeter - chrM:5144 1.0 20 20.4; 11:36:40.774 DEBUG Mutect2 - Processing assembly region at chrM:5444-5743 isActive: false numReads: 0; 11:36:41.211 DEBUG IntToDoubleFunctionCache - cache miss 11898 > 5320 expanding to 11908; 11:36:41.213 DEBUG IntToDoubleFunctionCache - cache miss 17632 > 11908 expanding to 23818; 11:36:41.254 DEBUG IntToDoubleFunctionCache - cache miss 29537 > 23818 expanding to 47638; 11:36:42.578 DEBUG Mutect2 - Processing assembly region at chrM:5744-6043 isActive: false numReads: 0; 11:36:47.533 DEBUG Mutect2 - Processing assembly region at chrM:6044-6343 isActive: false numReads: 30078; 11:36:47.979 DEBUG Mutect2 - Processing assembly region at chrM:6344-6353 isActive: false numReads: 30081; 11:36:48.322 DEBUG Mutect2 - Processing assembly region at chrM:6354-6629 isActive: true numReads: 60135; 11:36:55.630 DEBUG ReadThreadingGraph - Recovered 8 of 11 dangling tails; 11:36:55.645 DEBUG ReadThreadingGraph - Recovered 7 of 16 dangling heads; 11:36:55.737 DEBUG IntToDoubleFunctionCache - cache miss 26606 > 4800 expanding to 26616; 11:36:55.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2 - Processing assembly region at chrM:7494-7771 isActive: true numReads: 7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:13117,Recover,Recovered,13117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"tkforums.broadinstitute.org/gatk/discussion/24446/genomicsdbimport-not-completing-for-mixed-ploidy-samples/p1); ----------; I'm attempting to call variants on whole genomes for about 500 illumina paired-end samples with varying ploidy (haploid to tetraploid). I'm running a fairly standard uBam to GVCF pipeline with HaplotypeCaller passed the ploidy information (1,2,3, or 4) in -ERC GVCF mode. I then try to collect the GVCFs using GenomicsDBImport in a batch size of 50 and use GenotypeGVCFs on the combined database. My interval list that is passed to GenomicsDBImport is just each chromosome on a separate line. I'm using GATK v4.1.1.0<br />; <br />; Command:<br />; ```<br />; ${GATK_DIR}/gatk GenomicsDBImport \<br />; --java-options ""-Xmx110g -Xms110g"" \<br />; -R ${REF} \<br />; --variant ${FILE_LIST} \<br />; -L ${SCRIPT_DIR}/GATK_Style_Interval.list \<br />; --genomicsdb-workspace-path ${WORK_DIR}/GenomicsDB_20190912 \<br />; --batch-size 50 \<br />; --tmp-dir=${WORK_DIR}/<br />; ```<br />; <br />; GenomicsDBImport appears to run without error, but only shows progress for the first 6000 bp before moving onto the next batch. When I run select variants on the created database, I only get variants up to position 6716 in the first interval. When I try to run GenotypeGVCF on it, I get a strange error:<br />; htsjdk.tribble.TribbleException: Invalid block size -1570639203<br />; <br />; My first assumption is that one of the gvcf's is malformed from HaplotypeCaller failing after the first 6000 bp, but I've verified that the gvcfs have all completed and have 'validated' them with ValidateVariants using GATK v4.1.3.0. When I grep for the particular position in the sample's gvcfs I don't find anything out of the ordinary. I would use CombineGVCFs, but it fails due to trying to combine mixed ploidies. <br />; <br />; Any ideas on troubleshooting or experience with problems like this?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:3984,error,error,3984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,1,['error'],['error']
Availability,"tmost coordinate when the read begins with an insertion, the desired effect for the start of the interval. #### Steps to reproduce; Use an alignment with a read that begins with an insertion and a BED that specifies an interval that begins at that position. For example, alignment file:; ```; @HD VN:1.6 SO:coordinate; @SQ SN:ref LN:10; @RG ID:foo SM:bar PU:baz PL:ILLUMINA; r001 0 ref 2 40 6I4M * 0 0 AAAAAAAAAA IIIIIIIIII RG:Z:foo; ```; and ref:; ```; >ref; AAAAAAAAAA; ```. and BED file; ```; ref 0 1; ref 1 2; ref 2 3; ref 3 4; ref 4 5; ref 5 6; ref 6 7; ref 7 8; ref 8 9; ref 9 10; ```; Then run BaseRecalibrator and look at the output:; `gatk BaseRecalibrator -I aln.bam -R ref.fa --known-sites sites.bed.gz -O recal.txt`. #### Expected behavior; The output tables should be empty, since every site in our reference (bases 1-10 inclusive) should be skipped. #### Actual behavior; The output tables include the 6 inserted bases, and the cycle covariate values confirm they are the 6 leading inserted bases:; ```; ReadGroup QualityScore CovariateValue CovariateName EventType EmpiricalQuality Observations Errors; baz 40 1 Cycle M 40.0000 1 0.00; baz 40 2 Cycle M 40.0000 1 0.00; baz 40 3 Cycle M 40.0000 1 0.00; baz 40 4 Cycle M 40.0000 1 0.00; baz 40 5 Cycle M 40.0000 1 0.00; baz 40 6 Cycle M 40.0000 1 0.00; ```. ### Minimal BED examples; In the example read, the 1-based reference coordinates of the read bases are `2,2,2,2,2,2,2,3,4,5`.; I've done tests with various BED files and the bug only seems to happen when the interval begins with position 2; when position 2 lies in the middle of the interval or the interval ends with position 2, the insertion is properly skipped. This is consistent with the usage of the GetReadCoordinateForReferenceCoordinate function linked above, so I'm somewhat confident that is the reason for this behavior. A minimalistic BED to reproduce this behavior is:; ```; ref 0 1; ref 1 10; ```; which specifies 1-based inclusive intervals [1,1] and [2,10]. Like ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6385:1995,Error,Errors,1995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6385,1,['Error'],['Errors']
Availability,to debug further. The underlying error is an index error when calculating likelihoods:; ```; java.lang.ArrayIndexOutOfBoundsException: 4; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables(GenotypeLikelihoodCalculators.java:388); ```; I've been unable to generate a reproducible test case. Re-running on the same machine (Amazon m4.4xlarge instances with 16 cores and 64Gb of memory) works. I've seen the error on two different datasets but it happens infrequently as I've also run hundreds using the same setup without any exceptions. The only other thing I spot when looking through the traceback is block issues about the RDDs but I'm not sure if these are a symptom of the failure or a cause:; ```; 18/04/15 03:55:19 WARN BlockManager: Putting block rdd_18_12 failed due to an exception; 18/04/15 03:55:19 WARN BlockManager: Block rdd_18_12 could not be removed as it was not found on disk or in memory; ```; Here's the full traceback of the failure:; ```; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 WARN BlockManager: Putting block rdd_18_12 failed due to an exception; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 WARN BlockManager: Block rdd_18_12 could not be removed as it was not found on disk or in memory; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 ERROR Executor: Exception in task 12.0 in stage 7.0 (TID 828); [2018-04-15T03:55Z] ip-10-0-0-57: java.lang.ArrayIndexOutOfBoundsException: 4; [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables(GenotypeLikelihoodCalculators.java:388); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:263); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.makeGenotypeCall(GATKVa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:868,failure,failure,868,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,3,"['ERROR', 'failure']","['ERROR', 'failure']"
Availability,"to reproduce the last issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/2xni9oh362ovc71/AAAIm7MZ1tLL6xuUUp7tk2g_a?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.0.12.0/gatk-4.0.12.0.zip; unzip gatk-4.0.12.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chr12,length=133275309>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr12\t60339493\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339499\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339510\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 17 18; do; gatk-4.0.12.0/gatk Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; --tumor SM \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr12:60339493-60339510 \; --min-base-quality-score $score \; --bam-output output.$score.bam && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr12:60339493-60339510; done; ```. With the two outputs being:; ```; chr12	60339493	A	G	0/1	0,9; chr12	60339499	A	G	0/1	0,8; chr12	60339510	C	T	0/1	0,10; ```; and:; ```; chr12	60339493	A	G	0/1	6,0; chr12	60339499	A	G	0/1	2,5; chr12	60339510	C	T	0/1	0,9; ```. And these are the two BAMs with the reconstructed haplotypes I obtained:; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079:945,echo,echo,945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079,3,['echo'],['echo']
Availability,tor$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:14026,ERROR,ERROR,14026,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"tor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 18/04/23 20:42:02 INFO DAGScheduler: Job 0 failed: first at ReadsSparkSource.java:221, took 11.814317 s; 18/04/23 20:42:02 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.xx:4040; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:17352,down,down,17352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['down'],['down']
Availability,"tor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:00.455 WARN TaskSetManager:66 - Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 05:09:00.456 ERROR TaskSetManager:70 - Task 8 in stage 1.0 failed 1 times; aborting job; 05:09:10.808 ERROR MapOutputTrackerMaster:91 - Error communicating with MapOutputTracker; java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:202); at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:142); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:2142,ERROR,ERROR,2142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['ERROR'],['ERROR']
Availability,"tor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **20/03/05 09:28:58 INFO DAGScheduler: Job 0 failed: count at PathSeqPipelineSpark.java:245, took 63.806676 s** ; **20/03/05 09:28:58 INFO SparkUI: Stopped Spark web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:28:58 INFO MemoryStore: MemoryStore cleared** ; **20/03/05 09:28:58 INFO BlockManager: BlockManager stopped** ; **20/03/05 09:28:58 INFO BlockManagerMaster: BlockManagerMaster stopped** ; **20/03/05 09:28:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!** ; **20/03/05 09:28:58 INFO SparkContext: Successfully stopped SparkContext** ; **09:28:58.889 INFO PathSeqPipelineSpark - Shutting down engine** ; **[2020ÎÖÑ 3Ïõî 5Ïùº (Î™©) Ïò§Ï†Ñ 9Ïãú 28Î∂Ñ 58Ï¥à] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.25 minutes.** ; **Runtime.totalMemory()=19560660992** ; **org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:42202,down,down,42202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['down'],['down']
Availability,"tor; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7292,AVAIL,AVAILABLE,7292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"tps://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L147. Casued because attribute ""oneShotLogger"" is uninitialized. See line (https://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L42) and its missing initialization in the constructor method (https://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L65). ### Affected version(s); - [ ] Latest public release version [4.3.0.0]; - [ ] Latest master branch as of [12/01/2023]. ### Description ; I work as support for a HPC cluster and this bug has affected one of our users, so I won't be able to provide the exact specifics. Long story short, the user reports that for a high enough value of ploidy (20-50), they start getting null pointer exception errors. Here we can see an example of how they launch the program:. ```; gatk --java-options ""-Xmx4g"" HaplotypeCaller \; -I ${bamfile} \; -R ${reference} \; -O ${outpath}/${sample_id}.ploidy_${SLURM_ARRAY_TASK_ID}.output.g.vcf.gz \; -RF MappingQualityReadFilter \; --minimum-mapping-quality 10 \; --max-alternate-alleles 10 \; --max-genotype-count 75000 \; --dont-use-soft-clipped-bases true \; -ploidy ${SLURM_ARRAY_TASK_ID} \; -ERC GVCF; ```. And this is the stack trace obtained when it fails:. ```; java.lang.NullPointerException: Cannot invoke ""org.broadinstitute.hellbender.utils.logging.OneShotLogger.warn(String)"" because ""this.oneShotLogger"" is null; at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:147); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:21",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:1144,error,errors,1144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,1,['error'],['errors']
Availability,"tputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:38:18.971 INFO BlockManagerInfo - Removed broadcast_10_piece0 on hhnode-ib-16:42186 in memory (size: 1561.7 KiB, free: 17.8 GiB); ```. I have checked the node status and found MarkDuplicatesSpark suddenly cons",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1569,failure,failures,1569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"tputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:38:18.971 INFO BlockManagerInfo - Removed broadcast_10_piece0 on hhnode-ib-16:42186 in memory (size: 1561.7 KiB, free: 17.8 GiB); ```. I have checked the node status and found MarkDuplicatesSpark suddenly consumed huge amounts of memory. In the below image, there was no memory at ~11:26, and MarkDuplicatesSpark also hangs at that time. ![image](https://github.com/broadinstitute/gatk/assets/34618938/cc9ac23c-2f84-47c3-bbde-335efb325791). Below is",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1809,failure,failures,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"tputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:38:18.971 INFO BlockManagerInfo - Removed broadcast_10_piece0 on hhnode-ib-16:42186 in memory (size: 1561.7 KiB, free: 17.8 GiB); ```. I have checked the node status and found MarkDuplicatesSpark suddenly consumed huge amounts of memory. In the below image, there was no memory at ~11:26, and MarkDuplicatesSpark also hangs at that time. ![image](https://github.com/broadinstitute/gatk/assets/34618938/cc9ac23c-2f84-47c3-bbde-335efb325791). Below is the head of the log file showing my command and tool version. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:2049,failure,failures,2049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"tputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:38:18.971 INFO BlockManagerInfo - Removed broadcast_10_piece0 on hhnode-ib-16:42186 in memory (size: 1561.7 KiB, free: 17.8 GiB); ```. I have checked the node status and found MarkDuplicatesSpark suddenly consumed huge amounts of memory. In the below image, there was no memory at ~11:26, and MarkDuplicatesSpark also hangs at that time. ![image](https://github.com/broadinstitute/gatk/assets/34618938/cc9ac23c-2f84-47c3-bbde-335efb325791). Below is the head of the log file showing my command and tool version. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/hcaoad/miniconda2/envs/gatk4/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar MarkDuplicatesSpark -I U23_FDSW210237516-1r_H52MYDSX2_L4.namesort.bam -O U23.markdup.sort.bam; 10:38:16.187 INFO NativeLibraryLoader - Loading libgkl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:2289,failure,failures,2289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"tq.gz. (echo ""@NB500989:333:HKYJNAFX2:1:11101:24447:1024""; echo ""NNNNTTGTATTTTTAATAGAGACGGGGTTTCAACATGTTGGCCAGGCTGGTCTTGAACTCCTGACCTCAGATGATCCACCCGCCTTGGCCTCCCAAAGTGCTAAGATTACAGGTGTGAGCTACTGCACCTGGCCCCCTCTAGTTTCTTTC""; echo ""+""; echo ""####AEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEA<EEEEEEEEE/<EEEEEEE/EEEEEEEEEEE/EEEEEAEEEEEAEAEEEE/EEEEE/EEEEEEEEEEEEEAEEEEEEEEAE/<AAAA/<A<EE<<EA<A/AAE<""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""TTACAGGATCTGAAGAGAGGGAAAAATAAACATGCACGATTATTTAATTCTTTTGGAAAAACTGCATGTAAGTGAAGTTCTCTTTCACAAGACACAAGCATCGGTAACTTGACAAAAAATGTAAGCTTCAGATTTTTATGAGCCTTTACA""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEAEEEEEE/EEEAEEEEEEEEEEEEEAEEAE/EEEEEEEEEAEEEEEEA<EEEEEE<AAEEEEEEEEEEAEEEEEAEAAEAE/AAEAEAA<E"") | \; gzip > R2.fastq.gz; ```. Install bwa and GATK resources:; ```; sudo apt install java11-runtime bwa samtools; wget https://github.com/broadinstitute/gatk/releases/download/4.2.1.0/gatk-4.2.1.0.zip; unzip gatk-4.2.1.0.zip; echo dict fasta fasta.fai fasta.64.alt fasta.64.sa fasta.64.amb fasta.64.bwt fasta.64.ann fasta.64.pac | \; tr ' ' '\n' | xargs -i echo gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.{} | \; gsutil -m cp -I .; ```. Run FastqToSam with the `-SORT_ORDER ""unsorted""` option:; ```; gatk-4.2.1.0/gatk \; FastqToSam \; -FASTQ R1.fastq.gz \; -FASTQ2 R2.fastq.gz \; -OUTPUT unmapped.bam \; -SAMPLE_NAME SM \; -SORT_ORDER ""unsorted""; ```; Notice the option `-SORT_ORDER ""unsorted""` which prevents the tool from resorting the reads which can add both computational and storage requirements. Aligned the data with bwa:; ```; gatk-4.2.1.0/gatk \; SamToFastq \; -INPUT unmapped.bam \; -FASTQ /dev/stdout \; -INTERLEAVE true | \; bwa mem -K 100000000 -p -v 3 -t 16 -Y Homo_sapiens_assembly38.fasta /dev/stdin | \; samtools view -1 - > aligned.unmerged.bam; ```. Merge unmapped and aligned BAMs:; ```; gatk-4.2.1.0/gatk \; MergeBamAlignment \; -ALIGNED_BAM aligned.unmerged.bam \; -UNMAPPED_BAM unmap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:1805,echo,echo,1805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,1,['echo'],['echo']
Availability,"travis is now using the gradlew wrapper, which handles this download for us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/547:60,down,download,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/547,1,['down'],['download']
Availability,"tribution! I'd be happy to review, but the current CNV tech lead @mwalker174 should probably make the final decisions about how this tool should ultimately go in. A few quick thoughts:. 1) If you'd like to make the PR from your Broad account, feel free to reopen---either way is fine with us. However, if you do, perhaps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we also discussed, this will come with ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:1113,mainten,maintenance,1113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,2,['mainten'],['maintenance']
Availability,"tructure a bit simpler.; -@MartonKN should review, since he wrote PreprocessIntervals and is updating the caller. Added segmentation classes and tests for ModelSegments CNV pipeline.; -I added implementations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1345,down,downsampling,1345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,2,['down'],"['down', 'downsampling']"
Availability,"ts done. Elapsed time: 60.94 minutes. Runtime.totalMemory()=5,285,347,328. . . Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded. . . at java.util.Collections.unmodifiableList(Collections.java:1287). at htsjdk.samtools.Cigar.getCigarElements(Cigar.java:54). at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.getCigarElements(SAMRecordToGATKReadAdapter.java:336). at org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary$ReadLengthEqualsCigarLengthReadFilter.test(ReadFilterLibrary.java:217). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77). at org.broadinstitute.hellbender.engine.filters.CountingReadFilter.test(CountingReadFilter.java:126) . . . From: Louis Bergelson <notifications@github.com> ; Sent: Thursday, October 31, 2019 12:24 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: rdbremel <rdbremel017@gmail.com>; Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Funcotator shuts down (#6182). . I thought we'd added that to the retry list. ‚Äî; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VDSBPTB7S7VFLE2XWLQRMICTA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECYS3SA#issuecomment-548482504> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ANCR2VEH2EZJ2ZO3725ROVLQRMICTANCNFSM4I2MRFQA> . <https://github.com/notifications/beacon/ANCR2VDLH4PVQMRUNPKAWGLQRMICTA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECYS3SA.gif>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777:2599,down,down,2599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777,1,['down'],['down']
Availability,"ts index) for each sample ; ##; ## Description of inputs :; ##; ## ** Runtime ** (requires Docker; to use on-premises without Docker, change gatk4_jar from String to File); ## gatk4_jar: path to the java jar file containing GATK 4 (beta.2 or later) in the specified docker; ## picard_jar: path to retrieve a Picard jar (will be replaced by a docker image in a future version); ## m2_docker, oncotator_docker: docker images to use for GATK4 Mutect2 and for Oncotator; ## preemptible_attempts: how many preemptions to tolerate before switching to a non-preemptible machine (on Google); ##; ## ** Workflow options **; ## intervals: genomic intervals (will be used for scatter); ## scatter_count: number of parallel jobs to generate when scattering over intervals; ## artifact_modes: filtering options; ## m2_extra_args, m2_extra_filtering_args: additional arguments for Mutect2 calling and filtering (optional); ## is_run_orientation_bias_filter: if true, run the orientation bias filter post-processing step; ## is_run_oncotator: if true, annotate the M2 VCFs using oncotator (to produce a TCGA MAF); ##; ## ** Primary inputs **; ## ref_fasta, ref_fasta_index, ref_dict: reference genome, index, and dictionary; ## tumor_bam, tumor_bam_index, and tumor_sample_name: BAM, index and sample name for the tumor sample (sample name used for output naming); ## normal_bam, normal_bam_index, and normal_sample_name: BAM, index and sample name for the normal sample (optional if running tumor-only); ##; ## ** Primary resources ** (optional but strongly recommended); ## pon, pon_index: optional panel of normals in VCF format containing probable technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:986,toler,tolerate,986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['toler'],['tolerate']
Availability,"ts1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_250to35.g.vcf.gz; 17:52:24.744 INFO FeatureManager - Using codec VCFCodec to read file file:///db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_350to5.g.vcf.gz; 17:52:24.795 INFO FeatureManager - Using codec VCFCodec to read file file:///db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_50to69.g.vcf.gz; 17:52:24.841 INFO FeatureManager - Using codec VCFCodec to read file file:///db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_690to999.g.vcf.gz; 17:53:24.067 INFO CombineGVCFs - Done initializing engine; 17:53:24.121 INFO ProgressMeter - Starting traversal; 17:53:24.122 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:53:24.189 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location scaffold1159:34 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 17:53:31.218 INFO CombineGVCFs - Shutting down engine; [January 11, 2020 5:53:31 PM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.15 minutes.; Runtime.totalMemory()=2739404800; java.lang.IllegalStateException: The elements of the input Iterators are not sorted according to the comparator htsjdk.variant.variantcontext.VariantContextComparator; 	at htsjdk.samtools.util.MergingIterator.next(MergingIterator.java:107); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.for",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6368:4790,down,down,4790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6368,1,['down'],['down']
Availability,tsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:97); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:82); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:106); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:353); 	... 14 more; Caused by: htsjdk.samtools.util.RuntimeIOException: /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz has invalid uncompressedLength: -795051631; 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:257); 	at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132); 	at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:84); 	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); 	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); 	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); 	at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:5859,avail,available,5859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['avail'],['available']
Availability,"tter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please chec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2017,ERROR,ERROR,2017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['ERROR'],['ERROR']
Availability,"tter$FormatSpecifier.printString(Formatter.java:2886); at java.util.Formatter$FormatSpecifier.print(Formatter.java:2763); at java.util.Formatter.format(Formatter.java:2520); at java.util.Formatter.format(Formatter.java:2455); at java.lang.String.format(String.java:2940); at org.broadinstitute.hellbender.engine.FeatureDataSource.close(FeatureDataSource.java:589); at org.broadinstitute.hellbender.engine.FeatureManager.lambda$close$9(FeatureManager.java:505); at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608); at org.broadinstitute.hellbender.engine.FeatureManager.close(FeatureManager.java:505); at org.broadinstitute.hellbender.engine.GATKTool.onShutdown(GATKTool.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.onShutdown(VariantWalker.java:95); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); at org.broadinstitute.hellbender.Main.main(Main.java:288); Caused by: java.net.URISyntaxException: Illegal character in path at index 15: /media/yoshi/My Book/Aet_v4.0_ChrSeqSplit/HC.KU-2103.raw.snps.indels.g.vcf; at java.net.URI$Parser.fail(URI.java:2848); at java.net.URI$Parser.checkChars(URI.java:3021); at java.net.URI$Parser.parseHierarchical(URI.java:3105); at java.net.URI$Parser.parse(URI.java:3063); at java.net.URI.<init>(URI.java:588); at java.net.URI.create(URI.java:850); ... 19 more; '''. When I ran GenotypeGVCFs using the gvcf, it ran to completion, but threw the same ""java.lang.IllegalArgumentException"" errors at the end. I have submitted a bug report to FTP server.; The name of the uploaded archive file is YoshiM_BugReport.tar.gz.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657:2948,error,errors,2948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657,1,['error'],['errors']
Availability,"tty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:748); 18/04/24 17:42:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:42:11 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:42:11 INFO BlockManager: BlockManager stopped; 18/04/24 17:42:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:42:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:42:11 INFO SparkContext: Successfully stopped SparkContext; 17:42:11.053 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:42:11 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=866648064; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:38831,down,down,38831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['down'],['down']
Availability,tupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:9503,ERROR,ERROR,9503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"tureSources(FeatureManager.java:209); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:156); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeatures(GATKTool.java:488); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy), for input source: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz; 	at htsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:97); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:82); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:380); 	... 14 more; Caused by: java.io.FileNotFoundException: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy); 	at java.io.RandomAccessFile.open0(Native Method); 	at java.io.RandomAccessFile.open(RandomAccessFile.java:316); 	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); 	at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); 	at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059:1821,error,error,1821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059,1,['error'],['error']
Availability,"tute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:56:39 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 45.308012 s; 18/04/24 17:56:39 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.16:4040; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.he",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:38084,down,down,38084,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['down'],['down']
Availability,tute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:19589,error,error,19589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"typeGVCFs. The set of sample calls in a pair should be derived from WGS and WEx data for the same sample.; * </p>; ```. Does it _have_ to be WGS + WEx? Could it be WGS + WGS or WEx + Wex for example?. ```; * <h3>Output</h3>; * <p>; * A combined VCF with combined calls for each pair of samples specified and de-uniquified sample names.; * </p>; *; * <h3>Examples</h3>; * <pre>; * java -jar GenomeAnalysisTK.jar \; * -R ref.fasta \; * -T CombineSampleData \; * --variant vcf1.vcf \; * -o output.vcf; * </pre>; * <pre>; * java -jar GenomeAnalysisTK.jar \; * -R ref.fasta \; * -T CombineSampleData \; * --variant vcf1.vcf \; * --uniquified_sample_name NA12878.variant \; * --uniquified_sample_name NA12878.variant2; * -o output.vcf; * </pre>; ```. I don't get what's the difference between the first and second example. . In any case I'm not going to push this through now in light of all the TODOs:. ```; /*TODO: when this tool is moved into protected the following will have to be addressed:; * Do more robust error checking on sample name de-uniquification -- right now checks for pairs of <sampleName>.variantX and <sampleName>.variantY but should be extended to allow tagged VCF input into GenotypeGVCFs, which will produce names like <sampleName>.RODtagName; * Move sample name uniqufication/de-uniquification to SampleListUtils.java; * Check to make sure all genotype attributes are preserved after merge, e.g. allele phasing and genotype filters; * Generalize for all ploidies?; * Change GenotypeGVCFs --uniquifySamples argument from hidden (maybe still keep @advanced?); *; */; ```. ---. @ldgauthier commented on [Mon Nov 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-159059807). 1) Could be any two sets of data, I just did WGS + WEx for GTEx; 2) I think the first example probably should have two -V entries (that have the same sample names) compared with the second that has one input -V that has already uniquified samples. ---. @vdauwera commented on [Mo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2485:1863,robust,robust,1863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2485,2,"['error', 'robust']","['error', 'robust']"
Availability,uamF2YQ==) | `0.815% <0.815%> (√∏)` | `2 <2> (?)` | |; | [...hellbender/tools/AnalyzeSaturationMutagenesis.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BbmFseXplU2F0dXJhdGlvbk11dGFnZW5lc2lzLmphdmE=) | `5.426% <5.426%> (√∏)` | `0 <0> (?)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5796#issuecomment-473394038:2189,down,downsampling,2189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5796#issuecomment-473394038,1,['down'],['downsampling']
Availability,"ublic release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:1338,Redundant,Redundant,1338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,1,['Redundant'],['Redundant']
Availability,"ufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we were more careful about checking return values from system calls. Eg., in the function below from the BWA bindings we could check the return values of the `mmap()` and `calloc()` calls, and die with an appropriate error message if they fail:. ```; bwaidx_t* jnibwa_openIndex( int fd ) {; struct stat statBuf;; if ( fstat(fd, &statBuf) == -1 ) return 0;; uint8_t* mem = mmap(0, statBuf.st_size, PROT_READ, MAP_SHARED, fd, 0);; close(fd);; bwaidx_t* pIdx = calloc(1, sizeof(bwaidx_t));; bwa_mem2idx(statBuf.st_size, mem, pIdx);; pIdx->is_shm = 1;; mem_fmt_fnc = &fmt_BAMish;; bwa_verbose = 0;; return pIdx;; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:1975,fault,faults,1975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,3,"['error', 'failure', 'fault']","['error', 'failures', 'faults']"
Availability,"ug/' \; HaplotypeCallerSpark \; --reference /projects/rdocking_prj/software/bcbio-nextgen/data/genomes/Hsapiens/hg19/ucsc/hg19.2bit \; --annotation MappingQualityRankSumTest --annotation MappingQualityZero \; --annotation QualByDepth --annotation ReadPosRankSumTest \; --annotation RMSMappingQuality --annotation BaseQualityRankSumTest \; --annotation FisherStrand --annotation MappingQuality \; --annotation DepthPerAlleleBySample --annotation Coverage \; -I /projects/karsanscratch/rdocking/KARSANBIO-1390_rna_seq_runs/molm13_replicate_one_small/work/align/MOLM13_rep1/MOLM13_rep1-dedup.splitN.bam \; -L /projects/karsanlab/rdocking/KARSANBIO-1254_pipeline/KARSANBIO-1390_rna_seq_runs/data/gatk_debug/chr1_70k.bed \; --interval-set-rule INTERSECTION \; --spark-master local[12] \; --conf spark.local.dir=/projects/karsanscratch/rdocking/KARSANBIO-1390_rna_seq_runs/molm13_replicate_one_small/debug \; --conf spark.driver.host=localhost \; --conf spark.network.timeout=800 \; --conf spark.executor.heartbeatInterval=100 \; --annotation ClippingRankSumTest --annotation DepthPerSampleHC \; --emit-ref-confidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80 \; --output MOLM13_rep1-chr1-70k-gatk-haplotype.vcf; ```. When I run this command on a single chromosome with `-Xmx94349m`, the command completes successfully, but the resulting VCF header does not contain this expected header line:. ```; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ```. (along with most of the other header lines associated with gVCF output). When I up the memory request to 110g for the same input files, the proper VCF header is present. I discovered this in the context of running GATK within the bcbio pipeline, the original descriptions are at: https://github.com/bcbio/bcbio-nextgen/issues/2375. On the linked issue, I have examples of GATK output from runs that produced correct and incorrect output - please let me know if there's any other information you need. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4821:1441,heartbeat,heartbeatInterval,1441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4821,1,['heartbeat'],['heartbeatInterval']
Availability,uildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:8062,ERROR,ERROR,8062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,uildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLaunc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:4346,ERROR,ERROR,4346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,uildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:6074,ERROR,ERROR,6074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"uire integer read counts as input. These will still be backed by a ReadCountCollection until @asmirnov239's changes are in.; - [x] Remove optional outputs (factor-normalized and beta-hats) from DenoiseReadCounts. For now, TN and PTN output will remain in the same format (log2) to maintain compatibility with downstream tools.; - [x] Maximum number of eigensamples K to retain in the PoN is specified; the smaller of this or the number of samples remaining after filtering is used. The number actually used to denoise can be specified in DenoiseReadCounts. If we are going to spend energy computing K eigensamples, there is no reason we shouldn't expose all of them in the PoN, even if we don't want to use all of them for denoising. (Also, the current SVD utility methods do not allow for specification of K < N when performing SVD on an MxN matrix, even though the backend implementations that are called do allow for this; this is terrible. In any case, randomized SVD should be much faster than the currently available implementations, even when K = N).; - [x] Rename CreatePanelOfNormals to CreateReadCountPanelOfNormals; - [x] Refer to ""targets"" as intervals. See #3246.; - [x] Remove QC.; - [x] Refer to proportional coverage as fractional coverage.; - [x] Perform optional GC-bias correction internally if annotated intervals are passed as input.; - [x] Make standardization process for panel and case samples identical. Currently, a sample mean is taken at one point in the PoN standardization process, while a sample median is taken in the case standardization process.; - [x] HDF5 PoN will store version number, all integer read counts, all/panel intervals, all/panel sample paths/names, all annotated intervals (if GC-bias correction was performed), fractional-coverage medians for all intervals, relevant SVD results (eigenvalues and left-singular vectors) for the specified number of eigensamples, and command line.; - [x] In a future iteration, we could allow an input PoN to be the so",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687:1335,avail,available,1335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687,1,['avail'],['available']
Availability,"um_calling_processes int]; [--learning_rate float]; [--adamax_beta1 float]; [--adamax_beta2 float]; [--log_emission_samples_per_round int]; [--log_emission_sampling_median_rel_error float]; [--log_emission_sampling_rounds int]; [--max_advi_iter_first_epoch int]; [--max_advi_iter_subsequent_epochs int]; [--min_training_epochs int]; [--max_training_epochs int]; [--initial_temperature float]; [--num_thermal_advi_iters int]; [--convergence_snr_averaging_window int]; [--convergence_snr_trigger_threshold float]; [--convergence_snr_countdown_window int]; [--max_calling_iters int]; [--caller_update_convergence_threshold float]; [--caller_internal_admixing_rate float]; [--caller_external_admixing_rate float]; [--disable_sampler str_to_bool]; [--disable_caller str_to_bool]; [--disable_annealing str_to_bool]; cohort_denoising_calling.6786136740079319091.py: error: unrecognized arguments: --random_seed=1984 --num_samples_copy_ratio_approx=200; 23:44:54.590 INFO GermlineCNVCaller - Shutting down engine; [August 3, 2024 at 11:44:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 1.04 minutes.; Runtime.totalMemory()=2147483648; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 2; Command Line: python /tmp/cohort_denoising_calling.6786136740079319091.py --ploidy_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/ploidy/ploidy-calls --output_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-calls --output_tracking_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-tracking --random_seed=1984 --modeling_interval_list=/tmp/intervals15539986661449841065.tsv --output_model_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-model --enable_explicit_gc_bias_modeling=True --read_count_tsv_files /tmp/V30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:40088,down,down,40088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['down'],['down']
Availability,"umber of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/006/945/GCF_000006945.2_ASM694v2/GCF_000006945.2_ASM694v2_cds_from_genomic.fna.gz"". CDS_FA = join(""data"", ""{patient}_cds_from_genomic.fa""); SL1344_CDS_FA = CDS_FA.format(patient=""SL1344""); ATCC25586_CDS_FA = CDS_FA.format(patient=""ATCC25586""); LT2_CDS_FA = CDS_FA.format(patient=""LT2""); FQ1_PREFIX = join(""output"", ""simulated_{patient}-{sample}""); FQ1 = join(""output"", ""simulated_{patient}-{sample}_R1.fastq.gz""); pathseq_bam = join(""output"", ""PathSeq"", ""{patient}-{sample}"", ""pathseq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:1840,error,error,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,1,['error'],['error']
Availability,"un 22 17:06:37 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=1249378304; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.samtools.SAMException: Cannot read non-existent file: file:///data/infectious/schistosome/tmp/test%20a/data/calling/erc_prod2.SM_V7_1.vcf.gz; at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:498); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:485); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:173); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ## Cases when the error does not occur; * If I rename `test a` folder in `test-a` as previously said.; * If I copy my current `test a` in the `/tmp/` directory (`/tmp/test a/`). This may suggest that the path length plays a role.; * If I renamed the VCF files (first VCF becomes `a.vcf.gz`, second `b.vcf.gz`) (`gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz`).; * If I rename the first VCF file with as many `a` character as characters found in the original filename. (aaaaaaaaaaaaaaaaaa.vcf.gz).; * If I rename the first VCF by replacing all alphabetical character with a (aaaa_aaaa2.aa_a7_1.vcf.gz); * If I introduce random `_` in the file name (aaaa_aaa_aaaa_aaaa.vcf.gz).; * If I rename the first VCF file by removing the first character (`cerc_prod2.SM_V7_1.vcf.gz` -> `erc_prod2.SM_V7_1.vcf.gz`); * If I rename the first VCF file by introducing a letter at the beginning (`cerc_prod2.SM_V7_1.vcf.gz` -> `ccerc_prod2.SM_V7_1.vcf.gz`). It really seems that the combination of the path lengh, white space and parti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:7105,error,error,7105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,1,['error'],['error']
Availability,un-physical-phasing ; false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --use-flow-aligner-for-stepwise-hc-filtering false --adaptive-pruning false --do-not-recover-dan; gling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 ; --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.001 --pruning-lod-thresh; old 2.302585092994046 --pruning-seeding-lod-threshold 9.210340371976184 --max-unpruned-variants 100 --linked-de-bruijn-graph false --disable-artificial-haplotype-recovery false --enable-le; gacy-graph-cycle-detection false --debug-assembly false --debug-graph-transformations false --capture-assembly-failure-bam false --num-matching-bases-in-dangling-end-to-recover -1 --error-; correction-log-odds -Infinity --error-correct-reads false --kmer-length-for-read-error-correction 25 --min-observations-for-kmer-to-be-solid 20 --likelihood-calculation-engine PairHMM --ba; se-quality-score-threshold 18 --dragstr-het-hom-ratio 2 --dont-use-dragstr-pair-hmm-scores false --pair-hmm-gap-continuation-penalty 10 --expected-mismatch-rate-for-read-disqualification 0; .02 --pair-hmm-implementation FASTEST_AVAILABLE --pcr-indel-model CONSERVATIVE --phred-scaled-global-read-mismapping-rate 45 --disable-symmetric-hmm-normalizing false --disable-cap-base-qu; alities-to-map-quality false --enable-dynamic-read-disqualification-for-genotyping false --dynamic-read-disqualification-threshold 1.0 --native-pair-hmm-threads 4 --native-pair-hmm-use-dou; ble-precision false --flow-hmm-engine-min-indel-adjust 6 --flow-hmm-engine-flat-insertion-penatly 45 --flow-hmm-engine-flat-deletion-penatly 45 --pileup-detection false --pileup-detection-; enable-indel-pileup-calling false --num-artificial-haplotypes-to-add-per-allele,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:5432,recover,recovery,5432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,6,"['error', 'failure', 'recover']","['error', 'error-correct-reads', 'error-correction', 'failure-bam', 'recover', 'recovery']"
Availability,"unTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-02-17 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_980 in memory on scc-q04.scc.bu.edu:41981 (size: 4.9 MB, free: 42.5 GB); 2019-02-17 16:25:50 ERROR TransportRequestHandler:210 - Error while invoking RpcHandler#receive() for one-way message.; org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160); at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140); at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655); at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:42422,down,down,42422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,['down'],['down']
Availability,"unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. ```; 1 <?xml version=""1.0"" encoding=""UTF-8""?>; 2 <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; 3 <modelVersion>4.0.0</modelVersion>; 4 ; 5 <!--; 6 This pom is parent for all gatk poms; 7 See also:; 8 http://maven.apache.org/pom.html#Inheritance_v; 9 http://maven.apache.org/guides/introduction/introduction-to-the-pom.html#Project_Inheritance_vs_Project_Aggregation; 10 http://stackoverflow.com/questions/1992213/maven-parent-pom-vs-modules-pom; 11 -->; 12 ; 13 <groupId>org.broadinstitute.gatk</groupId>; 14 <artifactId>gatk-root</artifactId>; 15 <<<<<<< HEAD; 16 <version>3.8-1</version>; 17 =======; 18 <version>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:1719,ERROR,ERROR,1719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,4,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"up from the most recent GATK 4.1.7 on a WES sample like this:. gatk PileupSpark --spark-runner SPARK --spark-master local[{threads}] --conf ""spark.driver.memory=22g"" -I $DATA/NA12878.proper.wes.md.bam -R $DATA/Homo_sapiens_assembly18.fasta -O /tmp/gatk4s_{threads}.pileup'. mwiewior@Mareks-MacBook-Pro ~ % spark-submit --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceFileSource.<init>(ReferenceFileSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6642:1029,ERROR,ERROR,1029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642,1,['ERROR'],['ERROR']
Availability,upElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4025208Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4026746Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4037886Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T00:09:07.4038351Z @VisibleForTesting; 2022-08-16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:11104,error,error,11104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,upElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8014882Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8016302Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8023734Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T22:45:53.8023874Z @VisibleForTesting; 2022-08-16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:13142,error,error,13142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,update error message when sample name in VCF cannot be looked up in sampleMap.tsv,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7074:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7074,1,['error'],['error']
Availability,update htsjdk downstream tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3235:14,down,downstream,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3235,1,['down'],['downstream']
Availability,update htsjdk to a current snapshot and fix the test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3417:53,failure,failures,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3417,1,['failure'],['failures']
Availability,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/763:194,error,error,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763,1,['error'],['error']
Availability,updating the docker image to fix the failure in CreateFilterSet introduced by my older VSQR-Lite merge. [Successful run here.](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/95307258-02d0-4d33-b9bb-1ba1eaac6bff),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8210:37,failure,failure,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8210,1,['failure'],['failure']
Availability,"ups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsForAssembly \; --maxFASTQSize 10000000 \; -- \; --sparkRunner GCS \; --cluster svdev-caller; ```. ========================. On the other hand, we see a similar error if the input is changed to the same file but stored in a google bucket (although the cited cause is different):. ```; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:5723,ERROR,ERROR,5723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,uralLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabili,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:1275,Error,ErrorProbabilities,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Error'],['ErrorProbabilities']
Availability,uralLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabili,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1275,Error,ErrorProbabilities,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Error'],['ErrorProbabilities']
Availability,uralLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabili,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1276,Error,ErrorProbabilities,1276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Error'],['ErrorProbabilities']
Availability,"urceUtils.createAndRegisterFeatureInputs(DataSourceUtils.java:328); at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.createDataSourceFuncotationFactoriesForDataSources(DataSourceUtils.java:277); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:774); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1037); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Duplicate key 0, for input source: cadd.config; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:263); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeInt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:2020,error,error,2020,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['error'],['error']
Availability,use-dragstr-pair-hmm-scores false --pair-hmm-gap-continuation-penalty 10 --expected-mismatch-rate-for-read-disqualification 0; .02 --pair-hmm-implementation FASTEST_AVAILABLE --pcr-indel-model CONSERVATIVE --phred-scaled-global-read-mismapping-rate 45 --disable-symmetric-hmm-normalizing false --disable-cap-base-qu; alities-to-map-quality false --enable-dynamic-read-disqualification-for-genotyping false --dynamic-read-disqualification-threshold 1.0 --native-pair-hmm-threads 4 --native-pair-hmm-use-dou; ble-precision false --flow-hmm-engine-min-indel-adjust 6 --flow-hmm-engine-flat-insertion-penatly 45 --flow-hmm-engine-flat-deletion-penatly 45 --pileup-detection false --pileup-detection-; enable-indel-pileup-calling false --num-artificial-haplotypes-to-add-per-allele 5 --artifical-haplotype-filtering-kmer-size 10 --pileup-detection-snp-alt-threshold 0.1 --pileup-detection-i; ndel-alt-threshold 0.5 --pileup-detection-absolute-alt-depth 0.0 --pileup-detection-snp-adjacent-to-assembled-indel-range 5 --pileup-detection-bad-read-tolerance 0.0 --pileup-detection-pro; per-pair-read-badness true --pileup-detection-edit-distance-read-badness-threshold 0.08 --pileup-detection-chimeric-read-badness true --pileup-detection-template-mean-badness-threshold 0.0; --pileup-detection-template-std-badness-threshold 0.0 --bam-writer-type CALLED_HAPLOTYPES --dont-use-soft-clipped-bases false --override-fragment-softclip-check false --min-base-quality-s; core 10 --smith-waterman JAVA --max-mnp-distance 0 --force-call-filtered-alleles false --reference-model-deletion-quality 30 --soft-clip-low-quality-ends false --allele-informative-reads-o; verlap-margin 2 --smith-waterman-dangling-end-match-value 25 --smith-waterman-dangling-end-mismatch-penalty -50 --smith-waterman-dangling-end-gap-open-penalty -110 --smith-waterman-danglin; g-end-gap-extend-penalty -6 --smith-waterman-haplotype-to-reference-match-value 200 --smith-waterman-haplotype-to-reference-mismatch-penalty -150 --smith-waterman-ha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:6942,toler,tolerance,6942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,1,['toler'],['tolerance']
Availability,"used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding all this, if you're happy with the code as it stands, feel free to merge.; Back to you, review done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5153:1201,failure,failure,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5153,1,['failure'],['failure']
Availability,"used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding all this, if you're happy with the code as it stands, feel free to merge.; Back to you, review done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706:1076,failure,failure,1076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706,2,['failure'],['failure']
Availability,using --version results in a bizarre error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1293:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1293,1,['error'],['error']
Availability,"using IntelDeflater speeds up writing of bams by at least 15% (latest igzip is even faster, though only at compression level 1). We must have a way to use it. . note: the htsjdk jar does not contain the .so file - it's only available in the zip file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1585:224,avail,available,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1585,1,['avail'],['available']
Availability,"using full (even sites-only) VCFs for BQSR is heavy, especially in spark, when we broadcast them. They can go > 10GB in size. Really, it's just a few million positions, so we could compress it hugely: say we have 4 million variants to consider (common sites) - that's just 4M*32bits = 16 MB. . This would require creating a special format for this (or finding an existing one that works for this case). note that need to represent indel positions (with start and end, which complicates things) too but they are much less common (1 in 10 compared to snps). Or maybe Using a BloomFilter is the way to go. For a 10^-3 probability of failure and 4 million entries we only need ~7MB of size with 10 hash functions",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1407:630,failure,failure,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1407,1,['failure'],['failure']
Availability,"ut allow NONE as input (#7206); - SA support and consistent naming for all GVS WDLs (#7205); - fix GvsExtractCallset inputs file (#7210); - add clustering to tables (#7207); - add vqsr cutoffs to GvsExtractCallset wdl; clean up dockstore yml (#7209); - Avro test (#7192); - Enable call caching of TSV generation in GvsImportGenomes (#7226); - 266 Clean up ExtractCohort -- remove query mode param (#7227); - 288 Add an excess alleles param (#7221); - take sample name as a param (#7236); - How to run GIAB comparisons (#7237); - Update GvsCreateFilterSet.wdl (#7239); - Use GatherVcfsCloud in GvsCreateFilterSet.wdl (#7241); - parameterize TTL with defaults, reduce memory allocation (#7244); - Addressing OOM in CohortExtract (#7245); - make outputs optional, change case in output (#7252); - Support for FORMAT/FT VQSLod Filtering and cohort-wide LowQual filter (#7248); - removed arrays code, renamed packages (#7260); - 279 labels (#7233); - add conda commands to GIAB readme (#7268); - remove gvs branch (#7263); - remove gvs branch (#7263); - upgrade bq libraries (#7264); - #299 - Sample list ease of use for cohort extracts (#7272); - check for duplicate ids (#7273); - Rc 274 passing sites only (#7275); - added default value to drop_state; broadinstitute/dsp-spec-ops#310 (#7278); - version bump for reliability (#7284); - add timestamp check to ExtractTask call https://github.com/broadinstitute/dsp-spec-ops/issues/320; - serial inserts for scaling prepare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage versi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:14776,reliab,reliability,14776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['reliab'],['reliability']
Availability,"ut false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [June 7, 2017 12:48:13 AM UTC] Executing as tianj@ip-xxx-xx-xx-xxx on Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.alpha.2-1100-g04dbeb2-SNAPSHOT; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.total",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:3737,ERROR,ERROR,3737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability,"ut.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalization copy ratio are now referred to as standardized/denoised copy ratio.; - [x] Old code is still used for GC-bias correction in `CreateReadCountPanelOfNormals`, and we still use the `AnnotateTargets` tool. We should port this over (possibly as part of `PreprocessIntervals`) at some point (actually, I think we will be for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:1895,redundant,redundant,1895,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['redundant'],['redundant']
Availability,"utStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:31 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.24, executor 1, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:44322 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:44322 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:53 WARN TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7, xx.xx.xx.24, executor 1): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:30365,Error,Error,30365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Error'],['Error']
Availability,ute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class Visi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:19407,error,error,19407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,utes.; Runtime.totalMemory()=3966238720; java.util.concurrent.CompletionException: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.lambda$getFeatureReadersInParallel$614(GenomicsDBImport.java:605); at java.util.LinkedHashMap.forEach(LinkedHashMap.java:684); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReadersInParallel(GenomicsDBImport.java:600); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.createSampleToReaderMap(GenomicsDBImport.java:491); at com.intel.genomicsdb.importer.GenomicsDBImporter.lambda$null$2(GenomicsDBImporter.java:602); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590); ... 3 more; Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at java.util.concurrent.FutureTask.report(FutureTas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420:1325,Error,Error,1325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420,2,"['Error', 'Failure']","['Error', 'Failure']"
Availability,"util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); 	at java.lang.Thread.run(Thread.java:745). Container exited with a non-zero exit code 1. 18/01/09 18:31:21 INFO storage.BlockManagerMaster: Removal of executor 9 requested; 18/01/09 18:31:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 9; 18/01/09 18:31:21 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:30153,down,down,30153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['down'],['down']
Availability,utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(Filte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1284,Error,ErrorProbabilities,1284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['Error'],['ErrorProbabilities']
Availability,utils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.857% <100%> (√∏)` | `17 <0> (√∏)` | :arrow_down: |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZUlucHV0LmphdmE=) | `88.235% <0%> (-4.82%)` | `19% <0%> (+1%)` | |; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343:1939,down,downsampling,1939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343,1,['down'],['downsampling']
Availability,ution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:13650,ERROR,ERROR,13650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"utor.java:858); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138); at java.lang.Thread.run(Thread.java:745); 2019-02-17 16:25:50 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-02-17 16:25:50 INFO MemoryStore:54 - MemoryStore cleared; 2019-02-17 16:25:50 INFO BlockManager:54 - BlockManager stopped; 2019-02-17 16:25:50 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-02-17 16:25:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-02-17 16:25:50 INFO SparkContext:54 - Successfully stopped SparkContext; 16:25:50.893 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 17, 2019 4:25:50 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 5.28 minutes.; Runtime.totalMemory()=5059379200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 181 in stage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:47148,failure,failure,47148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['failure'],['failure']
Availability,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35322,down,down,35322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,4,['down'],['down']
Availability,"utors.java:511); at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:2956,failure,failure,2956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['failure'],['failure']
Availability,"utput from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace; Command being timed: ""gatk --java-options -Xmx200g -Xms16g GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace""; User time (seconds): 270716.45; System time (seconds): 1723.34; Percent of CPU this job got: 99%; Elapsed (wall clock) time (h:mm:ss or m:ss): 76:08:24; Average shared text size (kbytes): 0; Average unshared data size (kbytes): 0; Average stack size (kbytes): 0; Average total size (kbytes): 0; Maximum resident set size (kbytes): 2630440; Average resident set size (kbytes): 0; Major (requiring I/O) page faults: 5; Minor (reclaiming a frame) page faults: 206030721; Voluntary context switches: 11129822; Involuntary context switches: 176522; Swaps: 0; File system inputs: 627981312; File system outputs: 466730160; Socket messages sent: 0; Socket messages received: 0; Signals delivered: 0; Page size (bytes): 4096; Exit status: 0. ```. So using the import on reblocked gvcfs using --bypass-feature-reader was the fastest way to import our 3500 gVCFs and minimize memory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:2804,fault,faults,2804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,4,['fault'],['faults']
Availability,v1.7.20200521s; 10:25:49.785 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 10:25:49.785 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 10:25:49.785 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 10:25:49.788 INFO DataSourceUtils - Resolved data source file path: file:///technology/research_development/WES/vcf/gencode_xrefseq_v75_37.tsv -> file:///technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 10:25:49.789 INFO DataSourceUtils - Resolved data source file path: file:///technology/research_development/WES/vcf/achilles_lineage_results.import.txt -> file:///technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s/achilles/hg19/achilles_lineage_results.import.txt; 10:25:49.789 INFO DataSourceUtils - Resolved data source file path: file:///technology/research_development/WES/vcf/clinvar_20180401.vcf -> file:///technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 10:25:49.790 INFO DataSourceUtils - Resolved data source file path: file:///technology/research_development/WES/vcf/simple_uniprot_Dec012014.tsv -> file:///technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 10:25:49.791 INFO DataSourceUtils - Resolved data source file path: file:///technology/research_development/WES/vcf/clinvar_hgmd.tsv -> file:///technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv. **The input vcf file was from gatk FilterMutectCalls and just keep indel record**. what's the problem with the program? It have run a long time but without any results and errors. Thank you.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135:5833,error,errors,5833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135,1,['error'],['errors']
Availability,"va.io.tmpdir=/cromwell_root/tmp.H9t5pC; [December 14, 2017 7:41:30 PM UTC] GenomicsDBImport --genomicsDBWorkspace genomicsdb --batchSize 50 --sampleNameMap /cromwell_root/broad-jg-dev-storage/freimer_dutch_fin_wgs_v1/v1/sample_map --readerThreads 5 --intervals chr1:1-391754 --interval_padding 500 --genomicsDBSegmentSize 1048576 --genomicsDBVCFBufferSize 16384 --overwriteExistingGenomicsDBWorkspace false --consolidate false --validateSampleNameMap false --interval_set_rule UNION --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [December 14, 2017 7:41:30 PM UTC] Executing as root@7ca892f01ff3 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.6; [December 14, 2017 7:41:30 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=4116185088; ***********************************************************************. A USER ERROR has occurred: Bad input: Expected a file of format; Sample	File; but found line: I-PAL_FR02_000639 001	gs://broad-gotc-prod-storage/pipeline/G87944/gvcfs/I-PAL_FR02_000639_001.023ca2f7-4fba-4617-9f65-cb989818c858.g.vcf.gz. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3979:2677,ERROR,ERROR,2677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3979,1,['ERROR'],['ERROR']
Availability,va:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:2290,Error,ErrorProbabilities,2290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Error'],['ErrorProbabilities']
Availability,va:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:2290,Error,ErrorProbabilities,2290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Error'],['ErrorProbabilities']
Availability,va:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30T13:35:51.796108757Z 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:2291,Error,ErrorProbabilities,2291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Error'],['ErrorProbabilities']
Availability,va:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:15763,error,error,15763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,va:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8268598Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8269986Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8270563Z [0K; 2022-08-16T22:45:53.8270698Z [0K; 2022-08-16T22:45:53.8270832Z [0K; 2022-08-16T22:45:53.8272441Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 31s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/transformers/DRAGENMappingQualityReadTransformer.java:3: error: package com.google.common.annotations does not exist[0K; 2022-08-16T22:45:53.8283859Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8284709Z src/main/java/org/broadinstitute/hellbender/tools/walkers/hapl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:17801,error,error,17801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"va:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:56:39 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 45.308012 s; 18/04/24 17:56:39 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.16:4040; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:37441,down,down,37441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,2,['down'],['down']
Availability,"vaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.contig-sam-file.sam\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf.gz \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode client \; --executor-memory 85G\; --driver-memory 30g\; --num-executors 40\; --executor-cores 4\; --conf spark.yarn.submit.waitAppCompletion=false\; --name ""$SAMPLE"" \; --files $REF.img,$KMER \; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120; #### Expected behavior. Should complete and write output files. . #### Actual behavior; Job aborts after running 45 min and no output files are written. The error message refers to filename that is not actually passed as a parameter to the tool: hdfs://scc:-1/. Not sure where the -1 is coming from. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:6102,heartbeat,heartbeatInterval,6102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,2,"['error', 'heartbeat']","['error', 'heartbeatInterval']"
Availability,"validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 23, 2018 11:06:24 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 73.92 minutes.; Runtime.totalMemory()=10458497024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 27 in stage 15.0 failed 4 times, most recent failure: Lost task 27.3 in stage 15.0 (TID 29483, scc-q15.scc.bu.edu, executor 13): org.broadinstitute.hellbender.exc eptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:4474,down,down,4474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['down'],['down']
Availability,"var_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runW",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:7254,down,down,7254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['down'],['down']
Availability,variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:4011,Down,Download,4011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,1,['Down'],['Download']
Availability,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:4910,error,error,4910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,3,['error'],['error']
Availability,"vc71/AAAIm7MZ1tLL6xuUUp7tk2g_a?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.0.12.0/gatk-4.0.12.0.zip; unzip gatk-4.0.12.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chr12,length=133275309>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr12\t60339493\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339499\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339510\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 17 18; do; gatk-4.0.12.0/gatk Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; --tumor SM \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr12:60339493-60339510 \; --min-base-quality-score $score \; --bam-output output.$score.bam && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr12:60339493-60339510; done; ```. With the two outputs being:; ```; chr12	60339493	A	G	0/1	0,9; chr12	60339499	A	G	0/1	0,8; chr12	60339510	C	T	0/1	0,10; ```; and:; ```; chr12	60339493	A	G	0/1	6,0; chr12	60339499	A	G	0/1	2,5; chr12	60339510	C	T	0/1	0,9; ```. And these are the two BAMs with the reconstructed haplotypes I obtained:; ![igv_snapshot](https://user-images.githubusercontent.com/1829330/64201720-51bafc80-ce5d-11e9-8dc3-3b2d308da12c.png). However, I am unable to reproduce",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079:1149,echo,echo,1149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079,1,['echo'],['echo']
Availability,"vcf.gz; 23:24:51.451 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///omics/chatchawit/bundle/dsrc/oreganno/hg38/oreganno.tsv; 23:24:51.535 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///omics/chatchawit/bundle/dsrc/gencode/hg38/gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; WARNING	2018-05-23 23:24:53	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 23:25:09.380 INFO ProgressMeter - Starting traversal; 23:25:09.381 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:25:20.674 INFO ProgressMeter - chr1:24929636 0.2 3000 15941.9; 23:25:42.601 INFO ProgressMeter - chr1:64681324 0.6 6000 10837.2; 23:25:54.659 INFO ProgressMeter - chr1:156245393 0.8 9000 11926.3; 23:26:06.846 INFO ProgressMeter - chr1:206965947 1.0 12000 12529.6; 23:26:12.318 INFO Funcotator - Shutting down engine; [May 23, 2018 11:26:12 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1.38 minutes.; Runtime.totalMemory()=10974920704; java.lang.IllegalArgumentException: Genomic positions must be > 0.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722); 	at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:153); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getAlignedPosition(FuncotatorUtils.java:336); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1392); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotationForProteinCodingFeature(GencodeFuncotationFactory.java:751); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createExonFuncotation(GencodeFuncotationFactory",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032:4228,down,down,4228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032,1,['down'],['down']
Availability,"veGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field AS_SOR - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field FS - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field QD - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.528 INFO GenotypeGVCFs - Shutting down engine; [September 23, 2023 at 8:09:23 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2801795072; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:463); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:365); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291); at org.broadinstitute.hellbender.engine.VariantLocusWalker.initialize at org.broadinstitute.hellbender.engine.Varia",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8527:5730,down,down,5730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8527,1,['down'],['down']
Availability,vents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.run(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:13938,ERROR,ERROR,13938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"ver VM v1.8.0_181-b13; 14:35:47.080 INFO SelectVariants - Start Date/Time: September 24, 2018 2:35:45 PM EET; 14:35:47.080 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.081 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.082 INFO SelectVariants - HTSJDK Version: 2.16.1; 14:35:47.082 INFO SelectVariants - Picard Version: 2.18.13; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:47.082 INFO SelectVariants - Deflater: IntelDeflater; 14:35:47.082 INFO SelectVariants - Inflater: IntelInflater; ```. From @jean-philippe-martin . > This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM).; > ; > As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via gcloud auth, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on.; > ; > The message is useful, for if we were running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.; > . We should tone down the error message if possible.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:6468,down,down,6468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,2,"['down', 'error']","['down', 'error']"
Availability,"versed.selfRef.shifted.homoplasmies.vcf.bgz \\ ; ; \--annotation StrandBiasBySample \\ ; ; \--mitochondria-mode \\ ; ; \--max-reads-per-alignment-start 75 \\ ; ; \--max-mnp-distance 0 \\ ; ; \-L chrM:8023-9140 \\ ; ; \--genotype-filtered-alleles \\ ; ; \--debug-assembly-variants-out /rej.vcf \\ ; ; \--bam-output bamout.bam. In this instance the variant in question is listed in the rej.vcf file obtained via `--debug-assembly-variants-out`. I have examined `bamout.bam` as well as the input bam and there appears to be ample coverage at the site of interest (the T at position 8316 is the position of interest, highlighted):. ![](https://gatk.broadinstitute.org/hc/user_images/aGbHKebG7Tb8Lgu33gGzXw.png). I have tried running this with some of the additional parameters in \[[https://gatk.broadinstitute.org/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant\](/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant)](https://gatk.broadinstitute.org/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant](/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant)) (namely `--linked-de-bruijn-graph` and `--recover-all-dangling-branches`) to no avail. Coverage is very deep at this position (>2000x). Notably if I edit the input to `--alleles` and change the allele of interest (8316:T>A) to anything else (8316:T>C or T>G) it appropriately shows up in the output VCF. What am I missing here? Let me know if you have any solutions or if you need any additional files. UPDATE: Adding `--disable-adaptive-pruning` now produces the variant of interest specified in --alleles, but also adds several other new calls, in case that is helpful in isolating where this force-call variant is being lost.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/270138'>Zendesk ticket #270138</a>)<br> gz#270138</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7672:2471,recover,recover-all-dangling-branches,2471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7672,2,"['avail', 'recover']","['avail', 'recover-all-dangling-branches']"
Availability,"version : 1.4.3-6069e4a; 17:52:35.478 info NativeGenomicsDB - pid=66560 tid=66565 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 17:52:35.487 info NativeGenomicsDB - pid=66560 tid=66565 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 17:52:35.487 info NativeGenomicsDB - pid=66560 tid=66565 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 17:55:56.179 INFO GenotypeGVCFs - Done initializing engine; 17:55:56.692 INFO ProgressMeter - Starting traversal; 17:55:56.704 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 07:43:39.738 INFO ProgressMeter - 7:1067 2267.7 1000 0.4; 07:44:22.642 INFO ProgressMeter - 7:2069 2268.4 2000 0.9; 07:45:48.820 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.764015676999995,Cpu time(s),6.525572708; [2022Âπ¥5Êúà24Êó• ‰∏äÂçà07Êó∂45ÂàÜ51Áßí] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 2,276.03 minutes.; Runtime.totalMemory()=2278555648; java.lang.IllegalStateException: Genotype has no likelihoods: [CAU-SICAU-Y1035 A*/T GQ 80 DP 10]; at org.broadinstitute.hellbender.utils.GenotypeUtils.computeDiploidGenotypeCounts(GenotypeUtils.java:89); at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.calculateEH(ExcessHet.java:96); at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.annotate(ExcessHet.java:84); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.addInfoAnnotations(VariantAnnotatorEngine.java:355); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:334); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.an",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848:3535,down,down,3535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848,2,['down'],['down']
Availability,version bump for reliability,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7284:17,reliab,reliability,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7284,1,['reliab'],['reliability']
Availability,"very possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:1066,error,error,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,1,['error'],['error']
Availability,"vis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJpZM4clLLK>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 105 Broadway, Room 332; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:1411,Failure,Failures,1411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426,1,['Failure'],['Failures']
Availability,"vletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9273,AVAIL,AVAILABLE,9273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"vletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46679,AVAIL,AVAILABLE,46679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1240,error,error,1240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586,13,"['ERROR', 'Error', 'avail', 'error']","['ERROR', 'Error', 'available', 'error', 'errors']"
Availability,want to use HaplotypeCaller and GenotypeGVCFs to call SNPs and meet a problem and my GATK version is v3.3-0-g37228af . Here is my script and I have 427 sampleÔºö. $JAVA -Xmx8g -jar $GATK -T HaplotypeCaller -R Chr06.fa -I $NOW/${RIL}.final.bam -ERC GVCF -o $NOW/${RIL}.raw.g.vcf --genotyping_mode DISCOVERY -variant_index_type LINEAR -variant_index_parameter 128000 -nct 24; $JAVA -Xmx4g -jar $GATK -T GenotypeGVCFs -nt 24 -R $REF/Chr06.fa \; --variant $NOW/w-1.raw.g.vcf \; --variant $NOW/w-10.raw.g.vcf \; --variant $NOW/w-100.raw.g.vcf \; -o KF427.raw.vcf. I got a error like this:. ##### ERROR MESSAGE: Invalid command line: No tribble type was provided on the command line and the type of the file could not be determined dynamically. Please add an explicit type tag :NAME listing the correct type from among the supported types:; ##### ERROR Name FeatureType Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:845,ERROR,ERROR,845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,5,['ERROR'],['ERROR']
Availability,"was created from a contribution made by Chunyang Bao on June 14, 2021 23:15 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/1260803844270-ASEReadCounter-ouputs-only-header-](https://gatk.broadinstitute.org/hc/en-us/community/posts/1260803844270-ASEReadCounter-ouputs-only-header-). \--. I am using ASEReadCounter to call allelic read counts on 1000 genome reference. But, I found ASEReadCounter generatd only header in output file. Here I enclosed my command and stderr log. Please help me to check it. Thank you!. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.1.8.1 ; ; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \\ ; ; \-jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:1364,error,error,1364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['error'],['error']
Availability,"waterman argument is an enumerated type (Implementation), which can have one of the following values:. FASTEST_AVAILABLE; use the fastest available Smith-Waterman aligner that runs on your hardware; AVX_ENABLED; use the AVX enabled Smith-Waterman aligner; JAVA; use the pure java implementation of Smith-Waterman, works on all hardware; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007fafc8ed1000 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fafce3f37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fafce400698]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7faf73bfcfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7faf73bfcbf8]; [0x7fafb9a7eea2]; ```. and ; ```; *** Error in `java': double free or corruption (out): 0x00007f933d610780 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f93434427e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f934344b37a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f934344f53c]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f9248e4bfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f9248e4bbf8]; [0x7f932de9ceaa]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509:1462,Error,Error,1462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509,1,['Error'],['Error']
Availability,"we need a canonical set of tests that we run when we upgrade the cluster. We've been running terasort but it's not enough: 1) it does not run our code and 2) it does not even run java8 (recent config error when 2 nodes were running java7 was undetected). The task here is to write, in readme or in scripts directory, a script or set of scripts that must be run after every change to the cluster.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1392:200,error,error,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1392,1,['error'],['error']
Availability,"weinkauf/notes/persistence1d.html and http://www2.iap.fr/users/sousbie/web/html/indexd3dd.html?post/Persistence-and-simplification). A straightforward watershed algorithm can sort all local minima by persistence in linear time after an initial sort of the data.; 5) These sets of local minima from all window sizes together provide the pool of candidate changepoints (some of which may overlap exactly or approximately). We perform backwards selection using the global segmentation cost. That is, we compute the global segmentation cost given all the candidate changepoints, calculate the cost change for removing each of the changepoints individually, remove the changepoint with the minimum cost change, and repeat. This gives the global cost as a function of the number of changepoints _C_.; 6) Add a penalty _a C + b C log(N / C)_ to the global cost and find the minimum to determine the number of changepoints. For the above simulated data, _a = 2_ and _b = 2_ works well, recovering all of the changepoints in the above example with no false positives:; ![6](https://user-images.githubusercontent.com/11076296/29582517-fbd604be-874a-11e7-8ef7-7bd727f65dcb.png). ![7](https://user-images.githubusercontent.com/11076296/29582518-fddf015c-874a-11e7-89e4-87250d2a52ab.png). In contrast, CBS produces two false positives (around the third and seventh of the true changepoints):. ![8](https://user-images.githubusercontent.com/11076296/29582545-18875126-874b-11e7-9166-9061bb120e43.png). We can change the penalty factor to smooth out less significant segments (which may be due to systematic noise, GC waves, etc.). Setting _a = 10, b = 10_ gives:; ![9](https://user-images.githubusercontent.com/11076296/29582598-515dffe0-874b-11e7-93c4-59422cd43b54.png); ![10](https://user-images.githubusercontent.com/11076296/29583130-0fe5316c-874d-11e7-8504-43618928cf68.png). (Note that the DNAcopy implementation of CBS does not allow for such simple control of the ""false-positive rate,"" as even setting the",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586:2866,recover,recovering,2866,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586,2,['recover'],['recovering']
Availability,well looks like the offending line is this:; ` mLogLikelihoodArray = new double[readListSize * numHaplotypes]; //to store results`. I don't like that those two numbers are overflowing... numHaplotypes should really be getting bounded to ~256 and readListSize similarly should be capped by the downsampling. This warrants investigation,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440#issuecomment-1654212785:293,down,downsampling,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440#issuecomment-1654212785,1,['down'],['downsampling']
Availability,"when I use this CML: ; java -Xmx8G -jar /Users/mac/Downloads/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta -V /Users/mac/Desktop/NGS-/42variants.vcf -O /Users/mac/Desktop/NGS-/42varians_filt.vcf --filter-expression ""QD < 2.0 || MQ > 50"" --filter-name ""hard_filtering_snp"" . I get : 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Long.parseLong(Long.java:589); 	at java.lang.Long.parseLong(Long.java:631); 	at org.apache.commons.jexl2.JexlArithmetic.toLong(JexlArithmetic.java:906); 	at org.apache.commons.jexl2.JexlArithmetic.compare(JexlArithmetic.java:718); 	at org.apache.commons.jexl2.JexlArithmetic.greaterThan(JexlArithmetic.java:790); 	at org.apache.commons.jexl2.Interpreter.visit(Interpreter.java:796); 	at org.apache.commons.jexl2.parser.ASTGTNode.jjtAccept(ASTGTNode.java:18); 	at org.apache.commons.jexl2.Interpreter.visit(Interpreter.java:1283); 	at org.apache.commons.jexl2.parser.ASTOrNode.jjtAccept(ASTOrNode.java:18); 	at org.apache.commons.jexl2.Interpreter.interpret(Interpreter.java:232); 	at org.apache.commons.jexl2.ExpressionImpl.evaluate(ExpressionImpl.java:65); 	at htsjdk.variant.variantcontext.JEXLMap.evaluateExpression(JEXLMap.java:186); 	at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:95); 	at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:15); 	at htsjdk.variant.variantcontext.VariantContextUtils.match(VariantContextUtils.java:338); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:453); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:407); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:354); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Fo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887:51,Down,Downloads,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887,1,['Down'],['Downloads']
Availability,"when the cluster is created. The default for this value is `false`, per [here](https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml), which is the version of Hadoop used in Dataproc image version 1.3. If left as `false`, one keeps getting errors like below when requesting reference bases localized to the HDFS attached to the dataproc cluster, regardless if using *.fasta.gz or *.fasta.; ```; 19/07/26 20:15:43 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 20.5 in stage 50.0 (TID 45798, shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-w-2.c.broad-dsde-methods.internal, executor 44): htsjdk.samtools.SAMException: Unable to load chr14(100526932, 100526932) from /reference/Homo_sapiens_assembly38.fasta; 	at htsjdk.samtools.reference.AbstractIndexedFastaSequenceFile.getSubsequenceAt(AbstractIndexedFastaSequenceFile.java:207); 	at htsjdk.samtools.reference.IndexedFastaSequenceFile.getSubsequenceAt(IndexedFastaSequenceFile.java:49); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceHadoopSparkSource.getReferenceBases(ReferenceHadoopSparkSource.java:31); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvType.extractRefBases(SvType.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SimpleSVType$DuplicationTandem.<init>(SimpleSVType.java:190); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.inferSimpleTypeFromNovelAdjacency(ContigChimericAlignmentIterativeInterpreter.java:229); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.lambda$discoverVariantsFromChimeras$610a78cb$1(ContigChimericAlignmentIterativeInterpreter.java:84); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6064:273,error,errors,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6064,1,['error'],['errors']
Availability,"when trying to build GATK fully I get this error:; ```; > Task :gatkDoc FAILED; Execution optimizations have been disabled for task ':gatkDoc' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/classes/java/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/resources/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/jeremie/GATK/build/tmp/gatkDoc/javadoc.options'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 1 invalid unit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500:43,error,error,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500,1,['error'],['error']
Availability,where to download GATK3?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6373:9,down,download,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6373,1,['down'],['download']
Availability,"with LOD <= -5.0000.; 18:03:57.263 INFO GaussianMixtureModel - Initializing model with 100 k-means iterations...; 18:04:05.276 INFO VariantRecalibratorEngine - Finished iteration 0.; 18:04:07.160 INFO VariantRecalibratorEngine - Finished iteration 5. Current change in mixture coefficients = 0.47495; 18:04:09.021 INFO VariantRecalibratorEngine - Finished iteration 10. Current change in mixture coefficients = 0.07996; 18:04:10.871 INFO VariantRecalibratorEngine - Finished iteration 15. Current change in mixture coefficients = 0.02188; 18:04:12.690 INFO VariantRecalibratorEngine - Finished iteration 20. Current change in mixture coefficients = 0.00815; 18:04:14.555 INFO VariantRecalibratorEngine - Finished iteration 25. Current change in mixture coefficients = 0.00334; 18:04:15.663 INFO VariantRecalibratorEngine - Convergence after 28 iterations!; 18:04:15.938 INFO VariantRecalibratorEngine - Evaluating full set of 3826009 variants...; 18:04:20.008 INFO VariantRecalibrator - Shutting down engine; [July 28, 2021 6:04:20 PM EDT] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 7.70 minutes.; Runtime.totalMemory()=105907224576; java.lang.IllegalStateException: Gaussian mean vector does not have the same size as the list of annotations; at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.makeMeansTable(VariantRecalibrator.java:986); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.writeModelReport(VariantRecalibrator.java:887); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:680); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380:8737,down,down,8737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380,1,['down'],['down']
Availability,"with last release, its fine. Bug resolved. but still have this error : https://github.com/bcbio/bcbio-nextgen/issues/2829. I finished by doing like that : https://github.com/bcbio/bcbio-nextgen/commit/3ed523f04cbbbbf3ef19974d5a7585ed43af2c20. it happens with contr√¥le empty samples (zero variants)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-574103703:63,error,error,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-574103703,1,['error'],['error']
Availability,"wo different write modes. When `WRITE_AND_COPY` is selected, a temporary .pgen file is created and written to during the running of the tool, and then once all records have been written, a new file is created with the index at the top and the contents of the temporary .pgen file appended to it. When `WRITE_SEPARATE_INDEX` is selected, the index is instead written to a separate .pgi file. The default is `WRITE_AND_COPY`. #### max-alt-alleles; The PGEN format can only support up to 254 alt alleles per site. This argument allows you to specify a limit. The default is the max of 254. Any sites with more alt alleles than the specified max will not be written. #### lenient-ploidy-validation; PGEN is a bit quirky in that it requires samples to be diploid but has a special case for sex chromosomes, which are allowed to be haploid. By default, any attempt to write a record with an unsupported ploidy will result in an exception being thrown. If this flag is used, then ploidy failures will instead be logged and the records will be written as missing. #### writer-log-file; The C++ code in the PGEN writer in PGEN-JNI will log sites that exceed max-alt-alleles and with unsupported ploidy (if lenient-ploidy-validation is set) to the specified log file, if this argument is set. #### allow-empty-pgen; Empty PGEN files are not technically valid PGEN files. However, for parallel processing purposes, it is sometimes helpful to allow the creation of empty files when there are no variants to be written. The GvsExtractCallsetPgenMerged workflow relies on this. If this flag is set and no variants are written, an empty .pgen, .psam, and .pvar.zst file will be written in `onShutdown()`. By default (i.e. if this flag is not set), if there are no variants written, an exception will be thrown. . ### Part 3: GvsExtractCallsetPgenMerged; GvsExtractCallsetPgenMerged is a WDL workflow that calls ExtractCohortToPgen to extract data from GVS and write it to PGEN files, and then merges those PGEN file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:4866,failure,failures,4866,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['failure'],['failures']
Availability,"working to setup a singularity container for gatk-4.1.4.0. while preparing the gatk conda environment numpy-1.13.3 ins installed but biopython==1.70 requirement from the pip section of the gatkcondaenv.yml. removes it and install numpy-1.18.1. see relevant part of conda env create -n gatk -f gatk-4.1.4.0/gatkcondaenv.yml 2>&1 | tee log; NB full log is attached : [log.txt](https://github.com/broadinstitute/gatk/files/4091802/log.txt). ```; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:549,Down,Downloading,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['Down'],['Downloading']
Availability,wow... test failure... :(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-580921081:12,failure,failure,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-580921081,1,['failure'],['failure']
Availability,"wup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta -I /juffowup2/malaria/haplotypecaller_arg_testing/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam -O /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz --bam-output /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam -contamination 0 --sample-ploidy 2 --linked-de-bruijn-graph --pileup-detection true --pileup-detection-enable-indel-pileup-calling true --max-reads-per-alignment-start 20 --annotate-with-num-discovered-alleles -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -G StandardAnnotation -G StandardHCAnnotation -ERC GVCF --verbosity INFO; 14:14:15.323 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 14:14:15.328 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 14:14:15.388 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/juffowup/gatk/build/install/gatk/lib/gkl-0.8.11.jar!/com/intel/gkl/native/libgkl_compression.so; 14:14:15.435 INFO HaplotypeCaller - ------------------------------------------------------------; 14:14:15.439 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0-44-g1529aa1-SNAPSHOT; 14:14:15.439 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:14:15.439 INFO HaplotypeCaller - Executing as jonn@dsde-methods-jonn-juffowup on Linux v5.4.0-1104-gcp amd64; 14:14:15.439 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.7+7; 14:14:15.440 INFO HaplotypeCaller - Start Date/Time: July 26, 2023 at 2:14:15 PM UTC; ...; 22:15:34.977 INFO HaplotypeCaller - Shutting down engine; [July 26, 2023 at 10:15:34 PM UTC] org.broadinstitute.hellbender.tools.walkers.haplotypecal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:1222,Redundant,Redundant,1222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['Redundant'],['Redundant']
Availability,"x"": ""3.8036305555555554"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFControlSample/Benchmark/21373bda-c620-4200-ad29-1e3886ea52ad/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""104.20126111111112"",; ""NIST evalHCsystemhours"": ""0.20587777777777783"",; ""NIST evalHCwallclockhours"": ""76.10080000000004"",; ""NIST evalHCwallclockmax"": ""3.949438888888889"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFTestSample/Benchmark/b91bffd4-8057-453f-a8e2-4767648da91a/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169:22065,error,errors,22065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169,1,['error'],['errors']
Availability,xceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:6779,ERROR,ERROR,6779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,xec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:12908,ERROR,ERROR,12908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"xec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.HintGCAfterBuild.execute(HintGCAfterBuild.java:44); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_reso",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:12008,ERROR,ERROR,12008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,xecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8962,ERROR,ERROR,8962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"xecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:3166,heartbeat,heartbeat,3166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['heartbeat'],['heartbeat']
Availability,"xecutor.java:617); at java.lang.Thread.run(Thread.java:748). 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 1]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 2]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 3]; 18/04/23 20:42:02 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Cancelling stage 0; 18/04/23 20:42:02 INFO DAGScheduler: ResultStage 0 (first at ReadsSparkSource.java:221) failed in 11.519 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:14877,ERROR,ERROR,14877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['ERROR'],['ERROR']
Availability,xecutorException: ; python exited with 134; Command Line: python /tmp/training.741160770003597505.py --data_dir /tmp/readTensorDir7357298393069910206/ --output_dir /tmp/readTensorDir7357298393069910206/ --tensor_name read_tensor --annotation_set best_practices --conv_width 5 --conv_height 5 --conv_dropout 0.0 --padding valid --fc_dropout 0.0 --annotation_units 16 --epochs 1 --training_steps 5 --validation_steps 2 --gatk_version 4.1.4.1-11-gaa4eded-SNAPSHOT --id test_read_tensor_model --channels_last --mode train_default_2d_model; Stdout: ; Stderr: 2019-12-09 19:55:04.271829: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA; 2019-12-09 19:55:04.287419: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; terminate called after throwing an instance of 'Xbyak::Error'; what(): code is too big. 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantTrain.doWork(CNNVariantTrain.java:214); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:1285,Error,Error,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['Error'],['Error']
Availability,"xtHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:7994,AVAIL,AVAILABLE,7994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"xtHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8477,AVAIL,AVAILABLE,8477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"xtHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:35 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/13 18:11:36 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8646,AVAIL,AVAILABLE,8646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,"xtensive (growing with the number of points in a segment), and 2) binary segmentation is a global, greedy algorithm. These both cause long events to be preferred over short events, and thus the first changepoints found (and retained after applying the penalty) may not include those for small, obvious events. For example, see performance on this simulated data, which includes events of size 10, 20, 30, and 40 within 100,000 points at S/N ratio 3:1 in addition to sine waves of various frequency at S/N ratio 1:2 (to roughly simulate GC waves). Changepoints arising from the sine waves will be found first, since these give rise to longer segments:. ![wave-kern-no-local](https://user-images.githubusercontent.com/11076296/29322673-4dd9a1ac-81ac-11e7-94f5-5c5494e44ac5.png). CBS similarly finds many false positive breakpoints:. ![wave-cbs](https://user-images.githubusercontent.com/11076296/29322677-5576e4ba-81ac-11e7-888b-07ed5bff27e3.png). However, when we tune down the sine waves to 1:10, ApproxKernSeg still gets tripped up, but CBS looks better:. ![wave-kern-no-local-small-waves](https://user-images.githubusercontent.com/11076296/29322732-815df58c-81ac-11e7-8305-6e1798616336.png); ![wave-cbs-small-waves](https://user-images.githubusercontent.com/11076296/29322737-836b78fe-81ac-11e7-93be-753a40011203.png). To improve ApproxKernSeg, we can 1) make the cost function intensive, by simply dividing by the number of points in a segment, and 2) add to the cost function a local term, given by the cost of making each point a changepoint within a local window of a determined size. This local term was inspired by methods such as SaRa (http://c2s2.yale.edu/software/sara/). The reasoning is that with events at higher S/N ratio, we typically don't need to perform a global test to see whether any given point is a suitable changepoint; using the data locally surrounding the point typically suffices. With these modifications, ApproxKernSeg can handle both scenarios:; ![wave-kern](https://us",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045:1167,down,down,1167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045,2,['down'],['down']
Availability,"y 10 samples at a time using the command --genomicsdb-update-workspace-path and the relative .sample_map file containing the path to my g.vcf.gz and g.vcf.gz.tbi files. I tried running the GenomicsDBImport followed by GenotypeGVCFs using only four sampled and it worked appropriately by generating a .vcf.gz file along with the index .vcf.gz.tbi file. However, when I run GenotypeGVCFs with 222 samples I get the error: A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. The GATK version used is gatk-4.4.0.0 and the command used is the following:. python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz. attaches below also the complete program log. and the content of my callset.json file. Any idea about that?. Thank you very much. Stefano. REQUIRED for all errors and issues:; a) GATK version used: gatk-4.4.0.0; b) Exact command used: python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats_fatte_con_GenomicsDBImport.vcf.gz. c) Entire program log:. (base) administrator@srv2-napolioni:/mnt/nas2/Stefano/Cashmere/joint_variant_calling$ python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz; Using GATK jar /home/administrator/tool/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; ¬† ¬† java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /ho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:1168,error,errors,1168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['error'],['errors']
Availability,"y large numbers of false positives; > with bad mapping quality and very large normal artifact lods. The depth is; > often high due to mapping issues, which aggravates the problem. We should; > be able to modify our active region determination so that these bad sites; > don't trigger the assembly and likelihoods engines.; >; > ‚Äî; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/997>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdKeWsrA1DojH_u7JMVCvec1o-zOtks5ryCXbgaJpZM4ND1FU>; > .; >. ---. @LeeTL1220 commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/997#issuecomment-296208775). We should leverage that list for CNV tools as well. We get a lot of false positive CNVs in centromeres (particularly chr9). ---. @davidbenjamin commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/997#issuecomment-296262676). @ldgauthier Thank you! I have localized the regions, and that HaplotypeCaller interval list seems to exclude most or all of them (I can't say for sure because I have only localized down to about 100 kb). In our DREAM challenge wgs benchmarks we will lose about one in ten thousand true positives, which I can easily live with. This will save us a lot of time. ---. @davidbenjamin commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/997#issuecomment-296267603). @samuelklee if you're not already aware of this wgs intervals whitelist. ---. @samuelklee commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/997#issuecomment-296268137). Excellent, thanks. Looping in @asmirnov239, @mbabadi, and @achevali. ---. @samuelklee commented on [Wed May 03 2017](https://github.com/broadinstitute/gatk-protected/issues/997#issuecomment-299050342). Looping in @danielrosebrock and @dlivitz as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2975:3156,down,down,3156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2975,1,['down'],['down']
Availability,"y large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./gatk --java-options ""-Xmx100000m -Xms25000m"" \; HaplotypeCaller \; -R /juffowup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta \; -I ${WORKING_DIR}/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam \; -O ${WORKING_DIR}/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz \; --bam-output ${WORKING_DIR}/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam \; -contamination 0 \; --sample-ploidy 2 \; --linked-de-bruijn-graph \; --pileup-detection true \; --pileup-detection-enable-indel-pileup-calling true \; --max-reads-per-alignment-start 20 \; --annotate-with-num-discovered-alleles \; -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 \; -G StandardAnn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:5601,recover,recovery,5601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,2,['recover'],['recovery']
Availability,"y"">; ##FORMAT=<ID=MFRL,Number=R,Type=Integer,Description=""median fragment length"">; ##FORMAT=<ID=MMQ,Number=A,Type=Integer,Description=""median mapping quality"">; ##FORMAT=<ID=MPOS,Number=A,Type=Integer,Description=""median distance from end of read"">; ##FORMAT=<ID=OBAM,Number=A,Type=String,Description=""Whether the variant can be one of the given REF/ALT artifact modes."">; ##FORMAT=<ID=OBAMRC,Number=A,Type=String,Description=""Whether the variant can be one of the given REF/ALT artifact mode complements."">; ##FORMAT=<ID=OBF,Number=A,Type=Float,Description=""Fraction of alt reads indicating orientation bias error (taking into account artifact mode complement)."">; ##FORMAT=<ID=OBP,Number=A,Type=Float,Description=""Orientation bias p value for the given REF/ALT artifact or its complement."">; ##FORMAT=<ID=OBQ,Number=A,Type=Float,Description=""Measure (across entire bam file) of orientation bias for a given REF/ALT error."">; ##FORMAT=<ID=OBQRC,Number=A,Type=Float,Description=""Measure (across entire bam file) of orientation bias for the complement of a given REF/ALT error."">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=SA_MAP_AF,Number=3,Type=Float,Description=""MAP estimates of allele fraction given z"">; ##FORMAT=<ID=SA_POST_PROB,Number=3,Type=Float,Description=""posterior probabilities of the presence of strand artifact"">; etc..; etc..; etc..; 1 237752 . A G . artifact_in_normal;clustered_events;mapping_quality;panel_of_normals;strand_artifact DP=369;ECNT=3;IN_PON;NLOD=14.51;N_ART_LOD=9.23;POP_AF=0.168;P_GERMLINE=",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5158:3411,error,error,3411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5158,1,['error'],['error']
Availability,"y, which includes theano graph compilation. This includes 350 iterations of ADVI, but note that convergence to 1% was achieved after about 250 iterations. I also did not initialize with PCA. However, upping to T = 10^6 causes out of memory. Not sure if this could be naively alleviated by setting theano flags appropriately, but I think we will probably want to minibatch in T instead. Note also that this model uses the exact Poisson likelihood. Composing with an HMM segmentation step, perhaps alternating for a few iterations, would give the gCNV PoN without the Gaussian approximation we use. ---. @samuelklee commented on [Wed May 17 2017](https://github.com/broadinstitute/gatk-protected/issues/1038#issuecomment-302234920). The same run of T = 10^5 and N = 100 took <4 minutes on the gsa5 Tesla K40c GPU---about a 3x speedup over my home CPU. A slightly larger run of T = 1.5 * 10^5 and N = 200 took 10 minutes and 6GB of the GPU's 12GB memory. (I did start running into some weird theano/pymc3 errors when I tried to go bigger, unfortunately.) Moving to the GPU does require a bit of extra configuration but is relatively trivial. The real business goes down in exactly 11 lines of code, which cleanly specify the gCNV probabilistic model for read counts:. ```; with pm.Model() as model:; alpha_u = Uniform(name='alpha_u', lower=alpha_min, upper=alpha_max, shape=D); m_t = Uniform(name='m_t', lower=m_min, upper=m_max, shape=T); psi_t = Uniform(name='psi_t', lower=psi_min, upper=psi_max, shape=T); depth_s = Uniform(name='depth_s', lower=depth_min, upper=depth_max, shape=N); ; z_su = Normal(name='z_us', mu=0., sd=1., shape=(N, D)); W_tu = Normal(name='W_tu', mu=0., sd=1. / sqrt(alpha_u), shape=(T, D)); mu_st = Deterministic(name='mu_st', var=z_su.dot(W_tu.T) + m_t); b_st = Normal(name='b_st', mu=mu_st, sd=sqrt(psi_t), shape=(N, T)); n_ts = Poisson(name='n_ts', mu=depth_s * exp(b_st).T, observed=n_ts_data); ; fit_pm = pm.variational.advi(model=model, n=num_iterations, learning_rate=le",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2984:2082,error,errors,2082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2984,1,['error'],['errors']
Availability,"y.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789). the deletion that is causing the error is 141 base pairs, and I noticed the length of the contig Funcotator is trying to retrieve (895) is equal to the UTR length + deletion length + 1, 753 + 141 + 1. When I looked at the source code around where the error occurs, I see where the length of the retrieved interval is defined (line 738): . > final SimpleInterval transcriptInterval = new SimpleInterval(; > transcriptMapIdAndMetadata.mapKey,; > transcriptMapIdAndMetadata.fivePrimeUtrStart,; > transcriptMapIdAndMetadata.fivePrimeUtrEnd + extraBases; > );. and the logic for how large that extraBases should be (line 1566):. >final int numExtraTrailingBases = variant.getReference().length() < defaultNumTrail ingBasesForUtrAnnotationSequenceConstruction ? defaultNumTrailingBasesForUtrAnnotationSequenceConst ruction : variant.getReference().length() + 1;. I believe line 1566 is the source of the problem; there is no check that UTR-end + deletion length extends past the end of the transcript. #### Steps to reproduce. download funcotator_dataSources.v1.6.20190124s from Broad FTP server. run funcotator using:. `Funcotator -R /tmp/GRCh38.fa -V broken.vcf -O broken.out.vcf --data-sources-path funcotator_dataSources.v1.6.20190124s/ --output-file-format VCF --ref-ver",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:2256,error,error,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['error'],['error']
Availability,"y: (((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter); 58 read(s) filtered by: ((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter); 1 read(s) filtered by: (((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter); 1 read(s) filtered by: ((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter); 1 read(s) filtered by: (MappingQualityReadFilter AND MappingQualityAvailableReadFilter); 1 read(s) filtered by: MappingQualityReadFilter ; 57 read(s) filtered by: NotDuplicateReadFilter . 03:58:35.812 INFO ProgressMeter - 13:115070262 0.0 4029 203313.7; 03:58:35.812 INFO ProgressMeter - Traversal complete. Processed 4029 total regions in 0.0 minutes.; 03:58:35.839 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 8.397000000000001E-4; 03:58:35.839 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0028144000000000003; 03:58:35.839 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 03:58:35.840 INFO HaplotypeCaller - Shutting down engine; ```. #### Steps to reproduce; Command used:; ```; gatk HaplotypeCaller \; --input sample.bam \; --annotation OrientationBiasReadCounts \; --intervals b37.chr13.bed \; --reference hs37d5.fa \; --output sample.vcf.gz; ```. The processings were executed locally with Docker images `broadinstitute/gatk:4.1.1.0`, `broadinstitute/gatk:4.2.2.0` and `broadinstitute/gatk:4.3.0.0`. Other versions apart from these were not tested. #### Expected behavior; F1R2 and F2R1 computed and specified for each variant in recent versions of GATK. #### Actual behavior; F1R2 and F2R1 are described in the header, but they are not calculated in recent versions. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:14263,down,down,14263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['down'],['down']
Availability,"yBlockTransferService - Server created on 172.20.19.130:43279; 10:33:07.210 INFO BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 10:33:07.214 INFO BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.221 INFO BlockManagerMasterEndpoint - Registering block manager 172.20.19.130:43279 with 1076.2 GiB RAM, BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45003,AVAIL,AVAILABLE,45003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,yIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2990,ERROR,ERROR,2990,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,yes I think this is the reason of that error. but the reason the tool crash seems to be related to memory. I have run with 16 vs 32 and only the later runs to completion on a set of 30 WES (no specificly deep sequencing but they are cell line genomes),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939066359:39,error,error,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939066359,1,['error'],['error']
Availability,"yground/programs/gatk-protected/build/libs/gatk-protected-package-b4390fb-SNAPSHOT-local.jar; 102-b14; Version: 4.alpha.2-1136-gc18e780-SNAPSHOT; 16:55:21.931 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:21.932 INFO GermlineCNVCaller - Deflater: IntelDeflater; 16:55:21.932 INFO GermlineCNVCaller - Inflater: IntelInflater; 16:55:21.932 INFO GermlineCNVCaller - Initializing engine; 16:55:21.932 INFO GermlineCNVCaller - Done initializing engine; 16:55:21.933 INFO GermlineCNVCaller - Spark disabled. sparkMaster option (local[*]) ignored.; 16:55:23.448 INFO GermlineCNVCaller - Parsing the read counts table...; 16:55:24.876 INFO GermlineCNVCaller - Parsing the sample sex genotypes table...; 16:55:24.896 INFO GermlineCNVCaller - Parsing the germline contig ploidy annotation table...; 16:55:24.906 INFO ContigGermlinePloidyAnnotationTableReader - Ploidy tags: SEX_XX, SEX_XY; 16:55:25.056 INFO GermlineCNVCaller - Parsing the copy number transition prior table and initializing the caches...; 16:55:28.634 INFO GermlineCNVCaller - Initializing the EM algorithm workspace...; 16:55:32.861 INFO GermlineCNVCaller - Shutting down engine; [June 12, 2017 4:55:32 PM ACST] org.broadinstitute.hellbender.tools.coveragemodel.germline.GermlineCNVCaller done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=1364721664; org.broadinstitute.hellbender.exceptions.GATKException: Nd4j data type must be set to double for coverage modeller routines to function properly. This can be done by setting JVM system property ""dtype"" to ""double"". Can not continue. Thanks. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39376#Comment_39376",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3098:2420,down,down,2420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3098,1,['down'],['down']
Availability,yo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); ... 30 more; Caused by: java.lang.ClassNotFoundException: htsjdk.samtools.reference.AbstractFastaSequenceFile$$Lambda$85/2028177366; at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at com.esotericsoftware.kryo.util.DefaultClassResolver.readName(DefaultClassResolver.java:154); ... 50 more; 19/12/16 07:06:57 Thread-2 INFO ShutdownHookManager: Shutdown hook called; ```. I can reproduce a similar error locally:. ```; gatk HaplotypeCallerSpark \; -R src/test/resources/large/human_g1k_v37.20.21.fasta \; -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam \; --emit-ref-confidence GVCF \; -O out.vcf \; -- \; --spark-runner SPARK \; --spark-master spark://wm419-830:7077; ```; ```; Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IndexOutOfBoundsException: Index -2 out of bounds for length 299; Serialization trace:; positionLock (sun.nio.ch.FileChannelImpl); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); sequenceFile (org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile); val$taskReferenceSequenceFile (org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$1); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); 	at com.esotericsoftwa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6341:3320,error,error,3320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6341,1,['error'],['error']
Availability,"you may want to have a look here:; https://paste.opensuse.org/40b96df4. Before, I tried it with version 38 of Gencode. It is the indexing, that fails ; due to fixed fields, that changed looong time ago. -- ; ; r-engelmann.de - Ihre Seite f√ºr die Auswertung und Visualisierung von Daten ; aus den Bereichen Biomedizin, Finanzen, Sozio√∂konomie und weitere. On Dienstag, 30. August 2022 16:36:24 CEST Jonn Smith wrote:; > @robby81 Which scripts are you running and what are the errors you see? The ; data sources scripts; > are unsupported, but should work out of the box (they did last time I tried ; them).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1232016810:475,error,errors,475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1232016810,1,['error'],['errors']
Availability,"ype Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Des",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1864,error,error,1864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,1,['error'],['error']
Availability,"ype?; - The above is especially thorny for haplotypes that exhibit multiple variants.; - The FRD prior is only defined for individual events, not haplotypes.; - The BQD and FRD models use reads that overlap a variant site, but it is not clear how to use reads that only partially intersect a haplotype.; - BQD and FRD likelihoods are only defined for homozygous haplotypes, but heterozygous combinations of _haplotypes_ contribute to homozygous genotypes all loci where the distinct haplotypes agree. Clearly, generalizing BQD and FRD to entire haplotypes is not straightforward. Nor does it suffice to produce ""raw"" genotype likelihoods using the joint detection approach and then apply BQD and FRD on variant loci afterwards. Some difficulties with this include:. - BQD and FRD require the read-allele likelihoods matrix. Where are these likelihoods supposed to come from? The pre-joint-detection unrigorous ""marginalization"" where to each allele we assign the maximum likelihood over all haplotypes supporting that allele? Some read-allele likelihoods matrix derived from the read-haplotype likelihoods matrix?; - The drawbacks of the faulty ""marginalization"" actually become more severe with joint detection since genotyping multiple alleles together in a single determined span produces more haplotypes, which in turn increases the risk of the read-allele likelihoods cherry-picking from too many different haplotypes for different reads.; - The BQD and FRD models produce likelihoods on an absolute scale that is only meaningful relative to genotyping likelihoods from the pre-joint-detection approach. They do not inherently ""play nicely"" with the posterior probabilities produced by joint detection.; - BQD and FRD as currently implemented in the GATK modify likelihoods _before_ applying a prior, whereas joint detection yields posterior probabilities. Are we supposed to somehow un-apply the prior to joint detection likelihoods, apply BQD and FRD, then re-apply the prior? It is not clear.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616:2049,fault,faulty,2049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616,1,['fault'],['faulty']
Availability,"ype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --output_mode EMIT_VARIANTS_ONLY --allSitePLs false --readShardSize 5000 --readShardPadding 100 --minAssemblyRegionSize 50 --maxAssemblyRegionSize 300 --assemblyRegionPadding 100 --maxReadsPerAlignmentStart 50 --activeProbabilityThreshold 0.002 --maxProbPropagationDistance 50 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 9, 2017 10:13:02 AM AST] Executing as nkathiresan@nsnode11 on Linux 3.10.0-229.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.2-14-g4229219-SNAPSHOT; [INFO] Available threads: 32; [INFO] Requested threads: 1024; [WARNING] Using 32 available threads, but 1024 were requested; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.utils.MathUtils$Log10Cache).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; **[August 11, 2017 12:34:22 PM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. **Elapsed time: 3,021.34 minutes.****; Runtime.totalMemory()=57773916160; + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh. ; Thanks a lot,; With Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/10340/gatk-3-7-and-gatk-4-beta2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:7466,Avail,Available,7466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,2,"['Avail', 'avail']","['Available', 'available']"
Availability,"ys: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BEDCodec to read file file:///home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed; 09:39:56.024 INFO IntervalArgumentCollection - Processing 74592 bp from intervals; 09:39:56.032 INFO Mutect2 - Done initializing engine; 09:39:56.044 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 09:39:56.148 INFO Mutect2 - Shutting down engine; [July 3, 2020 9:39:56 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2233991168; htsjdk.samtools.util.RuntimeIOException: File not found: mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:451); 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695:3757,Avail,Available,3757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695,1,['Avail'],['Available']
Availability,"ython package archive in /home/axverdier/Tools/GATK4/git/gatk/build/gatkPythonPackageArchive.zip; :createPythonPackageArchive (Thread[Daemon worker Thread 2,5,main]) completed. Took 0.058 secs.; :compileJava (Thread[Daemon worker Thread 2,5,main]) started.; :compileJava; Executing task ':compileJava' (up-to-date check took 0.044 secs) due to:; No history is available.; All input files are considered out-of-date for incremental task ':compileJava'.; Compiling with JDK Java compiler API.; /home/axverdier/Tools/GATK4/git/gatk/src/main/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/inference/SuspectedTransLocDetector.java:13: warning: [unchecked] unchecked conversion; import org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignedContig;; ^; required: List<String>; found: List; error: warnings found and -Werror specified; 1 error; 1 warning; :compileJava FAILED; :compileJava (Thread[Daemon worker Thread 2,5,main]) completed. Took 4.116 secs. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > Compilation failed; see the compiler error output for details. * Try:; Run with --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':compileJava'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:5160,FAILURE,FAILURE,5160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['FAILURE'],['FAILURE']
Availability,"z; 15:46:44.076 WARN IndexUtils - Feature file ""snp151common_tablebrowser.bed.bgz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 15:46:44.500 WARN IndexUtils - Feature file ""snp151flagged_tablebrowser.bed.bgz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 15:46:44.798 INFO BaseRecalibrator - Done initializing engine; 15:46:44.936 INFO BaseRecalibrationEngine - The covariates being used here:; 15:46:44.936 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 15:46:44.937 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 15:46:44.937 INFO BaseRecalibrationEngine - 	ContextCovariate; 15:46:44.937 INFO BaseRecalibrationEngine - 	CycleCovariate; 15:46:44.953 INFO ProgressMeter - Starting traversal; 15:46:44.953 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 15:46:45.866 INFO BaseRecalibrator - Shutting down engine; [March 7, 2019 3:46:45 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=731381760; java.lang.IllegalArgumentException: fromIndex(64) > toIndex(62); 	at java.util.Arrays.rangeCheck(Arrays.java:113); 	at java.util.Arrays.fill(Arrays.java:3044); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateKnownSites(BaseRecalibrationEngine.java:354); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:322); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:137); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:91); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:5754,down,down,5754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['down'],['down']
Availability,"zed setting. ### Tool(s) or class(es) involved; GenomicsDBImport v.4.2.6.1 (current). ### Description ; As far as I understand it the joint germline variant calling process is like this (imagine 100 samples):; 1. Call variants using `Haplotypecaller` using the gVCF output flag for each sample; 2. use the multiple gVCFs (1 per sample) and a set of intervals (WGS_intervals.bed as an example) to build a Genomics DB store using `GenomicsDBImport`; 3. Use `GenotypeGVCFs` using the output of `GenomicsDBImport` as the input to consolidate the multiple samples into 1 multi-sample vcf. My question comes from the parallelization/interval splitting during step 2. If I parallelize the GenomicsDBImport across each interval. I would end up with ~300 intervals and subsequently, ~300 GenomicsDB directory paths since I am not adding new samples to an existing DB, then the specified output DB path, ""Must be an empty or non-existent directory"", which will contain the relevant interval calls for the 100 samples. . Am I supposed to use the 300 directory paths as input into a single `GenotypeGVCFs` call? Or process each of the 300 intervals into 300 multi-sample vcf files (each with 100 samples) and then merge those into a single vcf file using `GatherVcfs` or some other merging tool. The examples posted and documentation for `GenomicsDBImport` relay the need for intervals to work effectively, and so does [an old broad lecture recording](https://www.youtube.com/watch?v=XrHt5yBlp80&t=1243s). . Essentially it boils down to when and how to process and merge the same set of samples (100) over the many intervals (300). If I had 300 compute nodes (as an example) I want to parallelize as much of this as possible. so that each node can process an interval set, and at the end of the process I have 1 VCF file with 100 samples covering the entire range of intervals. I hope that was clear. Please let me know if you need any more info, or if I should be asking somewhere else. Thanks in advance!. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7898:1708,down,down,1708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7898,1,['down'],['down']
Availability,"{VariantContext@5509} ""[VC HC0 @ chr#:###551-###560 Q. of type=INDEL alleles=[CTTTTTTTTT*, C] attr={} GT=[] filters="" ; ```; And by chance that last variant (which happens to be supported by all haplotypes present) falls outside of our active region in the padding then we try to draw the variant span based on the first 4 haplotypes by the rules of haplotype expansion we end up making our trimming span `chr#:###326-###555` (note ###555 falls inside the span the 5th haplotype). When we go to trim all of our variant haplotypes (which happen to all have variant #5) they run into this code inside `Haplotype.trim()`:; ```; // note: the following returns null if the bases covering the ref interval start or end in a deletion.; final byte[] newBases = AlignmentUtils.getBasesCoveringRefInterval(newStart, newStop, getBases(), 0, getCigar());. if ( newBases == null || newBases.length == 0 ) { // we cannot meaningfully chop down the haplotype, so return null; return null;; }; ```; For all of our variant haplotypes at this site we find deletions at the end base and throw the whole haplotypes away when we try to trim it. In this particular case it meant we lost real variants in the previous 4 haplotypes as a result. I propose remedying this in one of two ways:; 1) Allow `AlignmentUtils.getBasesCoveringRefInterval()` to return partially spanning haplotypes when there are potentially 'shorter' than the reference haplotype span (this could easily cause all sorts of errors as the later code might not account for those mismatches. ; 2) Make `AlignmentUtils.getBasesCoveringRefInterval()` cheat and paste reference bases at the front or back of the haplotype to make it square with the reference offsets (we should never call or worry about deletions at the ends of haplotypes anyway) ; 3) Try to catch this edge case at the `AssemblyRegionTrimmer.trim()` stage, try to make the trimmer aware that there might be deletions overlapping its boundaries and expand them until there are no more overla",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7137:1612,down,down,1612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7137,1,['down'],['down']
Availability,| Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `84.091% <√∏> (√∏)` | `22 <0> (√∏)` | :arrow_down: |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470233081:1870,down,downsampling,1870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470233081,1,['down'],['downsampling']
Availability,"| Test failure | Fix |; | ------| ------ |; | FeatureInputUnitTest. testGcsPathAndName[0](gs://bucket/user/my.vcf, gs://bucket/user/my.vcf, gs://bucket/user/my.vcf) | seems like this should be doable unauthenticated |; | PSUtilsTest. testWriteTwoKryo | #2708 |; | BucketUtilsTest.testGetPathOnGcsDirectory | it seems like this should be doable unauthenticated #2707 |; | BucketUtilsTest. testIsCloudStorageURL | #2707 |; | GcsNioIntegrationTest. openPublicFile | mark as bucket |; | GcsNioIntegrationTest. testGcsEnabled | mark as bucket |",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300814385:7,failure,failure,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300814385,1,['failure'],['failure']
Availability,"| || | \ \ /\ / / _` | '__| '_ \| | '_ \ / _` | | || || | ; 12:11:32.828 WARN Funcotator - |_||_||_| \ \V V / (_| | | | | | | | | | | (_| | |_||_||_| ; 12:11:32.828 WARN Funcotator - (_)(_)(_) \_/\_/ \__,_|_| |_| |_|_|_| |_|\__, | (_)(_)(_) ; 12:11:32.828 WARN Funcotator - |___/ ; 12:11:32.828 WARN Funcotator - --------------------------------------------------------------------------------; 12:11:32.828 WARN Funcotator - Only IGRs were produced for this dataset. This STRONGLY indicates that this ; 12:11:32.828 WARN Funcotator - run was misconfigured. ; 12:11:32.828 WARN Funcotator - You MUST check your data sources to make sure they are correct for these data.; 12:11:32.828 WARN Funcotator - ================================================================================; 12:11:32.829 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 12:11:32.829 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 12:11:32.830 INFO Funcotator - Shutting down engine; [March 24, 2021 12:11:32 PM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.22 minutes.; Runtime.totalMemory()=1793064960; Tool returned:; true; (gatk) root@75181703d894:/gatk# . ----------------------------------------------------------------------------------------------------------------------------------. the variants.funcotated.maf:. #version 2.4; ##; ## fileformat=VCFv4.2; ## FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ## FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ## FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read Depth"">; ## source=Funcotator; ## GATKCommandLine=<ID=Funcotator,CommandLine=""Funcotator --output ./my_data/variants.funcotated.maf --ref-version hg19 --data-sources-path ./my_data/funcotator_dataSources.v1.7.20200521s --output-file-format MAF --variant ./my_data/test_b37.vcf --reference ./my_data/human_g1k_v37.fasta --disable-sequence-di",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7158:17995,down,down,17995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7158,1,['down'],['down']
Availability,"|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|3	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; And indeed, with that `--alleles` input with a single condensed record, HaplotypeCaller runs without error. Additionally, omitting the genotypes also runs without error:; ```; ##fileformat=VCFv4.1; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; 22	27658738	rs145982391	G	GGTTT,GGTTTGTTT	.	PASS	.; 22	27658738	rs374358960	GGTTTGTTT	G	.	PASS	.; ```; So it seems to be the combination of the split-record multiallelic and genotypes in `--alleles` file that is problematic here. Probably an edge case by most definitions (and straightforward to work around by either omitting genotypes or condensing multiallelics into a single record) but I figured it was worth pointing out. I should probably also add that many other split multiallelics seem to be processed fine, without crash, e.g.:; ```; ##fileformat=VCFv4.1; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	HG00096	HG00097	HG00099	HG00100	HG00101	HG00102	HG00103	HG00105	HG00106	HG00107	HG00108	HG00109	HG00110	HG00111	HG00112	HG00113	HG00114	HG00115	HG00116	HG00117	HG00118	HG00119	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:73983,error,error,73983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['error'],['error']
Availability,~okokok calm down it's just a draft!~. It's alive!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8534:13,down,down,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8534,2,"['alive', 'down']","['alive', 'down']"
Availability,"~~The `ALL_TRANSCRIPTS` output from Funcotator is not properly parsed by the built-in parsing methods for the funcotations.~~. ~~This should be fixed so that these parsing methods will work without producing an error.~~. -----------. It turns out that at least for `ClinVar_VCF_CLNVI`, hashes aren't being properly cleaned (i.e. URL encoded) before writing to the VCF fields. This is bad, because hash is our delimiter for `ALL_TRANSCRIPTS` mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5671:211,error,error,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5671,1,['error'],['error']
Availability,"¬†HaplotypeCaller - \* of the above arguments please manually construct the command. ¬†¬†¬†¬†¬†¬†¬†¬†\* ; ; 22:06:40.415 WARN ¬†HaplotypeCaller - \*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\* ; ; 22:06:40.437 INFO ¬†HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output ; ; 22:06:40.484 INFO ¬†NativeLibraryLoader - Loading libgkl\_utils.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_utils.so ; ; 22:06:40.485 INFO ¬†NativeLibraryLoader - Loading libgkl\_pairhmm\_omp.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_pairhmm\_omp.so ; ; 22:06:40.515 INFO ¬†IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM ; ; 22:06:40.516 INFO ¬†IntelPairHmm - Available threads: 4 ; ; 22:06:40.516 INFO ¬†IntelPairHmm - Requested threads: 4 ; ; 22:06:40.517 INFO ¬†PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation ; ; 22:06:40.545 INFO ¬†ProgressMeter - Starting traversal ; ; 22:06:40.545 INFO ¬†ProgressMeter - ¬†¬†¬†¬†¬†¬†¬†Current Locus ¬†Elapsed Minutes ¬†¬†¬†¬†Regions Processed ¬†¬†Regions/Minute ; ; 22:06:41.344 WARN ¬†InbreedingCoeff - InbreedingCoeff will not be calculated at position chr4:57843320 and possibly subsequent; at least 10 samples must have called genotypes ; ; 22:06:50.557 INFO ¬†ProgressMeter - ¬†¬†¬†¬†¬†¬†¬†chr4:69816964 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†0.2 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†570 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†3415.9 ; ; 22:07:00.633 INFO ¬†ProgressMeter - ¬†¬†¬†¬†¬†¬†¬†chr4:74352584 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†0.3 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†1340 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†4002.4 ; ; 22:07:10.827 INFO ¬†ProgressMeter - ¬†¬†¬†¬†¬†¬†¬†chr4:79856475 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†0.5 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†2370 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†4695.9 ; ; 22:07:20.846 INFO ¬†ProgressMeter - ¬†¬†¬†¬†¬†¬†¬†chr4:88243684 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†0.7 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†3370 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†5017.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:10583,Avail,Available,10583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['Avail'],['Available']
Availability,"‚Ä¶ as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416:323,error,errors,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416,2,['error'],['errors']
Availability,‚Ä¶ mismatches is too large. Removes an error that is thrown when the number of mismatches is greater than the number of mismatches/mismatches in the cigar. . It appears that some aligners do this. I am seeing it frequently in soft-clipped reads in TCGA RNA-seq BAMs (maybe a STAR bug?). . I would prefer to remove the thrown error rather than assume the dev will be aware of this issue and will catch it externally.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3639:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3639,2,['error'],['error']
Availability,‚Ä¶ over the VCF index if its better. Handle sequence interval validation when no sequence length is available. Fixes https://github.com/broadinstitute/gatk/issues/1999 and the downstream genomeLoc parser validation fallout.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2091:99,avail,available,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2091,2,"['avail', 'down']","['available', 'downstream']"
Availability,‚Ä¶ test. partial fix for #1042 - reenabled testStackOverFlowPairSetSwap - the failure was due to scoring strategy using by picard (total ref bases) vs spark (sum of quals). Spark did not even have a pluggable scoring strategy. Now it does and the test passes. For @davidadamsphd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1156:77,failure,failure,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156,1,['failure'],['failure']
Availability,"‚Ä¶bly to be activated if a mininum number of pieces of evidence agree on the distal target. Also:. - Some refactoring of the SATagAlignment and builder classes to support better treatment of SA tags.; - Increased the spark network timeout values for the SV pipeline to prevent nodes from losing heartbeats and being orphaned with running tasks. Since I made this change I have not had the issue. On the performance of this change on our calls:. I compared this branch with master. Master's results on the CHM1/13 mix:. ```; 16:57:37.270 INFO StructuralVariationDiscoveryPipelineSpark - Metadata retrieved.; 16:58:20.436 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 25977 intervals.; 16:58:20.517 INFO StructuralVariationDiscoveryPipelineSpark - Killed 377 intervals that were near reference gaps.; 16:58:49.939 INFO StructuralVariationDiscoveryPipelineSpark - Killed 175 intervals that had >1000x coverage.; 16:59:33.036 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 8773016 mapped template names.; 17:00:07.058 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 17:05:25.896 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 34752266 kmers.; 17:10:46.253 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 31945322 unique template names for assembly.; 17:45:06.748 INFO StructuralVariationDiscoveryPipelineSpark - Wrote SAM file of aligned contigs.; 17:45:26.199 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 5716 variants.; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INV: 231; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 3262; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1065; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1158; 17:45:26.397 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 8, 2017 5:45:26 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDis",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684:294,heartbeat,heartbeats,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684,1,['heartbeat'],['heartbeats']
Availability,‚Ä¶ceContentsAsFile(....). This gets rid of Hierarchical URI error message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4723:59,error,error,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4723,1,['error'],['error']
Availability,"‚Ä¶group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3726:40,down,downstream,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726,1,['down'],['downstream']
Availability,"‚Ä¶m for shuffle jobs. This is a first attempt at #1403 to get feedback on the approach. For aggregating tools that don‚Äôt have a shuffle (like CountReadsSpark), the existing 10MB per split is an issue since it dramatically slows down processing. Increasing the split size can be done via -bps, but that is not at all obvious and shouldn‚Äôt be necessary. The change I‚Äôve made here uses the default split size for Hadoop (which is 128MB on HDFS). For tools that do have a shuffle, I‚Äôve added a -P argument for all of them, which sets the level of parallelism to use for the shuffle. If not set it defaults to one partition per 10MB of input, which is the existing default. Note that for tools that write an output BAM, the level of parallelism set by -P is used for writing a single BAM (the default, since shardedOutput is false), since the reads are first sorted and written to multiple BAM files before finally being merged. Question: there‚Äôs a lot of duplicated code here. Would it be a good idea to have a ParallelismArgumentCollection and a ShardedOutputParallel collection? Note that some tools need a -P but not -shardedOutput (e.g. CompareDuplicatesSpark).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432:227,down,down,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432,1,['down'],['down']
Availability,"‚õî DO NOT MERGE this into the EchoCallset branch ‚õî just yet; it's probably better to address this bug in the current EchoCallset run by adding the two missing partitions to the last group and rerunning the last group only rather than rerunning all the groups with a larger group size. Add in `n_rounds - 1` to the group size expression to include all of the partitions in the set of groups, otherwise we omit the final `n_parts % n_rounds` partitions. Concretely for AoU Echo with 145192 total partitions and 5 rounds:. ```; >>> 145192 // 5; 29038; >>> 29038 * 5; 145190; >>> (145192 + 5 - 1) // 5; 29039; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8785:29,Echo,EchoCallset,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8785,3,['Echo'],"['Echo', 'EchoCallset']"
Availability,"üëç Looks good to me. Did you want to try to switch to the release version, or should we merge this as is? . I didn't know even know we had redundant `hidden` / `hiddenOption` tags... both unused.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-264959626:138,redundant,redundant,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-264959626,1,['redundant'],['redundant']
Deployability,"	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2019-10-01 02:53:03,81] [info] WorkflowManagerActor WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c is in a terminal state: WorkflowFailedState; [2019-10-01 02:53:07,42] [info] Not triggering log of token queue status. Effective log interval = None; [2019-10-01 02:53:08,41] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-10-01 02:53:12,32] [info] Workflow polling stopped; [2019-10-01 02:53:12,33] [info] 0 workflows released by cromid-876ccf5; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9364,release,released,9364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['release'],['released']
Deployability," 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:140); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); 	at org.seqdoop.hadoop_bam.Any",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:4181,deploy,deploy,4181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41); 	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658); 	at co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4646,deploy,deploy,4646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.getFilesMatching(NIOFileUtil.java:91); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:61); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2303,deploy,deploy,2303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shade,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3474,deploy,deploy,3474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shade,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:9040,deploy,deploy,9040,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isDirectory(Files.java:2192); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsData,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:2200,deploy,deploy,2200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability, 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(I,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12715,deploy,deploy,12715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability," (F√©vrier in french) August (Ao√ªt) or December (D√©cembre) have ISO-8859-1 encoding instead of UTF-8 encoding. Indeed, the output files have this line:. `##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output /volumes/vol002/COVID/GenomicDB/vcf/COVID.05022021.int00.vcf.gz --variant gendb://dbtot/int00 --reference /volumes/vol002/reference/human_g1k_v37.fasta --tmp-dir /volumes/vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false"",Version=""4.1.9.0"",Date=""5 f<E9>vrier 2021 10:42:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:1483,update,updates,1483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['update'],['updates']
Deployability, (√∏)` | `13 <2> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `93.333% <100%> (+6.377%)` | `6 <1> (-3)` | :arrow_down: |; | [...ools/spark/transforms/BaseRecalibratorSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0Jhc2VSZWNhbGlicmF0b3JTcGFya0ZuLmphdmE=) | `93.333% <100%> (-1.404%)` | `3 <3> (√∏)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `5 <1> (-3)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.97% <100%> (+4.323%)` | `7 <0> (+1)` | :arrow_up: |; | [...der/utils/collections/AutoCloseableCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9BdXRvQ2xvc2VhYmxlQ29sbGVjdGlvbi5qYXZh) | `18.75% <18.75%> (√∏)` | `1 <1> (?)` | |; | [...hellbender/utils/iterators/CloseAtEndIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvQ2xvc2VBdEVuZEl0ZXJhdG9yLmphdmE=) | `37.5% <37.5%> (√∏)` | `2 <2> (?)` | |; | ... and [20 more](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432:3129,pipeline,pipelines,3129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432,1,['pipeline'],['pipelines']
Deployability," +26 ; Misses 6771 6771 ; - Partials 2618 2619 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2518?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/91b41d8011a1465c637b7548899ff1e7f58f4e40...f741a033e28fe707ade9c9f0ea3fe9a20ecd78fd?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `66.667% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/FeatureWalker.java](https://codecov.io/gh/broadinstitute/gatk/compare/91b41d8011a1465c637b7548899ff1e7f58f4e40...f741a033e28fe707ade9c9f0ea3fe9a20ecd78fd?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZVdhbGtlci5qYXZh) | `86.957% <0%> (-2.699%)` | `9% <0%> (√∏)` | |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/91b41d8011a1465c637b7548899ff1e7f58f4e40...f741a033e28fe707ade9c9f0ea3fe9a20ecd78fd?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+9.179%)` | `14% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2518?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2518?src=pr&el=footer). Last update [91b41d8...f741a03](https://codecov.io/gh/broadinstitute/gatk/compare/91b41d8011a1465c637b7548899ff1e7f58f4e40...f741a033e28fe707ade9c9f0ea3fe9a20ecd78fd?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2518#issuecomment-288545729:2439,update,update,2439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2518#issuecomment-288545729,2,['update'],['update']
Deployability," - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change bac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26250,release,release,26250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['release'],['release']
Deployability," - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_412-b08; 02:55:32.063 INFO Funcotator - Start Date/Time: July 12, 2024 2:55:31 AM EDT; 02:55:32.063 INFO Funcotator - ------------------------------------------------------------; 02:55:32.063 INFO Funcotator - ------------------------------------------------------------; 02:55:32.063 INFO Funcotator - HTSJDK Version: 2.15.1; 02:55:32.063 INFO Funcotator - Picard Version: 2.18.2; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:55:32.063 INFO Funcotator - Deflater: IntelDeflater; 02:55:32.063 INFO Funcotator - Inflater: IntelInflater; 02:55:32.063 INFO Funcotator - GCS max retries/reopens: 20; 02:55:32.063 INFO Funcotator - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 02:55:32.063 WARN Funcotator - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: Funcotator is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 02:55:32.063 INFO Funcotator - Initializing engine; 02:55:32.318 INFO FeatureManager - Using codec VCFCodec to read file file:///export2/liuhw/wes_test/Mutect2_filter/K001137N_somatic_filtered.vcf.gz; 02:55:32.459 INFO Funcotator - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 02:55:32.466 INFO Funcotator - Shutting down engine; [July 12, 2024 2:55:32 AM EDT] org.broadinstitute.hellbender.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8913:2436,patch,patch,2436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8913,1,['patch'],['patch']
Deployability," - Picard Version: 2.25.0; 14:48:09.081 INFO GenomicsDBImport - Built for Spark Version: 2.4.5; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:48:09.082 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:48:09.082 INFO GenomicsDBImport - Deflater: IntelDeflater; 14:48:09.082 INFO GenomicsDBImport - Inflater: IntelInflater; 14:48:09.082 INFO GenomicsDBImport - GCS max retries/reopens: 20; 14:48:09.082 INFO GenomicsDBImport - Requester pays: disabled; 14:48:09.082 INFO GenomicsDBImport - Initializing engine; 14:48:09.524 INFO IntervalArgumentCollection - Processing 249250621 bp from intervals; 14:48:09.551 INFO GenomicsDBImport - Done initializing engine; 14:48:09.781 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 14:48:09.782 INFO GenomicsDBImport - Vid Map JSON file will be written to /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/vidmap.json; 14:48:09.782 INFO GenomicsDBImport - Callset Map JSON file will be written to /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/callset.json; 14:48:09.782 INFO GenomicsDBImport - Complete VCF Header will be written to /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/vcfheader.vcf; 14:48:09.782 INFO GenomicsDBImport - Importing to workspace - /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB/chr1; 14:48:09.783 INFO ProgressMeter - Starting traversal; 14:48:09.783 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 14:48:09.935 INFO GenomicsDBImport - Starting batch input file preload; 14:48:21.686 INFO GenomicsDBImport - Finished batch preload; 14:48:21.686 INFO GenomicsDBImport - Importing batch 1 with 400 samples; </pre>. I am now trying to solve this by reducing batch size, will update once it finished for batch1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:8034,update,update,8034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['update'],['update']
Deployability," -p gvcf.STR/$SAMPLE/tmp; gatk --java-options ""-Xmx16G"" ComposeSTRTableFile -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -O gvcf.STR/$SAMPLE/$SAMPLE.STR.table -I $CRAM; gatk --java-options ""-Xmx16G"" CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/$SAMPLE/$SAMPLE.STR.table -O gvcf.STR/$SAMPLE/$SAMPLE.Dragstr.model -I $CRAM. ```; The script runs the ComposeSTRTableFile to produce the table that is then read by CalibrateDragstrModel. ; ```; ./test.sh /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar ComposeSTRTableFile -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:44:55.228 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:44:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:44:55.456 INFO ComposeSTRTableFile - ------------------------------------------------------------; 13:44:55.458 INFO ComposeSTRTableFile - The Genome Analysis Toolkit (GATK) v4.2.0.0; 13:44:55.458 INFO ComposeSTRTableFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:3783,install,install,3783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['install'],['install']
Deployability," 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --output NA12892.raw.snps.indels.g.vcf --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --readValidationStringency LENIENT --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --createOutputVariantIndex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:2745,pipeline,pipeline,2745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['pipeline'],['pipeline']
Deployability," 12:18:11.388 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_151-b12; 12:18:11.388 INFO Mutect2 - Start Date/Time: April 11, 2018 12:18:10 PM PDT; 12:18:11.388 INFO Mutect2 - ------------------------------------------------------------; 12:18:11.388 INFO Mutect2 - ------------------------------------------------------------; 12:18:11.388 INFO Mutect2 - HTSJDK Version: 2.14.3; 12:18:11.388 INFO Mutect2 - Picard Version: 2.17.2; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:18:11.388 INFO Mutect2 - Deflater: IntelDeflater; 12:18:11.388 INFO Mutect2 - Inflater: IntelInflater; 12:18:11.389 INFO Mutect2 - GCS max retries/reopens: 20; 12:18:11.389 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 12:18:11.389 INFO Mutect2 - Initializing engine; 12:18:11.724 INFO Mutect2 - Done initializing engine; 12:18:12.288 INFO NativeLibraryLoader - Loading libgkl_utils.dylib from jar:file:/Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_utils.dylib; 12:18:12.290 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 12:18:12.290 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 12:18:12.290 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; 12:18:12.368 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:18:12.368 WARN IntelPairHmm - Ignoring request for",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:2387,patch,patch,2387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,1,['patch'],['patch']
Deployability," 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154). Any update on this, @yfarjoun ?. ---. @yfarjoun commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287826525). I think we will only fix the interval list when we move exomes to; hg38....so, no. On Mon, Mar 20, 2017 at 12:45 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > Any update on this, @yfarjoun <https://github.com/yfarjoun> ?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0hMTukUGLtk1oTOse4Oj3awHf_exks5rnq1CgaJpZM4JNjE->; > .; >. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287828851). OK well this workaround should really be moved to a ""validation stringency"" level decision, not a hardcoded hack. . @ronlevine Do you know if this hack is also present in GATK4's equivalent code?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:3975,update,update,3975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['update'],['update']
Deployability," 16:08:06 2017 -0500. Update test PoNs. commit 2c3b20e62a1cba7af24c0b0846eb1629422f51e6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:49:38 2017 -0500. Update test files. commit c65c6e9144ef396792364ab2e06b7b436bb97684; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:30:59 2017 -0500. Adding no-GC/do-GC WDL tests. commit 56451843066a456d9cf8e6eac55ae4df2c518ec3; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10462,release,release,10462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['release'],['release']
Deployability," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:2733,pipeline,pipeline,2733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,2,['pipeline'],['pipeline']
Deployability," 23:43:52.477 INFO GermlineCNVCaller - Initializing engine; 23:43:52.479 DEBUG ScriptExecutor - Executing:; 23:43:52.479 DEBUG ScriptExecutor - python; 23:43:52.479 DEBUG ScriptExecutor - -c; 23:43:52.480 DEBUG ScriptExecutor - import gcnvkernel. INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '18570' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; 23:44:42.124 DEBUG ScriptExecutor - Result: 0; 23:44:42.124 INFO GermlineCNVCaller - Done initializing engine; 23:44:42.126 INFO GermlineCNVCaller - Intervals specified...; 23:44:42.534 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:42.534 DEBUG GenomeLocParser - chr1 (248956422 bp); 23:44:42.534 DEBUG GenomeLocParser - chr2 (242193529 bp); 23:44:42.534 DEBUG GenomeLocParser - chr3 (198295559 bp); 23:44:42.535 DEBUG GenomeLocParser - chr4 (190214555 bp); 23:44:42.535 DEBUG GenomeLocParser - chr5 (181538259 bp); 23:44:42.535 DE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:5654,release,release,5654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['release'],['release']
Deployability," 64-Bit Server VM v1.8.0_201-b09; 18:08:13.874 INFO CombineGVCFs - Start Date/Time: May 18, 2019 6:08:13 PM CST; 18:08:13.874 INFO CombineGVCFs - ------------------------------------------------------------; 18:08:13.874 INFO CombineGVCFs - ------------------------------------------------------------; 18:08:13.874 INFO CombineGVCFs - HTSJDK Version: 2.14.3; 18:08:13.874 INFO CombineGVCFs - Picard Version: 2.17.2; 18:08:13.874 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:08:13.875 INFO CombineGVCFs - Deflater: IntelDeflater; 18:08:13.875 INFO CombineGVCFs - Inflater: IntelInflater; 18:08:13.875 INFO CombineGVCFs - GCS max retries/reopens: 20; 18:08:13.875 INFO CombineGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:08:13.875 INFO CombineGVCFs - Initializing engine; 18:08:14.718 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340092.HC.g.vcf.gz; 18:08:14.807 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340093.HC.g.vcf.gz; 18:08:14.852 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340094.HC.g.vcf.gz; 18:08:14.897 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340095.HC.g.vcf.gz; 18:08:14.958 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/result/SRR340096.HC.g.vcf.gz; 18:08:15.003 INFO FeatureManager - Using codec VCFCodec to read file file:///data/users/zhanglei/species/Medicago/re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947:2044,patch,patch,2044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947,1,['patch'],['patch']
Deployability, :arrow_down: |; | [...hellbender/tools/CountVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFZhcmlhbnRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...ne/spark/datasources/ReadsSparkSourceUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZVVuaXRUZXN0LmphdmE=) | `91.852% <√∏> (√∏)` | `25 <0> (√∏)` | :arrow_down: |; | [...ExampleReadWalkerWithReferenceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlUmVhZFdhbGtlcldpdGhSZWZlcmVuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <√∏> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `88.293% <√∏> (√∏)` | `30 <0> (√∏)` | :arrow_down: |; | [...ls/genomicsdb/GenomicsDBImportIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnRJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `89.356% <√∏> (√∏)` | `73 <0> (√∏)` | :arrow_down: |; | [...ls/CalculateGenotypePosteriorsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5112/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `95.082% <√∏> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...er/tools/funcotator/Funco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413033472:2256,pipeline,pipelines,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413033472,1,['pipeline'],['pipelines']
Deployability," ; ; ¬† ¬† at org.broadinstitute.hellbender.engine.ReadWalker.onStartup(ReadWalker.java:51) ; ; ¬† ¬† at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138) ; ; ¬† ¬† at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; ¬† ¬† at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; ¬† ¬† at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ; ¬† ¬† at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) ; ; ¬† ¬† at org.broadinstitute.hellbender.Main.main(Main.java:289). However, the bug wasn't reported when I didn't assign the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz ¬†-O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ; ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:14452,pipeline,pipeline,14452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability," <0%> (+16%)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...475cd13e0c19561a3569b7816f06ba5a52dabe77?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...475cd13e0c19561a3569b7816f06ba5a52dabe77?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `97.826% <0%> (+1.159%)` | `16% <0%> (+3%)` | :white_check_mark: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...475cd13e0c19561a3569b7816f06ba5a52dabe77?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `65.493% <0%> (+4.203%)` | `22% <0%> (+8%)` | :white_check_mark: |; | ... and [5 more](https://codecov.io/gh/broadinstitute/gatk/pull/2417?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2417?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2417?src=pr&el=footer). Last update [fcd103c...475cd13](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...475cd13e0c19561a3569b7816f06ba5a52dabe77?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-281527264:5186,update,update,5186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-281527264,2,['update'],['update']
Deployability," = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the T",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2951,INSTALL,INSTALLDIRGCC,2951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGCC']
Deployability," @lucidtronix Any update on this since I heard VQSR got ported to GATK4?. ---. @ldgauthier commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287905381). It's unlikely the behavior has changed. For gnomad we used hard filters to; address the problem, which is probably a good global recommendation. On Mar 20, 2017 1:35 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @lucidtronix; > <https://github.com/lucidtronix> Any update on this since I heard VQSR; > got ported to GATK4?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287837505>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLRwdezIkmt3uPqIABWLggVjRN3yks5rnrjegaJpZM4Dt4t7>; > .; >. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287919609). OK, that makes sense, thanks. Do you want me to migrate the issue to GATK4? Otherwise I'll just close it out here as WONTFIX. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-288223457). Somewhere we need a record of updates to filtering best practices until we; publish a new thing, so yeah, please migrate. On Mar 20, 2017 6:36 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > OK, that makes sense, thanks. Do you want me to migrate the issue to; > GATK4? Otherwise I'll just close it out here as WONTFIX.; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287919609>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdIeoOhkvNSNkC_XpxSZTt-kPdFDMks5rnv9RgaJpZM4Dt4t7>; > .; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:9538,update,updates,9538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['update'],['updates']
Deployability," @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported to GATK4?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLPwS6I5nu9TQiw4BFqRojmTiL0aks5rnq_OgaJpZM4FaLwX>; > .; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:8049,pipeline,pipelines,8049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['pipeline'],['pipelines']
Deployability, Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `58.73% <√∏> (-3.035%)` | `12 <0> (-1)` | |; | [...ols/examples/ExampleAssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `0% <0%> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...engine/spark/AssemblyRegionArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.566% <100%> (+0.983%)` | `13 <1> (+1)` | :arrow_up: |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25SZWFkU2hhcmRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...bender/engine/spark/AssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5386/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `77.083% <85.185%> (+77.083%)` | `15 <7> (+15)` | :arrow_up: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5386#issuecomment-435416461:1864,pipeline,pipelines,1864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5386#issuecomment-435416461,1,['pipeline'],['pipelines']
Deployability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2935907552.11](https://github.com/broadinstitute/gatk/runs/8042744893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.11/tests/test/index.html) |; | cloud | 8 | [2935907552.10](https://github.com/broadinstitute/gatk/runs/8042744743?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.10/tests/test/index.html) |; | unit | 11 | [2935907552.13](https://github.com/broadinstitute/gatk/runs/8042745129?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.13/tests/test/index.html) |; | integration | 11 | [2935907552.12](https://github.com/broadinstitute/gatk/runs/8042744999?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.12/tests/test/index.html) |; | conda | 8 | [2935907552.3](https://github.com/broadinstitute/gatk/runs/8043019512?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.3/tests/test/index.html) |; | unit | 8 | [2935907552.1](https://github.com/broadinstitute/gatk/runs/8043019322?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.1/tests/test/index.html) |; | variantcalling | 8 | [2935907552.2](https://github.com/broadinstitute/gatk/runs/8043019429?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.2/tests/test/index.html) |; | integration | 8 | [2935907552.0](https://github.com/broadinstitute/gatk/runs/8043019196?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876:1904,integrat,integration,1904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876,1,['integrat'],['integration']
Deployability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3002176541.11](https://github.com/broadinstitute/gatk/runs/8212856906?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.11/tests/test/index.html) |; | cloud | 8 | [3002176541.10](https://github.com/broadinstitute/gatk/runs/8212856796?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.10/tests/test/index.html) |; | unit | 11 | [3002176541.13](https://github.com/broadinstitute/gatk/runs/8212857102?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.13/tests/test/index.html) |; | integration | 11 | [3002176541.12](https://github.com/broadinstitute/gatk/runs/8212857016?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.12/tests/test/index.html) |; | unit | 8 | [3002176541.1](https://github.com/broadinstitute/gatk/runs/8213287905?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.1/tests/test/index.html) |; | integration | 8 | [3002176541.0](https://github.com/broadinstitute/gatk/runs/8213287794?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.0/tests/test/index.html) |; | variantcalling | 8 | [3002176541.2](https://github.com/broadinstitute/gatk/runs/8213288012?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.2/tests/test/index.html) |; | conda | 8 | [3002176541.3](https://github.com/broadinstitute/gatk/runs/8213288138?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387:1429,integrat,integration,1429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387,1,['integrat'],['integration']
Deployability, Files 2011 2011 ; Lines 150967 150967 ; Branches 16134 16134 ; ===============================================; + Hits 121341 131360 +10019 ; + Misses 24157 14021 -10136 ; - Partials 5469 5586 +117; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6046?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/6046/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6046/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6046/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/6046/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6046/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17.085% <0%> (-52.764%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6046#issuecomment-512322256:1578,pipeline,pipelines,1578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6046#issuecomment-512322256,1,['pipeline'],['pipelines']
Deployability," GT: `0/0` or `0/1` or `1/1`. We currently report depth based copy number and quality for these variants in custom format fields `RD_CN` and `RD_GQ` if they are available; we could possibly move those values to the standard `CN` and `CNQ`, but there is some complexity in how to handle events detected by paired end and split reads without good read depth support; ie those under 1kb or so depending on our depth binning size and the coverage. Our depth genotyping module makes estimates of copy number for these sites but sometimes these can be very inaccurate so at the moment we prefer not to report total copy number in those fields. Probably what we _should_ do is fill in CN with 0, 1, or 2 based on the genotype we emitted and set CNQ to the value we computed for GQ. For multiallelic CNVs (i.e. sites where our model is not sure that the variant is bi-allelic) we write:. - ALT: `<CNV>`; - SVTYPE: `CNV`; - GT and GQ: `.`; - CN and CNQ: estimate of total (diploid/unphased) copy number and quality of the depth evidence. I think there are some tradeoffs in completely characterizing the evidence for and quality of each call and enabling easy searching across the whole VCF without having to parse and understand the entire record. Older versions of our pipeline used to put the diploid copy number of the event into the GT field, I think similarly to what's being described above. This is incorrect VCF -- GT values should be indices into the allele list for the variant, and should be a list of length equal to the ploidy. . My view is that if you can confidently infer the alleles present at the site in the sample set you should use a GT value of the form `0/1`, and if you don't know or aren't interested in trying to infer them you should use CN for total copy number and CNQ for the quality. CNF is also available in the spec for fractional estimates of copy number; for example Genome STRiP uses it to report the raw depth signal, which is useful for QC and identifying mosaic events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171:1436,pipeline,pipeline,1436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171,1,['pipeline'],['pipeline']
Deployability," GenomicsDBImport - Start Date/Time: July 10, 2018 2:57:15 AM EDT; 02:57:15.773 INFO GenomicsDBImport - ------------------------------------------------------------; 02:57:15.773 INFO GenomicsDBImport - ------------------------------------------------------------; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Version: 2.16.0; 02:57:15.773 INFO GenomicsDBImport - Picard Version: 2.18.7; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:57:15.774 INFO GenomicsDBImport - Deflater: IntelDeflater; 02:57:15.774 INFO GenomicsDBImport - Inflater: IntelInflater; 02:57:15.774 INFO GenomicsDBImport - GCS max retries/reopens: 20; 02:57:15.774 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 02:57:15.774 INFO GenomicsDBImport - Initializing engine; 02:57:18.389 INFO IntervalArgumentCollection - Processing 11228744 bp from intervals; 02:57:18.437 INFO GenomicsDBImport - Done initializing engine; Created workspace ../RAW_VCF/my_database; 02:57:18.583 INFO GenomicsDBImport - Vid Map JSON file will be written to ../RAW_VCF/my_database/vidmap.json; 02:57:18.583 INFO GenomicsDBImport - Callset Map JSON file will be written to ../RAW_VCF/my_database/callset.json; 02:57:18.583 INFO GenomicsDBImport - Complete VCF Header will be written to ../RAW_VCF/my_database/vcfheader.vcf; 02:57:18.583 INFO GenomicsDBImport - Importing to array - ../RAW_VCF/my_database/genomicsdb_array; 02:57:18.583 INFO ProgressMeter - Starting traversal; 02:57:18.583 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 02:57:31.082 INFO GenomicsDBImport - Shutting dow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4994:2455,patch,patch,2455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4994,1,['patch'],['patch']
Deployability," GenomicsDBImport - Start Date/Time: March 8, 2018 5:00:53 PM CET; 17:00:53.771 INFO GenomicsDBImport - ------------------------------------------------------------; 17:00:53.771 INFO GenomicsDBImport - ------------------------------------------------------------; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Version: 2.13.2; 17:00:53.772 INFO GenomicsDBImport - Picard Version: 2.17.2; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:00:53.772 INFO GenomicsDBImport - Deflater: IntelDeflater; 17:00:53.772 INFO GenomicsDBImport - Inflater: IntelInflater; 17:00:53.772 INFO GenomicsDBImport - GCS max retries/reopens: 20; 17:00:53.772 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:00:53.772 INFO GenomicsDBImport - Initializing engine; 17:00:54.197 INFO IntervalArgumentCollection - Processing 135534747 bp from intervals; 17:00:54.200 INFO GenomicsDBImport - Done initializing engine; Created workspace /scratch/production/cluengo/genomicsdb/gdbworkspace-gatk; 17:00:54.418 INFO GenomicsDBImport - Vid Map JSON file will be written to gdbworkspace-gatk/vidmap.json; 17:00:54.418 INFO GenomicsDBImport - Callset Map JSON file will be written to gdbworkspace-gatk/callset.json; 17:00:54.418 INFO GenomicsDBImport - Complete VCF Header will be written to gdbworkspace-gatk/vcfheader.vcf; 17:00:54.418 INFO GenomicsDBImport - Importing to array - gdbworkspace-gatk/genomicsdb_array; 17:00:54.470 INFO ProgressMeter - Starting traversal; 17:00:54.470 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 17:00:54.488 INFO GenomicsDBImport",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514:2398,patch,patch,2398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514,1,['patch'],['patch']
Deployability," I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1450,pipeline,pipeline,1450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['pipeline'],['pipeline']
Deployability," INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 23:00:09 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 23:00:09 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 23:00:09 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 23:00:09 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 23:00:09 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 23:00:09 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 23:00:09 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 23:00:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 23:00:09 INFO SparkContext:54 - Successfully stopped SparkContext; 23:00:09.356 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 11:00:09 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 7.01 minutes.; Runtime.totalMemory()=4327997440; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-73067845-b641-4212-9c81-51e8d6aa9f31; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-b4b61d51-d75f-45e5-9e10-8171d3acea1d; ```. hadoop fs -ls /project/casa/gcad/adsp.cc/sv/*sam; -rw-r--r-- 3 farrell casa 389867305631 2019-06-03 23:00 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.sam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:16179,pipeline,pipelines,16179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['pipeline'],['pipelines']
Deployability," INFO FilterMutectCalls - ------------------------------------------------------------; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Version: 2.20.1; 09:44:29.502 INFO FilterMutectCalls - Picard Version: 2.20.5; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:44:29.503 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:44:29.503 INFO FilterMutectCalls - Deflater: IntelDeflater; 09:44:29.503 INFO FilterMutectCalls - Inflater: IntelInflater; 09:44:29.503 INFO FilterMutectCalls - GCS max retries/reopens: 20; 09:44:29.503 INFO FilterMutectCalls - Requester pays: disabled; 09:44:29.503 INFO FilterMutectCalls - Initializing engine; 09:44:29.869 INFO FeatureManager - Using codec VCFCodec to read file file:///mnt/md0/DataProcess/Ranshi/Mutect2/Try.vcf.gz; 09:44:29.942 INFO FilterMutectCalls - Done initializing engine; 09:44:30.029 INFO FilterMutectCalls - Shutting down engine; [2019Âπ¥8Êúà21Êó• ‰∏äÂçà09Êó∂44ÂàÜ30Áßí] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2097152000; ***********************************************************************. A USER ERROR has occurred: Mutect stats table Try.vcf.gz.stats not found. When Mutect2 outputs a file calls.vcf it also creates a calls.vcf.stats file. Perhaps this file was not moved along with the vcf, or perhaps it was not delocalized from a virtual machine while running in the cloud. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. `Try.vcf.stat` was lost, I have to re-run `Mutect2` using latest release. It seems that this bug was fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-523262338:3744,release,release,3744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-523262338,1,['release'],['release']
Deployability," Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved. VariantRecalibrator. ### Description. VariantRecalibrator automatically runs the generated Rscript to produce recalibration plots. This is usually good and convenient, but it requires that all *R* dependencies must be installed in the same environment in the current running GATK environment. This is not necessarily the case for sandbox-based package managers e.g. docker or conda. A viable fix on the user's side is to include R dependencies with GATK in e.g. docker or conda. But I think I would prefer if my packages were as independent of each other as possible. It would be great if **VariantRecalibrator had an option to write but not run the Rscript for recalibration plots.** Then, the user can call the Rscript in an appropriate e.g. R conda environment or docker image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697:1441,install,installed,1441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697,1,['install'],['installed']
Deployability," Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:59:52 2023 -0500. update gCNV WDL tests. commit 31a204b9e900849b5a313e161893de34a2094bb0; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:14:34 2023 -0500. staged base rc1. commit 74f8fa724dfac142ccd7ac79a757c0e5ac3bb06c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:01:38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seed",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1223,update,update,1223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['update'],['update']
Deployability," Partials 2620 2618 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2453?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...9b319acdbc3eb6e5d6b26bffcd1ad2b53f40bc3a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0 <0> (-5)` | |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...9b319acdbc3eb6e5d6b26bffcd1ad2b53f40bc3a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `66.917% <85.714%> (+2.211%)` | `38 <6> (+6)` | :white_check_mark: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...9b319acdbc3eb6e5d6b26bffcd1ad2b53f40bc3a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2453?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2453?src=pr&el=footer). Last update [5d2f859...9b319ac](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...9b319acdbc3eb6e5d6b26bffcd1ad2b53f40bc3a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2453#issuecomment-285796600:2467,update,update,2467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2453#issuecomment-285796600,2,['update'],['update']
Deployability," QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle 15 TB /table /day import limit (#7167); - #260 filter out AS_QD, SOR, FS from cohort extract VCF (#7173); - Full scientific validation via end to end comparison of filtered results between WARP and BQ (#7179); - Cherry pick of commits to fix GATK tests from master (#7183); - ExtractCohort supports -XL exclusion and follows intervals, other optimizations (#7181); - ExtractFeatures supports -XL exclusion and follows intervals, other optimizations (#7184); - change 0/0 GQ0 sites to nocalls (#7190); - updated (#7195); - Rename ""metadata"" table to ""sample_info"" table, fix vet schema (#7196); - Allow users to specify VQSLOD sensitivity and apply threshold in ExtractCohort (#7194); - Calculate and Store site-level QCs (#7197); - Filter Failing QC Sites from Extract (#7201); - WDLize GvsPrepareCallset (briefly known as CreateCohortTable) (#7200); - default drop_state to 60, but allow NONE as input (#7206); - SA support and consistent naming for all GVS WDLs (#7205); - fix GvsExtractCallset inputs file (#7210); - add clustering to tables (#7207); - add vqsr cutoffs to GvsExtractCallset wdl; clean up dockstore yml (#7209); - Avro test (#7192); - Enable call caching of TSV generation in GvsImportGenomes (#7226); - 266 Clean up ExtractCohort -- remove query mode param (#7227); - 288 Add an excess alleles param (#7221); - take sample name as a param (#7236); - How to run GIAB comparisons (#7237); - Update GvsCreateFilterSet.wdl (#7239); - Use GatherVcfsCloud in GvsCreateFilterSet.wdl (#7241); - parameterize TTL with defaults, reduce memory allocation (#7244); - Addressing OOM in CohortExtract (#7245); - make outputs optional, change case",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:12506,Update,Update,12506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,6,"['Update', 'update']","['Update', 'updated']"
Deployability, Running: ; ; ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/shell/temp -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:09:41.541 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.554 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:09:41.557 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.558 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:09:41.678 INFO ¬†BaseRecalibrator - ------------------------------------------------------------ ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:09:41.679 INFO ¬†Base,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:2392,pipeline,pipeline,2392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability, Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1500,Configurat,ConfigurationResolver,1500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Configurat'],['ConfigurationResolver']
Deployability," Since GC bias is a; > property of the fragments that are pulled by the baits, a reasonable; > measure of ""GC content"" of each bait has to be calculated from the expected; > value of the GC content of the fragments that the bait pulls (not the GC; > content of the baits or targets), and this can be easily calculated from; > the previously obtained empirical distributions.; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/914>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0qEpyk5wss6qvl653UQo-BAiQWfIks5rdjPNgaJpZM4ME4kq>; > .; >. ---. @mbabadi commented on [Sat Feb 18 2017](https://github.com/broadinstitute/gatk-protected/issues/914#issuecomment-280820307). @yfarjoun, thanks for your comments. On the first two points, I agree. Let me clarify: I was going to use the bait-length and insert-length as _hyperparameters_ of the pdf, where the pdf itself gives the probability of having an insert in a certain configuration relative to the bait. I think the parametrization you proposed, i.e. the distance between nearest ends of insert and bait, is very reasonable since the PDF is going to be reflection-symmetric once averaged over all baits; and you're right, the bait length is constant (77bp for ICE) so we can drop it from the analysis. If the fragment capture efficiency is insensitive to the relative position of the bait sequence in the fragment, we expect the pdf to be approximately uniform (save for boundary effects at the scale of bait length), with the 0.5 x (insert length - bait length) setting the upper bound of the distribution. However, some dependency on the position of the bait is expected: e.g. if the bait sequence is on the dangling end of a fragment, it is less likely to stay bound than if it is in the middle of the fragment. I'm curious to see what comes out (who knows -- maybe another 6-bp periodicity!).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2947:6394,configurat,configuration,6394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2947,1,['configurat'],['configuration']
Deployability," VCF for the input (since this has both non-AS and AS annotations; EDIT: Scratch that, it only has AS_InbreedingCoeff and AS_QD), 2) the Omni SNP training/truth VCF (yielding ~3.5k training), and 3) the Mills training/truth VCF (yielding ~500 training). Incidentally, VariantRecalibrator SNP and INDEL runs both fail to converge on these small training sets without the #7709 fix, but do converge with it. I still need to check if enough multiallelics are included here; if not, I'll choose a different snippet. EDITEDIT: Now using gs://broad-gotc-test-storage/joint_genotyping/exome/scientific/truth/master/gather_vcfs_high_memory/small_callset_low_threshold.vcf.gz provided by @ldgauthier, which does have AS annotations.; ; We'll use expected outputs here as inputs to downstream steps, but rather than provide the expected outputs directly, we'll create copies of them and provide those as inputs. This will make the tests better encapsulated. However, it should be relatively easy to update the whole chain of test files, should one choose to do so. EDIT: Let's just provide the expected outputs directly. So it'll be even easier to update the whole chain---just set the flags for all three tools to overwrite the expected results.; ; We test the Cartesian product of the following options: 1) non-allele-specific vs. allele-specific, 2) SNP vs. indel vs. both, and 3) positive vs. positive-unlabeled. Downstream, we'll further subset to a subset of these options, since training/scoring functionality shouldn't really change across some of them.; ; I'm currently just using call outs to system commands to diff and h5diff the VCFs and HDF5s, respectively. I think the latter command should be available in the GATK Conda environment. This will be a bit awkward, in the sense that the tests for this tool will require the Conda environment, but the tool itself will not. But I think this is probably preferable to writing test code to compare HDF5s, minimal though that might be, since the schema",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:1959,update,update,1959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,1,['update'],['update']
Deployability," VM v1.8.0_45-b14; 12:37:00.530 INFO GenotypeGVCFs - Start Date/Time: July 12, 2018 12:37:00 PM EDT; 12:37:00.530 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:37:00.530 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:37:00.530 INFO GenotypeGVCFs - HTSJDK Version: 2.16.0; 12:37:00.530 INFO GenotypeGVCFs - Picard Version: 2.18.7; 12:37:00.530 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:37:00.531 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:37:00.531 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:37:00.531 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:37:00.531 INFO GenotypeGVCFs - Deflater: IntelDeflater; 12:37:00.531 INFO GenotypeGVCFs - Inflater: IntelInflater; 12:37:00.531 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 12:37:00.531 INFO GenotypeGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 12:37:00.531 INFO GenotypeGVCFs - Initializing engine; 12:37:02.095 INFO FeatureManager - Using codec VCFCodec to read file file:///home-1/cvalenc1@jhu.edu/work/cvalenc1/Paralysis/NEW_ALIGNEMENT/Sample_VCF/Multi.g.vcf; 12:37:03.426 INFO GenotypeGVCFs - Done initializing engine; 12:37:03.683 INFO ProgressMeter - Starting traversal; 12:37:03.683 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:37:13.942 INFO ProgressMeter - chr1:1034498 0.2 14000 81887.3; 12:37:24.351 INFO ProgressMeter - chr1:1322991 0.3 41000 119030.3; 12:37:34.716 INFO ProgressMeter - chr1:1926324 0.5 83000 160474.3; 12:37:44.726 INFO ProgressMeter - chr1:3786982 0.7 124000 181273.3; 12:37:45.921 INFO GenotypeGVCFs - Shutting down engine; [July 12, 2018 12:37:45 PM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.76 minutes.; Runtime",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5009:2374,patch,patch,2374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5009,1,['patch'],['patch']
Deployability," With native libraries (note the lack of the usual warning):. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark --java-options ""-Djava.library.path=${HADOOP_DIR}/hadoop-2.6.5-src/hadoop-common-project/hadoop-common/target/hadoop-common-2.6.5/lib/native"" -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam --spark-master local[8]; 21:47:47.494 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 21:47:47.827 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:${GATK_DIR}/gatk/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.so; 21:47:48.268 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.268 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-7-g46a8661-SNAPSHOT; 21:47:48.268 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:47:48.270 INFO MarkDuplicatesSpark - Executing as cwhelan@gsa6.broadinstitute.org on Linux v2.6.32-696.16.1.el6.x86_64 amd64; 21:47:48.270 INFO MarkDuplicatesSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 21:47:48.270 INFO MarkDuplicatesSpark - Start Date/Time: May 7, 2018 9:47:47 PM EDT; 21:47:48.270 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 21:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:5496,install,install,5496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['install'],['install']
Deployability, [.../markduplicates/MarkDuplicatesScoringStrategy.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU2NvcmluZ1N0cmF0ZWd5LmphdmE=) | `76.471% <0%> (-5.882%)` | `7 <0> (√∏)` | |; | [...r/utils/read/markduplicates/sparkrecords/Pair.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyLmphdmE=) | `100% <100%> (√∏)` | `26 <1> (-1)` | :arrow_down: |; | [...forms/markduplicates/MarkDuplicatesSparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmtVdGlscy5qYXZh) | `91.284% <100%> (-0.079%)` | `65 <0> (√∏)` | |; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvTWFya0R1cGxpY2F0ZXNTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `89.933% <100%> (+1.383%)` | `27 <6> (+6)` | :arrow_up: |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9GcmFnbWVudC5qYXZh) | `92.857% <100%> (-0.893%)` | `6 <1> (-1)` | |; | [...ats/collections/SimpleCountCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uVW5pdFRlc3QuamF2YQ==) | `83.784% <0%> (-5.105%)` | `5% <0%> (+2%)` | |; | [...ber/formats/collections/Simp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5023#issuecomment-405694045:2894,pipeline,pipelines,2894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5023#issuecomment-405694045,1,['pipeline'],['pipelines']
Deployability," [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single line or maybe two that were required to reproduce this issue, but that range appears to be needed. Eliminating either the first or last line from the range will make the program work again. Did not attempt to remove lines from the middle of the range yet to see if they're necessary to cause the fault, but it's 2am and I should probably sleep.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7759,pipeline,pipeline,7759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['pipeline'],['pipeline']
Deployability, `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (√∏)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `91.667% <0%> (+1.344%)` | `17% <0%> (+5%)` | :arrow_up: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `85.465% <0%> (+2.608%)` | `58% <0%> (+24%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `89.873% <0%> (+2.917%)` | `23% <0%> (+9%)` | :arrow_up: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `77.656% <0%> (+6.845%)` | `54% <0%> (+14%)` | :arrow_up: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:3413,Update,UpdateVCFSequenceDictionary,3413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability," addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; GenotypeGVCFs, /public2/home/gaoshibin/software/gatk-4.4.0.0/gatk --java-options ""-Xmx160g -Djava.io.tmpdir=./tmp_fat"" GenotypeGVCFs -R /public2/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR9_gvcf_database -G StandardAnnotation -L 9:1-5000000 -O ./test.vcf.gz --genomicsdb-shared-posixfs-optimizations true; ### Affected version(s); - [ 4.1.9.0-4.4.0.0] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; The ParaStor file system suffers from low CPU operating efficiency and extremely slow read and write speeds. If I test it on my own mobile hard drive, it's normal. The file format of my mobile hard disk is EXT4; #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; /public2/home/gaoshibin/software/gatk-4.4.0.0/gatk --java-options ""-Xmx160g -Djava.io.tmpdir=./tmp_fat"" GenotypeGVCFs -R /public2/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR9_gvcf_database -G StandardAnnotation -L 9:1-5000000 -O ./test.vcf.gz --genomicsdb-shared-posixfs-optimizations true; #### Expected behavior; _Tell us what should happen_; The ParaStor file system suffers from",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8546:1654,release,release,1654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8546,1,['release'],['release']
Deployability," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6938:1430,pipeline,pipeline,1430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938,1,['pipeline'],['pipeline']
Deployability," another way:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz ¬†-O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ; ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam ; ; 00:11:11.683 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.697 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:8405,pipeline,pipeline,8405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability, args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:6892,update,updates,6892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,4,"['integrat', 'update']","['integration', 'updates']"
Deployability," at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [828b3d22-2109-4128-b4af-427a9d410db0] entered state [ERROR] while waiting for [DONE].; ```. Likely because of . ```; ""--conf"", ""spark.yarn.dist.files="" + script + ""/build/libIntelDeflater.so"",; ```. in gatk-launch. This likely needs special handling for dataproc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:9274,deploy,deploy,9274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,6,['deploy'],['deploy']
Deployability," batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're happy to take PRs!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:2001,release,released,2001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,2,"['install', 'release']","['installations', 'released']"
Deployability," been added to a panel that was created when requesting a minimum of 30, 45, or even 50 samples displaying a variant at the same site. #### Steps to reproduce; ```; gatk --java-options ""-Xmx30g"" Mutect2 \; -R /ref/Homo_sapiens_assembly38.fasta \; -I /bams/input/WES_Normal/${infile} \; -max-mnp-distance 0 \; -O /bams/output/${outfile}. gatk --java-options ""-Xmx100g"" GenomicsDBImport \; -R /ref/Homo_sapiens_assembly38.fasta -L /mydir/S33266340_hg38_Regions.bed \; --tmp-dir /scratch/ --genomicsdb-workspace-path ${RAMDISK}/PON_db_50_samples \; --merge-input-intervals true \; -V /bams/output/sample1.vcf.gz -V /bams/output/sample2.vcf.gz [....]. gatk --java-options ""-Xmx10g"" CreateSomaticPanelOfNormals \; -R /ref/Homo_sapiens_assembly38.fasta \; -V gendb://${RAMDISK}/PON_db_50_samples \; --germline-resource /gnomad/gnomAD.r2.1.1.GRCh38.PASS.AC.AF.only.vcf.gz \; --min-sample-count 50 \; -O /mydir/output/variants_100percent_samples_PON_50_samples.vcf.gz; ```. Am I missing something? Has this been fixed in more recent releases? . #### Expected behavior; For this chr12:25245348 it should not have been included at all in the PON, or only if I had set --min-sample-count to 4 and the fraction should have been 0.08 (don't know about the beta). `chr12 25245348 . C A,G . . BETA=?,?;FRACTION=0.08`. #### Alternative method to create the panel. After I noticed the problem, I ran bcftools isec to get for all the files a stripped VCF where 90% of them had a mutation at the same position and at least some of the alternative alleles were the same. `bcftools isec -n+45 --collapse some -p /mydir/output/isec ${vcfs}`. This shows me sites that are actually shared by 90% of my samples. Can't I just get chromosome, start, and end from one of these files, set INFO to ""."" and use this as the panel of normals with mutect2? Unfortunately, this seems more accurate than using CreateSomaticPanelOfNormals, though I would have liked to. . Importantly, **it seems like this only affects multiallelic sites.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8916:3728,release,releases,3728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8916,1,['release'],['releases']
Deployability, broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]; Reading package lists... ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1575,update,updates,1575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['update'],['updates']
Deployability," by `-0.002%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2448 +/- ##; ===============================================; - Coverage 76.238% 76.236% -0.002% ; + Complexity 10859 10854 -5 ; ===============================================; Files 751 750 -1 ; Lines 39559 39551 -8 ; Branches 6912 6911 -1 ; ===============================================; - Hits 30159 30152 -7 ; Misses 6780 6780 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2448?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/e7c90f1da2ac17173e56d352fbc4d926f9d2b871...23ba83e98b5b49ad0285a6366e79ad37e70efd0b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (√∏)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/e7c90f1da2ac17173e56d352fbc4d926f9d2b871...23ba83e98b5b49ad0285a6366e79ad37e70efd0b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2448?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2448?src=pr&el=footer). Last update [e7c90f1...23ba83e](https://codecov.io/gh/broadinstitute/gatk/compare/e7c90f1da2ac17173e56d352fbc4d926f9d2b871...23ba83e98b5b49ad0285a6366e79ad37e70efd0b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2448#issuecomment-285370809:2047,update,update,2047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2448#issuecomment-285370809,2,['update'],['update']
Deployability," dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in sub-cohort prepare correctly [VS-772] (#8156); - Remove unused VAT Creation WDL (#8172); - Gg consistently use dataset name as input parameter (#8173); - AoU cleanup docs, round 1 [VS-671] (#8104); - VDS docs remove samples and correct GT [VS-807] (#8178); - [VS-693] Add support for VQSR Lite to GvsCreateFilterSet (#8157); - VAT Documentation Update Round 1 [VS-531]; - VS-530 VDS creation documentation for AoU (#8169); - Update beta docs to tell people not to use free credits (#8184); - VS-816 Keeping ingestion under quota (#8193); - CromwellOnAzure + Azure SQL DB + AAD first steps doc [VS-805] (#8191); - Edit and re-format VDS -> VAT doc [VS-821] (#8187); - VS-820 Incorporate code to stay under Google quotas for new accounts into beta workflow (#8200); - Update docs for Nirvana reference disk [VS-531] [VS-796] (#8170); - VS-694 - Extract Callset for VQSR Lite (#8182); - Updating docker image (#8210); - Document VCF generation [VS-795] (#8202); - Variants GATK Docker image building docs + script [VS-827] (#8207); - Update GATK jar used in GvsJointVariantCalling WDL (#8216); - Hello Azure SQL Database from Cromwell on Azure [VS-812] (#8220); - Remove what appear to be accidentally added files [VS-834] (#8225); - VS-815: Add Support for YNG to VQSR Lite (#8206); - Disentangle non-GVS code from GVS code [VS-834] (#8229); - VS-695. Updates to run Precision and Sensitivity on VQSR Lite (#8230); - Track avro export costs [VS-769] (#8236); - Add note that we deleted a VDS! (#8214); - Vs 822 Add documentation for the work that we did on the latest iteration of Delta (#8205); - Rc vs 822 gq0 documentation (#8240); - Add a test exclusion for gvs scripts; - testing if the exclusion works. [VS-16]: https://broadworkbench.atlassian.net/browse/VS-16?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8251:33076,Update,Updates,33076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8251,1,['Update'],['Updates']
Deployability," dragen mode.¬† ; ; \-¬† --alleles is taken from a normal HC run.¬† ; ; \-¬† roughly the same heterozygous calls & hom.ALT calls are made with/without --alleles (which is expected behaviour). \=======================. REQUIRED for all errors and issues: ; ; a) GATK version used: 4.2.5.0. b) Exact command used:. gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller \\ ; ; ¬†¬†-R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta \\ ; ; ¬†¬†-I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam \\ ; ; ¬†¬†-O results/wesep-229191-f.vcf \\ ; ; ¬†¬†--alleles affected\_alleles.vcf \\ ; ; ¬†¬†-L 0005-scattered.interval\_list \\ ; ; ¬†¬†-bamout results/wesep-229191-f.variants.bam \\ ; ; ¬†¬†-G StandardAnnotation -G StandardHCAnnotation \\ ; ; ¬†¬†--dragen-mode \\ ; ; ¬†¬†--dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params \\ ; ; ¬†¬†--native-pair-hmm-threads 2. ¬† ; ; c) Entire program log:. (ELPREP) gvandeweyer@ngsvm-pipelines:~/elprep\_streaming/VariantCalling\_Test/scattered$ gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller ¬†¬†¬†-R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta ¬†¬†¬†-I /home/gvandeweyer/elprep\_streaming/results/wesep- ; ; 229191-f.bam ¬†¬†¬†-O results/wesep-229191-f.vcf ¬†¬†¬†--alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.interval\_list ¬†¬†¬†-bamout results/wesep-229191-f.variants.bam ¬†¬†¬†-G StandardAnnotation -G StandardHCAnnotation ¬†¬†¬†--dragen-mode ¬†¬†¬†--dragstr-params- ; ; path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params 2>&1 | tee Runtime.log.txt ; ; Using GATK jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ; ¬†¬†¬†java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp -Xmx3g -jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:2543,pipeline,pipelines,2543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['pipeline'],['pipelines']
Deployability," even more repositories, but I'm not sure those approaches would be preferable. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215491991). This came out of a discussion between myself and @LeeTL1220 . ---. @lbergelson commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""throwing out ideas for discussion"" phase, and alternate proposals are welcome provided they include the concept of a GATK-wide release, and make some provision for the situation where the CNV tools (or some other sub-category) are ready for release but other tools are not. ---. @vdauwera commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215498517). Frankly on the face of it I hate the idea of toolset-specific jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing peop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:1675,release,released,1675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,3,['release'],"['released', 'releases']"
Deployability," existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----; Thanks in advance!; ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:10343,release,release,10343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,1,['release'],['release']
Deployability," false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 11, 2017 2:19:10 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: 4.beta.5-70-gdc3237e-SNAPSHOT; 14:19:10.289 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:2963,patch,patch,2963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['patch'],['patch']
Deployability," false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 13, 2017 6:11:33 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: 4.beta.5-70-gdc3237e-SNAPSHOT; 18:11:33.870 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:11:33.871 INFO PrintReadsSpark - Deflater: IntelDeflater; 18:11:33.871 INFO PrintReadsSpark - Inflater: IntelInflater; 18:11:33.871 INFO PrintReadsSpark - GCS max retries/reopens: 20; 18:11:33.871 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:11:33.871 INFO PrintReadsSpark - Initializing engine; 18:11:33.871 INFO PrintReadsSpark - Done initializing engine; 17/10/13 18:11:33 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 17/10/13 18:11:34 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use ""yarn"" with specified deploy mode.; 17/10/13 18:11:34 INFO spark.SparkContext: Submitted application: PrintReadsSpark; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs);",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:3374,patch,patch,3374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['patch'],['patch']
Deployability," false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:3190,patch,patch,3190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,1,['patch'],['patch']
Deployability, file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1654,install,install,1654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['install'],['install']
Deployability," for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:55:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/5 is now RUNNING; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:10 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:55:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.16:49734 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:55:05 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/0 is now RUNNING; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/6 is now RUNNING; 18/04/24 17:55:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.25:54754) with ID 2; 18/04/24 17:55:07 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.25:41354 with 366.3 MB RAM, BlockManagerId(2, xx.xx.xx.25, 41354, None); 18/04/24 17:55:07 INFO FileInputFormat: Total input paths to process : 1; 18/04/24 17:55:07 INFO SparkContext: Starting job: first at ReadsSparkSource.java:221; 18/04/24 17:55:07 INFO DAGScheduler: Got job 0 (first at ReadsSparkSource.java:221) with 1 output partitions; 18/04/24 17:55:07 INFO DAGScheduler: Final stage: ResultStage 0 (first at ReadsSparkSource.java:221); 18/04/24 17:55:07 INFO DAGScheduler: Parents of final stage: List(); 18/04/24 17:55:07 INFO DAGScheduler: Missing parents: List(); 18/04/24 17:55:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at ReadsSparkSource.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:14569,update,updated,14569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,2,['update'],['updated']
Deployability," for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4692,configurat,configuration,4692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['configurat'],['configuration']
Deployability," go back; > and check what the defaults were for whatever version of the jar they were; > using at the time. Option 2 might also make it easier to inadvertently; > override parameters, etc. via command-line typos or copy-and-paste; > errors---it's much more straightforward to require and check that every; > parameter is specified once and fallback to a default if not, as we do now.; > Not to say that we couldn't get around any of these issues in Barclay, but; > I think it'll require some thought and careful design. Would be interested; > to hear Engine team's opinions.; >; > Finally, one point that I think will become more relevant as our tools and; > pipeline become more flexible and parameterized: I think we should start; > thinking of ""Best Practices Recommendations"" less as ""here is the best set; > of parameters to use with your data"" and more as ""here is *how to find*; > the best set of parameters to use with your data (for a given truth set,; > sensitivity requirement, etc.)"". After all, if we are putting together; > pipelines to do hyperparameter optimization, there is no reason not to; > share them with the community.; >; > This would also relax the requirement that the defaults in the WDL (which; > have to be kept in sync with those in the GATK jar) represent some sort of; > Best Practices Recommendation, which is awkward in exactly scenarios like; > the one you highlight.; >; > @vdauwera <https://github.com/vdauwera> @LeeTL1220; > <https://github.com/LeeTL1220> @sooheelee <https://github.com/sooheelee>; > might have some thoughts.; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2h5MhZ7nXrNgo6MrFpMD-TGiAE8ks5tt8gjgaJpZM4TtVZZ>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379:2328,pipeline,pipelines,2328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379,1,['pipeline'],['pipelines']
Deployability," have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs."". ----; User Report; ----. This is the error message I am getting but it doesn't make much sense, given that I got it also on smaller datasets with large amounts of memory (larger than some of the specifications listed on this forum for genomicDBimport). Our IT people, after observing the job, seem to think this is a java-related bug as the process itself doesn't use anywhere near the memory specified. We have installed a new version of java and I will be re-running the analysis to see if this solved the issues. . I'm not sure if I should be creating a new thread for this, but I do have a general comment about genomicDBimport. The project I am involved with is in partnership with an industrial partner, who sequences a number of animals every few weeks. In the pipeline using GATK 3.6, the newly sequenced animals were combined using combinegVCF and multiple gVCFs were then fed into genotypeGVCFs. . Unless I am missing something, the current set up in GATK 4.0 is not ideal for routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/47819#Comment_47819",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4667:1426,pipeline,pipeline,1426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4667,1,['pipeline'],['pipeline']
Deployability," htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scal",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:8915,pipeline,pipelines,8915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['pipeline'],['pipelines']
Deployability," implemented in sl_purity_ploidy_mcmc branch. Could stand some refactoring and code cleanup before it is PR ready and needs tests.; - [x] Algorithm improvements; - Currently, the model is initialized assuming a 50-50 normal-tumor split and only a clonal population. This is run for ~100 MCMC iterations, and the result is used to initialize a second run that expands the number of populations. This tends to work reasonably well, but there are situations where the model can get stuck in incorrect, degenerate solutions. Going to try adding some MH steps that will swap populations to see if these can help get the model unstuck.; - Need to add outlier absorption to the model, which appears to be critical for inference of subclonal populations from real data (i.e., ACNV output), which may have spurious segments, oversegmentation, etc. Simple clonal models appear to work reasonably well without this, though.; - [x] Evaluate algorithm on simulated data.; - Implemented simple Queue pipeline for running CLI on simulated ACNV segment files. Takes <2 minutes for ~1000 iterations for each sample, can run 100s of samples in parallel on the gsa clusters.; - Need to write up some scripts to automatically calculate and plot metrics.; - [x] Evaluate algorithm on real data; - Some initial runs on HCC1143 purity series show reasonable results for the clonal model, i.e., purity is recovered within credible intervals (question: what are the error bars on the purities of the samples?). Subclonal performance is a little less clear due to 1) no real ground truth, 2) events in the normal, and 3) lack of outlier absorption.; - Can we get a hold of some cleaner purity series?; - [ ] Document algorithm in technical whitepaper. ---. @samuelklee commented on [Thu Dec 08 2016](https://github.com/broadinstitute/gatk-protected/issues/750#issuecomment-265798051). The first release of this tool will most likely include the following:. - Some refactoring to MCMC package and addition of an EnsembleSampler",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2909:1624,pipeline,pipeline,1624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2909,1,['pipeline'],['pipeline']
Deployability," information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-env.1.gz; git-lfs usr/share/man/man1/git-lfs-ext.1.gz; git-lfs usr/share/man/man1/git-lfs-fetch.1.gz; git-lfs usr/share/man/man1/git-lfs-filter-process.1.gz; git-lfs usr/share/man/man1/git-lfs-fsck.1.gz; git-lfs usr/share/man/man1/git-lfs-install.1.gz; git-lfs usr/share/man/man1/git-lfs-lock.1.gz; git-lfs usr/share/man/man1/git-lfs-locks.1.gz; git-lfs usr/share/man/man1/git-lfs-logs.1.gz; git-lfs usr/share/man/man1/git-lfs-ls-files.1.gz; git-lfs usr/share/man/man1/git-lfs-merge-driver.1.gz; git-lfs usr/share/man/man1/git-lfs-migrate.1.gz; git-lfs usr/share/man/man1/git-lfs-pointer.1.gz; git-lfs usr/share/man/man1/git-lfs-post-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-post-commit.1.gz; git-lfs usr/share/man/man1/git-lfs-post-merge.1.gz; git-lfs usr/share/man/man1/git-lfs-pre-push.1.gz; git-lfs usr/share/man/man1/git-lfs-prune.1.gz; git-lfs usr/share/man/man1/git-lfs-pull.1.gz; git-lfs usr/share/man/man1/git-lfs-push.1.gz; git-lfs usr/share/man/man1/git-lfs-smudge.1.gz; git-lfs usr/share/man/man1/git-lfs-standalone-file.1.gz; git-lfs usr/share/man/man1/git-lfs-status.1.gz; git-lfs usr/share/man/man1/git-lfs-track.1.gz; git-lfs usr/share/man/man1/git-lfs-uninstall.1.gz; git-lfs usr/share/man/man1/git",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:2240,install,install,2240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['install'],['install']
Deployability," is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely use some of my time on such a feature if it wasn't possible to workaround the use case of tumor-normal data, but my previous suggestion is enough until someone (even myself) can spend some time on developing the feature. All this said, I am really interested in getting the indel realignment pipeline out in GATK4, and that's why I am implementing it. If the only way is adding support for every extra-feature of the tools, I have no other chance than doing it, but I can't promise that my schedule allows me to do it soon. I already started porting `IndelRealigner` without some features, and thus I think that if the n-way out can wait a bit, I can have the tool sooner than if I need to spend some time on working around the problems at the engine level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:2292,pipeline,pipeline,2292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231,1,['pipeline'],['pipeline']
Deployability," is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO ProgressMeter - Traversal complete. Processed 210940859 total records in 5.4 minutes.; 12:56:02.429 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190225/data3/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 12:56:02.429 INFO IndexFeatureFile - Shutting down engine; [April 25, 2019 12:56:02 PM CST] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 5.42 minutes.; Runtime.totalMemory()=5618270208; ```; Althought no warning/error messages was issued for the indexing of this big genome, I have tried to debug on 3 things I could think of:. 1. The chromosome and the coordinate are sorted ascendandly, although the chromosome names are not simply numeric continuous because of the A/B subgroup for each chromosome.; 2. The genome size difference, for which no clue was aboserved about the chromosome length limits. ; 3. The chromosome names for this big genome is quite long, but I tried the shorter names as A11 for chr1A_part1, A12 for chr1A_part2, ... B72 for chr7B_part2 (42 chromosomes in total), and the problem stayed exactly the same. Not sure what I may have missed. I appreciate any insight of this problem.; Yifang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:6099,continuous,continuous,6099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,2,"['A/B', 'continuous']","['A/B', 'continuous']"
Deployability," it's pretty short. Looks like this:. ````java; /**; * Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector.; */; @CommandLineProgramProperties(; summary = ""Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector"",; oneLineSummary = ""Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector"",; programGroup = ReadProgramGroup.class; ); public class ExampleNioCheckFS extends SparkCommandLineProgram {; private static final long serialVersionUID = 1L;. @Argument(fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME, shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME, doc = ""Output file (if not provided, defaults to STDOUT)"", common = false, optional = true); private File OUTPUT_FILE = null;. @Argument(fullName = ""inputPath"", shortName = ""P"", doc = ""Input path (eg. gs://foo/bar.bam)"", optional = false); private String path = null;. // Typically set to number of executors times number of cores per executor.; @Argument(fullName = ""parts"", doc = ""number of partitions"", optional = false); private int parts = 3;. private void countReads(JavaSparkContext ctx) {; PrintStream outputStream;. try {; outputStream = OUTPUT_FILE != null ? new PrintStream(OUTPUT_FILE) : System.out;; }; catch ( FileNotFoundException e ) {; throw new UserException.CouldNotReadInputFile(OUTPUT_FILE, e);; }. NioBam input = new NioBam(path, path + "".bai"");; List<String> ret = input.getReads(ctx, parts).mapPartitions(ExampleNioCheckFS::getFS).collect();; outputStream.println(""**** Results **** : "" + String.join("", "", ret));; }. private static Iterator<String> getFS(Iterator<SAMRecord> rs) {; boolean hasGS = FileSystemProvider.installedProviders().contains(""gs"");; return ImmutableList.of(""gs:""+(hasGS?""yes"":""no"")).iterator();; }. /**; * Runs the pipeline.; *; * @param ctx; */; @Override; protected void runPipeline(JavaSparkContext ctx) {; countReads(ctx);; }; }; ````",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-267424466:2038,install,installedProviders,2038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-267424466,2,"['install', 'pipeline']","['installedProviders', 'pipeline']"
Deployability," lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '18570' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; 23:44:42.124 DEBUG ScriptExecutor - Result: 0; 23:44:42.124 INFO GermlineCNVCaller - Done initializing engine; 23:44:42.126 INFO GermlineCNVCaller - Intervals specified...; 23:44:42.534 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:42.534 DEBUG GenomeLocParser - chr1 (248956422 bp); 23:44:42.534 DEBUG GenomeLocParser - chr2 (242193529 bp); 23:44:42.534 DEBUG GenomeLocParser - chr3 (198295559 bp); 23:44:42.535 DEBUG GenomeLocParser - chr4 (190214555 bp); 23:44:42.535 DEBUG GenomeLocParser - chr5 (181538259 bp); 23:44:42.535 DEBUG GenomeLocParser - chr6 (170805979 bp); 23:44:42.535 DEBUG GenomeLocParser - chr7 (159345973 bp); 23:44:42.535 DEBUG GenomeLocParser - chr8 (145138636 bp); 23:44:42.535 DEBUG GenomeLocParser - chr9 (138394717 bp); 23:44:42.535 DEBUG GenomeLocParser - chr10 (133797422 bp); 23:44:42.535 DEBUG Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:5952,release,release,5952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['release'],['release']
Deployability," major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - add fields for uncompressed imputed data; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array extract tool (#6827); - fix enum (#6834); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebase conflicts; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:1400,update,update,1400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['update'],['update']
Deployability," master #2529 +/- ##; ===============================================; + Coverage 76.266% 76.277% +0.011% ; - Complexity 10877 10879 +2 ; ===============================================; Files 752 752 ; Lines 39584 39586 +2 ; Branches 6922 6923 +1 ; ===============================================; + Hits 30189 30195 +6 ; + Misses 6774 6771 -3 ; + Partials 2621 2620 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.595% <100%> (+0.15%)` | `17 <0> (+1)` | :arrow_up: |; | [...nder/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9EZXB0aFBlclNhbXBsZUhDLmphdmE=) | `73.913% <100%> (+10.277%)` | `8 <0> (+1)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=footer). Last update [47d8c52...d16a01a](https://codecov.io/gh/broadinstitute/gatk/pull/2529?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2529#issuecomment-289058454:2217,update,update,2217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2529#issuecomment-289058454,2,['update'],['update']
Deployability," might be a hundred or so reads; and each cell is only contributing one to three reads. For other; mutations, maybe there's less than 10 reads corresponding to less than 10; cells, and it can vary pretty dramatically. The total number of cells; represented in a single sample can be thousands to tens of thousands,; usually - but could be many more as the tech advances. My hack for it at the moment is to encode both the cell barcode and the UMI; information into the read name. Then, for each variant, I query the reads; that overlap that variant in the bam file and analyze each read for; supporting the variant or the REF allele - then I can count the reads; according to the specific cells and also deal with any UMI redundancy per; cell. This works pretty well except for the cases where the HC reassembly; provides evidence for the variant and I can't track it to the originally; aligned reads. Also, mostly I think the difficulty here relates to indels; around homopolymers with our pacbio long isoform reads in our rna-seq; variant pipeline that leverages the gatk rna-seq protocol with HC. On Thu, Feb 29, 2024 at 8:58‚ÄØAM G√∂kalp √áelik ***@***.***>; wrote:. > Since each cell has a barcode wouldn't it be nice to use them as their; > Read Group ID and Sample Name within the BAM so that variant callers will; > distinguish each cell from their Sample Name and produce a multisample VCF; > for that variant site. Once IDs and Sample Names are split per cell you may; > be able to color them differently in IGV to even visually observe those; > events.; >; > ‚Äî; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971203108>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX6LYHUXDUMGDU3AIFLYV4ZZLAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGIYDGMJQHA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953:1085,pipeline,pipeline,1085,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953,1,['pipeline'],['pipeline']
Deployability," not long before our release of gCNV in 2018, but it's very old now.; > 3. The latest version of Python that is supported by PyMC3 3.1 in conda is Python 3.6.; > 4. @asmirnov239 has a draft PR (#8094) that updates PyMC3 to 3.5 and Python to 3.7, which clearly still falls short of Python 3.10+. This PR also updated some gCNV code to make it compatible with PyMC3 3.5. (It also removed TensorFlow and added PyTorch.); > 5. @asmirnov239 also merged a PR that added tests for numerical reproducibility of GermlineCNVCaller in cohort mode in #7889.; > 6. The earliest version of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off from the original expected results. It remains to be seen whether this is due to the randomness of inference, some slight changes to the model prior that were necessitated by the API changes, or some bugs introduced in other code updates. (Also note that I believe Andrey's PR in item 4 already broke ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:1456,release,released,1456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,2,"['release', 'update']","['released', 'updated']"
Deployability," on the [forum](https://gatkforums.broadinstitute.org/gatk/discussion/13680/variants-with-ad-0-0-and-dp-0#latest)... Aparently some variants with non-zero quals have 0 AD and DPs. Other annotations are also missing from the INFO columns. . After some debugging it turns out that the criteria to determine whether a read should be considered for a variant in terms of alignment overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ```marginalize``` call if the conditional is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:1052,configurat,configuration,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['configurat'],['configuration']
Deployability," org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11468,pipeline,pipelines,11468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['pipeline'],['pipelines']
Deployability," pip list from my environment:. cached-property 1.5.2+computecanada ; cycler 0.11.0+computecanada ; enum34 1.1.10+computecanada ; gatkpythonpackages 0.1 ; gcnvkernel 0.8 ; h5py 3.1.0+computecanada ; intel-openmp 2021.1.1+computecanada; joblib 0.14.1+computecanada ; kiwisolver 1.3.1+computecanada ; matplotlib 3.3.4+computecanada ; mkl 2021.1.1+computecanada; numpy 1.17.3+computecanada ; pandas 1.0.3+computecanada ; patsy 0.5.3+computecanada ; Pillow 8.1.2+computecanada ; pip 20.0.2 ; pymc3 3.1 ; pyparsing 3.1.0 ; python-dateutil 2.8.2+computecanada ; pytz 2023.3+computecanada ; scipy 1.1.0+computecanada ; setuptools 46.1.3 ; six 1.16.0+computecanada ; tbb 2021.1.1+computecanada; Theano 1.0.4 ; tqdm 4.19.5+computecanada ; wheel 0.34.2 ; ----. I used python 3.6.10 as suggested in gatkcondaenv.yml.template and respecting these dependencies found here setup_gcnvkernel.py:. ""theano == 1.0.4"",; ""pymc3 == 3.1"",; ""numpy >= 1.13.1"",; ""scipy >= 0.19.1"",; ""tqdm >= 4.15.0"" . ----. mkl is installed in my environment.; When I do : python -c ""import numpy ; numpy.show_config()"". I get this message:. blas_mkl_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; blas_opt_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/inc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:6129,install,installed,6129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['install'],['installed']
Deployability," really know what's happening. We wouldn't expect gatk4 haplotype caller to be that much slower. . It looks like they're running beta2 which is kind of old as well. Can you ask them what exact version they're using?. Can you ask if they have the log (stdout + stderr) for the gatk4 non-spark run? I can't tell what pairhmm they're actually running with and the logs would help with that. . Can you also find out what sort of hardware they're running on? Specifically, is it an intel machine with support for AVX?. A good setting for` --nativePairHmmThreads` is probably 4-8, you won't see any improvement after that. I also noticed that they're setting -XX:+UseParallelGC -XX:ParallelGCThreads=32 for the gatk3. They would be better off setting it to 2-4 threads. Performance gets worse beyond that typically from what I've seen. They can set the same thing for gatk4 using`--javaOptions ' -XX:+UseParallelGC -XX:ParallelGCThreads=4'`. Their spark configuration looks wrong in a number of ways which is probably a big part of why they're not seeing any improvement. In general you want executors with ~4-8 cores and at least 4g of memory per core. I don't know how much memory their nodes have, and I don't know if they're running with autoscaling turned on, but I suspect they're only allocating 1 executor on 1 node and then it's thrashing memory because it's trying to run 32 threads at once. Spark tuning for haplotype caller is going to be complicated though and I don't know how to do it will yet, we will be revisiting it in the next quarter probably. They're also running withs spark 2.1.0, we currently require spark 2.0.2 which is an unfortunately specific version, we're planning on upgrading to spark 2.2.+ in the next quarter. . You should make it clear to them that the results will not be the same between 3, 4, and 4-spark yet and that 4 is in rapid state of flux and has known performance issues that we're planning on working soon. Even so though, that slowdown they're seeing is bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964:971,configurat,configuration,971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964,2,['configurat'],['configuration']
Deployability," redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f9afec0957; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:38:15 2017 -0500. fixed arg issues in somatic WDL; exposed all missing args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:5961,update,update,5961,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['update']
Deployability," remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalization copy ratio are now referred to as standardized/denoised copy ratio.; - [x] Old code is still used for GC-bias correction in `CreateReadCountPanelOfNormals`, and we still use the `AnnotateTargets` tool. We should port this over (possibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoise",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:2300,pipeline,pipeline,2300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['pipeline'],['pipeline']
Deployability," removed TensorFlow and added PyTorch.); > 5. @asmirnov239 also merged a PR that added tests for numerical reproducibility of GermlineCNVCaller in cohort mode in #7889.; > 6. The earliest version of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off from the original expected results. It remains to be seen whether this is due to the randomness of inference, some slight changes to the model prior that were necessitated by the API changes, or some bugs introduced in other code updates. (Also note that I believe Andrey's PR in item 4 already broke these tests, although the numerical differences were much smaller and more reasonable---but perhaps he can confirm. Also noting here that I think determinism is still currently broken as of this commit---there have been some changes to PyTensor/PyMC seeding so that our previous theano/PyMC3 hack no longer applies.). So I think the next step is to just go to scientific-level ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:1841,update,updates,1841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['update'],['updates']
Deployability," routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs."". ----; User Report; ----. This is the error message I am getting but it doesn't make much sense, given that I got it also on smaller datasets with large amounts of memory (larger than some of the specifications listed on this forum for genomicDBimport). Our IT people, after observing the job, seem to think this is a java-related bug as the process itself doesn't use anywhere near the memory specified. We have installed a new version of java and I will be re-running the analysis to see if this solved the issues. . I'm not sure if I should be creating a new thread for this, but I do have a general comment about genomicDBimport. The project I am involved with is in partnership with an industrial partner, who sequences a number of animals every few weeks. In the pipeline using GATK 3.6, the newly sequenced animals were combined using combinegVCF and multiple gVCFs were then fed into genotypeGVCFs. . Unless I am missing something, the current set up in GATK 4.0 is not ideal for routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4667:1070,install,installed,1070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4667,1,['install'],['installed']
Deployability," save on the cloud but maybe @yfarjoun is willing to help. ---. @yfarjoun commented on [Fri Oct 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252258477). I don't have special privileges on the cloud...requests like this need to; go through pipeline-help...sorry. Y. On Fri, Oct 7, 2016 at 9:08 AM, ldgauthier notifications@github.com wrote:. > I don't know what intermediates we save on the cloud but maybe @yfarjoun; > https://github.com/yfarjoun is willing to help.; > ; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:2471,pipeline,pipeline-help,2471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['pipeline'],['pipeline-help']
Deployability," should definitely provide defaults for typical data types in *documentation*.) And in the end, I think it is beneficial for users that wish to tweak knobs to do some work to understand what those knobs actually do (even if just at a basic level). The other downside of option 2 is that it might not be immediately obvious from the command line what parameters are being used. For example, if a user chooses a set of defaults but then overrides some of them, we should make it so they don't have to go digging through the logs to see what parameters are actually used in the end. Nor should they have to go back and check what the defaults were for whatever version of the jar they were using at the time. Option 2 might also make it easier to inadvertently override parameters, etc. via command-line typos or copy-and-paste errors---it's much more straightforward to require and check that every parameter is specified once and fallback to a default if not, as we do now. Not to say that we couldn't get around any of these issues in Barclay, but I think it'll require some thought and careful design. Would be interested to hear Engine team's opinions. Finally, one point that I think will become more relevant as our tools and pipelines become more flexible and parameterized: I think we should start thinking of ""Best Practices Recommendations"" less as ""here is the best set of parameters to use with your data"" and more as ""here is *how to find* the best set of parameters to use with your data (for a given truth set, sensitivity requirement, etc.)"". After all, if we are putting together pipelines to do hyperparameter optimization, there is no reason not to share them with the community. This would also relax the requirement that the defaults in the WDL (which have to be kept in sync with those in the GATK jar) represent some sort of Best Practices Recommendation, which is awkward in exactly scenarios like the one you highlight. @vdauwera @LeeTL1220 @sooheelee might have some thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289:1581,pipeline,pipelines,1581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289,2,['pipeline'],['pipelines']
Deployability," spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [November 16, 2016 11:25:07 PM AST] Executing as root@hpcgenomicn24 on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_66-b17; Version: Version:4.alpha.2-98-g8fa5092-SNAPSHOT; 23:25:07.556 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; 23:25:07.556 INFO PrintReadsSpark - Defaults.COMPRESSION_LEVEL : 5; 23:25:07.556 INFO PrintReadsSpark - Defaults.CREATE_INDEX : false; 23:25:07.556 INFO PrintReadsSpark - Defaults.CREATE_MD5 : false; 23:25:07.556 INFO PrintReadsSpark ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:1510,pipeline,pipelines,1510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['pipeline'],['pipelines']
Deployability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:10755,pipeline,pipeline,10755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,"['Update', 'integrat', 'pipeline', 'update']","['Update', 'integration', 'pipeline', 'updates']"
Deployability," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1529,integrat,integrate,1529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,2,['integrat'],['integrate']
Deployability," the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported to GATK4?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLPwS6I5nu9TQiw4BFqRojmT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:7627,release,release,7627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['release'],['release']
Deployability," the python package theano(which is a requirement of gcnvkernel) with python 3.6.6 which is compiled with gcc 7.3.0. I am not using the conda environment to install these packages.; Then i tried to run theano-nose, but is giving me the following error:. ```sh. $ theano-nose; --; ; You can find the C code in this temporary file: /tmp/theano_compilation_error_gp0ar1kx; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x1a): is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x6b): is not found.; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:1291,INSTALL,INSTALLDIRGATK,1291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability," to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pick the CNV tools (or whatever) into it, and release that. Then when the HC stabilizes and master is once again releasable, we do the next release from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:4374,release,release,4374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,3,['release'],['release']
Deployability," tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help. ‚Äî; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1221,integrat,integrate,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,3,['integrat'],"['integrate', 'integrating', 'integration']"
Deployability," two different scenarios:. 1. Using full path without any non-ascii characters as tmp path and it succeeded:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:35:32.710 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:32.890 INFO BaseRecalibrator - ------------------------------------------------------------; 13:35:32.891 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:35:32.891 INFO BaseRecalibrator - For support and documentation go to https://softwa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:1186,pipeline,pipeline,1186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability," unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tree/da_read_pipeline? Is that at a point where I could try with pipeline on Spark, or should I wait until it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:1918,pipeline,pipeline,1918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,2,['pipeline'],['pipeline']
Deployability," was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:1024,install,install,1024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891,2,['install'],['install']
Deployability," yes, I know is still in beta but I‚Äôve found these problems when I compared the outputs from Haplotypecaller in spark and in not Spark versions. For comparing these results I've used this tool [https://drive.google.com/file/d/1r2WHyiz5WqOIyY_EZ1VZt92wGlL19SE4/view?usp=sharing](url) and I've obtained these plots for sensitivity and specificity( The sensitivity is defined as the number of sites inwhich both sequencing and microarrays detected a deviation from the reference sequencedivided by the number of sites where a variant was detected by using the microarrays). **Spark**; Sensitivity; ![spark_sensitivity_hg19](https://user-images.githubusercontent.com/10074137/47148261-86b77280-d2d0-11e8-8b5a-9ecfef16d889.png); Specificity; ![sparkspecificityhg19](https://user-images.githubusercontent.com/10074137/47148277-933bcb00-d2d0-11e8-97eb-1adceb4e5ee2.png). **Local non Spark tool with GATK 2.7**; ![hg19local](https://user-images.githubusercontent.com/10074137/47148427-fcbbd980-d2d0-11e8-87d8-04ec20c1005d.png); furthermore I've executed the pipeline until BQSR in Spark version and after, I am focused just on Haplotypecaller because I've used this ""backwards"" approach and I've discovered that the pipeline is deterministic from the phase Variant Discovery, but don't in the phase of Preprocessing because when I've executed this phase more times, I've obtained results completely, this is the test with one single sample:; ![comparisons_pfc32](https://user-images.githubusercontent.com/10074137/47148552-49071980-d2d1-11e8-8b1c-aec468285699.png); furthermore when I've used the output from BQSR (executed in Spark) for execute of Haplotypecaller in local(not in Spark) and adapting this output for Haplotypecaller, I had to use the tool Samtools for sort the outputs and after this step the outputs are passed from average of 19 gigabytes to 13 gigabytes average for the all samples. I've opened this Issue because I would to help you with my experiments to improvement your tool.; thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323:1289,pipeline,pipeline,1289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323,2,['pipeline'],['pipeline']
Deployability, | `100% <100%> (√∏)` | `5 <0> (-1)` | :arrow_down: |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `67.391% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ls/ExtractOriginalAlignmentRecordsByNameSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9FeHRyYWN0T3JpZ2luYWxBbGlnbm1lbnRSZWNvcmRzQnlOYW1lU3BhcmsuamF2YQ==) | `90.909% <100%> (√∏)` | `10 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/RevertSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9SZXZlcnRTYW1TcGFyay5qYXZh) | `83.895% <100%> (√∏)` | `86 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `78.947% <100%> (+1.17%)` | `7 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.418% <100%> (√∏)` | `78 <1> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <100%> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | ... and [12 more](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-461951346:3698,pipeline,pipelines,3698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-461951346,1,['pipeline'],['pipelines']
Deployability, | `83.582% <√∏> (-0.122%)` | `36 <0> (-1)` | |; | [...roadinstitute/hellbender/metrics/MetricsUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL01ldHJpY3NVdGlscy5qYXZh) | `57.143% <√∏> (√∏)` | `1 <0> (√∏)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.625% <100%> (√∏)` | `10 <2> (√∏)` | :arrow_down: |; | [...k/pipelines/metrics/MetricsCollectorSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmtUb29sLmphdmE=) | `75% <100%> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...nes/metrics/QualityYieldMetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9RdWFsaXR5WWllbGRNZXRyaWNzQ29sbGVjdG9yU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `7 <1> (√∏)` | :arrow_down: |; | [...trics/multi/ExampleMultiMetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9tZXRyaWNzL211bHRpL0V4YW1wbGVNdWx0aU1ldHJpY3NDb2xsZWN0b3JTcGFyay5qYXZh) | `86.364% <100%> (√∏)` | `7 <1> (√∏)` | :arrow_down: |; | [...lines/metrics/InsertS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449:2434,pipeline,pipelines,2434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449,1,['pipeline'],['pipelines']
Deployability, | |; |---|---|---|---|; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.746% <√∏> (-0.22%)` | `73 <0> (-1)` | |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470642394:1899,pipeline,pipelines,1899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470642394,1,['pipeline'],['pipelines']
Deployability, |; | [...tools/copynumber/ModelSegmentsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL01vZGVsU2VnbWVudHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `89.308% <100%> (+0.206%)` | `20 <0> (√∏)` | :arrow_down: |; | [...ools/copynumber/formats/records/LegacySegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9MZWdhY3lTZWdtZW50LmphdmE=) | `46.875% <46.875%> (√∏)` | `7 <7> (?)` | |; | [...r/formats/collections/LegacySegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvTGVnYWN5U2VnbWVudENvbGxlY3Rpb24uamF2YQ==) | `72.222% <72.222%> (√∏)` | `4 <4> (?)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `48% <0%> (+12%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (√∏)` | `13% <0%> (+6%)` | :arrow_up: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135:2892,integrat,integration,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135,1,['integrat'],['integration']
Deployability, |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 95% | _new_ [...dinstitute/hellbender/engine/MultiVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C746956617269616E7457616C6B65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | _new_ [...adinstitute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F56617269616E7457616C6B6572426173652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../broadinstitute/hellbender/engine/VariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F56617269616E7457616C6B65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...titute/hellbender/utils/SequenceDictionaryUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F53657175656E636544696374696F6E6172795574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...stitute/hellbender/tools/walkers/vqsr/ApplyVQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F4170706C79565153522E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...org/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F5265616457616C6B65722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [0454f48...aa6e5ed](https://codecov.io/gh/broadinstitute/gatk/compare/0454f48af55c48529f7e8332c687c7306d9600b0...aa6e5ed7c0721c3cbcd7190ddd064900d4f24482?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018:3205,update,update,3205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018,1,['update'],['update']
Deployability, Œî | Complexity Œî | |; |---|---|---|---|; | [...llbender/tools/walkers/annotator/TandemRepeat.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9UYW5kZW1SZXBlYXQuamF2YQ==) | `100% <√∏> (√∏)` | `6 <0> (√∏)` | :arrow_down: |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5943/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5943#issuecomment-492798650:1873,pipeline,pipelines,1873,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5943#issuecomment-492798650,1,['pipeline'],['pipelines']
Deployability,![image](https://user-images.githubusercontent.com/38786115/40131493-50819d2a-5964-11e8-9e95-3c834521f7b7.png). I guess you've done something. How can I know that the bug has been fixed? How to download and install the new version? Please help. Thank you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-389590814:207,install,install,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-389590814,1,['install'],['install']
Deployability,""" ; 7: Setting LC_MEASUREMENT failed, using ""C"" ; Error in readRDS(pfile) : ; cannot read workspace version 3 written by R 3.6.0; need R 3.5.0 or newer; Calls: source ... library -> find.package -> lapply -> FUN -> readRDS; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. when opening the docker container one can see installed version of R is 3.2.5. ```; Singularity broadinstitute_gatk_sha256_cec850f20311f0686fcf88510bc44e529590d78bec7076a603132115943c09e6.sif:~> R --version. R version 3.2.5 (2016-04-14) -- ""Very, Very Secure Dishes""; Copyright (C) 2016 The R Foundation for Statistical Computing; Platform: x86_64-pc-linux-gnu (64-bit); ```. #### Steps to reproduce; Run any AnalyzeCovariates. #### Expected behavior; create plots. #### Actual behavior; Docker faceplants",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6393:5536,install,installed,5536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6393,1,['install'],['installed']
Deployability,"""""""""; gatk]# ./gradlew; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; ............................................; Download https://repo1.maven.org/maven2/commons-codec/commons-codec/1.6/commons-codec-1.6.jar; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/data/md1/zhouyajun/biotools/gatk/gatk/build.gradle' line: 102. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; """"""; what should I do ?; How can I install GATK4 successful?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669:757,install,install,757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669,1,['install'],['install']
Deployability,"""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:1863,INSTALL,INSTALLDIRGATK,1863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"""D:\Program Files\Java\jdk1.8.0_121\bin\java.exe"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:62530,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\Users\Sweet\AppData\Local\JetBrains\IntelliJIdea2020.1\captureAgent\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath ""D:\Program Files\Java\jdk1.8.0_121\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:564,deploy,deploy,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['deploy'],['deploy']
Deployability,"# . ----------------------------------------------------------------------------------------------------------------------------------. the variants.funcotated.maf:. #version 2.4; ##; ## fileformat=VCFv4.2; ## FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ## FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ## FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read Depth"">; ## source=Funcotator; ## GATKCommandLine=<ID=Funcotator,CommandLine=""Funcotator --output ./my_data/variants.funcotated.maf --ref-version hg19 --data-sources-path ./my_data/funcotator_dataSources.v1.7.20200521s --output-file-format MAF --variant ./my_data/test_b37.vcf --reference ./my_data/human_g1k_v37.fasta --disable-sequence-dictionary-validation true --remove-filtered-variants false --five-prime-flank-size 5000 --three-prime-flank-size 0 --force-b37-to-hg19-reference-contig-conversion false --transcript-selection-mode CANONICAL --lookahead-cache-bp 100000 --min-num-bases-for-segment-funcotation 150 --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false"",Version=""4.2.0.0"",Date=""March 24, 2021 12:11:32 PM GMT"">; ## Funcotator 4.2.0.0 | Date 20211124T121132 | Gencode 34 CANONICAL | Achilles 110303 | CGC full_2012_03-15 | ClinVar 12.03.20 | C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7158:19452,update,updates,19452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7158,1,['update'],['updates']
Deployability,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:155,pipeline,pipeline,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,1,['pipeline'],['pipeline']
Deployability,"# Bug Report. ## Affected tool(s) or class(es); gatk `GenomicsDBImport ` `GenotypeGVCFs`; ## Affected version(s); The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDBÔºåI have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:413,configurat,configuration,413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,2,"['configurat', 'update']","['configuration', 'update-workspace-path']"
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2378?src=pr&el=h1) Report; > Merging [#2378](https://codecov.io/gh/broadinstitute/gatk/pull/2378?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9d82097641f160e00fa1ef4236d9bcdccbfa38b0?src=pr&el=desc) will **not impact** coverage. ```diff; @@ Coverage Diff @@; ## master #2378 +/- ##; =========================================; Coverage 76.378% 76.378% ; =========================================; Files 748 748 ; Lines 39315 39315 ; Branches 6847 6847 ; =========================================; Hits 30028 30028 ; Misses 6693 6693 ; Partials 2594 2594; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2378?src=pr&el=tree) | Coverage Œî | |; |---|---|---|; | [...roadinstitute/hellbender/utils/tsv/TableUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...30b7f8dc5646d760cd7d8b42513538b30f803d33?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVVdGlscy5qYXZh) | `85% <√∏> (√∏)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2378?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2378?src=pr&el=footer). Last update [9d82097...30b7f8d](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...30b7f8dc5646d760cd7d8b42513538b30f803d33?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2378#issuecomment-276484501:1508,update,update,1508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2378#issuecomment-276484501,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2387?src=pr&el=h1) Report; > Merging [#2387](https://codecov.io/gh/broadinstitute/gatk/pull/2387?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/14f73e217970a1c53092dee88c409f8a6cdb6e87?src=pr&el=desc) will **increase** coverage by `-0.002%`. ```diff; @@ Coverage Diff @@; ## master #2387 +/- ##; ===============================================; - Coverage 76.379% 76.377% -0.002% ; - Complexity 0 10849 +10849 ; ===============================================; Files 748 748 ; Lines 39325 39347 +22 ; Branches 6849 6851 +2 ; ===============================================; + Hits 30036 30052 +16 ; - Misses 6695 6703 +8 ; + Partials 2594 2592 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2387?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ce8d93ca83ab90330776d2f46fea691af347349d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `78.065% <54.167%> (-0.883%)` | `20 <√∏> (+20)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2387?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2387?src=pr&el=footer). Last update [14f73e2...ce8d93c](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ce8d93ca83ab90330776d2f46fea691af347349d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2387#issuecomment-277112231:1661,update,update,1661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2387#issuecomment-277112231,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2403?src=pr&el=h1) Report; > Merging [#2403](https://codecov.io/gh/broadinstitute/gatk/pull/2403?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/30365e7bea2d081204a11e7d916026cb3494961f?src=pr&el=desc) will **increase** coverage by `0.003%`. ```diff; @@ Coverage Diff @@; ## master #2403 +/- ##; ===============================================; + Coverage 76.133% 76.135% +0.003% ; - Complexity 10785 10786 +1 ; ===============================================; Files 748 748 ; Lines 39372 39372 ; Branches 6856 6856 ; ===============================================; + Hits 29975 29976 +1 ; Misses 6791 6791 ; + Partials 2606 2605 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2403?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...a51febdea00d0e15069996b5b8a492587d6d220b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <√∏> (+1.429%)` | `24% <√∏> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2403?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2403?src=pr&el=footer). Last update [30365e7...a51febd](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...a51febdea00d0e15069996b5b8a492587d6d220b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2403#issuecomment-279082175:1633,update,update,1633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2403#issuecomment-279082175,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2407?src=pr&el=h1) Report; > Merging [#2407](https://codecov.io/gh/broadinstitute/gatk/pull/2407?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/f45f6a52d69fbf01541099cf737a0fc5391d584e?src=pr&el=desc) will **increase** coverage by `0.005%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2407 +/- ##; ===============================================; + Coverage 76.201% 76.206% +0.005% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39417 ; Branches 6858 6858 ; ===============================================; + Hits 30036 30038 +2 ; + Misses 6775 6773 -2 ; Partials 2606 2606; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2407?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...9d14cf8831c2f51e6ca75d560343f35411b15c5b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <√∏> (+1.587%)` | `61% <√∏> (+2%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2407?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2407?src=pr&el=footer). Last update [f45f6a5...9d14cf8](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...9d14cf8831c2f51e6ca75d560343f35411b15c5b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2407#issuecomment-279825441:1668,update,update,1668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2407#issuecomment-279825441,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@a49f0b3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2411 +/- ##; ==========================================; Coverage ? 76.206% ; Complexity ? 10814 ; ==========================================; Files ? 750 ; Lines ? 39421 ; Branches ? 6859 ; ==========================================; Hits ? 30041 ; Misses ? 6773 ; Partials ? 2607; ```. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=footer). Last update [a49f0b3...00efddd](https://codecov.io/gh/broadinstitute/gatk/compare/a49f0b30b69eb3de3263cc976f976cd528721cc5...00efddd232b43006ad4f33e51d9387f507efe6ae?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2411#issuecomment-280715503:1028,update,update,1028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2411#issuecomment-280715503,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2435?src=pr&el=h1) Report; > Merging [#2435](https://codecov.io/gh/broadinstitute/gatk/pull/2435?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/92cb86051b59acb6b18115135a5b5db99b617d22?src=pr&el=desc) will **decrease** coverage by `-0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2435 +/- ##; ===============================================; - Coverage 76.231% 76.223% -0.008% ; Complexity 10822 10822 ; ===============================================; Files 750 750 ; Lines 39425 39425 ; Branches 6885 6885 ; ===============================================; - Hits 30054 30051 -3 ; - Misses 6754 6757 +3 ; Partials 2617 2617; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2435?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f615b91329aaa84fff4fb4c22660820e2ed0dcb0?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <0%> (-2.083%)` | `36% <0%> (√∏)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2435?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2435?src=pr&el=footer). Last update [92cb860...f615b91](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f615b91329aaa84fff4fb4c22660820e2ed0dcb0?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-284289466:1645,update,update,1645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-284289466,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2456?src=pr&el=h1) Report; > Merging [#2456](https://codecov.io/gh/broadinstitute/gatk/pull/2456?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/dfa9cf1a420490285b7be7917082222a07e2b042?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2456 +/- ##; ===============================================; + Coverage 76.254% 76.256% +0.003% ; - Complexity 10861 10862 +1 ; ===============================================; Files 750 750 ; Lines 39556 39556 ; Branches 6914 6914 ; ===============================================; + Hits 30163 30164 +1 ; Misses 6775 6775 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2456?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...988bc45a8ccfe0ae3884f0c8401015ce053f45bb?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2456?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2456?src=pr&el=footer). Last update [dfa9cf1...988bc45](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...988bc45a8ccfe0ae3884f0c8401015ce053f45bb?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-285972823:1666,update,update,1666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-285972823,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2513?src=pr&el=h1) Report; > Merging [#2513](https://codecov.io/gh/broadinstitute/gatk/pull/2513?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9c1d1fb2cc1aeb171e01764ee69c1544698e796d?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2513 +/- ##; ===========================================; Coverage 76.256% 76.256% ; Complexity 10864 10864 ; ===========================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===========================================; Hits 30154 30154 ; Misses 6771 6771 ; Partials 2618 2618; ```. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2513?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2513?src=pr&el=footer). Last update [9c1d1fb...7fc08f1](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...7fc08f1c4ac1def9789665bd56448220d7ba774a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2513#issuecomment-288454418:1104,update,update,1104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2513#issuecomment-288454418,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2544?src=pr&el=h1) Report; > Merging [#2544](https://codecov.io/gh/broadinstitute/gatk/pull/2544?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/8b4122cfb8268dcd86cca6bd8d6b3b4b6e1ed5a6?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2544 +/- ##; ===========================================; Coverage 76.282% 76.282% ; Complexity 10892 10892 ; ===========================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===========================================; Hits 30200 30200 ; Misses 6768 6768 ; Partials 2622 2622; ```. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2544?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2544?src=pr&el=footer). Last update [8b4122c...df921e4](https://codecov.io/gh/broadinstitute/gatk/pull/2544?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2544#issuecomment-290236909:1104,update,update,1104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2544#issuecomment-290236909,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=h1) Report; > Merging [#2547](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **decrease** coverage by `0.005%`.; > The diff coverage is `90%`. ```diff; @@ Coverage Diff @@; ## master #2547 +/- ##; ===============================================; - Coverage 76.279% 76.275% -0.005% ; + Complexity 10891 10889 -2 ; ===============================================; Files 752 752 ; Lines 39590 39574 -16 ; Branches 6925 6922 -3 ; ===============================================; - Hits 30199 30185 -14 ; + Misses 6768 6767 -1 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.226% <90%> (-2.896%)` | `39 <15> (-2)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=footer). Last update [c8ede6e...24e6497](https://codecov.io/gh/broadinstitute/gatk/pull/2547?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2547#issuecomment-290296401:1605,update,update,1605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2547#issuecomment-290296401,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=h1) Report; > Merging [#2568](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **decrease** coverage by `0.008%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2568 +/- ##; ===============================================; - Coverage 76.386% 76.378% -0.008% ; Complexity 10898 10898 ; ===============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ===============================================; - Hits 30212 30209 -3 ; - Misses 6727 6730 +3 ; Partials 2613 2613; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `47.807% <0%> (-1.316%)` | `41 <0> (√∏)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=footer). Last update [6859a12...8066d14](https://codecov.io/gh/broadinstitute/gatk/pull/2568?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2568#issuecomment-291909495:1583,update,update,1583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2568#issuecomment-291909495,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=h1) Report; > Merging [#2570](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **increase** coverage by `0.005%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2570 +/- ##; ===============================================; + Coverage 76.386% 76.391% +0.005% ; Complexity 10898 10898 ; ===============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ===============================================; + Hits 30212 30214 +2 ; + Misses 6727 6725 -2 ; Partials 2613 2613; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=footer). Last update [6859a12...b9b665a](https://codecov.io/gh/broadinstitute/gatk/pull/2570?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2570#issuecomment-291915451:1583,update,update,1583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2570#issuecomment-291915451,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2576?src=pr&el=h1) Report; > Merging [#2576](https://codecov.io/gh/broadinstitute/gatk/pull/2576?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/7a3d966f08a205f0961eebf73d89ed8b69be185d?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2576 +/- ##; ========================================; Coverage 76.4% 76.4% ; Complexity 10922 10922 ; ========================================; Files 755 755 ; Lines 39674 39674 ; Branches 6927 6927 ; ========================================; Hits 30311 30311 ; Misses 6740 6740 ; Partials 2623 2623; ```. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2576?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2576?src=pr&el=footer). Last update [7a3d966...49bbaba](https://codecov.io/gh/broadinstitute/gatk/pull/2576?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2576#issuecomment-292395135:1091,update,update,1091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2576#issuecomment-292395135,2,['update'],['update']
Deployability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=h1) Report; > Merging [#2580](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/d054e7aa910767c9f8d1b1a780435779d389080d?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2580 +/- ##; ===========================================; Coverage 76.036% 76.036% ; Complexity 11010 11010 ; ===========================================; Files 768 768 ; Lines 39952 39952 ; Branches 6956 6956 ; ===========================================; Hits 30378 30378 ; Misses 6943 6943 ; Partials 2631 2631; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <√∏> (√∏)` | `28 <0> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=footer). Last update [d054e7a...c1d2a60](https://codecov.io/gh/broadinstitute/gatk/pull/2580?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2580#issuecomment-292624127:1552,update,update,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2580#issuecomment-292624127,2,['update'],['update']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=h1) Report; > Merging [#2620](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/b60560ae0e6ec2f3809aeaf3a4753692e591e3ac?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `86.111%`. ```diff; @@ Coverage Diff @@; ## master #2620 +/- ##; ===============================================; + Coverage 77.718% 77.718% +<.001% ; - Complexity 11526 11536 +10 ; ===============================================; Files 787 788 +1 ; Lines 41697 41724 +27 ; Branches 7243 7248 +5 ; ===============================================; + Hits 32406 32427 +21 ; - Misses 6556 6559 +3 ; - Partials 2735 2738 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `92% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `95.238% <100%> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-297073887:944,pipeline,pipelines,944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-297073887,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=h1) Report; > Merging [#2785](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/752d0207aed7adcad5bf33d36f6bd34ad4bd4894?src=pr&el=desc) will **increase** coverage by `0.17%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2785 +/- ##; ==============================================; + Coverage 77.659% 77.828% +0.17% ; - Complexity 11523 11729 +206 ; ==============================================; Files 787 787 ; Lines 41743 42356 +613 ; Branches 7251 7443 +192 ; ==============================================; + Hits 32417 32965 +548 ; - Misses 6586 6613 +27 ; - Partials 2740 2778 +38; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...spark/pipelines/metrics/MetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmsuamF2YQ==) | `100% <√∏> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.582% <√∏> (-0.122%)` | `36 <0> (-1)` | |; | [...roadinstitute/hellbender/metrics/MetricsUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL01ldHJpY3NVdGlscy5qYXZh) | `57.143% <√∏> (√∏)` | `1 <0> (√∏)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449:929,pipeline,pipelines,929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2791?src=pr&el=h1) Report; > Merging [#2791](https://codecov.io/gh/broadinstitute/gatk/pull/2791?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/ec1b0f4b5913ebf9c44225f03ddf282e1ce0fb3d?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `83.333%`. ```diff; @@ Coverage Diff @@; ## master #2791 +/- ##; ===============================================; + Coverage 79.971% 79.973% +0.001% ; - Complexity 16726 16727 +1 ; ===============================================; Files 1139 1139 ; Lines 60898 60902 +4 ; Branches 9436 9437 +1 ; ===============================================; + Hits 48701 48705 +4 ; Misses 8401 8401 ; Partials 3796 3796; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2791?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2791?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2791?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `51.724% <83.333%> (+1.136%)` | `24 <0> (+1)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2791#issuecomment-305358096:931,pipeline,pipelines,931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2791#issuecomment-305358096,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=h1) Report; > Merging [#3096](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c18e7800ed85c55f81387cf02fdcbf6cb3aaaf5e?src=pr&el=desc) will **decrease** coverage by `0.46%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3096 +/- ##; ==============================================; - Coverage 80.129% 79.669% -0.46% ; + Complexity 16970 16898 -72 ; ==============================================; Files 1143 1143 ; Lines 61566 61566 ; Branches 9592 9592 ; ==============================================; - Hits 49332 49049 -283 ; - Misses 8417 8711 +294 ; + Partials 3817 3806 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/spark/pipelines/SortReadFileSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFJlYWRGaWxlU3BhcmsuamF2YQ==) | `70.588% <100%> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904:933,pipeline,pipelines,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=h1) Report; > Merging [#3452](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/1edf1b6455708fa7974896ec792e64bb24c7307c?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `90.909%`. ```diff; @@ Coverage Diff @@; ## master #3452 +/- ##; ===============================================; + Coverage 80.092% 80.092% +0.001% ; - Complexity 17763 17766 +3 ; ===============================================; Files 1188 1188 ; Lines 64415 64417 +2 ; Branches 10006 10007 +1 ; ===============================================; + Hits 51591 51593 +2 ; + Misses 8838 8837 -1 ; - Partials 3986 3987 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `91.429% <90%> (-1.675%)` | `10 <1> (+2)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `83.168% <91.667%> (+4.121%)` | `25 <5> (+1)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (√∏)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-323129083:942,pipeline,pipelines,942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-323129083,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=h1) Report; > Merging [#3474](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/bfa9af462f484c77597a9fdbdc46f66393afaff1?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `84.615%`. ```diff; @@ Coverage Diff @@; ## master #3474 +/- ##; ===============================================; + Coverage 80.079% 80.087% +0.008% ; - Complexity 17760 17762 +2 ; ===============================================; Files 1188 1188 ; Lines 64410 64415 +5 ; Branches 10004 10006 +2 ; ===============================================; + Hits 51579 51588 +9 ; + Misses 8845 8840 -5 ; - Partials 3986 3987 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <100%> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `69.231% <100%> (+2.564%)` | `5 <0> (+1)` | :arrow_up: |; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <50%> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGU,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325007520:927,pipeline,pipelines,927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325007520,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3989?src=pr&el=h1) Report; > Merging [#3989](https://codecov.io/gh/broadinstitute/gatk/pull/3989?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/a14e85db4e491d4bd0f03593cbf2e3a4bbc72967?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `92.683%`. ```diff; @@ Coverage Diff @@; ## master #3989 +/- ##; ===============================================; + Coverage 78.775% 78.783% +0.009% ; - Complexity 16502 16506 +4 ; ===============================================; Files 1065 1065 ; Lines 58788 58788 ; Branches 9578 9578 ; ===============================================; + Hits 46310 46315 +5 ; + Misses 8752 8746 -6 ; - Partials 3726 3727 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3989?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <√∏> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `90.476% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785:934,pipeline,pipelines,934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=h1) Report; > Merging [#4308](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/e455fd57e2c1270f250931206ae2bed47711139b?src=pr&el=desc) will **increase** coverage by `0.017%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4308 +/- ##; ===============================================; + Coverage 80.073% 80.091% +0.017% ; - Complexity 17420 17437 +17 ; ===============================================; Files 1080 1081 +1 ; Lines 63131 63201 +70 ; Branches 10200 10215 +15 ; ===============================================; + Hits 50551 50618 +67 ; Misses 8587 8587 ; - Partials 3993 3996 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (+1.17%)` | `5 <1> (+1)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.388% <100%> (+0.083%)` | `94 <1> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.796% <100%> (+0.665%)` | `14 <2> (+2)` | :arrow_up: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142:926,pipeline,pipelines,926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4853?src=pr&el=h1) Report; > Merging [#4853](https://codecov.io/gh/broadinstitute/gatk/pull/4853?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/140d76cad6c00bd902243b83935e8225da328ae4?src=pr&el=desc) will **increase** coverage by `0.006%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4853 +/- ##; ===============================================; + Coverage 80.421% 80.427% +0.006% ; - Complexity 17820 17821 +1 ; ===============================================; Files 1089 1089 ; Lines 64161 64159 -2 ; Branches 10344 10344 ; ===============================================; + Hits 51599 51601 +2 ; + Misses 8501 8497 -4 ; Partials 4061 4061; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4853?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...lbender/tools/spark/pipelines/PrintReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4853/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrLmphdmE=) | `100% <√∏> (√∏)` | `3 <0> (-1)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4853/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4853#issuecomment-395207710:933,pipeline,pipelines,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4853#issuecomment-395207710,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5028?src=pr&el=h1) Report; > Merging [#5028](https://codecov.io/gh/broadinstitute/gatk/pull/5028?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/1977c537b209d25fea504d2f601af7a9731debcf?src=pr&el=desc) will **decrease** coverage by `1.009%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5028 +/- ##; ===============================================; - Coverage 60.162% 59.153% -1.009% ; + Complexity 12772 12571 -201 ; ===============================================; Files 1095 1095 ; Lines 64616 64616 ; Branches 10394 10394 ; ===============================================; - Hits 38874 38222 -652 ; - Misses 21504 22146 +642 ; - Partials 4238 4248 +10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5028?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `87.037% <√∏> (√∏)` | `17 <0> (√∏)` | :arrow_down: |; | [...bender/tools/walkers/mutect/FilterMutectCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/5028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9GaWx0ZXJNdXRlY3RDYWxscy5qYXZh) | `0% <√∏> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...ender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/5028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2ZpbHRlcnMvVmFyaWFudEZpbHRyYXRpb24uamF2YQ==) | `89.076% <100%> (√∏)` | `41 <0> (√∏)` | :arrow_down: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/5028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5028#issuecomment-405970435:942,pipeline,pipelines,942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5028#issuecomment-405970435,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=h1) Report; > Merging [#5251](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/fe62acc2402164cb4b2ba7d348fd64a90e7992e8?src=pr&el=desc) will **increase** coverage by `0.139%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5251 +/- ##; ===============================================; + Coverage 86.903% 87.042% +0.139% ; - Complexity 30311 32163 +1852 ; ===============================================; Files 1849 1974 +125 ; Lines 140507 147466 +6959 ; Branches 15475 16232 +757 ; ===============================================; + Hits 122105 128358 +6253 ; - Misses 12793 13189 +396 ; - Partials 5609 5919 +310; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...spark/ReadsPreprocessingPipelineSparkTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZHNQcmVwcm9jZXNzaW5nUGlwZWxpbmVTcGFya1Rlc3REYXRhLmphdmE=) | `0% <0%> (-94.03%)` | `0% <0%> (-11%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671:949,pipeline,pipelines,949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=h1) Report; > Merging [#5645](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c176be2d7fc1caab8616ec8dbb41a5cb5a8c0a71?src=pr&el=desc) will **decrease** coverage by `0.594%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #5645 +/- ##; ===============================================; - Coverage 87.035% 86.441% -0.594% ; - Complexity 31726 31896 +170 ; ===============================================; Files 1943 1943 ; Lines 146193 148531 +2338 ; Branches 16141 16607 +466 ; ===============================================; + Hits 127239 128391 +1152 ; - Misses 13067 14170 +1103 ; - Partials 5887 5970 +83; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `37.008% <0%> (-29.189%)` | `9% <0%> (-5%)` | |; | [...llbender/utils/reference/FastaReferenceWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvRmFzdGFSZWZlcmVuY2VXcml0ZXIuamF2YQ==) | `64.593% <0%> (-27.872%)` | `48% <0%> (-3%)` | |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077:957,pipeline,pipelines,957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=h1) Report; > Merging [#5689](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/226f6d70a9c09318d45506c726f6744e2379d60c?src=pr&el=desc) will **decrease** coverage by `0.005%`.; > The diff coverage is `90.865%`. ```diff; @@ Coverage Diff @@; ## master #5689 +/- ##; ===============================================; - Coverage 87.069% 87.064% -0.005% ; + Complexity 31875 31850 -25 ; ===============================================; Files 1940 1941 +1 ; Lines 146738 146599 -139 ; Branches 16226 16208 -18 ; ===============================================; - Hits 127764 127635 -129 ; + Misses 13061 13057 -4 ; + Partials 5913 5907 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `92.857% <100%> (+4.325%)` | `2 <1> (-29)` | :arrow_down: |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <100%> (+3.205%)` | `3 <1> (-23)` | :arrow_down: |; | [...ender/tools/AbstractPrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BYnN0cmFjdFByaW50UmVhZHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `90.777% <90.777%> (√∏)` | `28 <28> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5689#issuecomment-465117014:945,pipeline,pipelines,945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5689#issuecomment-465117014,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=h1) Report; > Merging [#5750](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/68809f0d285bcbea1d09301fe27370ec7a655dc9?src=pr&el=desc) will **decrease** coverage by `6.78%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5750 +/- ##; ==============================================; - Coverage 87.069% 80.289% -6.78% ; + Complexity 31891 30238 -1653 ; ==============================================; Files 1943 1943 ; Lines 146770 146770 ; Branches 16224 16224 ; ==============================================; - Hits 127791 117840 -9951 ; - Misses 13065 23217 +10152 ; + Partials 5914 5713 -201; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <√∏> (-95.313%)` | `1 <0> (-6)` | |; | [...kers/filters/VariantFiltrationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2ZpbHRlcnMvVmFyaWFudEZpbHRyYXRpb25JbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.826% <0%> (-99.174%)` | `1% <0%> (-25%)` | |; | [...dorientation/CollectF1R2CountsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9Db2xsZWN0RjFSMkNvdW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.917% <0%> (-99.083%)` | `1% <0%> (-12%)` | |; | [.../walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5750#issuecomment-469352829:930,pipeline,pipelines,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5750#issuecomment-469352829,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=h1) Report; > Merging [#5909](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9e759f6f440d58f1d8b2f99d5042a691f4543975?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #5909 +/- ##; ===============================================; + Coverage 80.117% 80.119% +0.002% ; - Complexity 30673 30674 +1 ; ===============================================; Files 1991 1991 ; Lines 149341 149342 +1 ; Branches 16481 16482 +1 ; ===============================================; + Hits 119647 119651 +4 ; + Misses 23892 23890 -2 ; + Partials 5802 5801 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `69.767% <√∏> (-0.348%)` | `18 <0> (√∏)` | |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `83.212% <100%> (√∏)` | `28 <0> (√∏)` | :arrow_down: |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5909#issuecomment-488239579:948,pipeline,pipelines,948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5909#issuecomment-488239579,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5949?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8e78dc6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `71.429%`. ```diff; @@ Coverage Diff @@; ## master #5949 +/- ##; ==========================================; Coverage ? 80.152% ; Complexity ? 31063 ; ==========================================; Files ? 2016 ; Lines ? 151429 ; Branches ? 16623 ; ==========================================; Hits ? 121373 ; Misses ? 24201 ; Partials ? 5855; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5949?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (√∏)` | `0 <0> (?)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `2.381% <0%> (√∏)` | `1 <0> (?)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `5 <0> (?)` | |; | [...ender/tools/ApplyBQSRUniqueArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BcHBseUJRU1JVbmlxdWVBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (√∏)` | `2 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-493932361:809,pipeline,pipelines,809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-493932361,6,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5974?src=pr&el=h1) Report; > Merging [#5974](https://codecov.io/gh/broadinstitute/gatk/pull/5974?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/a47aa22783e3bfde2b63746c0e33d4f5f3509fd3?src=pr&el=desc) will **decrease** coverage by `0.002%`.; > The diff coverage is `88.095%`. ```diff; @@ Coverage Diff @@; ## master #5974 +/- ##; ===============================================; - Coverage 86.931% 86.929% -0.002% ; - Complexity 32715 32721 +6 ; ===============================================; Files 2013 2013 ; Lines 151268 151306 +38 ; Branches 16604 16610 +6 ; ===============================================; + Hits 131499 131529 +30 ; - Misses 13716 13720 +4 ; - Partials 6053 6057 +4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5974?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5974/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvTWFya0R1cGxpY2F0ZXNTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `91.837% <100%> (+0.47%)` | `44 <2> (+2)` | :arrow_up: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5974/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.625% <80.769%> (-3.97%)` | `41 <5> (+5)` | |; | [...tools/walkers/haplotypecaller/graphs/SeqGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5974/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxR3JhcGguamF2YQ==) | `87.059% <0%> (-2.353%)` | `23% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5974#issuecomment-497125061:934,pipeline,pipelines,934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5974#issuecomment-497125061,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5991?src=pr&el=h1) Report; > Merging [#5991](https://codecov.io/gh/broadinstitute/gatk/pull/5991?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/e8f544362b6bec8152472fe62c8791881d84cd07?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5991 +/- ##; ===============================================; + Coverage 86.926% 86.927% +0.001% ; + Complexity 32732 32731 -1 ; ===============================================; Files 2014 2014 ; Lines 151333 151333 ; Branches 16612 16612 ; ===============================================; + Hits 131548 131549 +1 ; Misses 13724 13724 ; + Partials 6061 6060 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5991?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90.909% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504:936,pipeline,pipelines,936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504,1,['pipeline'],['pipelines']
Deployability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6010?src=pr&el=h1) Report; > Merging [#6010](https://codecov.io/gh/broadinstitute/gatk/pull/6010?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/083aac832cb64515fd0456008bf847dd22f6c234?src=pr&el=desc) will **increase** coverage by `0.274%`.; > The diff coverage is `41.176%`. ```diff; @@ Coverage Diff @@; ## master #6010 +/- ##; ===============================================; + Coverage 86.929% 87.204% +0.274% ; + Complexity 32765 32712 -53 ; ===============================================; Files 2016 2011 -5 ; Lines 151460 150925 -535 ; Branches 16628 16132 -496 ; ===============================================; - Hits 131663 131612 -51 ; + Misses 13732 13701 -31 ; + Partials 6065 5612 -453; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6010?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `56.522% <0%> (-36.335%)` | `2 <0> (√∏)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `63.158% <100%> (+1.825%)` | `18 <1> (+1)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.873% <100%> (+0.095%)` | `78 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6010#issuecomment-503050294:948,pipeline,pipelines,948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6010#issuecomment-503050294,1,['pipeline'],['pipelines']
Deployability,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6882:106,release,release,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). All Spark tools that takes parameter `-L`. ### Affected version(s); - [x] Latest public release version [4.0.4.0]; - [x] Latest master branch as of [2018-06-30]. ### Description . When running a Spark tool and passing in interval arguments via the standard `-L` argument, if the interval file (only BED file is tested) is stored in HDFS, we see errors like below. ```; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Query interval ""hdfs://shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-m:8020/data/merged_commonFPDel.bed"" is not valid for this input.; 	at org.broadinstitute.hellbender.utils.GenomeLocParser.getUnambiguousInterval(GenomeLocParser.java:350); 	at org.broadinstitute.hellbender.utils.GenomeLocParser.parseGenomeLoc(GenomeLocParser.java:309); 	at org.broadinstitute.hellbender.utils.IntervalUtils.parseIntervalArguments(IntervalUtils.java:300); 	at org.broadinstitute.hellbender.utils.IntervalUtils.loadIntervals(IntervalUtils.java:226); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.parseIntervals(IntervalArgumentCollection.java:174); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getTraversalParameters(IntervalArgumentCollection.java:155); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getIntervals(IntervalArgumentCollection.java:111); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeIntervals(GATKSparkTool.java:514); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:451); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:439); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLinePro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4852:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4852,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). FastaAlternateReferenceMaker. ### Affected version(s); - [x] Latest public release version 4.1.4.1; - [ ] Latest master branch as of [date of test?]. ### Description . A null pointer exception in . #### Steps to reproduce. We called variants with HaplotypeCaller & use resulting VCF with FastaAlternateReferenceMaker. See command below, but only reference fasta & HC vcf are given as input (no snp masking or interval list, though error also occurs when using interval list with multiple -L calls). #### Expected behavior. Alternate-adjusted reference file or at least a helpful error message. #### Actual behavior. ```; + latest-gatk/gatk-4.1.4.1/gatk FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; Using GATK jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:125,release,release,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es). GermlineCNVCaller. ### Affected version(s). - [x] Latest public release version gatk 4.2.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . The same set of hdf5 works fine with another annotated_intervals.tsv . the stack trace:; ```; 11:52:33.788 INFO GermlineCNVCaller - Aggregating read-count file /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/; 20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:114,release,release,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es). HC java.lang.IllegalStateException: Padded span must contain active span. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description. ```; Runtime.totalMemory()=2494038016; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:104); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:80); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popNextReadyAssemblyRegion(ActivityProfile.java:332); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popReadyAssemblyRegions(ActivityProfile.java:277); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:159); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:112); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:35); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:192); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7289:169,release,release,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7289,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). HaplotypeCaller. ### Affected version(s); - [x] Latest public release version (4.4.0.0, also 4.1.4.1); - [ ] Latest master branch as of [date of test?]. ### Description . I am using the HaplotypeCaller (GATK 4.4.0.0). When I look at the input BAM file in IGV, I expect the variant `NC_000015.9:g.48760182_48760185delinsGGGT`. However, HaplotypeCaller reports `NC_000015.9:g.48760182_48760185del` as well as an insertion `NC_000015.9:g.48760184_48760185insGGGT` (i.e. two distinct variants instead of a single indel). In the `bamout`, one can clearly see that the local realignment suggests the deletion + insertion and not the indel. ![image](https://user-images.githubusercontent.com/58295931/226553360-bff887ea-3823-44b7-bddb-46f70705c0b3.png). I understand that the local realignment is expected to improve variant calling and that his approach is battle-tested. I am thus not convinced this is a bug. However, the realignment/variant call is not obvious to the human eye - one would expect the indel instead. The variant seems like a clear heterozygous indel. I checked this [blog post](https://gatk.broadinstitute.org/hc/en-us/articles/360035891111-Expected-variant-at-a-specific-site-was-not-called): The bamout is as outlined above, the mapping + base quality seems fine (judging by IGV) and `--max-alternate-alleles` doesn't seem useful here (and indeed doesn't do anything to the result). I didn't got into kmer fiddling as suggested by the blog post. This is not a homopoly region. I also tested with 4.1.4.1 which only reports the deletion. The screenshot from above is from the 4.4.0.0 invocation. Here is the same situation for 4.1.4.1 (realignment is similar, `out.vcf` does not contain the insertion):. ![image](https://user-images.githubusercontent.com/58295931/226554045-0d9dd7e3-65ec-40ce-a6bd-74d73d4a2507.png). FYI, the variant lies on FBN1 / NM_000138.5 (rev strand). cDNA notation would be `NM_000138.5:c.4698_4701del` or `NM_000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8253:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8253,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). MuTect2 for the test case, but any caller using the Reference Bases annotation and calling bases near the end of chromosomes. ### Affected version(s). This occurs with the latest release (4.0.8.1) and not with the previous (4.0.7.0). It appears to be related to the addition of the Orientation Bias filter (#4895) and assessing sequence context:. https://github.com/broadinstitute/gatk/pull/4895/files#diff-07e3c8c33f865c5b32b362afe50cfd86R48. ### Description . When identifying variants near the end of chromosome boundaries, MuTect2 fails with:; ```; java.lang.StringIndexOutOfBoundsException: String index out of range: 369; at java.lang.String.substring(String.java:1963); at org.broadinstitute.hellbender.tools.walkers.annotator.ReferenceBases.annotate(ReferenceBases.java:48); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:270); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:176); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:212); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5130:229,release,release,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5130,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). ValidateVariants: `--fail-gvcf-on-overlap` / `-no-overlaps`. ### Affected version(s); - [x] Latest public release version: 4.2.6.1; - [ ] ~Latest master branch as of~ [did not test, but affected file hasn't changed since August 2021]. ### Description . If there are overlapping reference blocks when running ValidateVariants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:156,release,release,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es). VariantAnnotator ... but this is due to an old syntax update perhaps other docs in other tools are also affected. ### Affected version(s); - [X] Latest public release version [version?]; - [Presumptive] Latest master branch as of [date of test?]. ### Description . The argument ```--resource``` example(s) show a wrong syntax in regards to the location of the ""provider"" name ; ; #### Steps to reproduce; Google 'GATK VariantAnnotator'; the first or one of the first hits points to the current GATK doc on the tool. . #### Expected behavior. The example should read ```--resource:foo resource-file.vcf.gz```. #### Actual behavior. The example reads ```--resource foo:resource-file.vcf.gz```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8143:104,update,update,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8143,2,"['release', 'update']","['release', 'update']"
Deployability,## Bug Report. ### Affected tool(s) or class(es). `cnv_germline_cohort_workflow.wdl`. ### Affected version(s); - [x] Latest public release version [4.4.0.0]; - [x] Latest master branch as of [2023-04-14]. ### Description . cnv_germline_cohort_workflow.wdl currently outputs the following ; https://github.com/broadinstitute/gatk/blob/0374937bd7b152ecf1c2c922989371fcccedf184/scripts/cnv_wdl/germline/cnv_germline_cohort_workflow.wdl#L405. whereas the task that generates the corresponding result outputs `String`; https://github.com/broadinstitute/gatk/blob/0374937bd7b152ecf1c2c922989371fcccedf184/scripts/cnv_wdl/cnv_common_tasks.wdl#L297. #### Expected behavior. `cnv_germline_cohort_workflow.wdl` should output `Array[String]`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8290:131,release,release,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8290,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); - gatk/scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; - gatk/scripts/cnv_wdl/germline/cnv_getmline_cohort_workflow.wdl. ### Affected version(s); - **WDL** file from GATK latest release (4.2.5.0); - **GATK Docker** - latest (4.2.5.0). ### Description ; Accoridng to [GATK Germline CNV WDL instructions](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/README.md), I ran cnv_getmline_cohort_workflow.wdl and got data to run cnv_germline_case_workflow.wdl. (contig_ploidy_model_tar file and 40 gcnv_model_tars files). Then I tried to run cnv_germline_case_workflow.wdl with one sample and got an error: ; ```; java.lang.IllegalArgumentException: The number of input call shards must match the number of input model shards.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.validateArgum; ```. PostprocessGermlineCNVCalls only completes correctly if I use only one of the gcnv_model_tars files, but it only produces results for the iterval_list file that is included in the used gcnv_model_tars. #### Case mode files; [case.log](https://github.com/broadinstitute/gatk/files/8186658/case.log); [case-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186662/case-inputs.json.txt). #### Cohort mode files; [cohort.log](https://github.com/broadinstitute/gatk/files/8186665/cohort.log); [cohort-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186667/cohort-inputs.json.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7706:237,release,release,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7706,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); AddCommentsToBam. ### Affected version(s); - [x] Latest public release version [version?] GATK-4.0.10.1. ### Description ; I was trying to run AddCommentsToBam and with the -C flag, it was crashing when I had a colon in the string, so I had to delete it. #### Steps to reproduce; `gatk AddCommentsToBam -I=In.bam -O=Out.bam -C=""Bad: comment""`; `gatk AddCommentsToBam -I=In.bam -O=Out.bam -C=""Good comment""`. #### Expected behavior; A new BAM with the comment should be created. #### Actual behavior; I get this output: No value found for tagged argument: C=Bad: comment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5315:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5315,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); All Spark tools. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [2020-03-20]. ### Description ; Complains that the `driver-memory` is not a recognized argument.; Does not recognize these arg too; https://github.com/broadinstitute/gatk/blob/00f1e43402d9c8c195de383248099399f261e2cc/gatk#L425. #### Steps to reproduce; ```bash; gatk PrintReadsSpark -I <input.bam> -O <output.bam> \; -- \; --driver-memory 20g; ```. #### Expected behavior; NA; #### Actual behavior; NA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6515:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6515,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); AnalyzeCovariates . ### Affected version(s); - [x] Latest public release version [v4.1.4.0] [hash:cec850f20311f0686fcf88510bc44e529590d78bec7076a603132115943c09e6]. ### Description ; AnalyzeCovariates fails with ; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.4.0-local.jar AnalyzeCovariates -bqsr /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/IN-PM01004_rmd.recal.bam.recalTable -plots /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf; 23:15:29.581 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 19, 2020 11:15:30 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 23:15:30.435 INFO AnalyzeCovariates - ------------------------------------------------------------; 23:15:30.437 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.4.0; 23:15:30.437 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:15:30.438 INFO AnalyzeCovariates - Executing as shollizeck@papr-res-compute204.unix.petermac.org.au on Linux v3.10.0-1062.4.3.el7.x86_64 amd64; 23:15:30.438 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_212-8u212-b03-0ubuntu1.16.04.1-b03; 23:15:30.438 INFO AnalyzeCovariates - Start Date/Time: January 19, 2020 11:15:29 PM UTC; 23:15:30.439 INFO AnalyzeCovariates - ------------------------------------------------------------; 23:15:30.439 INFO AnalyzeCovariates - ------------------------------------------------------------; 23:15:30.439 INFO AnalyzeCovariates - HTSJDK Version: 2.20.3; 23:15:30.439 INFO AnalyzeCovariates - Picard Ve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6393:115,release,release,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6393,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); BaseRecalibrator, `BaseRecalibrationEngine.calculateKnownSites`. ### Affected version(s); - public release version [tested on >=4.1? no idea how to check]. ### Description ; When running BaseRecalibrator, if a read begins with an insertion and the KnownSites file contains an interval that begins at that position, the bases will not be skipped as GetReadCoordinateForReferenceCoordinate returns the read coordinate after the insertion. To properly handle this case, in the line https://github.com/broadinstitute/gatk/blob/9bca5119e996886ee85ef6c890eba79ec5d6cfb1/src/main/java/org/broadinstitute/hellbender/utils/recalibration/BaseRecalibrationEngine.java#L340 ReadUtils.ClippingTail.LEFT_TAIL should be changed to ReadUtils.ClippingTail.RIGHT_TAIL. Making this substitution would ensure that the coordinate returned is always the leftmost coordinate when the read begins with an insertion, the desired effect for the start of the interval. #### Steps to reproduce; Use an alignment with a read that begins with an insertion and a BED that specifies an interval that begins at that position. For example, alignment file:; ```; @HD VN:1.6 SO:coordinate; @SQ SN:ref LN:10; @RG ID:foo SM:bar PU:baz PL:ILLUMINA; r001 0 ref 2 40 6I4M * 0 0 AAAAAAAAAA IIIIIIIIII RG:Z:foo; ```; and ref:; ```; >ref; AAAAAAAAAA; ```. and BED file; ```; ref 0 1; ref 1 2; ref 2 3; ref 3 4; ref 4 5; ref 5 6; ref 6 7; ref 7 8; ref 8 9; ref 9 10; ```; Then run BaseRecalibrator and look at the output:; `gatk BaseRecalibrator -I aln.bam -R ref.fa --known-sites sites.bed.gz -O recal.txt`. #### Expected behavior; The output tables should be empty, since every site in our reference (bases 1-10 inclusive) should be skipped. #### Actual behavior; The output tables include the 6 inserted bases, and the cycle covariate values confirm they are the 6 leading inserted bases:; ```; ReadGroup QualityScore CovariateValue CovariateName EventType EmpiricalQuality Observations Errors",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6385:149,release,release,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6385,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Bug when this line is executed: https://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L147. Casued because attribute ""oneShotLogger"" is uninitialized. See line (https://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L42) and its missing initialization in the constructor method (https://github.com/broadinstitute/gatk/blob/9f77b1fddedb8e047948078b29ac9fbb70d005b0/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L65). ### Affected version(s); - [ ] Latest public release version [4.3.0.0]; - [ ] Latest master branch as of [12/01/2023]. ### Description ; I work as support for a HPC cluster and this bug has affected one of our users, so I won't be able to provide the exact specifics. Long story short, the user reports that for a high enough value of ploidy (20-50), they start getting null pointer exception errors. Here we can see an example of how they launch the program:. ```; gatk --java-options ""-Xmx4g"" HaplotypeCaller \; -I ${bamfile} \; -R ${reference} \; -O ${outpath}/${sample_id}.ploidy_${SLURM_ARRAY_TASK_ID}.output.g.vcf.gz \; -RF MappingQualityReadFilter \; --minimum-mapping-quality 10 \; --max-alternate-alleles 10 \; --max-genotype-count 75000 \; --dont-use-soft-clipped-bases true \; -ploidy ${SLURM_ARRAY_TASK_ID} \; -ERC GVCF; ```. And this is the stack trace obtained when it fails:. ```; java.lang.NullPointerException: Cannot invoke ""org.broadinstitute.hellbender.utils.logging.OneShotLogger.warn(String)"" because ""this.oneShotLogger"" is null; at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:147); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCall",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:796,release,release,796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:102,release,release,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,4,"['continuous', 'release']","['continuous', 'release', 'release-notes']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6727:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6865:115,release,release,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - GATK 4.1.8.1 (Latest release as of 08/24/20). ### Description ; User is running CombineGVCFs and getting a java error java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52). This issue was discussed at the GATK Office Hours meeting. ### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect wheth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - [X] Latest public release version [4.2.5.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; The auto-generated wdl for CombineGVCFs on dockstore won't work because it doesn't have any inputs for the indices of the input vcfs. This means GATK cannot access the vcf indices because they never get localized, so the workflow fails. . #### Steps to reproduce; Take any vcfs and run them through the workflow to get an error about missing indices. . #### Expected behavior; Including the indices in the task inputs will allow them to get localized along with the vcfs so GATK can operate normally. . #### Actual behavior; You get an error saying it requires index files to proceed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7681:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7681,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); CountReadsSpark. ### Affected version(s); gatk-4.0.12.0. ### Description ; Reading cram generates the following error when running CountReadsSpark on yarn. . ```; ./gatk-4.0.12.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:13:11.050 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:13:11.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:625,install,install,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['install'],['install']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); CreateReadCountPanelOfNormals. ### Affected version(s); - [ ] Latest public release version [4.1.0.0]. ### Description ; When you run it on a single machine, it trys to use _hadoop_ and failed. ```; $ java -jar ../gatk-package-4.1.0.0-local.jar CreateReadCountPanelOfNormals --input in.counts.hdf5 --output out.pon.hdf5; 12:33:52.103 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:126,release,release,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] v.4.1.3.0 using us.gcr.io/broad-gatk/gatk:4.1.3.0; - [ ] 11/22 failed in Terra. ### Description ; There is a bug in the logic with how Funcotator is handling this variant. It is a variant after ; chr14:24655355 ; **Stacktrace**; <img width=""1248"" alt=""Screen Shot 2019-11-27 at 4 37 31 PM"" src=""https://user-images.githubusercontent.com/13475639/69761316-026f2a00-1135-11ea-9b50-491f5b22971c.png"">. Jonn has the input files, log file, and WDL. #### Steps to reproduce; To reproduce this issue, all the inputs and full pipeline are listed in this[ Zendesk ticket 3847](https://broadinstitute.zendesk.com/agent/tickets/3847). Contact Tiffany for access. #### Expected behavior; The tool should handle this situation more gracefully?. #### Actual behavior; It fails with a java.lang.StringIndexOutOfBoundsException: String index out of range: 776. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289:611,pipeline,pipeline,611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289,1,['pipeline'],['pipeline']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [4.2.1.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When processing a VCF with tumor and matched normal into a MAF, the `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields are not populated. #### Steps to reproduce. `gatk --java-options -Xmx2048m Funcotator --data-sources-path /cromwell_root/datasources_dir --ref-version hg38 --output-file-format MAF -R /cromwell_root/getzlab-workflows-reference_files-oa/hg38/gdc/GRCh38.d1.vd1.fa -V` [`C3N-02729.vcf.gz`](https://github.com/broadinstitute/gatk/files/6977700/C3N-02729.vcf.gz) `-O C3N-02729.maf --annotation-default normal_barcode:C3N-02729_N --annotation-default tumor_barcode:C3N-02729_T --annotation-default Center:broadinstitute.org --annotation-default source:Unknown --transcript-selection-mode BEST_EFFECT`. (NOTE: reference files available at `gs://getzlab-workflows-reference_files-oa/hg38/gdc`). #### Expected behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields should be populated as appropriate based on the `GT` field for the matched normal in the VCF. #### Actual behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` are populated with `__UNKNOWN__`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7408:107,release,release,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7408,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Funcotator appears to output an unnecessary extra tab at the end of each line. The change appears to have happened between gatk 4.1.4.0 and 4.1.6.0. #### Expected behavior; Output correct number of tabs corresponding to the number of column headers. #### Actual behavior; Outputs an extra tab.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6693:107,release,release,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6693,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK 4.1.0.0 AnalyzeCovariates. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; The csv produced by AnalyzeCovariates is invalid. It doesn't escape commas in fields, resulting in an error in the R script. #### Steps to reproduce; If you have a comma in the readgroup in a BAM, this will happen. #### Expected behavior; It should produce valid csv files, and then be able to properly produce the plots. #### Actual behavior; Commas in read group names result in malformed (unescaped) csv where it's impossible to parse fields properly. This results in the following R script error:; ```; Error in read.table(file = file, header = header, sep = sep, quote = quote, :; more columns than column names; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5739:127,release,release,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5739,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK GenotypeGVCFs. ### Affected version(s); GATK 4.2.2.0. ### Description . When running GenotypeGVCFs,; 1. multiple warnings of **No valid combination operation found for INFO field** ; 2. AS_VarDP warnings:; ```; WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; ```. 3. java.lang.NullPointerException occurs. ; 4. No variants output into VCF. This is the log:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:1-105581 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-1-105581.vcf.gz; 00:05:54.259 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 00:05:54.319 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 12:05:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:05:54.582 INFO GenotypeGVCFs - -------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:985,install,install,985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['install'],['install']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotype caller. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. The Genome Analysis Toolkit (GATK) v4.1.0.0; HTSJDK Version: 2.18.2; Picard Version: 2.18.25. ### Description ; HaplotypeCaller is outputting variants which have a no-call as the ALT, which breaks a bunch of downstream tools, this is new behavior in 4.1, AFAICT. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	s1564	s1741	s1851	s1852	s1862	s1901	s1912	s1971	s2017	s2021	s2026	s2056	s2100	s2102	s2104	s2122	s2124	s2151	s2157; 1	937796	.	T	.	179.65	.	AN=38;DP=31;MMQ=60;MQ=60.00	GT:AD:DP	0/0:0:0	0/0:0:0	0/0:4:4	0/0:0:0	0/0:1:1	0/0:1:1	0/0:0:0	0/0:0:0	0/0:2:2	0/0:0:0	0/0:1:1	0/0:3:3	0/0:1:1	0/0:8:8	0/0:1:1	0/0:0:0	0/0:2:2	0/0:7:7	0/0:0:0; ```. #### Steps to reproduce; I'm not doing anything special, so I suspect these variants should exist in other projects as well. I'm doing batch calling on several samples simultaneously; an example:. ```; unset JAVA_HOME && export PATH=/home/rdk4/local/share/bcbio/anaconda/bin:$PATH && gatk --java-options '-Xms4g -Xmx5000m -XX:+UseSerialGC -Djava.io.tmpdir=/n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/bcbiotx/tmpTSg0hJ' HaplotypeCaller -R /n/app/bcbio/dev/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --annotation MappingQualityRankSumTest --annotation MappingQualityZero --annotation QualByDepth --annotation ReadPosRankSumTest --annotation RMSMappingQuality --annotation BaseQualityRankSumTest --annotation FisherStrand --annotation MappingQuality --annotation DepthPerAlleleBySample --annotation Coverage -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2017/s2017-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2056/s2056-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2122/s2122-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5650:118,release,release,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK installation. ### Affected version(s); - [x] Latest public release version 4.4.0.0; - [x] Latest master branch as of [11.12.2023]. ### Description ; Latest `conda` versions cannot install pip packages. #### Steps to reproduce; Create `gatk` `env` with `conda` version equal or newer than `23.10`. #### Expected behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.9.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: - Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.vn0sukco.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=8095375e139fa0729c7a41c8f5e8a43281fc1b6859b6d3951d3bfba7296ee349; Stored in directory: /tmp/pip-ephem-wheel-cache-ecx6e_m0/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. #### Actual behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transactio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:55,install,installation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,5,"['Install', 'install', 'release']","['Installing', 'install', 'installation', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK v4.1.4.0 using FilterMutectCalls. ### Affected version(s); - [x] Latest public release version `4.1.4.0` installed from conda release `gatk4-4.1.4.0-1`; - [ ] Latest master branch as of [date of test?]. ### Description ; This issue reports the same error that is reported in #6237, but on the latest release, and in a mitochondrial calling setting. My command is:; ```bash; gatk FilterMutectCalls -V MT.vcf.gz\; -R human_g1k_v37.main.fasta\; -O MT.filtered.vcf.gz\; --stats MT.vcf.gz.stats\; --mitochondria-mode; ```. I get the following output to STDERR:; ```; 11:15:57.152 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 07, 2019 11:15:57 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:15:57.328 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.328 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.4.0; 11:15:57.328 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:15:57.328 INFO FilterMutectCalls - Executing as warkre@fuji on Linux v4.9.0-9-amd64 amd64; 11:15:57.328 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 11:15:57.329 INFO FilterMutectCalls - Start Date/Time: November 7, 2019 11:15:57 AM CET; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Version: 2.20.3; 11:15:57.329 INFO FilterMutectCalls - Picard Version: 2.21.1; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:134,release,release,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,4,"['install', 'release']","['installed', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GATK version: 4.1.1.0-VariantRecalibrator-ApplyVQSR. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I am doing VQSR with gatk-VariantRecalibrator-ApplyVQSR, and i got some mistakes in the log fileÔºå and i dont konw what was wrong with my script,. #### Steps to reproduce; Below are my complete scripts:; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6948:148,release,release,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GatherTranches. ### Affected version(s); Latest public release version 4.2.6.1. ### Description ; I ran `VariantRecalibrator` in scattered (using intervals) mode and now trying to gather the scattered tranches into a single file but somehow the number of novel variants is < 0. This is the exact error:; `Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320`. #### Steps to reproduce; ```; inputs_cmdl = ' '.join([f'--input {t}' for t in tranches]); j.command(; f""""""set -euo pipefail; gatk --java-options -Xms6g \\; GatherTranches \\; --mode SNP \\; {inputs_cmdl} \\; --output {j.out_tranches}""""""; ); ```. #### Expected behavior; Gathered scattered VQSLOD tranches into a single file. #### Actual behavior; Fails because of what seems like an integer overflow according to @ldgauthier; ```; org.broadinstitute.hellbender.exceptions.GATKException: Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.Tranche.<init>(Tranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.<init>(VQSLODTranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:205); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:139); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GatherTranches.doWork(GatherTranches.java:80); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7859:105,release,release,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7859,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport . ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of Apr 4, 2022. ### Description ; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found. #### Steps to reproduce; Run the first test case for GnarlyGenotyperIntergrationTest::testUsingGenomicsDB() on the branch https://github.com/broadinstitute/gatk/pull/7750. The test contains the argument `--intervals chrX:1000000-5000000`, but I'm not sure why that would be an issue. The tool runs fine and the output is valid. #### Expected behavior; An informative warning or a single output of the existing warning. #### Actual behavior; Excessive logging",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7751:114,release,release,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7751,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [ ] Latest public release version [4.2.5.0]. ### Description ; My gVCF files are block compressed and indexed, but the files have the file extension "".gvcf.gz"" rather than "".vcf.gz"". When I run `GenomicsDBImport` with `--bypass-feature-reader`, the "".gvcf.gz"" file cannot be recognized as a block compressed vcf file. The code of `GenomicsDBImport` validates if input is block compressed by checking if the file extension is "".vcf.gz"". ```; private static void assertVariantFileIsCompressedAndIndexed(final Path path) {; if (!path.toString().toLowerCase().endsWith(FileExtensions.COMPRESSED_VCF)) {; throw new UserException(""Input variant files must be block compressed vcfs when using "" +; BYPASS_FEATURE_READER + "", but "" + path.toString() + "" does not appear to be"");; }; Path indexPath = path.resolveSibling(path.getFileName() + FileExtensions.COMPRESSED_VCF_INDEX);; IOUtils.assertFileIsReadable(indexPath);; }; ```. I understand that this is an issue on my side because I did not name my gVCF files with the standard extension "".vcf.gz"". Is it possible to make this check less stringent in a future release? Maybe make any "".gz""/"".bgz"" file acceptable, or check the "".tbi"" index file to identify block compression (existing index typically means the file is block compressed and indexed). . Thank you. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7691:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7691,2,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [ ] Public release version 4.1.4.1 . ### Description ; Running GenomicsDBImport on an HPC cluster using SLURM, admin mentioned that the jobs are writing inefficiently to shared storage (@spikebike will follow up with HPC specifics and logs). . #### Steps to reproduce; ```; Using GATK jar /share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -Xms60g -jar /share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GenomicsDBImport --genomicsdb-workspace-path data/interim/combined_database_bpres/0004 --batch-size 50 --reader-threads 6 --sample-name-map data/processed/sample_map --intervals data/processed/scattered_intervals/0004-scattered.intervals --tmp-dir /scratch/sdturner/genomicsdbimport/0004; ```. #### Expected behavior; My understanding is that it may be more efficient to use a small buffer and write the final database in full. . #### Actual behavior; Again my (limited) understanding is that the tool is writing output multiple times and throwing out all but the last write. Here is an example of a log for a 2.6 Mb region and 295 samples: ; ; ```; 07:24:39.198 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 28, 2020 7:24:39 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:24:39.616 INFO GenomicsDBImport - ------------------------------------------------------------; 07:24:39.617 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.4.1; 07:24:39.617 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6487:106,release,release,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6487,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); -4.1.8.1, 4.1.6.0. ### Description ; Two users are running GenomicsDBImport and getting a Duplicate Sample Name Error and both have reported that they do not have duplicate sample names in their map files. @nalinigans @mlathara does this look like a user issue or bug with GenomicsDBImport?. ### First Example; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:704,update,update-workspace-path,704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['update'],['update-workspace-path']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs 4.0.0.12. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I've run into a weird case where GenotypeGVCFs is doing something unexpected. I have a gVCF with the following entry in it:. ```; chr11 6637739 . ATTTTT A,AT,ATT,ATTT,ATTTT,ATTTTTT,<NON_REF> 565.73 . BaseQRankSum=-0.014;ClippingRankSum=0.508;DP=94;ExcessHet=3.0103;MLEAC=0,0,0,1,0,0,0;MLEAF=0,0,0,0.5,0,0,0;MQRankSum=0;RAW_MQandDP=338400,94;REF_BASES=GCCGGCCTGGATTTTTTTTTT;ReadPosRankSum=-0.812 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 0/4:9,3,3,11,15,8,3,0:52:8,2,2,8,12,6,3,0:1,1,1,3,3,2,0,0:56:603,504,1526,335,1171,1118,56,661,640,608,0,362,313,183,335,336,500,389,187,171,527,655,864,622,277,169,466,1026,597,1101,953,645,465,625,861,1133:8,1,33,10; ```. It's a messy site for sure, an indel in a long homopolymer-T, but I think that's a separate issue. If I run the following on that gVCF:. ```; gatk GenotypeGVCFs \; -R hg19.fa -V test.g.vcf -O test.vcf \; -A ClippingRankSumTest -A Coverage -A ExcessHet -A FisherStrand \; -A MappingQualityRankSumTest -A OxoGReadCounts -A QualByDepth -A ReadPosRankSumTest \; -A ReferenceBases -A RMSMappingQuality -A StrandOddsRatio -A TandemRepeat \; -L chr11:6637730-6637750 \; -stand-call-conf 18.0 \; ```. then I get the following output to the VCF just like I'd expect:. ```; chr11 6637739 . ATT A 565.73 . AC=1;AF=0.500;AN=2;BaseQRankSum=-1.400e-02;ClippingRankSum=0.508;DP=94;ExcessHet=3.0103;FS=1.779;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=23.57;REF_BASES=GCCGGCCTGGATTTTTTTTTT;RPA=15,13;RU=T;ReadPosRankSum=-8.120e-01;SOR=0.386;STR GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:9,15:52:8,2,2,8,12,6,3,0:1,1,1,3,3,2,0,0:99:603,0,335; ```. QUAL is unchanged since I'm genotyping a single-sample gVCF. However, if I raise my `-stand-call-conf` threshold to 19.0, GenotypeGVCFs no longer outputs any variants. 565.73 >> 19.0, so I'm confused as to why that var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5793:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs with --keep-combined-raw-annotations. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of (not tested). ### Description ; @ldgauthier was kind enough to introduce the `--keep-combined-raw-annotations` option for us after the discussion in issue #5698, and we've been using it extensively. We recently noticed a problem that affects a small fraction of variants though. We're noticing this with `AS_SB_TABLE` but it probably applies to all annotations that are per-allele or per-alt allele. The problem is that when GenotypeGVCFs runs it may chose to output only a subset of the alleles present in the gVCF. When it does this it does not appear to update the annotations to remove the values for the removed alleles. This results in annotations with more values than there are alleles, and no safe/predictable way to interpret those annotations since you don't know the original ordering of alleles and which ones were removed when looking at the resulting VCF. This is happening, in my case, primarily at homopolymer sites and occasionally at STRs with larger repeat units. I've attached a zip file - [AS_SB_TABLE_bug.zip](https://github.com/broadinstitute/gatk/files/3357101/AS_SB_TABLE_bug.zip) - which contains a one-record gVCF, the command to generate the VCF and the resulting VCF, which should be sufficient to demonstrate the problem and reproduce it. Here's what an offending variant looks like:. ```; chr1 100366446 . GTT G 562.64 . AC=1;AF=0.500;AN=2;AS_SB_TABLE=19,6|16,6|4,0|2,2|1,1;...;REF_BASES=ATGTTTTTTTGTTTTTTTTTT;RPA=13,11;RU=T;ReadPosRankSum=-1.296e+00;SOR=0.534;STR GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:25,22:57:19,16:4,4:99:570,0,819; ```. #### Steps to reproduce; See attached zip file. #### Expected behavior; All per-allele and per-alt-allele annotations should be subsetted to only the values for the alleles that are output in the resulting VCF. #### Actual behavi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6029:147,release,release,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6029,2,"['release', 'update']","['release', 'update']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [X] Latest public release version. ### Description ; GenotypeGVCFs outputs samples (individuals) with no reads (depth) as reference genotypes: ; 0/0:0,0:0:0:.:.:0,0,0. or with very small number of reads, like 1:; 0/0:1,0:1:3:.:.:0,3,31. I believe that this issue was also reported here:; https://gatk.broadinstitute.org/hc/en-us/community/posts/4476803114779-GenotypeGVCFs-Output-no-call-as-reference-genotypes. #### Steps to reproduce; I have followed all GATK steps with default settings. . #### Expected behavior; I believe that samples with no reads (or very small number of reads) should be reported as missing, like:; ./. Thank you for your help,; Marcin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7792:110,release,release,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7792,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; GenotypeGVCFs won't joint call DRAGEN mitochondrial data because of the DRAGEN somatic output format. We should be able to use the DRAGEN SQ in place of Mutect2's TLOD (see line 279 in GenotypeGVCFsEngine); Note that DRAGEN SQ is a Phred-scaled double. #### Steps to reproduce; DRAGEN somatic GVCF entries from version 3.8.4 look like:; chrM 1 . G <NON_REF> . weak_evidence END=1 GT:AD:DP:SQ:MIN_DP 0/0:112,1579:1691:0:1691. Run GenotypeGVCFs with -V to a file like that (reference GenotypeGVCFsIntegrationTest::testGenotypingForSomaticGVCFs() for more details); Must include `--input-is-somatic` as of now. #### Expected behavior; The task should run to completion, calculating a site quality store using the DRAGEN SQ value. #### Actual behavior; Error from AlleleFrequencyCalculator about not having PLs or GQ.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7840:110,release,release,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7840,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); 4.6.0.0. ### Description ; When I was doing GenotypeGVCFs from GenomicsDB of 420 samples, the process interrupted due to significant memory issues. This process was eating up memory continuously. In 4.5.0.0, I did same process, and I confirmed it works fine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918:272,continuous,continuously,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918,1,['continuous'],['continuously']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller. ### Affected version(s); - [x] Latest public release version [4.5.0.0]; - [x] Latest master branch as of [14.12.2023]. ### Description ; Very different results after update from 4.4.0.0 to 4.5.0.0. We updated test results after https://github.com/broadinstitute/gatk/issues/8619, but now we see big changes (especially in `segments` file). #### Steps to reproduce; Command list:; ```; /soft/gatk-4.5.0.0/gatk PreprocessIntervals -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa --padding 0 -L chr1:10000-35000 -L chr22:198477-20003000 -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list. /soft/gatk-4.5.0.0/gatk AnnotateIntervals -L /outputs/gatk_intervals.interval_list -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list.annotated.tsv. /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_normal_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_normal_alignment.bam.counts.hdf5; /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_tumor_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk DetermineGermlineContigPloidy -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --contig-ploidy-priors /outputs/a_valid_ploidy_priors_table.tsv.copy.tsv --output /outputs/COHORT_runDir --output-prefix COHORT --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk GermlineCNVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gatk_intervals.interval_list.annotated.tsv --contig-ploidy-calls /outputs/COHORT_run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628:114,release,release,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628,3,"['release', 'update']","['release', 'update', 'updated']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); GnarlyGenotyper. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]; - [x] 4.2.3 - snapshot -> https://console.cloud.google.com/gcr/images/broad-dsde-methods/US/gatk_subset_dragen_allele_frac@sha256:f5e93bda2278f1c999bd9def027c6851eeb098736b47a93469c524863b46c21f/details. ### Description ; WDL joint genotyping using GnarlyGenotyper after ReblockGVCF (fixed on the snapshot above). #### Steps to reproduce; Joint Genotyper wdl pipeline with ""GatkJointGenotyping.useGnarlyGenotyper"": true , **samples from DRAGEN 3.8+**. #### Expected behavior; Complete the pipeline. #### Actual behavior; Failing with diploid error on Sexual Chromosomes. Hello again everyone.; First of all, thank you¬†@ldgauthier¬†to send us that snapshot docker. It kind of solved reblock problem. As feedback here, I tried with the newest GATK version (4.2.5) as it modified ReblockGVCF, but it didn`t work.; Anyway, I have another issue here...; While I was using only one or few chromosomes, the pipeline with reblock + gnarly was working fine. Once I added all chromosomes I started to get this type of error (GnarlyGenotyper):. ```; A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA18668 has ploidy 1 at position chrY:2789135. or. A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA14734 has ploidy 1 at position chrX:36667858. ```; I checked every failed log, and it's all related to the sexual chromosomes. Any thought/tip about that? ; ps.: From chr1 to chr22 it worked fine!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690,4,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller --output-mode EMIT_ALL_SITES. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm trying to generate a VCF (not a gVCF) that contains calls spanning all the sites in my regions. Each region is small, and is more or less equivalent to a single variant. Ideally I'd use `GENOTYPE_GIVEN_ALLELES`, but I don't know the alleles, and in some cases the variant location is approximate (e.g. somewhere in _this_ 10bp window). I've been trying to use HaplotypeCaller to produce a VCF that contains calls covering my entire set of regions, but nothing seems to work. I started with just `--output-mode` and eventually ended up with:. ```; gatk HaplotypeCaller \; -R ref.fasta \; -L regions.interval_list \; --disable-optimizations \; --force-active \; --output-mode EMIT_ALL_SITES \; -I my.bam \; -O my.vcf.gz; ```. This does output considerably more records, including a lot of hom-ref records, but still nowhere near to the full set of bases within my regions. E.g. in one test this emits variants spanning 3,468bp which is way better than the ~120bp I get without those options, but nowhere near the 293,570bp with the regions I'm supplying. It would be great if `--output-mode EMIT_ALL_SITES` did as the documentation described, but if that's not possible, then perhaps that mode should simply be removed?. #### Steps to reproduce; Try calling a BAM file with HaplotypeCaller with a 100-1000bp region with `--output-mode EMIT_ALL_SITES`. #### Expected behavior; VCF should contain records spanning the entire input region. #### Actual behavior; VCF contains a minority of sites from the region.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6059:141,release,release,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6059,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller . ### Affected version(s); - [x] Latest public release version [4.1.6.0]; - [ ] Latest master branch (not tested). ### Description ; I have a sample that has a slightly complicated event in it that is getting miscalled. The easiest way to see it is probably with an IGV screenshot:. ![variant](https://user-images.githubusercontent.com/1609210/78403555-c6077b00-75b9-11ea-96f3-8f9ca6c25e86.png). BWA aligns the reads with a 7bp deletion followed by 2 mismatches, though am inclined to think of it as a 9bp deletion coupled with a 2bp insertion (or a swap of 9bp of reference for 2bp of novel sequence). The original alignments are in the top half of the IGV view. The bottom is the assembly BAM from running the HaplotypeCaller. From what I see the assembly is getting it right. . But the problem is that the event extraction/genotyping goes wrong. I've run it two ways. If I run to generate a called VCF directly using:. ```; gatk HaplotypeCaller \; --input snippet.bam \; --output snippet.vcf \; -R hg19/hg19.fa \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. Then I get only a single variant reported in the region (the 9bp deletion):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr1 68896832 . CTTTAGTTTT C 1597.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.000;DP=122;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=14.52;ReadPosRankSum=1.341;SOR=0.350 GT:AD:DP:GQ:PL 0/1:67,43:110:99:1605,0,2683; ```. If i run to generate a gvcf then things get more interesting:. ```; gatk HaplotypeCaller \; --input snippet.bam \; --output snippet.g.vcf \; -R hg19/hg19.fa \; -ERC GVCF \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. yields:. ```; #CHROM POS ID REF A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6538:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6538,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1 with -ERC GVCF. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; It would appear that variants covered by a spanning deletion are not output with phasing information even when surrounded by phased variants on either side. Since one of the alleles is covered by an upstream deletion phase is known, but the genotype itself is not phased and no phase set is attached. The following is a cut-down example from a gVCF:. ```; chr6 51618169 . GT G,<NON_REF> 948.60 . DP=94 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:32,39,0:71:3,4,0:29,35,0:99:0|1:51618169_GT_G:956,0,808,1054,926,1980:51618169:3,29,4,35; chr6 51618170 . T *,G,<NON_REF> 776.01 . DP=92 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:2,39,30,0:71:1,4,2,0:1,35,28,0:99:3533,786,723,1141,0,956,2837,916,1206,2757:1,1,6,63; chr6 51618171 . G <NON_REF> . . END=51618173 GT:DP:GQ:MIN_DP:PL 0/0:90:99:90:0,120,1800; chr6 51618174 . A G,<NON_REF> 1001.60 . DP=89 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:33,41,0:74:3,4,0:30,37,0:99:0|1:51618169_GT_G:1009,0,803,1108,926,2034:51618169:3,30,4,37; ```. You can see that the SNP at 51618170 is flanked by phased variants at 51618169 and 51618174, but is output with unphased genotype and no `PS` (or `PID/PGT`). I'm not entirely sure if this is on purpose for some reason I don't understand, or simply an edge case in the phasing code that's handled incorrectly. #### Steps to reproduce; Run HC on reads with three variants, starting with a deletion, a variant spanned by the deletion and a variant just beyond the deletion. FWIW I've requested permission to share an example case from real data and am awaiting an answer. #### Expected behavior; I think the spanned variant should be output with phasing information, e.g. in the above case I would expect (abbreviated):. ```; chr6 51618169 . GT G,<NON_REF> ... GT:DP:PS 0|1:71:51618169; chr6 51618170 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651:131,release,release,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1.1.0. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch as of 3/31/2019. ### Description ; It looks like PR #5840 did a lot of refactoring to the way F1R2/F2R1 annotations are computed. Along the way it looks like `OxoGReadCounts` was renamed to `OrientationBiasReadCounts`. This is, unfortunately for some, a non-backwards compatible change as any pipeline that uses `-A OxoGReadCounts` will now fail. I'm not sure if there's a deprecation mechanism for annotations that would inform users of this, and I'm not sure there's a whole lot to be done at this point. I'm logging this issue mainly so anyone else who runs into this will find the answer quickly. Might be nice to add a line to the 4.1.1.0 release notes though noting this change.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5848:120,release,release,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848,3,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller `--annotation OrientationBiasReadCounts`. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]; - [ ] 4.2.2.0. ### Description; When specifying OrientationBiasReadCounts, HaplotypeCaller adds the description of F1R2 and F2R1 to the header, but does not calculate them. This was observed in GATK 4.2.2.0 and also in a test with 4.3.0.0 (the latest at the moment of this issue).; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ```. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT sample; 13 32911888 . A G 177.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.086;DP=21;ExcessHet=3.0103;FS=1.719;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=8.46;ReadPosRankSum=0.475;SOR=0.368 GT:AD:DP:GQ:PL 0/1:13,8:21:99:185,0,339; 13 32913055 . A G 402.06 . AC=2;AF=1.00;AN=2;DP=15;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=26.80;SOR=1.112 GT:AD:DP:GQ:PL 1/1:0,15:15:45:416,45,0; 13 32915005 . G C 378.06 . AC=2;AF=1.00;AN=2;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.08;SOR=1.179 GT:AD:DP:GQ:PL 1/1:0,13:13:39:392,39,0; 13 32929232 . A G 168.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=1.335;DP=16;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=15.33;ReadPosRankSum=-1.442;SOR=0.446 GT:AD:DP:GQ:PL 0/1:5,6:11:99:176,0,121; 13 32929387 . T C 209.02 . AC=2;AF=1.00;AN=2;DP=7;ExcessHet=3.0103;FS=0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:153,release,release,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller when emitting physical phasing. ### Affected version(s); - [x] Latest public release version [4.1.4.1]; - [ ] Latest master branch as of [n/a]. ### Description ; When there are three SNPs in close proximity with the first having a homozygous-alt genotype and the other two being hets that are in trans, the GATK incorrectly outputs genotypes and phasing indicating they are in cis. I haven't tested more broadly (e.g. with > 3 variants or with indels etc.) but my suspicion is that it is to do with the first variant in the phase set being homozygous. This was seen happening on real data from a real sample, but I have also been able to reproduce this with synthetic test data that I can attach here. #### Steps to reproduce; I've attached [phasing.zip](https://github.com/broadinstitute/gatk/files/4237216/phasing.zip) to this issue. It contains a BAM file of synthetic data where I've introduced two variant haplotypes at 50 locations each separated by about 1000 bases. My goal in doing this was just to have a number of different sequence contexts and variant alleles in case that affected anything. It also contains the resulting VCF from running this GATK command using 4.1.4.1:. ```; gatk HaplotypeCaller -I phasing.bam -O phasing.g.vcf -ERC GVCF \; -R hg19.fasta -L chr2:179390700-179672150; ```. While the BAM clearly shows the two hets as in trans with one another:; ![hom_with_in_trans_hets](https://user-images.githubusercontent.com/1609210/75055826-edcfd300-5492-11ea-8bb7-b3c492140797.png). The resulting variant calls are given as in-cis:. ```; chr2 179393825 . C A,<NON_REF> 2686.03 . DP=60;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;RAW_MQandDP=216000,60 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,60,0:60:99:0|1:179393825_C_A:2700,181,0,2700,181,2700:179393825:0,0,60,0; chr2 179393826 . T <NON_REF> . . END=179393826 GT:DP:GQ:MIN_DP:PL 0/0:60:99:60:0,120,1800; chr2 179393827 . T G,<NON_REF> 1386.60 . BaseQRankSum=0.000;DP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6463:143,release,release,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6463,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller with `--max-mnp-distance` filter. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; I think there's a problem with the StrandOddsRatio (SOR) annotation and the `--map-mnp-distance` flag. I'm looking at a small region of NA24143 (one of the GIAB samples). There's a pair of SNPs in very close proximity. When called without the MNP output I get a pair of variants as follows (some info removed for clarity), coordinates are HG19:. ```; chr4 5743509 . C T 5903.03 . FS=0.000;QD=25.36;SOR=9.825 GT:AD:DP:GQ:PL 1/1:0,135:135:99:5917,406,0; chr4 5743512 . T C 2766.60 . FS=0.000;QD=21.12;SOR=0.983 GT:AD:DP:GQ:PL 0/1:57,74:131:99:2774,0,2060; ```. I'm trying to get permission to share the BAM over this region, but the key information is that every single read that spans or is in proximity to these variants is on the R strand. There is zero F strand coverage. This seems reasonable. It's a bit odd to me that the first SNP which is hom-var has a SOR value of 9.825, but it's homozygous so it's more or less irrelevant. Looking at the code, I think the problem here is that the code avoids divide-by-zero errors by adding pseudo-counts of `1.0` to the table, which for homozygous variants with no coverage on one strand creates a weird situation. I think it would be better to just detect if _all_ coverage is on one strand and short-circuit the calculation, but I digress. The real problem comes when running with `--max-mnp-distance 5`. Then I get this single variant:. ```; chr4 5743509 . CTAT TTAC,TTAT 5506.10 . FS=0.000;QD=25.36;SOR=9.750 GT:AD:DP:GQ:PL 1/2:0,74,56:130:99:5523,2213,2060,3016,0,2774; ```. Now I have a het variant with an SOR of 9.75. This seems really wrong to me - note how FS is 0.0. Again all coverage of all alleles is on one strand. And the het SNP that forms part of this MNP had an SOR of 0.983 when called independen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5698:145,release,release,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected [Version 4.1.5.0](https://github.com/broadinstitute/gatk/tree/4.1.5.0); - [GATK 4.1.5.0 ] public release version . ### Description ; 1. miscalled known germline MSH2 c.942+3A>T in sample1 (bam file in the zip file attached); 2. miscalled known germline DICER1 c.4206+9G>T in sample2 (bam file in the zip file attached). #### Steps to reproduce; The command used was. ```; java -Djava.io.tmpdir='' -jar gatk-4.1.5.0/gatk-package-4.1.5.0-local.jar HaplotypeCaller \; -R human_g1k_v37_fasta \; -L ROI.bed \; --dbsnp dbsnp_138.b37.vcf.gz \; -I sample1.bam \; -O sample1.4.1.5.0.gvcf.gz \; -ERC GVCF \; --native-pair-hmm-threads 16 \; --interval-padding 100 \; --min-base-quality-score 20 \; -bamout sample1.4.1.5.0.bamout.bam \; --minimum-mapping-quality 20; ```; The interval list file `ROI.bed` and the two bam files `sample1.bam` and `sample2.bam` are attached. Also attached are the gvcf files and bamout files we generated. . #### Expected behavior; There are two known germline variants in the two bam files. - **Sample 1**. miscalled germline MSH2 c.942+3A>T, rs193922376 in MSH2, NM_000251.1; intron 5 c.942+3A>T, heterozygous; chr2:47,641,560 A>T. ![Sample 1 bamout ](https://user-images.githubusercontent.com/56843518/77380922-e41be280-6d52-11ea-981f-140e719bece6.png). A screen shot of the variant loci in the bamout bam generated by HaplotypeCaller is provided above. Even though the variant was observed in the bam file, it was not reported by HaplotypeCaller. It seems that the variant was called at loci chr2:47641562 instead, as shown in the gvcf below; ```; C02ZC340LVDM:outputs_bamout xxx$ grep 47641562 sample1.4.1.5.0.gvcf; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT; 2 47641562 . A T,<NON_REF> 1044.64 . BaseQRankSum=0.829;DP=100;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.114;RAW_MQandDP=354425,100;ReadPosRankSum=0.692 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:46,48,6:100:99:0|1:47641559_TAA_T:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6521:177,release,release,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6521,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - Latest public release version [4.2.5.0]. ### Description . #### Steps to reproduce; Specify `--mate-too-distant-length` parameter. #### Expected behavior; Use specified value to filter paired-end reads. #### Actual behavior; Java exception:. ```; Using GATK jar /home/rwilton/tools/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/rwilton/tools/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar HaplotypeCaller; --reference /datascope/rwilton/scratch/GATK/GRCh38/chr14.fna; --intervals chr14; --emit-ref-confidence GVCF; --sample-name HG002; --smith-waterman FASTEST_AVAILABLE; --native-pair-hmm-threads 48; --read-filter MateDistantReadFilter; --mate-too-distant-length 1500; --minimum-mapping-quality 10; --mapping-quality-threshold-for-genotyping 10; --input full.chr14.bam; --output vcf1/full.chr14.g.vcf.gz; org.broadinstitute.barclay.argparser.CommandLineException$ShouldNeverReachHereException: Couldn't set field value for mateTooDistantLength in org.broadinstitute.hellbender.engine.filters.MateDistantReadFilter@55fdf7f9 with value 1500.; at org.broadinstitute.barclay.argparser.NamedArgumentDefinition.setArgumentValue(NamedArgumentDefinition.java:680); at org.broadinstitute.barclay.argparser.NamedArgumentDefinition.setScalarValue(NamedArgumentDefinition.java:380); at org.broadinstitute.barclay.argparser.NamedArgumentDefinition.setArgumentValues(NamedArgumentDefinition.java:293); at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.propagateParsedValues(CommandLineArgumentParser.java:490); at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:233,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7696:108,release,release,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7696,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [ ] 4.0.8.1; - [x] 4.0.9.0; - [x] Latest public release version [4.1.2.0]. ### Description ; This maybe a series of mistakes.; I guess it will happen when a new variant should be detected within a spanning deletion.; Below is an example:. in 4.0.8.1, a NMP ( CTTT>CAAAA ) was detected as two variants( CTTT>C + T>TAAAA ).; *vcf of 4.0.8.1*; ```vcf of 4.0.8.1; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	19B0117493; chr13	32944606	.	CTTT	C	9210.73	.	AC=1;AF=0.500;AN=2;BaseQRankSum=1.374;DP=813;ExcessHet=3.0103;FS=0.518;MLEAC=1;MLEAF=0.500;MQ=60.03;MQRankSum=0.000;QD=11.81;ReadPosRankSum=0.295;SOR=0.728	GT:AD:DP:GQ:PL	0/1:423,357:780:99:9248,0,45245; chr13	32944609	.	T	TAAAA	14802.73	.	AC=1;AF=0.500;AN=2;BaseQRankSum=4.179;DP=787;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=18.93;ReadPosRankSum=0.241;SOR=0.689	GT:AD:DP:GQ:PL	0/1:411,371:782:99:14840,0,45112; ```; *gvcf of 4.0.8.1*; ```gvcf of 4.0.8.1; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	19B0117493; chr13	32944440	.	T	<NON_REF>	.	.	END=32944605	GT:DP:GQ:MIN_DP:PL	0/0:592:99:352:0,120,1800; chr13	32944606	.	CTTT	C,<NON_REF>	9210.73	.	BaseQRankSum=1.374;DP=813;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQ=2929400.00;ReadPosRankSum=0.295	GT:AD:DP:GQ:PL:SB	0/1:423,357,0:780:99:9248,0,45245,10522,46330,56852:212,211,175,182; chr13	32944609	.	T	A,TAAAA,<NON_REF>	14802.73	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQ=2833200.00;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0:770:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. but from version 4.0.9.0 which `support for genotyping spanning deletions and a fix to the reference confidence calculation around indels`,; the second variants got filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:142,release,release,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [4.3.0.0 ] Latest public release version . ### Description ; I'm attempting to run HaplotypeCaller on Ultima flow based bams with the ""--flow-mode STANDARD"" and ""--likelihood-calculation-engine FlowBasedHMM"" arguments. However, I'm getting the following error ""java.lang.IllegalArgumentException: read must be flow based: 180652-BC94-0022826568 chr1:14585-14703"". The bams were created from fastqs provided directly from Ultima, so they are definitely flow-based. One question I have: how does HaplotypeCaller determine if a read is flow-based or not? Is this specified in the Read Groups?. #### Steps to reproduce; gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg38.fa --flow-mode STANDARD --likelihood-calculation-engine FlowBasedHMM -I [bam] -O [bam%.BQSRapplied.bam].GATK.vcf.gz. #### Expected behavior; HaplotypeCaller should complete successfully. #### Actual behavior; HaplotypeCaller fails, expecting flow-based reads",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8112:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8112,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [?] Latest public release version [version?]; - [x] Latest master branch as of Sept 10, 2019. ### Description ; Contamination estimate doesn't appear to be taken into account for reference blocks in GVCFs. #### Steps to reproduce; I'm looking at expected integration test results with uncontaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.calls.20.10100000-10150000.vcf) vs. 15% contaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.CONTAMINATED.WITH.HCC1143.NORMALS.15PCT.20.10100000-10150000.postIndelRefConfUpdate.g.vcf). #### Expected behavior; Contaminated calls should have lower depth because the reads are being downsampled (in a biased way) by the contamination fraction. #### Actual behavior; In the expected HC integration test results I'm seeing for 0 contamination; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:57:99:57:0,120,1800. For 15% contamination:; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:56:99:56:0,120,1800. The pileup has 55 (I'm not going down the rabbit hole of the bonus reads), so I would expect the contaminated GVCF to have < 55 DP. The variants look good in some places and less good in others. Looking through the code, I don't see anywhere the contamination estimate would be used for reference confidence. I suspect @davidbenjamin has been harboring a desire to update the contamination model anyway.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,4,"['integrat', 'release', 'update']","['integration', 'release', 'update']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6817:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.2.0.0]. ### Description ; HaplotypeCaller fails with the following java error:. ```*** Error in `java': munmap_chunk(): invalid pointer: 0x00007f1da5980f00 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7f3e4)[0x7f1daaec73e4]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(_Z21runSWOnePairBT_avx512iiiiPhS_iiaPcPs+0x338)[0x7f05b3b50f48]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)```. #### Steps to reproduce; Using properly-aligned paired-end reads from GIAB reference sample HG002 (NA24385) with GRCh38.p12. Please see the attached log file for parameterization and stderr log:; [vcall.swbug.log](https://github.com/broadinstitute/gatk/files/6275740/vcall.swbug.log). #### Expected behavior; No error. #### Actual behavior; See above and attached log file. Thank you in advance for having a look at this!. Richard Wilton; Johns Hopkins University,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); GATK 3.7 and GATK 4.0.11.0; ### Description . GATK Pipeline (HaplotypeCaller->gvcf-->importdb->GenotypeGVCF)is calling sites with a GQ=0. But these sites often have plenty of coverage and no obvious reason for such a low GQ score. Often the GQ should be 99 as the DP >40. This seems to be primarily an issue with homozygous reference calls. . The GT is accurate for the high DP sites but the inaccurate GQ is problematic for any genotype level qc on the pVCF. If the site is recoded from 0/0 to './.' for GQ <20, the result is higher missing rate due to the inaccurate GQ=0. . Directly calling the VCF with HaplotypeCaller without the gVCF intermediate gVCF file calculates the correct GQ score. Freebayes also calculates a correct GQ on these samples.; [rs429358_gq_dp.pdf](https://github.com/broadinstitute/gatk/files/2612419/rs429358_gq_dp.pdf). #### Steps to reproduce. I am seeing this bug for 57 samples of 5000 crams at snp rs429358 but I would expect it is not unique to this site. . Select two crams with a Passed site with:; cram 1. Call with GT='0/0, GQ=0 and DP >40.; cram 2. Call with GT='0/1' or '1/1' and DP>20. . Create vcf with two approaches:. Pipeline 1. HaplotypeCaller-->vcf. module load gatk/4.0.11.0; gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I gq0_cram.list\; -L chr19:44907684-44909822\; --use-new-qual-calculator\; -O good.vcf.gz. Good GQ scores were also estimated with Freebayes on these samples also. Pipeline 2 HaplotypeCaller --> bvcf--->ImportVCF-->GenotypeVCF-->VCF with 2 samples. gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I $sample.cram\; --use-new-qual-calculator\; -L chr19:44907684-44909822\; -ERC GVCF\; -O bad.g.vcf.gz. Followed by import and GenotypeVCF. . #### Expected behavior; Pipeline 2 should generate accurate GQ scores that match the GQ in th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:143,Pipeline,Pipeline,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,1,['Pipeline'],['Pipeline']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller/ActiveProfile. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]. ### Description ; In function findEndOfRegion (line 355 in src/main/java/org/broadinstitute/hellbender/utils/activityprofile/ActivityProfile.java), it tries to determine the end of an active region. . The problem happens here, (at line 356); ![activeregion](https://user-images.githubusercontent.com/34263164/205565469-84900a73-1180-48e1-ba9f-f96c23d91e11.PNG); There could be an edge case where stateList.size() = maxRegionSize + getMaxProbPropagationDistance(), the function processes forward for further calculation. Hence the end of active region is determined immediately. However, the end of region is determined earlier than we expected. If by coincidence location at maxRegionSize is determined as minimum, region end is determined here. IBut wait a sec... If location at maxRegionSize+50 (which is NOT involved in current code in the ""if"" judgement at line 356) has an active score larger than 0, it rises the probability value at location maxRegionSize. . Now you should understand what I said. The state of location at maxRegionSize+50 is not updated when you accessed it. Let's assume ; maxRegionSize = 300 and point at location 350 has active value > 0. We trasverse the region to find the minimum point where we could cut the region and we found location at 300 in current logic. However, location 350 can acturally increase the probability at point 300 but this is not considered (or not updated) when making region end decision. #### Expected behavior; Simply use less or equal to at line 356 in the above image would fix this problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8118:126,release,release,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8118,3,"['release', 'update']","['release', 'updated']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); In the tutorial ""[(How to part I) Sensitively detect copy ratio alterations and allelic segments](https://gatk.broadinstitute.org/hc/en-us/articles/360035531092)"", users are asked to install R components using [install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R). . ### Affected version(s); Latest public release version [4.5.0.0]. ### Description ; Running the script with `Rscript install_R_packages.R` results in the following error:. `Error in download.file(p, destfile, method, mode = ""wb"", ...) : ; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz'; In addition: Warning message:; In download.file(p, destfile, method, mode = ""wb"", ...) :; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz': HTTP status was '404 Not Found'`. This can be fixed by changing line [35 of install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R#L35) from `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz""` to `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.1.tar.gz""`. . The script runs as expected once this change is made. #### Steps to reproduce; Run `Rscript install_R_packages.R`. #### Expected behavior; Successfully installs all necessary R packages with the correct versions. #### Actual behavior; Fails to install the 'HMM' package.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8638:233,install,install,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8638,4,"['install', 'release']","['install', 'installs', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); JointGermlineCNVSegmentation. ### Affected version(s); - [x] Latest public release version [v4.3.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; I get the following exception when running JointGermlineCNVSegmentation on an exome trio dataset:. ```; [January 19, 2023 at 6:59:29 AM CET] org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation done. Elapsed time: 0.82 minutes.; Runtime.totalMemory()=300941312; java.lang.IllegalStateException: Encountered genotype with ploidy 0 but 1 alleles.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.lambda$createDepthOnlyFromGCNVWithOriginalGenotypes$4(JointGermlineCNVSegmentation.java:666); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$Itr.forEachRemaining(ArrayList.java:1033); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.createDepthOnlyFromGCNVWithOriginalGenotypes(JointGermlineCNVSegmentation.java:667); at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8164:125,release,release,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8164,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark. ### Affected version(s); - [ ] Latest public release version [version?]; 4.0.8.1; - [ ] Latest master branch as of [date of test?]; Sep 10, 2018. ### Description ; 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 515, localhost, executor 1, partition 0, NODE_LOCAL, 5270 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 516, localhost, executor 2, partition 1, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 517, localhost, executor 1, partition 2, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 518, localhost, executor 2, partition 3, NODE_LOCAL, 5594 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 519, localhost, executor 1, partition 4, NODE_LOCAL, 5317 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 520, localhost, executor 2, partition 5, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:147,release,release,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,3,['release'],"['release', 'release-']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mitochondria WDL. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Mitochondria WDL still has `--genotyping-mode` argument: https://github.com/broadinstitute/gatk/blob/master/scripts/mitochondria_m2_wdl/AlignAndCall.wdl#L420. This argument doesn't exist in GATK version 4.1.1.0 (which is the one that is currently being used in the mitochondria WDL), so this argument should be changed to the new force-call argument which was added in #6090",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6286:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6286,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2 `--max-mnp-distance 0`. ### Affected version(s); - [X] Latest public release version [4.2.6.1]. ### Description; Same issue than described here: https://github.com/broadinstitute/gatk/issues/6473; ```; singularity exec docker://broadinstitute/gatk:4.2.6.1 gatk Mutect2 \; -R NC_000962.3.fa \; -I input.bam \; -O output.vcf \; --annotation StrandBiasBySample \; --num-matching-bases-in-dangling-end-to-recover 1 \; --max-reads-per-alignment-start 75 \; --max-mnp-distance 0; ```. And a MNP remains:; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T,G . . AS_SB_TABLE=0,0|9,9|0,2;DP=20;ECNT=1;MBQ=0,17,23;MFRL=0,311,334;MMQ=60,60,60;MPOS=31,40;POPAF=7.30,7.30;TLOD=44.10,3.01GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1/2:0,18,2:0.807,0.143:20:0,5,0:0,4,1:0,15,2:0,0,9,11; ```. #### Expected behavior; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T [...]; NC_000962.3 761155 . C G [...]; ```. BAM, BAI, and VCF here: [files.zip](https://github.com/broadinstitute/gatk/files/8488204/files.zip). Cheers!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7782:127,release,release,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7782,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of 7/18/18. ### Description ; When running Mutect yesterday on Mitochondrial data I got the following error:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chrM start:-4 end:65. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:728); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:86); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:48); 	at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); 	at org.broadinstitute.hellbender.transformers.ReadTransformer$$Lambda$107/1786040872.apply(Unknown Source); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.fillDownsampledReadsCache(ReadsDownsamplingIterator.java:69); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.advanceToNextRead(ReadsDownsamplingIterator.java:55); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.<init>(ReadsDownsamplingIterator.java:34); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:149); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:109); 	at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version 4.1.5.0. ### Description . #### Steps to reproduce; It seems that Mutect2 is emitting MNPs despite `--max-mnp-distance 0`. 1. Calling in tumor-only mode to prep PON:; ```; Using GATK jar /gatk/gatk-package-4.1.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx20G -jar /gatk/gatk-package-4.1.5.0-local.jar Mutect2 --max-mnp-distance 0 --input /mnt/data/input/gs/file.bam.cram --reference /mnt/data/input/gs/gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --germline-resource /mnt/data/input/gs/ukbb_v2/projects/jamesp/data/mutect2/bravo-dbsnp-all-f5.exome.chr.sorted.reheader.vcf.gz --intervals /mnt/data/input/gs/gcp-public-data--broad-references/hg38/v0/exome_calling_regions.v1.interval_list --output /mnt/data/output/gs/file.bam.cram.unfiltered.vcf.gz; ```. 2. GenomicsDB creation for PON step:; ```; Using GATK jar /gatk/gatk-package-4.1.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx40G -jar /gatk/gatk-package-4.1.5.0-local.jar GenomicsDBImport --reference /mnt/data/input/gs/gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --intervals chr1 --intervals chr2 --intervals chr3 --intervals chr4 --intervals chr5 --intervals chr6 --intervals chr7 --intervals chr8 --intervals chr9 --intervals chr10 --intervals chr11 --intervals chr12 --intervals chr13 --intervals chr14 --intervals chr15 --intervals chr16 --intervals chr17 --intervals chr18 --intervals chr19 --intervals chr20 --intervals chr21 --intervals chr22 --intervals chrX --genomicsdb-workspace-path pon_db {etc}. ***********************************************************************. A,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version [2.1]; - [x] Latest master branch as of [2018-09-13]. ### Description ; The VCF header line; ""##Mutect Version=x.y""; causes problems for some VCF readers. Each header line is required to be a key-value pair and a space character is not expected in the key. (The VCF specification is not clear on this matter, but I've never encountered a space character in a VCF header key before.); Making VCF files that are easily readable by downstream tools should be in the interest of Mutect2. #### Steps to reproduce; Create a VCF file using Mutect2 and look at the header. #### Expected behavior; output; ""##MutectVersion=2.1"". #### Actual behavior; output; ""##Mutect Version=2.1""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5183:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5183,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version [4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; Mutect2 occasionally writes lines including INFO tag `MPOS=-2147483648`. This doesn't look sensible for ""median distance from end of read"", and the specific value is disallowed in [section 1.3 of the VCF specification](https://samtools.github.io/hts-specs/VCFv4.3.pdf). I've had a quick look at the code, and think the dubious value may be generated in [ReadPosition::getValueForRead](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosition.java#L57) when the result from [ReadPosRankSumTest.getReadPosition](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L53) is cast to an `int`. Looking at that function, it can [return `INVALID_ELEMENT_FROM_READ`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L62) which is [defined as `Double.NEGATIVE_INFINITY`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/RankSumTest.java#L23). According to the [java documentation](https://docs.oracle.com/javase/specs/jls/se7/html/jls-5.html#jls-5.1.3), casting NEGATIVE_INFINITY to int will result in a value of `INT_MIN`. (Disclaimer: I haven't tested this, so it may be completely wrong...). #### Steps to reproduce; See attached .zip file which includes a smallish bam file that shows the problem. I ran mutect2 on it in the Docker container for the latest GATK release:; ```sh; unzip mpos_issue.zip; cd mpos_issue; ../gatk Mutect2 --input input/small.bam --reference input/small.fa --output small.vcf; grep MPOS=- small.vcf; ```. #### Expected behavior; `MPOS` should have a se",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6342:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6342,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version: 4.0.11.0; - [ ] Latest master branch as of [date of test?]. ### Description ; The output vcf for a few samples looks like this:. ```; chrM 151 . CT TC . PASS DP=3420;ECNT=23;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=14304.21 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:27,3242:0.992:3269:13,1545:14,1697:30,30:317,335:60:26:0:0.990,0.990,0.992:0.045,0.015,0.940:9,18,1541,1701; chrM 152 . T C . chimeric_original_alignment DP=3358;ECNT=23;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=46.40 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:PGT:PID:POTENTIAL_POLYMORPHIC_NUMT:SA_MAP_AF:SA_POST_PROB:SB 0/1:250,25:0.099:275:119,13:131,12:30,30:336,317:60:29:25:0|1:8660_C_T:true:0.091,0.061,0.091:2.722e-03,0.035,0.962:112,138,7,18; ```. ```; chrM 151 . CT TC . PASS DP=1867;ECNT=20;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=6145.34 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:13,1792:0.993:1805:7,879:6,913:30,30:441,442:60:39:0:0.990,0.990,0.993:0.026,0.024,0.950:5,8,745,1047; chrM 152 . T C . PASS DP=1847;ECNT=20;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=12.96 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:0,1755:0.999:1755:0,862:0,893:0,30:0,442:60:39:6:0.990,0.990,1.00:0.027,0.027,0.946:0,0,726,1029; ```. Note that site 152 is a T->C that is also captured in the MNP at site 151 CT->TC. In one case site 152 is filtered, but in the other it passes, but in both cases the MNP passes. . #### Steps to reproduce; @klaricch Could you please post the input BAMs into the Mutect task as well as the output VCFs from that task? Could you also post the ""script"" generated by Cromwell that will show what command Cromwell actually ran at this point? Thanks!. #### Expected behavior; I'm not sure what should happen in this case, but the two o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5513:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.4.0.0. ### Description ; Hello GATK team,. I am working on a pipeline that calls variants using Mutect2 and uses those mutations for somatic variant calling in other samples. To achieve this I'm using the -allele flag in Mutect2 to pass the desired positions to genotype to Mutect2. However it appears that Mutect2 will output variants that it then is unable to parse as an -allele file. I believe this is because the REF column is too long. #### Steps to reproduce; Try to variant call using an -allele VCF containing this line:. ```; 5	283041	.	AGAAGACTCGGGGAGGAGCTGAGGTTCTAGTTTGAGGGTCGTGCACCTGGAGAACTGGACAGGAGCTGATGTTCTAGATTGAGCATCGTACAGCTGAAGACTTGGGGAGGAGCTTATGTTGTTCACTTTGAGGGTCTTTCAGCTGGAGACTCAGGCAGGAGCTGATGTTCTAGTTTGAGGATCTCGTAGCTGCAGAATCAGAGAGGAGCTGATGTTCTAGATTGAGGATCTTGTAGCTACAGACCCATAGAGGAGCTGATGATCTAGATTCAGGGTCATGCAGCT	A	.	.	AS_SB_TABLE=57,54|8,7;DP=126;ECNT=1;MBQ=30,31;MFRL=358,237;MMQ=60,60;MPOS=15;POPAF=7.30;TLOD=3.22	GT:AD:AF:DP:F1R2:F2R1:FAD:SB	0/1:111,15:0.028:126:17,1:18,5:86,9:57,54,8,7; ```. #### Expected behavior; Mutect2 should either not emit an invalid variant or it should be able to parse it; #### Actual behavior. ```; java.lang.ArrayIndexOutOfBoundsException: arraycopy: source index -152 out of bounds for byte[278]; 	at java.base/java.lang.System.arraycopy(Native Method); 	at java.base/java.util.Arrays.copyOfRange(Arrays.java:3823); 	at org.broadinstitute.hellbender.tools.walkers.annotator.TandemRepeat.getNumTandemRepeatUnits(TandemRepeat.java:54); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer.trim(AssemblyRegionTrimmer.java:189); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:273); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:304); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8699:147,pipeline,pipeline,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8699,1,['pipeline'],['pipeline']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); N/A. ### Affected version(s); - [ x] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Dockerfile does not create unprivileged user account. #### Steps to reproduce; * git clone https://github.com/broadinstitute/gatk.git; * cd gatk; * git checkout 4.5.0.0; * docker build -t gatk .; * docker run ... #### Expected behavior; I'd expect the user to be in an unprivileged account in `/home/gatk` when the container is started. If there is a use case for enabling root (say for allowing system installs) this should be an option (config or a separate Dockerfile). #### Actual behavior; On `docker run` the user is root under `/gatk`. A container should not put the user in a root account upon startup. This is especially so in shared computing environments. I attempted to create a ""gatk"" account with `RUN useradd -d /home/gatk -ms /bin/bash gatk` (etc) in the Dockerfile but I get `Permission denied: '/root/.config/conda/.condarc'.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856:101,release,release,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856,2,"['install', 'release']","['installs', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); PlotModeledSegments. ### Affected version(s); Confirmed with 4.1.3, but also any version before this that uses optparse. ### Description ; The R package `optparse` is used in the R script `PlotModeledSegments.R` for plotting. The latest version of `optparse` (1.6.4) has been updated to include a check that the short-name of an option is only 1 character. ; See here: https://github.com/trevorld/r-optparse/commit/66acec58645f7401fc365bb769a72751671c2114; The `PlotModeledSegments.R` script in gatk has this line:; ```make_option(c(""--sample_name"", ""-sample_name""), dest=""sample_name"", action=""store""),```; which will now make `optparse` throw an error. #### Steps to reproduce; Install `optparse 1.6.4` and run `gatk PlotModeledSegments`. #### Expected behavior; The Rscript should parse the inputs and run. #### Actual behavior; PlotModeledSegments.R gives an error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6207:326,update,updated,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6207,2,"['Install', 'update']","['Install', 'updated']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls . ### Affected version(s); - [X ] Latest public release version [4.3.0.0]. ### Description ; Hello, I am a regular user of the gCNV pipeline of GATK4. Since version GATK 4.2.0.0, you have introduced the germline CNV calling joint which I wanted to try and I encountered several problems. So I used, in order, the DetermineGermlineContigPloidy and GermlineCNVCaller tools (cutting my target into 8 bins) version 4.3.0.0 on a cohort of 540 patients. Then I used the PostProcessGermlineCaller tool to produce the VCF files for these patients. Next, I used the JointGermlineCNVSegmentation beta tool to produce a multisample VCF which I reused with PostProcessGermlineCaller to produce joined VCFs. The problem is that the time needed to produce each VCF file has been multiplied by 20 (on average 120 minutes compared to 6), which makes it difficult to use on large cohorts. Here is an extract of the logs, from a sample without, then with the --clustered-breakpoints option: ; #PostprocessGermlineCNVCalls. 14:23:53.500 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:23:54.242 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 14:23:54.242 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.3.0.0; 14:23:54.242 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:23:54.262 INFO PostprocessGermlineCNVCalls - Executing as [tintest@dahu132.u-ga.fr](mailto:tintest@dahu132.u-ga.fr) on Linux v5.10.0-18-amd64 amd64; 14:23:54.262 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:23:54.263 INFO PostprocessGermlineCNVCalls - Start Date/Time: December 2, 2022 2:23:53 PM GMT; 14:23:54.263 INFO PostprocessGermlineCNVCall",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:126,release,release,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); ReadsPipelineSpark (HaplotypeCallerSpark) when running over a spark cluster. ### Affected version(s); - [x] Latest public release version [GATK v4.1.8.1]. ### Description . #### Tools used:; latest docker image from broadinstitute/gatk; latest hadoop (3.3.0); spark 2.3.1 without hadoop which is able to use the custom hadoop setup. #### Steps to reproduce. **Script run:**; ```; #!/bin/bash. export HADOOP_CONF_DIR=/etc/hadoop; export HADOOP_HOME=/mnt/hadoop-latest; export JAVA_HOME=/mnt/jre1.8.0_192; export SPARK_HOME=/mnt/spark-2.3.1-bin-without-hadoop; export HADOOP_USER_NAME=hadoop. # export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:172,release,release,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); ReadsPipelineSpark. ### Affected version(s); - [x] Latest public release version 4.1.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . ```; java.lang.IllegalArgumentException: Interval NC_007605:1-171823 not within the bounds of a contig in the provided dictionary; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:87); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:66); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.lambda$runTool$0(ReadsPipelineSpark.java:221); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:115,release,release,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,2,"['pipeline', 'release']","['pipelines', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); Reblock | JointGenotype. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; We found a bug while running the latest JointGenotype pipeline (2.0.2). We are working with Dragen data (version 3.6.3); The error:. <details><summary>OPEN ERROR HERE</summary>; <p>. + gatk --java-options -Xms8g GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-SplitIntervalList/glob-d928cd0f5fb17b6bd5e635f48c18ccfb/0073-scattered.interval_list --sample-name-map sample_name_map --reader-threads 5 --merge-input-intervals --consolidate; --; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-ImportGVCFs/shard-73/tmp.9a65c1fc; 18:46:55.750 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 01, 2021 6:46:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:46:55.894 INFO GenomicsDBImport - ------------------------------------------------------------; 18:46:55.894 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.3.0; 18:46:55.895 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:46:55.895 INFO GenomicsDBImport - Executing as root@ip-10-10-156-13.us-west-2.compute.internal on Linux v4.14.243-185.433.amzn2.x86_64 amd64; 18:46:55.895 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 18:46:55.895 INFO GenomicsDBImport - Start Date/Time: December 1, 2021 6:46:55 PM GMT; 18",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:120,release,release,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF (& how it interacts with GenotypeGVCFs). ### Affected version(s); - [x] 4.2.6.1 ; - [ ] Latest public release version (haven't tried yet, but doesn't look like ReblockGVCFs has been changed substantially since 4.2.6.1); - [ ] Latest master branch (haven't tried yet, but doesn't look like ReblockGVCFs has been changed substantially since 4.2.6.1). ### Description . Our samples run with ReblockGVCF appear to have unusually high numbers of variants with missing / not called genotypes (`./.`). These variants seem to have coverages that are good enough to successfully call variants ‚Äî and, genotypes are called at these sites as hom refs (`0/0`) when we run these ***same samples*** through the ***same pipeline*** (WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7)) ***without the reblocking step***. . It also seems as if we lose the PL field for these variants when working with reblocked gvcfs (which could explain why GenotypeGVCF isn‚Äôt giving us calls for these variants). I've heard that support for hom-refs with no PLs was implemented in CombineGVCFs as of Sept 2021, but I'm still seeing the issue with CombineGVCFs 4.3.0.0. To provide more info:. - We are seeing these issues regardless of if reblocked gvcfs are analyzed together with or separate from non-reblocked gvcfs. (For reference, the downstream steps in our pipeline are GenomicsDBImport & GenotypeGVCFs, but we‚Äôre seeing the same results with CombineGVCFs & GenotypeGVCFs on a smaller set of test gvcfs.); - I have a test set of samples that I've run with and without ReblockGVCF, and have used CombineGVCFs 4.3.0.0 & GenotypeGVCFs 4.3.0.0, and we're still seeing this issue.; - I have rerun ReblockGVCF including the `--allow-missing-home-ref-data` and `--all-site-pls` flags, but neither of these seem to solve the issue either. . #### Steps to reproduce. Run WARP's [ExomeGermlineSingle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8208:164,release,release,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8208,3,"['pipeline', 'release']","['pipeline', 'release', 'releases']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x ] Latest public release version [version?] _**GATK 4.2.6.1**_; - [ ] Latest master branch as of [date of test?]. ### Description ; We ran ReblockGVCF in 549 samples with the newest GATK (4.2.6.1). 8 of them returned the error similar to the message below . `org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrM:1 [VC /tmp/scratch/prs-sabe-files/GRAR/2031812880_AJ.hard-filtered.gvcf.gz @ chrM:1 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=1} GT=[[2031812880_AJ G*/G* DP 1691 AD 112,1579 {MIN_DP=1691, SQ=0}]] filters=weak_evidence`. and right below, we could find in all of them; `Caused by: org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: Homozygous reference genotypes must contain GQ or PL. Both are missing for hom ref genotype at chrM:1`. All the ""failed samples"" produced a broken output, in this case, missing the chrM (and the alt chr, such as HLA, chr1_alt etc)... It was weird because on WDL it returned as **_Success_** job... We need all the samples with a proper output to run the JointGenotype pipeline with the Reblocked Dragen samples output. #### Steps to reproduce; I'll share with you the chrM:1 from GVCF from a sample with no error; `chrM	1	.	G	<NON_REF>	.	PASS	END=72	GT:AD:DP:GQ:MIN_DP:PL:SPL:ICNT	0/0:2441,2:2443:99:1613:0,120,1800:0,255,255:40,13`. And now, the chrM:1 from a sample with the error; `chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691`. #### Expected behavior; No broken output. #### Actual behavior; Failing in a few samples, breaking the expected output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x] Latest public release version [4.2.6.1]; - [x] Latest master branch (probably). ### Description ; First position on a contig can be missing if that position is low quality in the input GVCF. #### Steps to reproduce; Run Reblock GVCF with the following parameters: --floor-blocks true --gvcf-gq-bands 20 --gvcf-gq-bands 30 --gvcf-gq-bands 40 --do-qual-score-approximation true --variant $inputVC -R $hg38. where inputVC contains; chr13	18173860	.	A	C,<NON_REF>	0	.	AS_RAW_BaseQRankSum=|-4.9,1|NaN;AS_RAW_MQ=51256.00|4709.00|0.00;AS_RAW_MQRankSum=|0.5,1|NaN;AS_RAW_ReadPosRankSum=|1.2,1|NaN;AS_SB_TABLE=23,2|1,1|0,0;BaseQRankSum=-4.896;DP=28;ExcessHet=0.0000;MLEAC=0,0;MLEAF=0.00,0.00;MQRankSum=0.564;RAW_MQandDP=59565,28;ReadPosRankSum=1.252	GT:AD:DP:GQ:PL:SB	0/0:25,2,0:27:61:0,61,946,75,951,965:23,2,1,1; appears to be dropped in output. Full input GVCF at gs://broad-dsde-methods-gauthier/reblocking-bug/. #### Expected behavior; QUAL 0 VC should be replaced with a GQ0 reference block. #### Actual behavior; Output GVCF is missing position chr13:18173860 and fails ValidateVCF task",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7884:108,release,release,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7884,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); SAMSequenceDictionary function in IndexUtils.java: https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/IndexUtils.java. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; The SAMSequenceDictionary function always logs a warning when a file is passed in. Needs an if statement that validates whether or not the file is actually a sequence dictionary before logging the warning. #### Steps to reproduce; Run GATK's HaplotypeCaller with a --dbsnp option set, or just pass a sequence dictionary into the SAMSequenceDictionary function directly. #### Expected behavior; Should use the --dbsnp file that I pass in if valid, rather than log a warning and creating a separate sequence dictionary. #### Actual behavior; Logs a warning and instead tries to create a new sequence dictionary based on the index file it finds",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5692:264,release,release,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5692,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); SV type inference pipeline. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch as of 2018-06-26. ### Description ; Though we've never seen this case with `bwa mem`, it is theoretically possible&mdash;and happened in an experimental (mis-) run of another aligner&mdash; that a query sequence generates two alignment records, where the two alignments's overlap on the read and on the reference are of the same length. See illustration below.; ```; --------------------------sssssssssssssss READ ALN1; ssssssssssssssss------------------------- READ ALN2; | |; | |; | |; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REF; ```. This scenario will trigger our code to resolve a complicated tandem duplication structure. ; But the code should check for such case, or better yet two alignments should really be stitched together. #### Steps to reproduce; Run the code with some funny alignments. #### Expected behavior; Two alignments should be merged into one, by the type inference pipeline. #### Actual behavior; Exception would be thrown currently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4951:68,pipeline,pipeline,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4951,3,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); SelectVariants. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of Dec 14, 2020. ### Description ; I believe SelectVariants doesn't handle multi-allelic sites, which have more than one value per INFO field. The problem seems to be in coercing values like 0.00022456 and 2.496e-05 (note the decimal and scientific notation) into doubles, which happens in the apache commons code. But the problem is not limited to decimal values‚Äîit fails to coerce integers like 0 and 9 (see below). . #### Steps to reproduce; gnomad=gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz; java -jar $gatkjar SelectVariants -V $gnomad -select ""AF > 0.05"" -O af-only-gnomad.hg38.contamination.vcf.gz. This one fails with `java.lang.ArithmeticException: Double coercion: java.util.ArrayList:([0.0002246, 2.496e-05])`. Also fails with the expression ""AC > 3"":. javadebug -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar $gatkjar SelectVariants -V $gnomad -select ""AC > 3"" -O af-only-gnomad.hg38.contamination.vcf.gz. `java.lang.ArithmeticException: Long coercion: java.util.ArrayList:([9, 1])`. #### Expected behavior; The tool should run to completion. #### Actual behavior; It doesn't.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6998:111,release,release,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6998,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); SelectVariants. ### Affected version(s); - [x] Latest public release version [4.5.0.0]. ### Description ; When trying to stream a reference file from a public URL, there is trouble interpreting the path when the file ends with `.fa.gz`, especially in finding the index. . #### Steps to reproduce; This was discovered trying to debug another Picard issue. To reproduce, run this command:; ```; gatk SelectVariants -L chr17:22477226-22477227 -V https://jmorp.megabank.tohoku.ac.jp/datasets/tommo-54kjpn-20230626-af_snvindelall/files/tommo-54kjpn-20230626r3-GRCh38-af-autosome.vcf.gz -R https://jmorp.megabank.tohoku.ac.jp/datasets/tommo-jg2.1.0-20211208/files/jg2.1.0.fa.gz -O subset.vcf.gz; ```; Here we try to stream a small region from a VCF using a public reference file. . #### Expected behavior; The file `subset.vcf.gz` should be written with just the regions given. #### Actual behavior; You get a stacktrace:; ```; org.broadinstitute.http.nio.HttpPath$CantDealWithThisException: Attempting to resolve this against a path which is relatve but looks like it has a scheme.; This: https://jmorp.megabank.tohoku.ac.jp/datasets/tommo-jg2.1.0-20211208/files; Other: https:/jmorp.megabank.tohoku.ac.jp/jg2.1.0.fa.gz.fai; Other interpretted as URI: https:/jmorp.megabank.tohoku.ac.jp/jg2.1.0.fa.gz.fai; This is a limitatation of the current implementation of resolve.; Please use choose a less horrible file name or get in touch with the developers to complain.; 	at org.broadinstitute.http.nio.HttpPath.resolve(HttpPath.java:381); 	at org.broadinstitute.http.nio.HttpPath.resolve(HttpPath.java:53); 	at java.base/java.nio.file.Path.resolveSibling(Path.java:549); 	at org.broadinstitute.http.nio.HttpPath.resolveSibling(HttpPath.java:418); 	at htsjdk.samtools.reference.ReferenceSequenceFileFactory.getFastaIndexFileName(ReferenceSequenceFileFactory.java:262); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8751:111,release,release,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8751,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); StructuralVariationDiscoveryPipelineSpark. ### Affected version(s); GATK 4.1.0.0. ### Description . Running SV program generates a Java exception...; java.lang.IllegalArgumentException: provided start is negative: -1. #### Steps to reproduce; ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv//$SAMPLE.contig-sam-file\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode client \; --executor-memory 80G\; --driver-memory 30g\; --num-executors 40\; --executor-cores 4\; --conf spark.yarn.submit.waitAppCompletion=false\; --name ""$SAMPLE"" \; --files $REF.img,$KMER \; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120. ```. ```; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --deploy-mode client --executor-memory 80G --driver-memory 30g --num-executors 40 --executor-cores 4 --conf spark.yarn.submit.w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:733,deploy,deploy-mode,733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy-mode']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); The docker image: `broadinstitute/gatk`. ### Affected version(s); `latest`. ### Description ; - The current GATK image has 44 layers; - In [the Azure Container Registry standard service tier](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-skus#registry-throughput-and-throttling), ""ReadOps per minute"" is limited to 3000; - ""A `docker pull` translates to multiple read operations based on the number of layers in the image, plus the manifest retrieval.""; - 3000 / 45 = 66. That means that the image can only be pulled 66 times per minute. This is problematic for running many concurrent workflows that also have many shards. Once that limit is exceeded, the task can fail, which can cause the entire workflow to fail. ; - Layers can be viewed here: `docker history --no-trunc broadinstitute/gatk > gatk-image-layers.txt`; [gatk-image-layers.txt](https://github.com/broadinstitute/gatk/files/14212774/gatk-image-layers.txt). #### Steps to reproduce; `docker history --no-trunc broadinstitute/gatk > gatk-image-layers.txt`. #### Expected behavior; `--squash` shall be added to `build_docker_base_cloud.sh`, like has been added to `build_docker_base_locally.sh` already: https://github.com/broadinstitute/gatk/blob/a353e49f218e675f331abf629f0bb46df1d5151d/scripts/docker/gatkbase/build_docker_base_locally.sh#L24. #### Workaround; Users can pull the existing image, and [use `docker-squash` to squash the image to a single layer](https://github.com/goldmann/docker-squash), then push it into their private ACR, then update their WDLs to reference the new image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684:1594,update,update,1594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684,1,['update'],['update']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); TransferReadTags. ### Affected version(s); - [X] Latest public release version [gatk-4.3.0.0]. ### Description ; When traversing the reads in both aligned (target) and unaligned (the one with the desired tag) BAMs an error is thrown complaining about a read `found in the aligned bam is not found in the unmapped bam`. However the reads exists. It looks like the `traverse` function that uses the lexicographic order difference between both query names will find a _negative_ `diff` and assume that the read in the aligned BAM is missing in the uBAM. However, with Illumina read headers it seems almost guaranteed that this is going to be an issue since the y-coord (the last colon-separated field in the header) often has numbers with different number of digits. The lexicographical comparison will fail to adjust when comparing two read names where the length of the read in the target BAM is larger than the length of the read in the uBAM. . This is the `traverse` function that throws the error:; https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L109-L145 . #### Steps to reproduce; Run `TransferReadTags` with an Illumina sequenced aligned BAM. I can provide dummy files if needed, but should be easy to reproduce. The following example should help illustrate the issue:. ```sh; $ /data/reddylab/software/gatk/gatk-4.3.0.0/gatk TransferReadTags \; --output /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam \; --read-tags RX \; --unmapped-sam /data/reddylab/Alex/tmp/TEST_BAM.umi.nsorted.ubam \; --input /data/reddylab/Alex/tmp/TEST_BAM.nsorted.bam; ```. Produces the following output:; ```; Using GATK jar /gpfs/fs1/data/reddylab/software/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); UpdateVCFSequenceDictionary. ### Affected version(s); - \[x] Latest master branch as of 8/3/18. ### Description ; I am running UpdateVCFSequenceDictionary on a vcf which should have a hg38 header but which (for unrelated unpleasant reasons) instead has a hg19 header. Using an hg38 dictionary as source dict to try to fix the header. If I ask to output a .vcf file, everything works fine. If I ask to output a .vcf.gz file, gatk crashes with; ```; java.lang.ArrayIndexOutOfBoundsException: 12922; 	at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:89); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:146); 	at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:212); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.UpdateVCFSequenceDictionary.closeTool(UpdateVCFSequenceDictionary.java:174); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:983); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ``` . #### Steps to reproduce; Works: ``gatk UpdateVCFSequenceDictionary -V /dsde/working/ckachulis/UpdateVCFSequenceDictionary_Bug/na12878_hg38_giab_pg_hybrid_happy.vcf.gz -O corrected.dictionary.vcf --source-dictionary /seq/references/Homo_sapiens_as",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5087:50,Update,UpdateVCFSequenceDictionary,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5087,2,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator -A ReferenceBases -A TandemRepeat. ### Affected version(s); - [x] Latest public release version [4.1.3]; - [ ] Latest master branch as of [date of test?]. ### Description ; VariantAnnotator doesn't seem to correctly generate annotations that are based off the reference. I've tried on a few different VCFs and with different genome builds, and get the same result every time. For `ReferenceBases` it seems to generate a string for each variant that is the ref allele, followed by `20-len(ref) * N`. E.g.:. ```; 1 118617 rs372912307 T C 50 PASS REF_BASES=TNNNNNNNNNNNNNNNNNNNN; 1 567239 rs78150957 CG C 50 PASS REF_BASES=CGNNNNNNNNNNNNNNNNNNN; ```. The STR annotations get their header lines added to the header, but not a single variant is flagged as an STR. I've tried processing the GIAB VCFs for NA12878 and NA24385 with the same results - even obvious STR variants are not flagged. I suspect this is related to the fact that REF_BASES isn't compute properly. #### Steps to reproduce; Take any decent size VCF without the above annotations (e.g. GIAB VCFs) and run something like:. gatk VariantAnnotator -V NA12878.vcf.gz -O NA12878.ann.vcf.gz -A TandemRepeat -A ReferenceBases -R hg38.fa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6095:147,release,release,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6095,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version 4.5.0.0; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; Using GATK jar /directory_masked/programs/gatk-4.5.0.0/gatk-package-4.5.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /directory_masked/gatk-4.5.0.0/gatk-package-4.5.0.0-local.jar VariantAnnotator -I ../test.bam -V test.vcf -O test_2.vcf --reference /directory_masked/refs/hg19/ucsc.hg19.fasta --enable-all-annotations true -jdk-deflater true -jdk-inflater true; 14:02:45.344 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.346 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.5.0.0; 14:02:45.346 INFO VariantAnnotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:02:45.346 INFO VariantAnnotator - Executing as username@hostname.local on Mac OS X v14.2 aarch64; 14:02:45.346 INFO VariantAnnotator - Java runtime: OpenJDK 64-Bit Server VM v17.0.10+0; 14:02:45.346 INFO VariantAnnotator - Start Date/Time: April 30, 2024 at 2:02:45 PM HKT; 14:02:45.346 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.346 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.347 INFO VariantAnnotator - HTSJDK Version: 4.1.0; 14:02:45.347 INFO VariantAnnotator - Picard Version: 3.1.1; 14:02:45.347 INFO VariantAnnotator - Built for Spark Version: 3.5.0; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:02:45.348 INFO V",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689:113,release,release,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); - [X] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; As of v1.3.0 the `scales` R package turns the use of deprecated values for the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‚Äò1.3.0‚Äô; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ‚ñÜ; 1. ‚îú‚îÄbase::source(""/path/to/rscript.r""); 2. ‚îÇ ‚îú‚îÄbase::withVisible(eval(ei, envir)); 3. ‚îÇ ‚îî‚îÄbase::eval(ei, envir); 4. ‚îÇ ‚îî‚îÄbase::eval(ei, envir); 5. ‚îî‚îÄggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ‚îú‚îÄggplot2::continuous_scale(...); 7. ‚îÇ ‚îî‚îÄggplot2::ggproto(...); 8. ‚îÇ ‚îî‚îÄrlang::list2(...); 9. ‚îî‚îÄscales::seq_gradient_pal(low, high, space); 10. ‚îî‚îÄscales::pal_gradient_n(c(low, high), space = space); 11. ‚îî‚îÄlifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. ‚îî‚îÄlifecycle:::deprecate_stop0(msg); 13. ‚îî‚îÄrlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,2,"['install', 'release']","['install', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); GATK 4.2.0.0 . ### Description . When running VariantRecalibrator on a joint-called gVCF with 2000 samples, the following java.lang.IllegalStateException occurs: **Gaussian mean vector does not have the same size as the list of annotations**. ```; 17:56:38.072 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 28, 2021 5:56:38 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:56:38.485 INFO VariantRecalibrator - ------------------------------------------------------------; 17:56:38.487 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.0.0; 17:56:38.487 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:56:38.488 INFO VariantRecalibrator - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.25.1.el7.x86_64 amd64; 17:56:38.488 INFO VariantRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 17:56:38.488 INFO VariantRecalibrator - Start Date/Time: July 28, 2021 5:56:38 PM EDT; 17:56:38.489 INFO VariantRecalibrator - ------------------------------------------------------------; 17:56:38.489 INFO VariantRecalibrator - ------------------------------------------------------------; 17:56:38.490 INFO VariantRecalibrator - HTSJDK Version: 2.24.0; 17:56:38.491 INFO VariantRecalibrator - Picard Version: 2.25.0; 17:56:38.491 INFO VariantRecalibrator - Built for Spark Version: 2.4.5; 17:56:38.491 INFO VariantRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:56:38.491 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:56:38.491 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRIT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380:454,install,install,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380,1,['install'],['install']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _FilterAlignmentArtifacts_. ### Affected version(s); - [x] Latest public release version [4.1.4.1]. ### Description ; FilterAlignmentArtifacts consistently errors out with segmentation faults or IllegalArgumentExceptions. I've attached the log files for each of these errors below.; [invalid_interval.log](https://github.com/broadinstitute/gatk/files/4017907/invalid_interval.log); [seg_fault.log](https://github.com/broadinstitute/gatk/files/4017908/seg_fault.log). #### Steps to reproduce; The command to reproduce both errors is the same, and I have attached it below.; [realignment_filter.txt](https://github.com/broadinstitute/gatk/files/4017918/realignment_filter.txt); The BWA mem index I'm using is hg38, however the BAM that I am realigning from is hg19; thus, the reference argument is the hg19 fasta. I am happy to transfer zip files containing the other files need to reproduce this. Just let me know where to send them. #### Expected behavior; _FilterAlignmentArtifacts_. #### Actual behavior; _Errors_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344:123,release,release,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_, _GencodeFuncotationFactory::createUtrFuncotation_. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch as of [20181019]. ### Description ; When determining whether a variant in a 5' UTR is a `DE_NOVO_START_IN_FRAME` or `DE_NOVO_START_OUT_FRAME`, Funcotator only checks whether the new start codon is in frame with the end of the current UTR (the UTR in which the variant occurs). Funcotator should account for the case that there are multiple 5' UTRs. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; All UTRs should be considered for whether or not the new start codon is in frame. #### Actual behavior; Only the UTR in which the variant occurs is considered for whether the new start codon is in frame.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5333:160,release,release,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5333,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_, _GencodeFuncotationFactory_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; The transcript position in Funcotator is always being populated as a single integer value. While this is correct for SNPs, it should be populated as a range - `<START_POS>_<END_POS>` for events spanning more than 1 base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5375:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5375,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version v4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description . Hi @jonn-smith , I saw you often address Funcotator related issues, so I thought this might be of interest to you. I ran funcotator on a vcf created by mutect2 from RNA-seq data. The vcf includes a large deletion in the GABARAP gene, and when Funcotator processes this annotation, it dies with an error about a query that extends past the end of a contig:. > htsjdk.samtools.SAMException: Query asks for data past end of contig. Query contig ENST00000571253.1|ENS; G00000170296.9|OTTHUMG00000102156.3|OTTHUMT00000440082.2|AC120057.8-003|GABARAP|837|UTR5:1-753|CDS:754-8; 37| start:1 stop:895 contigLength:837; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(Ca; chingIndexedFastaSequenceFile.java:316); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource; .java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource; .java:64); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:78",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; When annotating a VCF, if the VCF already contains funcotations Funcotator will add a new funcotator line to the header. This will cause the parser to fail because it will not be able to get the correct line from the header. This is a bit of a pathological case (I can't currently see a good reason to funcotate a VCF twice), but since this behavior is valid it should be accounted for. The primary issue is how to resolve the two funcotation sets. Ideally we would leave them both in and somehow version them (to preserve all the information). Alternatively we can append to the existing funcotation list. This second method will likely involve a lot of work and probably isn't worth it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5368:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5368,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _GencodeFuncotationFactory_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; When a trouble transcript comes up for an allele pairl, `GencodeFuncotationFactory::createFuncotationsHelper` does not create a default annotation for the allele pair. This will cause the parsing of funcotations to fail because not all the alleles are represented in the funcotation list. See the `todo` in `GencodeFuncotationFactory::createFuncotationsHelper`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5366:124,release,release,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5366,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - GATK 4.1.4.1. ### Description ; When running Mutect2 (from GATK v4.1.4.1) using the following command:. `gatk Mutect2 -R [path to grch37-1kg.fa] -I testcase.bam -O pon.vcf`. to create a PoN on NovaSeq WGS-data processed through the best practice pipeline (with the BQSR-steps run through the Spark-enabled tools, and bwa mem with -Y flag) I get the following error in multiple regions:. [Stacktrace](https://www.dropbox.com/s/d2n5zflj9u11oj8/stacktrace.png?dl=0). AFAIK this is related to the new code path introduced in #6240 and seem to be triggered when there are more than 2 reads supporting a fragment but all of them are either duplicate reads or supplemntary/secondary alignments. Any input is greatly appreciated. I guess a temporary fix is to use the --independent-mates flag (although haven't tried it yet -- how much worse mutation calling performance do one incur when using that flag?). #### Steps to reproduce; Use the following small test case .bam-file as input to the command specified above:. [Testcase](https://www.dropbox.com/s/hilcj3aj0jnjdmh/testcase.bam?dl=0). #### Expected behavior; Completion of mutect2 without Exception. #### Actual behavior; Early termination of the mutect2 run due to raising an exception when trying to create a fragment with no read data to back it up. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6310:334,pipeline,pipeline,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6310,1,['pipeline'],['pipeline']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.1.7.0. ### Description . The following error message is output:. A USER ERROR has occurred: Bad input: Is the input a file of segment variant contexts? Variant context does not represent a copy number segment: [VC null @ 6:4130448-4130544 Q. of type=SYMBOLIC alleles=[C*, <DEL>] attr={END=4130544, Num_Probes=1, Segment_Call=-, Segment_Mean=-30.018694} GT=[] filters=. The local info in the segment file is:; 5 176563624 180687750 618 -0.053122 0; 6 203183 4128317 205 0.046724 0; 6 4130448 4130544 1 -30.018694 -; 6 4130545 6168103 42 -0.085445 0; 6 6174562 17463556 490 0.022415 0; 6 17493361 25510885 347 0.080520 0. This is a bad error message. The minimum size for a segment to be processed is 150 bases and that variant is only 96 bases, so it's failing that validation. #### Expected behavior; Should process variant without producing error. Hat tip: @jonn-smith for figuring out the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6575:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6575,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.2.2.0. ### Description . Running apt-get inside docker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,2,"['release', 'update']","['release', 'update']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/CalculateContamination.java; /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java. ### Affected version(s); - [x] Latest public release version - v4.2.0.0 (also detected on previous versions) ; - [x] Latest master branch as of 03/30/2021. ### Description ; **ContaminationModel**; **Problem:**; Where errorDepth is greater than oppositeDepth, the output contamination is reported as **‚Äô0‚Äô contamination** , which can be misinterpreted by the end user. calculateContaminationFromHoms receives the list of pileups PileupSummary; It iterates from 0.4 INITIAL_MAF_THRESHOLD down to zero. In each iteration pileups are selected using multiple, different strategies.; When the stdError exit condition is met (i.e., stdError < (contamination* MIN_RELATIVE_ERROR +MIN_ABSOLUTE_ERROR)), it reports out the contamination and stdError values. The issue is that this stdError exit condition is also met when contamination = 0, because in this case, stdError is also equal to 0, and thus is always less than the minimum value for (contamination * MIN_RELATIVE_ERROR [0.2] + MIN_ABSOLUTE_ERROR [0.001]), which cannot be less than 0.001. . final double stdError = homs.isEmpty() ? 1 : Math.sqrt(homs.stream().mapToDouble(ps -> {; final double d = ps.getTotalCount();; final double f = 1 - oppositeAlleleFrequency.applyAsDouble(ps);; return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);; }).sum()) / totalDepthWeightedByOppositeFrequency;. ** return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);**. Root cause:; At the first MAF iteration where errorDepth is greater than oppositeDepth, contamination is set to ‚Äú0‚Äù (according to the code logic shown below), the function exits the iteration process, and no further MAF thresholds are t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177:348,release,release,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. FilterAlignmentArtifacts. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. 4.3.0.0. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. ```; Using GATK jar /gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -XX:+UseNUMA -jar /gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar FilterAlignmentArtifacts -R /raid/bundle/hg38/Homo_sapiens_assembly38.fasta.gz -O WGS-NA12878.FilterAlignmentArtifacts.vcf --tmp-dir . -V WGS-NA12878.filtered.vcf -I WGS-NA12878.sorted.dedup.recal.bam --bwa-mem-index-image /raid/bundle/hg38/Homo_sapiens_assembly38.fasta.img; 11:24:09.761 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:24:09.942 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.942 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.3.0.0; 11:24:09.943 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:24:09.943 INFO FilterAlignmentArtifacts - Executing as root@D52BV-2U on Linux v4.15.0-202-generic amd64; 11:24:09.943 INFO FilterAlignmentArtifacts - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_352-8u352-ga-1~18.04-b08; 11:24:09.943 INFO FilterAlignmentArtifacts - Start Date/Time: February 24, 2023 11:24:09 AM CST; 11:24:09.943 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.943 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.943 INFO Filter",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:164,release,release,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. `SortSamSpark --sort-order coordinate`. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. `4.4.0.0`. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. An error occurs when using SortSamSpark to sort the large BAM file that contain long reads only (90x human wgs, min. read length>10kbp).; However, if the large BAM file contains short reads, it executes normally. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```shell; sysctl -w vm.max_map_count=2147483642; gatk SortSamSpark \; --input HG002-NA24385-GM24385.bam \; --output HG002-NA24385-GM24385.sorted.bam \; --sort-order coordinate \; --java-options ""-XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G"" \; --tmp-dir . \; -- \; --spark-runner LOCAL --spark-master local[96] --conf spark.local.dir=./tmp --conf spark.port.maxRetries=61495; ```. #### Expected behavior; _Tell us what should happen_. Output a sorted BAM file. #### Actual behavior; _Tell us what happens instead_. `java.lang.OutOfMemoryError: Required array length ? is too large`. The last lines of the log file.; ```; 11:00:42.884 INFO BlockManagerInfo - Removed taskresult_15758 on 172.20.19.130:43279 in memory (size: 10.5 MiB, free: 1076.2 GiB); 11:00:42.888 INFO TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool; 11:00:42.902 INFO DAGScheduler - ResultStage 0 (sortByKey at SparkUtils.java:165) finished in 1652.742 s; 11:00:42.915 INFO DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job; 11:00:42.916 INFO TaskSchedulerImpl - Killing all running ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:178,release,release,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; CalibrateDragstrModel; ### Affected version(s); - [ ] Latest public release version [gatk/4.2.0.0]. ### Description . gatk 4.2.0.0 CalibrateDragstrModel produces the following stacktrace.... ```; 13:55:31.187 INFO CalibrateDragstrModel - Initializing engine; 13:55:33.395 INFO CalibrateDragstrModel - Done initializing engine; 13:55:33.396 INFO ProgressMeter - Starting traversal; 13:55:33.396 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:55:42.364 INFO CalibrateDragstrModel - Shutting down engine; [April 4, 2021 1:55:42 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2384986112; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:161,release,release,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; Mutect2; ### Affected version(s); - [ ] 4.1.1.0. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; We have run mutect2 on the same sample using the same input crams, references, and intervals. The only discernible difference is the docker image used that we built. The difference between the first and second one is that the first one was built without samtools, the second one with samtools. The third is exactly the same as the second except it was re-built about a year or more later. Looking at a count of the `PASS` results based on each:. |Run type |var count|; |---------------------------|---------|; |docker no samtools | 8265 |; |docker yes samtools | 8283 |; |docker yes samtools rebuilt | 8273 |; |docker no samtools recently built | 8271 |. Out of curiosity, we tried building the docker again without samtools, so in theory, the only possible change is that when each docker is built, apt update is run. The differences are small, but is that expected? That with and without samtools, and if `apt` packages change, mutect2 could be influenced?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I can't replicate scenario 1 in the table because it was built in 2019, so apt packages were different then.; Scenario 2 dockerPull: `docker pull kfdrc/gatk:4.1.1.0`; Scenario 3 dockerPull: `docker pull pgc-images.sbgenomics.com/d3b-bixu/gatk:4.1.1.0`; Scenario 4 dockerPull: `docker pull migbro/gatk:4.1.1.0L`. No samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1; \; wget -q https://github.com/broadinstitute/g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269:1066,update,update,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269,1,['update'],['update']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; Picard IlluminaBasecallsToSam and IlluminaBasecallsToFastq. ### Affected version(s); - [X] Latest public release version [4.2.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; ""This bug has been fixed in Picard release https://github.com/broadinstitute/picard/releases/tag/2.25.4 - The version of gatk that you are using (4.2.0.0) was packaged with Picard https://github.com/broadinstitute/picard/releases/tag/2.25.0 in it (which has the bug)."" See [IlluminaBasecallsToSam and IlluminaBasecallsToFastq do not demultiplex NovaSeq barcoded reads](https://github.com/broadinstitute/picard/issues/1679) for details. The GATK release needs to be updated to contain Picard 2.25.4 or better. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; Run tools with NovaSeq run directory as input and many dual index barcodes. #### Expected behavior; _Tell us what should happen_; Reads having each of the dual index barcodes should be demultiplexed to separate files. #### Actual behavior; _Tell us what happens instead_; Reads having each of the dual index barcodes are all in the UNKNOWN files. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254:198,release,release,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254,6,"['release', 'update']","['release', 'releases', 'updated']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); _VariantEval, -O, --output_. ### Affected version(s); - [X] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Program starts then terminates with error:; `***********************************************************************`; `A USER ERROR has occurred: Couldn't read file file:///[.....]/X034.eval.grp. Error was: It doesn't exist.`; `***********************************************************************`. Note: The error is not thrown, and VariantEval completes successfully, if a zero-byte file with the name passed with the `-o` or `--output` arguments is created before executing VariantEval; For this example: `touch X034.eval.grp`. #### Steps to reproduce; Command line:; `gatk VariantEval -R $ref -L autosomes.list --eval W034.raw.annotated.vcf.gz --dbsnp dbsnp.vcf.gz -O X034.eval.grp`. #### Expected behavior; Expect the program to create its own output file (as other GATK tools do). #### Actual behavior; Terminates with error (above). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5674:124,release,release,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5674,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description . Functotator MAF output does not properly show genotypes from somatic multi-tumor VCF files produced using M2. It looks like only genotypes from the first tumor sample are shown, but there are no errors or messages to point the user to this fact. Only a single `tumor_sample` and `normal_sample` are reported in the MAF header:. ```; ##normal_sample=xxx; ##source=FilterMutectCalls; ##source=Funcotator; ##source=Mutect2; ##tumor_sample=xxx; ```. Conversely, instructing `Funcotator` to output VCF format properly adds the annotation to the INFO field while retaining the FORMAT-level genotypes works well. However, in this case the VCF header also only lists a single tumor_sample (take note: this is a separate bug, though mostly aesthetics) despite all tumor genotypes being included. #### Steps to reproduce; Run Funcotator with output format set to MAF on any multi-tumor VCF file. #### Expected behavior; Either one of:; 1. `Funcotator` should return an error when trying to process multi-tumor VCF to MAF output; 2. `Funcotator` MAF should output multiple lines per funcotation for each tumor sample, indicating the comparison in the `Tumor_Sample_Barcode` and `Normal_Sample_Barcode` columns.; 3. `Funcotator` should not output genotype information when processing multi-tumor VCF to MAF (this could also be an additional Funcotator parameter that must be switched on when requesting MAF output). #### Actual behavior; Funcotator runs without errors or warnings and the output file is missing genotypes for the other tumor samples",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5687:102,release,release,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5687,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description ; Funcotator returns a `NullPointerException` when trying to output compressed VCF:. ```; 15:35:26.085 INFO Funcotator - Creating a VCF file for output: XXXX; 15:35:26.125 INFO ProgressMeter - Starting traversal; 15:35:26.125 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.vcf.VcfFuncotationFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 15:35:26.328 INFO Funcotator - Shutting down engine; [February 15, 2019 3:35:26 PM EST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=3391094784; java.lang.NullPointerException; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:231); at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRenderer.close(VcfOutputRenderer.java:137); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:883); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:970); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683:102,release,release,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `GATK MarkDuplicatesSpark`; `GATK EstimateLibraryComplexity`. ### Affected version(s); - [x] Latest public release version 4.2.0.0. ### Description ; The metrics from `GATK MarkDuplicatesSpark` and `GATK EstimateLibraryComplexity` do not match, even though those from `GATK MarkDuplicatesSpark` are the same as `Picard MarkDuplicatesWithMateCigar`. #### Expected behavior; I'd expect that the metrics from `GATK MarkDuplicatesSpark` and `GATK EstimateLibraryComplexity` would be the same, since [here](https://gatk.broadinstitute.org/hc/en-us/articles/360050814112-MarkDuplicatesSpark) recommends to run `GATK MarkDuplicatesSpark` without metrics (it is faster) and run `GATK EstimateLibraryComplexity` afterwards. #### Actual behavior. EstimateLibraryComplexity ; ```; ## htsjdk.samtools.metrics.StringHeader; # EstimateLibraryComplexity INPUT=[temp/align/bwa_aln/c_lib1_L001.sorted.bam] OUTPUT=stats/align/estimate_library_complexity/c_lib1.metrics.txt MIN_IDENTICAL_BASES=5 MAX_DIFF_RATE=0.03 MIN_MEAN_QUALITY=20 MAX_GROUP_RATIO=500 MAX_READ_LENGTH=0 MIN_GROUP_COUNT=2 READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=2279706 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; ## htsjdk.samtools.metrics.StringHeader; # Started on: Wed Mar 24 21:31:32 CET 2021. ## METRICS CLASS picard.sam.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED SECONDARY_OR_SUPPLEMENTARY_RDS UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Unknown 0 9951 0 0 0 0 0 0. ## HISTOGRAM java.lang.Integer; duplication_group_count Unknown; 1 9951; ```. MarkDuplicatesSpark; ```; #",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7161:157,release,release,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7161,1,['release'],['release']
Deployability,## Bug Report. ### Affected tool(s) or class(es); `GermlineCNVCaller`. ### Affected version(s); - [x] Latest public release version [`4.3.0.0` and `4.4.0.0`]. ### Description ; `GermlineCNVCaller` pipeline provide different results with same GATK version (`4.3.0.0`) on different base Ubuntu images (`18.04` and `22.04`). Test results of GATK version `4.3.0.0` and `4.4.0.0` are same on Ubuntu 22.04 - I assume there are no changes in `GermlineCNVCaller` between `4.3.0.0` and `4.4.0.0`. #### Steps to reproduce; Command list:; ```sh; /soft/gatk-4.3.0.0/gatk PreprocessIntervals -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa --padding 0 -L chr1:10000-35000 -L chr22:198477-20003000 -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list. /soft/gatk-4.3.0.0/gatk AnnotateIntervals -L /outputs/gatk_intervals.interval_list -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list.annotated.tsv. /soft/gatk-4.3.0.0/gatk CollectReadCounts -I /inputs/E07002_normal_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_normal_alignment.bam.counts.hdf5; /soft/gatk-4.3.0.0/gatk CollectReadCounts -I /inputs/E07002_tumor_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.3.0.0/gatk DetermineGermlineContigPloidy -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --contig-ploidy-priors /outputs/a_valid_ploidy_priors_table.tsv.copy.tsv --output /outputs/COHORT_runDir --output-prefix COHORT --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.3.0.0/gatk GermlineCNVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `Mutect2` and `FilterMutectCalls`. ### Affected version(s); GATK 4.1.0.0 release (though I suspect this was also in 4.0.x). ### Description ; M2 force-calling multi-allelic sites using GGA mode results in automatic `mappinq_quality` filter if one allele does not have any reads mapped, even if the other variant allele has good mapping quality. In my testing this happened when I force-called the following IDH1 mutations:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO; 2 209113112 . C A . . .; 2 209113112 . C T . . .; ```. The first listed is the common IDH1 R132H variant and the second listed is the less common but equally pathogenic R132L variant. The purpose for force-calling both variants is that one wants to absolutely exclude the possibility of either variant at this site. In most my tests, variants would fail `FilterMutectCalls` because only one of the multi-allelic alleles would be present, eg. *(representative except of `Mutect2` + `FilterMutectCalls` output)*. ```; VAR 	2	209113112	.	C	A,T; FILTER	mapping_quality;read_position; INFO	MMQ=60,0,60; FORMAT	GT:AD 0/1/2:56,0,47; ```. Only in rare cases would the variant site `PASS`, and that's when there would be at least one variant read in the second allele, eg:. ```; VAR 	2	209113112	.	C	A,T; FILTER	PASS; INFO	MMQ=60,60,60; FORMAT	GT:AD 0/1/2:28,1,16; ```. #### Steps to reproduce; To reproduce this specific example you will need a BAM file with a C>T mutation at `2:209113112`, and no reads with an `A` at this position. You will then need to run M2 and `FilterMutectCalls` with `--genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles ...` set to a VCF with both lines as shown in the description. #### Expected behavior; `FilterMutectCalls` should not apply a `mapping_quality` filter if one of the alleles would pass. Perhaps the mapping quality filter could ignore alleles with zero mapped reads, rather than assigning a MMQ of zero by default? *Note that this issue would also",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5695:123,release,release,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5695,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `ParallelCopyGCSDirectoryIntoHDFSSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [2019-05-13]. ### Description . `ParallelCopyGCSDirectoryIntoHDFSSpark` behaves in the following strange way:. * under __master/latest__ release, it __fails__ to copy a GCS ""directory"" containing __BAMs__; * under __master/latest__ release, it __successfully__ copies a GCS ""directory"" containing __reference__; * changing the nio lib version from 81 to 66 in `build.gradle`, it __successfully__ copies GCS ""directories"" containing __reference__ or __BAMs__; * see attached logs. #### Steps to reproduce. Both scripts referred to below need to be updated accordingly, but trivially. * from the master branch, run the attached `test.nio.ver.81.sh`. * branch out from master, change the literal `81` to `66` on line 69 in `build.gradle`, run the attached `test.nio.ver.66.sh`. #### Expected behavior. Files in the ""directories"" given in the gs path copied successfully. #### Actual behavior; Fail. See logs attached. -------------; [test.nio.paraCopyHDFSSpark.zip](https://github.com/broadinstitute/gatk/files/3174143/test.nio.paraCopyHDFSSpark.zip). UPDATE:; reuploaded attachment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935:136,release,release,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935,5,"['UPDATE', 'release', 'update']","['UPDATE', 'release', 'updated']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `PrintReadsSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . I first encountered this type of error in a prototype tool I'm writing, so to dig further about what's happening, I run our simplest Spark tool&mdash;`PrintReadsSpark`. `PrintReadsSpark` reports errors when intervals are specified in a BED file (see command given in the stack trace). * Scenario 1: run with a WGS bam and give intervals via `-L PATH_TO_BED_FILE`, error is reported; * Scenario 2: run with the WGS bam and give intervals via `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 3: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L PATH_TO_BED_FILE`, no error; * Scenario 4: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 5: download the shrunken bam to local machine and run `PrintReadsSpark` with `-L PATH_TO_BED_FILE`, no error. Stack trace from scenario 1:; ```; ./gatk PrintReadsSpark \; -I hdfs://shuang-small-m:8020/data/HG00512.cram.samtools1_9.bam \; -O hdfs://shuang-small-m:8020/results/temp.bam \; -L hdfs://shuang-small-m:8020/data/intervals.bed \; -- \; --spark-runner GCS \; --cluster shuang-small \; --project broad-dsde-methods. Using GATK jar /Users/shuang/GATK/gatk/build/libs/gatk-spark.jar; found cached jar: gs://broad-dsde-methods/shuang/tmp/gatk-jars/gatk-spark_5710525a8758807e46bbb660ac998e63.jar. Replacing spark-submit style args with dataproc style args. --cluster shuang-small --project broad-dsde-methods -> --cluster shuang-small --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=false,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-DGATK_STA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:114,release,release,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `SAMRecord` from `GATKRead`. ### Affected version(s); - [x] Latest master branch as of January 30, 2024. ### Description ; When I run a tool with a bam file as input, the following code will give me a null:; ```java; @Override; public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {. // Build sets of read IDs for each file.; final SAMRecord samRecord = read.convertToSAMRecord(getHeaderForReads());; final SAMFileSource fileSource = samRecord.getFileSource();; System.out.println(fileSource);; ```. Output:; (a long list of `null`). #### Steps to reproduce; Create a ReadWalker that takes in a bam file. Here is an integration test that will replicate the issue:. ```java; public class ReadConcordanceIntegrationTest extends CommandLineProgramTest {. @Test; public void testTwoCrams() throws IOException {; final File output = createTempFile(""testReadConcordanceOutputFile"", "".txt"");; final File input = new File(GATKBaseTest.largeFileTestDir, ""expected.K-562.splitNCigarReads.chr20.bam"");. final ArgumentsBuilder args = new ArgumentsBuilder();. args.addInput(input);; this.runCommandLine(args.getArgsArray());; }; }; ```. #### Expected behavior; Output should be the file used in the read data source (bam file) for each read. #### Actual behavior; I get nulls instead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8671:712,integrat,integration,712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8671,1,['integrat'],['integration']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `combine_tracks.wdl`, `CombineSegmentBreakpoints`. ### Affected version(s); - [ ] Latest master branch as of October 4, 2018. ### Description ; `CombineSegmentBreakpoints` does not have any notion of the num probes or num het columns. As a result, it cannot update those values as the segments are broken into pieces. ; This will get more complicated if both segment files have NUM_POINT columns.; #### Steps to reproduce; Seg File 1; ```; CONTIG START END NUM_POINTS_COPY_RATIO; 1 100 200 25; ```. Seg File 2; ```; CONTIG START END type; 1 100 150 centromere; ```. Result:; ```; CONTIG START END NUM_POINTS_COPY_RATIO type; 1 100 150 25 centromere; 1 151 200 25 ; ```. This result is incorrect, since we have suddenly doubled the number of points b/w 1:100-200. #### Expected behavior; Result:; ```; CONTIG START END NUM_POINTS_COPY_RATIO type; 1 100 150 12 centromere; 1 151 200 13 ; ```; Assuming that there are 12 points in 1:100-150 and 13 points in 1:151-200",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5280:308,update,update,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5280,1,['update'],['update']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); `org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.BreakpointsInference`, hence affecting the location of breakpoint output by the SV discovery pipeline. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Micro-homology around breakpoints affects where we place breakpoints in the SV.; Take the simplest example of deletion; where (10A10G10A); ```; ......AAAAAAAAAAGGGGGGGGGGAAAAAAAAAA......; ```; becomes (10A); ```; ......AAAAAAAAAA......; ```; Here we have a homology of exactly 10A's.; When we detect the deletion by studying the alignment signature, the alt haplotype would have two alignments mapped to the reference, one ends just before the G-block, one starts just after the G-block, with the A-block on the alt haplotype mapped to two places.; We follow the left-align/left-justify convention, and place the POS 1-bp before the left most A (hence saying `10A10G` was deleted, as opposed to right-justify which would say `10G10A` deleted, in fact without the convention any contiguous substring of 20 bp long of `10A10G10A` would be correct). However, it can be imagined the homologous sequences flanking the G's are not exactly the same, or may not be the same length (small indels), and the alignments would contain small gaps in their CIGARs. By assuming the homologous sequence are of the same length, which is what we are doing now, we could get the breakpoint location wrong. This is generally not a serious problem, but when the accumulated gap sizes are large enough, we can end up too-far off. A similar issue is when inferring SVLEN for small tandem duplications, where we are assuming the extra copies have the same length. This is not always true and when the `DUP_SEQ_CIGARS` annotation is available, it should be easily fixable. When it is not available, one could use the difference between `SEQ_ALT_HAPLOTYPE` and END-POS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4883:209,pipeline,pipeline,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4883,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656:122,release,release,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656,5,"['Install', 'install', 'release']","['Install', 'install', 'installation', 'release']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); gatk GenotypeGVCFs. ### Affected version(s); - [X] Latest public release version [GATK 4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Files generated by 'gatk GenotypeGVCFs' with french locale in February (F√©vrier in french) August (Ao√ªt) or December (D√©cembre) have ISO-8859-1 encoding instead of UTF-8 encoding. Indeed, the output files have this line:. `##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output /volumes/vol002/COVID/GenomicDB/vcf/COVID.05022021.int00.vcf.gz --variant gendb://dbtot/int00 --reference /volumes/vol002/reference/human_g1k_v37.fasta --tmp-dir /volumes/vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:115,release,release,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); gatkcondaenv.yml from gatk-4.3.0.0.zip downloaded from https://github.com/broadinstitute/gatk/releases. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]. ### Description ; I downloaded gatk-4.3.0.0.zip from https://github.com/broadinstitute/gatk/releases, unzip it on my linux server, and installed gatk by runnimg command line:; conda env create -n gatk -f gatkcondaenv.yml; After installing ended, I checked my installed gatk version and found it be 3.8-1-0-gf15c1c3ef but not installed 4.3.0.0. Any solution?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8120:144,release,releases,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8120,7,"['install', 'release']","['installed', 'installing', 'release', 'releases']"
Deployability,"## Bug Report. ### Affected tool(s) or class(es); org.broadinstitute.hellbender.utils.fragments.FragmentUtils. ### Affected version(s); - [x] Latest public release version 4.1.8.1; - [X] Latest master branch as of September 8th, 2020. ### Description ; At, https://github.com/broadinstitute/gatk/blob/12511551a3e273a1ad767253ccba9918d6eb45b9/src/main/java/org/broadinstitute/hellbender/utils/fragments/FragmentUtils.java#L93-L96. Both insertions and deletions use `getBaseInsertionQualities`. Deletions should instead use `getBaseDeletionQualities`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6801:156,release,release,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6801,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool(s) or class(es); particularly _SelectVariants_, but really anything that writes out a vcf. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [2/6/2020]. ### Description ; There are minimal/inconsistent checks that variants added to vcfWriters are correctly ordered (an issue with htsjdk I think). This leads to an insidious bug, where a sorted vcf can be fed through SelectVariants, and depending on the flavor of output vcf, either crash, or succeed but output an incorrectly sorted vcf. The issue is that in some circumstances SelectVariants will trim alleles to their minimal representation, which can change the location of a variant record, and thus reorder them. However, SelectVariants does nothing to account for the potential order change. Since vcfWriter implementations in htsjdk seem to do minimal/inconsistent checks on the order of variants being added to them, this may write out an incorrectly sorted vcf, or throw an exception, depending on the flavor of vcfWriter. . #### Steps to reproduce; With attached (zipped because github) vcf, run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf`; Tool will succeed, but output vcf will be incorrectly sorted. Somehow, this incorrectly sorted vcf will also be accompanied by an index! Though if you try to run `IndexFeatureFile` on the output vcf separately, it will fail. . run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf.gz`; tool will throw exception w/ stack trace:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=17148456, end=17148456, featureStartFilePosition=2460, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=17148447, end=17148457, featureStartFilePosition=2509, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6443:169,release,release,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6443,1,['release'],['release']
Deployability,"## Bug Report. ### Affected tool; Mutect2. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/19/2020. ### Description; It looks like there may be a typo in Mutect2Engine.java that was introduced before the most recent release, https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2Engine.java#L392. The line currently reads:; ```java; if (bestNormalAltAllele.getLeft() == bestNormalAltAllele.getLeft()) {; ```; It seems like this line should instead be:; ```java; if (bestNormalAltAllele.getLeft() == bestTumorAltAllele.getLeft()) {; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6901:88,release,release,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6901,2,['release'],['release']
Deployability,"## Bug Report. ### Affected tool; Mutect2. ### Affected versions; - [x] Latest public release version 4.1.8.1; - [x] Latest master branch as of 9/20/2020. ### Description ; Mutect2‚Äôs header defines `AS_FilterStatus` as follows:; ```text; ##INFO=<ID=AS_FilterStatus,Number=A,Type=String,Description=""Filter status for each allele, as assessed by ApplyRecalibration. Note that the VCF filter field will reflect the most lenient/sensitive status across all alleles."">; ```. `AS_FilterStatus` uses the pipe character `|` for per-allele concatenation and a comma `,` for filter concatenation. This causes records to have an incorrect number of values at sites with multiple filters or multiple alleles. Some examples:; ```text; chr1 826950 . G T . clustered_events;contamination;map_qual;strand_bias AS_FilterStatus=map_qual,strand_bias,contamination;AS_SB_TABLE=86,101|7,0;DP=199;ECNT=3;GERMQ=93;MBQ=35,34;MFRL=193,211;MMQ=33,27;MPOS=6;NALOD=1.28;NLOD=5.42;POPAF=1.39;ROQ=80;TLOD=8.79 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:36,0:0.05:36:18,0:18,0:24,12,0,0 0/1:151,7:0.055:158:76,4:71,3:62,89,7,0; chr1 3633298 . GT G,GTT . contamination;multiallelic;normal_artifact;slippage;weak_evidence AS_FilterStatus=weak_evidence,contamination|weak_evidence,contamination;AS_SB_TABLE=89,7|7,0|7,0;DP=129;ECNT=1;GERMQ=67;MBQ=20,20,20;MFRL=0,0,0;MMQ=60,60,60;MPOS=17,31;NALOD=-0.2424,0.21;NLOD=6.4,6.36;POPAF=2.49,2.04;ROQ=93;RPA=11,10,12;RU=T;STR;STRQ=1;TLOD=3.04,4.6 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:58,4,4:0.072,0.069:66:28,2,2:28,2,2:54,4,8,0 0/1/2:38,3,3:0.083,0.084:44:21,1,3:15,2,0:35,3,6,0; ```. A quick fix would be to define `Number=1` for `AS_FilterStatus` in the VCF header. Alternatively, using a pipe for filter concatenation and a comma for per-allele concatenation might be more compliant with the VCF specification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6857:86,release,release,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6857,1,['release'],['release']
Deployability,"## Bug Report. ### Affected version(s); - Latest master branch as of 1/12/2022. ### Description ; When I tried to build from the github repo, I received the following error:. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 688. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all files for configuration ':runtimeClasspath'.; > Could not find biz.k11i:xgboost-predictor:0.3.0.; Searched in the following locations:; - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; Required by:; project :. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. #### Steps to reproduce; `git clone https://github.com/broadinstitute/gatk.git`; `cd gatk/`; `./gradlew bundle`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7636:375,configurat,configuration,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7636,1,['configurat'],['configuration']
Deployability,"## Bug Report. - OS: Arch Linux; - Java: 17. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Firstly, I run `./gradle localJar`. ```; Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip; ...........10%............20%...........30%............40%...........50%............60%...........70%............80%...........90%............100%. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:90,release,release,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,4,"['continuous', 'release']","['continuous', 'release', 'release-notes']"
Deployability,"## Bug Report. Dear developers,. I tried to update the GENCODE database and used the getGencode.sh scripts to get the data. However, I was not able to index the feature-file: Do you have any idea why that happens and how to get it done?. Code:; /home/robby/Tools/NGS/gatk-4.2.0.0/gatk IndexFeatureFile -I /home/robby/Tools/NGS/gatk-master4_2_src/scripts/funcotator/data_sources/gencode/hg19/gencode.v37lift37.annotation.REORDERED.gtf; Using GATK jar /home/robby/Tools/NGS/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/robby/Tools/NGS/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar IndexFeatureFile -I /home/robby/Tools/NGS/gatk-master4_2_src/scripts/funcotator/data_sources/gencode/hg19/gencode.v37lift37.annotation.REORDERED.gtf; 18:53:59.113 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robby/Tools/NGS/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 08, 2021 6:53:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:53:59.283 INFO IndexFeatureFile - ------------------------------------------------------------; 18:53:59.283 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.2.0.0; 18:53:59.284 INFO IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:53:59.290 INFO IndexFeatureFile - Initializing engine; 18:53:59.290 INFO IndexFeatureFile - Done initializing engine; 18:53:59.417 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 37): ##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103), mapped to GRCh37 with gencode-backmap Continuing, but err",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134:44,update,update,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134,1,['update'],['update']
Deployability,"## Bug Report. Hi there,; So I downloaded the gatk-4.4-0.0.zip and unzipped it for using gatk. I also created the conda env using the gatkcondaenv.yml and used conda to install java ""1.7.0_91"". But when I run ./gatk --list I got this error message: . `; ./gatk --list; Using GATK jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar --help; Error: Invalid or corrupt jarfile /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; `; Next, I moved on to git clone the gatk repository, trying to build gatk. Again, I stay in the java ""1.7.0_91"" gatk env that I already created. But I got this error msg this time:; `; ./gradlew localJar; Gradle 7.5.1 requires Java 1.8 or later to run. You are currently using Java 1.7.; `; When I switch back to the server default java (1.8.0_292-b10), i got another error msg.; `; java -version; openjdk version ""1.8.0_292""; OpenJDK Runtime Environment (build 1.8.0_292-b10); OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode). ./gradlew localJar. > Configure project :; Warning: using Java 1.8 but only Java 17 has been tested. FAILURE: Build failed with an exception. * Where:; Build file '/home/athchu/bin/gatk/build.gradle' line: 141. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > A Java 17 compatible (Java 17 or later) version is required to build GATK, but 1.8 was found. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; `; So to sum up, my issues are :; 1) downloaded gatk-4.4.0.0 but it contained invalid jar file and i ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432:169,install,install,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432,1,['install'],['install']
Deployability,"## Bug Report. No changes have been made to the BQSR code that calculates qualities, but there are differences in quality scores from version to version. This is to understand why. ### Affected tool(s) or class(es); BQSR. ### Affected version(s); - [x] Latest public release version. #### Steps to reproduce. Ran GATK 4.1.8 and 4.1.3 on the same bam, got different quality scores. #### Expected behavior. Expect same quality scores across these versions. #### Actual behavior. These are quality distributions that differ from the two different versions on the same bam.; [qual.pdf](https://github.com/broadinstitute/gatk/files/4984005/qual.pdf); [qual.pdf](https://github.com/broadinstitute/gatk/files/4984007/qual.pdf)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6728:267,release,release,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6728,1,['release'],['release']
Deployability,"## Bug Report. Originally reported by @ldgauthier via slack. ### Affected tool(s) or class(es); CalibrateDragstrModel. ### Affected version(s); - [X ] Latest public release version [4.2.0.0]. ### Description ; An out-of-memory exception when running the aforementioned tool in at least one of many samples. Location where the error occur does not seem to be always the same but it was fixable by increasing memory over 15Gb. #### Steps to reproduce. Since I'm not sure the data is public I won't disclose its location nor ID in this issue. Let's call it the ""SAMPLE"" in ""SAMPLE.cram"":. ```; gatk --java-options ""-Dsamjdk.reference_fasta=Homo_sapiens_assembly38.fasta -Xmx2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" \; CalibrateDragstrModel \; -R Homo_sapiens_assembly38.fasta \; -I SAMPLE.cram \; -str Homo_sapiens_assembly38.str \; -O SAMPLE.final.cram.dragstr \; --parallel \; --verbosity DEBUG; ```. ```Homo_sapiens_assembly38.str``` depends only on the reference and ca be composed using this:. ```; gatk ComposeSTRFile -R Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.str; ```. #### Expected behavior; Completes without issues. #### Actual behavior; a Java Out-of-Memory error is throw and the execution finished without results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7189:165,release,release,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7189,1,['release'],['release']
Deployability,"## Bug Report. We're finding that in rare instances that `GenotypeGVCFs` can emit a variant with a spanned allele (`*`), and a genotype that references the spanned allele, but fail to emit the upstream spanning variant. This seems like a bug to me - either the spanning variant should be emitted _or_ the spanned allele should revert to a reference call. FWIW I have a sneaking suspicion that this is related to setting a non-zero value for `-stand-call-conf` (see #5793). My guess is that in one part of the code it determines the upstream variant _will_ be emitted so retains the allele as spanned, but then somewhere later the upstream variant is filtered out. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [not tested]. ### Description ; Here's the example from the VCF in the attached zip file:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test_sample; chr17 46806234 . TC T 148.64 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:208,25:239:116,16:90,8:99:156,0,6824; chr17 46806237 . TTCTCTCTCTCTC TTCTC,* 1528.04 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 1/2:3,60,33:174:1,29,20:1,21,11:99:3633,1088,2142,1538,0,3285; ```. You can see from this that a) the first variant does not have a spanned allele, implying that there cannot be a spanning event further upstream and b) the second variant has a spanned allele that is present in the `1/2` genotype. #### Steps to reproduce. The attached zip file contains a reduced test case with a 3-record gVCF and a 2-record VCF that exhibits the problem. To reproduce:. 1. Unzip the attached zip file; 2. Edit `command.sh` to put in the path to HG19; 3. Run `. command.sh` in the directory with the extracted files. #### Expected behavior; Either the spanning variant should be emitted, or the spanned allele should not be. #### Actual behavior; A spanned allele is emitted when there is no spanning variant!. ZIP file with test case: [spanned_allele_not_spanne",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6031:759,release,release,759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6031,1,['release'],['release']
Deployability,"## Bug Report; ### Version Information; GenomicsDBImport 4.1.9.0. ### Summary; A user posted on the forum with an error from GenomicsDBImport. @nalinigans @mlathara Can you determine what is causing this java.lang.IndexOutOfBoundsException?. This request was created from a contribution made by vivekruhela on January 12, 2021 19:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport). \--. Dear GATK Team,. I am using GATK version 4.1.9.0 for my WES data pipeline. In order to get accurate somatic call, I am trying to generate the Panel of Normal (PON) using GenomicsDBImport module of GATK. While using GenomicsDBImport for PON generation, I am not getting any output from my command. Here is the command I used to print the stack trace:. ```; gatk GenomicsDBImport \\ ; ; \-R /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037:622,pipeline,pipeline,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037,1,['pipeline'],['pipeline']
Deployability,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7007:174,install,installed,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007,2,"['install', 'pipeline']","['installed', 'pipeline']"
Deployability,"## Bug Report; Hi, we are using the dockstore version of the GATK variant calling pipeline that leverages mutect 2:; [github.com/broadinstitute/gatk/mutect2:4.1.8.1](https://dockstore.org/workflows/github.com/broadinstitute/gatk/mutect2:4.1.8.1). We're processing human glioma data, and currently we are making it through much of the pipeline, but failing on `GetPileupSummaries`. There's a thread about it on the discussion board [here] (https://gatk.broadinstitute.org/hc/en-us/community/posts/6179012337819-No-Pileup-Tables). . We are specifying a file for `variants_for_contamination`, and a file for `variants_for_contamination_idx` in the workflow, but the index is never passed to `GetPileupSummaries`, and it fails with this enigmatic error message:. ```; A USER ERROR has occurred: An index is required but was not found for file gs://bruce-processed-data/Prins_Cloughesy_Neoadjuvant/terra_reference_files/small_exac_common_3.hg38.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input.; ```. If you check out the source code in [mutect2.wdl](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl), you can see that that input variable `variants_for_contamination_idx`, which we have thoughtfully set and passed into the workflow, is never actually used in `GetPileupSummaries`. I'm not even sure there is an option to pass the index, from reading the [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360037593451-GetPileupSummaries). Here is an example of how the command is being called within our workflow:. ```; gatk --java-options ""-Xmx149500m"" GetPileupSummaries -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://fc-d31bc4e7-6d10-4dc4-a585-5895ab2346f3/cfce2061-efd6-449e-bdc9-a7ff2b633644/PreProcessingForVariantDiscovery_GATK4/b4adf777-4f97-425c-b3e2-b37c9d927667/call-GatherBamFiles/SRR7588418.hg38.bam --interval-set-rule INTERSECTION ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7935:82,pipeline,pipeline,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7935,2,['pipeline'],['pipeline']
Deployability,"## Bug Report; I was running the JointDiscovery pipeline as a part of the GATK Best Practices pipeline. I am running this on many vcf files (~150) called by the HaplotypeCaller. I am getting this error: . ```; 19:01:58.009 WARN VariantDataManager - WARNING: Very large training set detected. Downsampling to 2500000 training variants.; 19:04:18.918 INFO VariantRecalibrator - Shutting down engine; [September 16, 2019 7:04:18 PM EDT] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 912.93 minutes.; Runtime.totalMemory()=3204972544; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.MultivariateGaussian.<init>(MultivariateGaussian.java:31); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GaussianMixtureModel.<init>(GaussianMixtureModel.java:34); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:48,pipeline,pipeline,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,2,['pipeline'],['pipeline']
Deployability,"## Bug Report; JDK8 is no longer available for the current stable Debian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:73,release,release,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,3,"['install', 'release']","['install', 'release']"
Deployability,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7008:552,release,release-,552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008,1,['release'],['release-']
Deployability,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:697,release,release,697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['release'],['release']
Deployability,"## Bug/Usability Report. ### Affected tool(s) or class(es); Mutect2 WDL. ### Affected version(s); - [x] Latest public release version [4.1.81]; - [x] Latest master branch as of October 28, 2021. ### Description ; The Mutect2 WDL's Funcotate task has an unintuitive setup with regard to setting memory for the Funcotate task. Funcotate task memory is defined [here](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L1108); ![image](https://user-images.githubusercontent.com/45641912/139333822-aa0b3adc-b92e-4317-a75e-da322f96822f.png). This is using the dictionary defined earlier called **standard_runtime**. ![image](https://user-images.githubusercontent.com/45641912/139333917-0d97ef00-88e6-4340-8cee-e3295127eab8.png). This dictionary uses a variable called **machine_mem** which is calculated using the workflow's **small_task_mem** input, which is configurable. ![image](https://user-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:118,release,release,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,1,['release'],['release']
Deployability,"## Documentation request. ### Description ; I propose that installation of gcc be added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:59,install,installation,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,7,"['Install', 'install', 'release']","['Installing', 'install', 'installation', 'installed', 'installing', 'release', 'released']"
Deployability,"## Documentation request. ### Description ; I was unable to successfully follow the R setup instructions required to run integration tests locally. I don't know whether this is a general concern regarding initial setup on Mac OS X High Sierra 10.13.6, or the problem is specific to my system. . #### R installation itself; Expected: `brew install R` would install R with all necessary core functionality.; Actual: `brew install R` installed a version of R without X11 support. The binary I downloaded from [CRAN](https://cran.r-project.org/bin/macosx/) had the proper support. #### R package installation; Expected `sudo Rscript scripts/docker/gatkbase/install_R_packages.R` would install the necessary packages for R scripts needed.; Actual: Failure to compile source packages, with an error like `clang: error: unsupported option '-fopenmp'`. I made some attempts to update my local `clang` but was unsuccessful. Instead, I installed the packages at the R prompt:; ```; $ R; > install.packages('ggplot2'); > install.packages('reshape'); > install.packages('gplots'); > install.packages('gridExtra'); > install.packages('gsalib'); > install.packages('data.table'); > quit(); ```. After doing so, my test run `TEST_TYPE=integration ./gradlew shadowJar test` succeeded.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:121,integrat,integration,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,17,"['install', 'integrat', 'update']","['install', 'installation', 'installed', 'integration', 'update']"
Deployability,"## Documentation request. ### Tool(s) or class(es) involved. In the document `docs/mutect/mutect.pdf` there are many references to filter names that have either changed or used shorthand names. We should update the documentation to reflect the actual filter names used in Mutect2. Some examples:; ""fragment_length"" in the document refers to ""fragment"" filter.; ""duplicate_evidence"" as ""duplicates""; ""base_quality"" as ""base_qual"". There are probably a number of other differences, we should ensure all are up to date.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6965:204,update,update,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6965,1,['update'],['update']
Deployability,"## Documentation request. ### Tool(s) or class(es) involved. LeftAlignIndels. ### Description . The example for LeftAlignIndels uses a parameter `-O` which doesn't exist for the tool - the parameter listed in the documentation is `--OUTPUT`. Either the example should be updated to use `--OUTPUT`, or the tool should be changed to accept `-O`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5072:271,update,updated,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5072,1,['update'],['updated']
Deployability,"## Documentation request. ### Tool(s) or class(es) involved; GermlineCNVCaller. ### Description ; I'm trying to get a pipeline running to call germline CNVs on small cohorts (20-40) PCR free whole genome samples sequenced to ~45X depth. I'm running into problems figuring out how wide to scatter the analysis, and how to allocate resources. It would be incredibly helpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My second",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:118,pipeline,pipeline,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,## Documentation request. ### Tool(s) or class(es) involved; LearnReadOrientationModel. ### Description ; The tool LearnReadOrientationModel does not appear in the tool docs. We would like to update the documentation for this tool so that it is included with the other tool docs when GATK is updated and is more visible to users.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6862:192,update,update,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862,2,['update'],"['update', 'updated']"
Deployability,"## Documentation request. ### Tool(s) or class(es) involved; Readme for M2 in https://github.com/broadinstitute/gatk/tree/master/scripts/mutect2_wdl. ### Description ; This is the text currently in the readme, it needs to be updated to feature Funcotator instead of Oncotator:. > Functional annotation (Oncotator); > ; > The M2 WDL can optionally run oncotator for functional annotation and produce a TCGA MAF from the M2 VCF. Oncotator is not a GATK4 tool and is provided in the M2 WDL as a convenience. There are several notes and caveats; > ; > Several parameters should be passed in to populate the TCGA MAF metadata fields. Default values are provided, though we recommend that you specify the values. These parameters are ignored if you do not run oncotator.; > ; > Several fields in a TCGA MAF cannot be generated by M2 and oncotator, such as all fields relating to validation alleles. These will need to be populated by a downstream process created by the user.; > ; > Oncotator does not enforce the TCGA MAF controlled vocabulary, since it is often too restrictive for general use. This is up to the user to specify correctly. Therefore, we cannot guarantee that a TCGA MAF generated here will pass the TCGA Validator. If you are unsure about the ramifications of this statement, then it probably does not concern you.; > ; > More information about Oncotator can be found at: http://archive.broadinstitute.org/cancer/cga/oncotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889:225,update,updated,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889,1,['update'],['updated']
Deployability,"## Documentation request. ### Tool(s) or class(es) involved; [Mutect2 WDL's README](https://github.com/broadinstitute/gatk/tree/2e6045a259ed2ded3e9036a5b44a1f8ba330860d/scripts/mutect2_wdl) references several template JSONs that do not seem to exist in this repository, specifically:; * mutect2_multi_sample_template.json; * mutect2_template.json; * mutect2-replicate-validation_template.json. There is [one JSON](https://github.com/broadinstitute/gatk/blob/2e6045a259ed2ded3e9036a5b44a1f8ba330860d/scripts/mutect2_wdl/mutect_resources_json/mutect_resources_process_gnomAD_2.1.json) in the folder, although it's not immediately clear which of these three (if any) it is meant to replace. ### Description ; I did find some JSONs in the deprecated repo, although I'm not sure if they need to be updated. https://github.com/broadinstitute/gatk-protected/tree/master/scripts/mutect2_wdl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7596:793,update,updated,793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7596,1,['update'],['updated']
Deployability,"## Documentation system request. Currently, the tooldoc generation system does not separate arguments that relate to deployment decisions like compute platform (eg `--gcs-project-for-requester-pays`) from the ones that modify the analytical or processing behavior of the tools. This adds to the cognitive burden involved in sorting through all the options available for a given tool. We'd like to have a separate category for these arguments so that they would be isolated from the rest. . In addition, there are a bunch of convenience arguments in the common args section that have more to do with how we're running the tool than its analysis behavior, and could also be consolidated into this separate category (or their own category but that might be too granular). Examples below are from the popular tool [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_walkers_variantutils_SelectVariants.php):. #### Arguments that would be stratified as platform args. `--cloud-index-prefetch-buffer`; `--cloud-prefetch-buffer`; `--disable-bam-index-caching`; `--gcs-max-retries`; `--gcs-project-for-requester-pays`. #### Arguments that would be stratified as convenience args. `--arguments_file` ; `--help` ; `--version` ; `--create-output-bam-index` ; `--create-output-bam-md5`; `--create-output-variant-index`; `--create-output-variant-md5`; `--gatk-config-file`; `--QUIET`; `--seconds-between-progress-updates`; `--tmp-dir`; `--use-jdk-deflater`; `--use-jdk-inflater`; `--verbosity`; `--showHidden` -> I thought we had got rid of hidden args??. These could also be stratified as convenience but one could argue they affect tool behavior qualitatively:. `--disable-sequence-dictionary-validation`; `--lenient`; `--read-validation-stringency`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5234:117,deploy,deployment,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5234,2,"['deploy', 'update']","['deployment', 'updates']"
Deployability,"## Feature request and Question. Original question was posted in GATK forum https://gatkforums.broadinstitute.org/gatk/discussion/12026/how-to-do-downsampling,; but it seems to me that the question should be posted here to ask the developer team. ### Tool(s) or class(es) involved; PrintReads. ### Description. In GATK4, printReads doesn't have an option to do downsample to coverage anymore. Is there any reason for that ? Or is there any update suggestions to do the same thing but migrating it from GATK3 to GATK4 ? The forum maintainer told me in original discussion that there is a `DownsampleSam` function in picard, but it can't be used to downsample to coverage directly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075:440,update,update,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075,1,['update'],['update']
Deployability,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6912:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912,6,"['release', 'update']","['release', 'update', 'updated']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved. (sv) VCF producing tool(s). ### Description. The VCF spec allows `POS` column to take value 0, when the suspected event is at a telomere.; The given example is in section 5.4.5 (see example event illustrated in Figure 6 and VCF records below the figure).; However, currently GATK writes VCF via `VariantContext`'s, which defines coordinate 0 as illegal.; I can of course push this feature request to htsjdk, if that is deemed more appropriate. **UPDATE**; Looking back at the error message, it is actually the `SimpleInterval` that I use for constructing the `VariantContext` throwing the error message.; Temporary workaround would be to ""hack"" the POS to be 1 or N, and warn using an INFO annotation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5915:501,UPDATE,UPDATE,501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5915,1,['UPDATE'],['UPDATE']
Deployability,"## Feature request. ### Tool(s) or class(es) involved. SV pipeline, Funcotator, etc. ### Description. In trying to build test data for SV, time and time again we face the problem of not being able to find actual desired events on the two chromosomes 20 and 21, hence end up having to painfully perform all kinds of coordinate hacks in order to have enough test coverage. It seems that the Funcotator team is also facing a similar issue. Therefore it will be great if the whole reference genome for HG38, and maybe HG19 as well, can be included in the tests, so that tool developers spend less time worrying about hassles in moving real events to chr20 and chr21. One of the potential downside is obvious: it increases the repo size and time for running tests (downloading a bigger file) on Travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111:58,pipeline,pipeline,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111,1,['pipeline'],['pipeline']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; All WDL tests (Mutect2, CNV, Mitochondria pipeline, etc). ### Description; I'd like to be able to include tasks in GATK WDLs that use NIO (tasks with `String input_file` rather than `File input_file`). When I tried this with local git lfs files I got an error saying that the file could not be found (even though the file was being downloaded correctly). I then tried putting the file in `gs://hellbender/test/resources/large`, but when the tool tried to run on travis I got a permission error (see below). It would be great if the WDL tests all ran in the cloud since that's the main way we expect to run these WDLs. It would also be great it the local tests could account for NIO tasks (especially as we want to make more tasks use NIO in the future). ```; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified. It is possible to skip checking for Compute Engine metadata by specifying the environment variable NO_GCE_CHECK=true.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:438); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:236); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at com.google.cloud.RetryHelper.run(RetryHelper.java:76); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:235); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:687); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5855:97,pipeline,pipeline,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5855,1,['pipeline'],['pipeline']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; Docker container environment for FireCloud / GATK. ### Description. I started a FireCloud instance with a GATK example. It looks like although conda does seem to be correctly pulling TensorFlow from the Anaconda repository, TensorFlow is still not being enabled with Intel MKL-DNN (which would make TensorFlow much faster on CPU). To test this, you can start a notebook or python session and do:. `import tensorflow; print(tensorflow.pywrap_tensorflow.IsMklEnabled())`. If True, then MKL-DNN is enabled in TensorFlow. Currently, this is showing up as false. I'm wondering whether I could work with someone (possibly Sam @lucidtronix) to update the conda environment. Also, the compute instances on FireCloud are using older CPU hardware (AVX-2). Is there any way to update this to a Skylake or Cascade Lake instance (AVX-512/VNNI)?. Thanks.; -Tony",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6020:692,update,update,692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6020,2,['update'],['update']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6839:1322,update,update-flags,1322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839,2,['update'],"['update', 'update-flags']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport(v4.1.8.1). ### Description; Hello, I was construct to genomicdb using GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtim",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:183,update,update,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,3,['update'],['update']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; LearnReadOrientation (& others I believe). ### Description; Wondering if you would consider modifying the exit status for 'java.lang.OutOfMemoryError` to reflect it being a memory-related error, perhaps `137`? This would help with pipelines that will retry with more memory in response to a memory-related error. The exit status is currently a generic `1`:. ```; Command exit status:; 1. ...; [March 23, 2023 at 5:50:17 AM GMT] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 2,210.83 minutes.; Runtime.totalMemory()=7796817920; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at org.apache.commons.math3.linear.Array2DRowRealMatrix.<init>(Array2DRowRealMatrix.java:61); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelEngine.<init>(LearnReadOrientationModelEngine.java:131); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel.doWork(LearnReadOrientationModel.java:163); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /gatk/gatk-package-4.4.0.0-local.jar; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8264:286,pipeline,pipelines,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8264,1,['pipeline'],['pipelines']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; M2 PoN Creation. ### Description; There is no progress meter when running `CreateSomaticPanelOfNormals`. This makes debugging harder and the tool could be accidentally identified as frozen. ### Proposed solution; `final Consumer<Locatable> progressUpdater,` as a parameter to the backend class.; The CLI ( `CreateSomaticPanelOfNormals`) can just pass in `l -> progressMeter.update(l)` as long as the CLI extends GATKTool.; When you want to disable the progress meter, you can simply pass in: `l -> {}`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5629:429,update,update,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5629,1,['update'],['update']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; M2 WDL and FC deployment of M2. ### Description; We should specify the same file listed in the GATK forum (https://gatkforums.broadinstitute.org/gatk/discussion/4154/howto-install-and-run-oncotator-for-the-first-time), which can be downloaded from: https://personal.broadinstitute.org/lichtens/oncobeta/tx_exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt; This should be used as the default transcript selection list for funcotator (@jonn-smith I assume that funcotator and oncotator use the same format for this file. Please confirm.). The only time you would not want this file is if you are not running on hg19. For other references, ideally, we would want different lists. - This list needs to be put into a bucket (gatk-best-practices?); - Please notify @bshifaw for deployment in the FC featured workspace in the appropriate funcotator parameter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5841:69,deploy,deployment,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841,3,"['deploy', 'install']","['deployment', 'install-and-run-oncotator-for-the-first-time']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; M2, at least. ### Description; With Cromwell v33, we should be able to merge the mutect2.wdl and mutect_nio.wdl into one WDL. There will need to be WDL modifications, for sure. https://github.com/broadinstitute/cromwell/releases",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4948:275,release,releases,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4948,1,['release'],['releases']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; The docker image would need to be updated (gatkbase docker image). See line ~17 in `scripts/docker/gatkbase/Dockerfile`. ### Description; Can you include a later version of samtools in the GATK image? The current samtools version (1.7) does not support crams. ; I believe that you would need to update gatkbase to make this change. . Additional suggestion, which should not be a requirement for closing this issue: you may want to fix the versions of the software in gatkbase (lines ~6-25 in `scripts/docker/gatkbase/Dockerfile`). Note: I have only replicated this issue in `us.gcr.io/broad-gatk/gatk:4.2.6.1`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7886:89,update,updated,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7886,2,['update'],"['update', 'updated']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; ValidateBasicSomaticShortMutations . ### Description; It turns out that this tool is doing a subset of the CGA tool, MutationValidator. Originally, the understanding (by both DSP and CGA) was the the GATK tool was doing a different algorithm, but this turned out to be incorrect. We should rename the GATK tool perhaps to SomaticShortMutationValidator and cite MutationValidator. Any relevant WDL should be updated to prevent unnecessary workflow failures. @davidbenjamin . (citation does not exist as per last offline meeting with CGA)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5871:462,update,updated,462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5871,1,['update'],['updated']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _FindBreakpointEvidenceSpark_, _StructuralVariationDiscoveryPipelineSpark_, when using _XGBoostEvidenceFilter.java_. ### Description; The SV pipeline filters BreakpointEvidence based on BreakpointDensityFilter, or optionally XGBoostEvidenceFilter. The XGBoostEvidenceFilter uses a saved classifier model trained with Python code external to the GATK. This poses two main problems:; 1) The external Python code was designed for proof-of-principle and method development, not maintainability or ease of use. Additionally, GATK users and developers are assumed to be familiar with Java, not necessarily Python.; 2) The external Python code must share heterogeneous data with Java for unit/integration tests (supplying test BreakpointEvidence, expected classifier features, and expected classifier probabilities). Currently this is done via JSON files organized to (invertibly) store Pandas or Numpy objects. The resulting code to load these JSON files in on the Java side is complex.; These problems can be resolved by; 1) Replacing external python code by porting to an **experimental** tool in the GATK.; 2) Replacing JSON files with a serialization strategy currently supported by the GATK (e.g. Kryo). Additional benefits can be obtained by ensuring that the classifier-training subroutines are sufficiently general to speed development for other projects that may want to use boosted decision trees for classification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4922:196,pipeline,pipeline,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4922,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator scripts_. ### Description; The scripts for Funcotator (`src/scripts/funcotator`) should all be refactored, if necessary, to allow for command-line arguments rather than internal configurations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5346:245,configurat,configurations,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5346,1,['configurat'],['configurations']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator, VcfFuncotationFactory_. ### Description; When using a VCF file as a data source, `Funcotator` should include the `ID` column as a separate funcotation. The specific use case is for CLINVAR, but should apply to all VCF data sources. The annotation can be added as `<NAME>_ID` in the VCF data source's output annotations. This feature is requested specifically for the clinical pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5186:444,pipeline,pipeline,444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5186,1,['pipeline'],['pipeline']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator,GencodeFuncotationFactory_. ### Description; When annotating a variant and the `VariantClassification` is `SPLICE_SITE, INTRON`, Funcotator should include a non-empty `cDNA` annotation. This `cDNA` annotation should include the number of bases that the start of the variant is away from the exon, as well as the reference and alternate alleles of the variant in question. Concretely:; `c.e[EXON NUMBER][+|-][BASES FROM EXON][REF ALLELE]>[ALT ALLELE]`. For example:; c.e2-1A>G; Where:; 2 = the number of the closest exon (1-based); -1 = number of bases away from the exon (1 before); A = Reference allele; G = Alternate allele. This feature is requested for the clinical pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5187:737,pipeline,pipeline,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5187,1,['pipeline'],['pipeline']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_, _DataSourceFuncotationFactory_. ### Description; Funcotator should support NIO for data sources and data sources backing files.; In addition, the data source readers should be updated to support multiple backing files to support the `gnomAD` case (http://gnomad.broadinstitute.org/downloads).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5348:245,update,updated,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5348,1,['update'],['updated']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; Currently the data sources for the clinical pipeline work contain ExAC. This must be updated to use gnomAD. The change will require a new release of the data sources which must be connected to the data source downloader tool. Additionally, these new data sources must be validated in four ways:; - By visually inspecting the gnomAD source file for correctness.; - By verifying that the source file for gnomAD does not contain special characters.; - By validating that the source file for gnomAD is a valid VCF (assuming it is used VCF format).; - By running a large file and spot checking at least 10 variants for correctness. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5259:130,pipeline,pipeline,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5259,3,"['pipeline', 'release', 'update']","['pipeline', 'release', 'updated']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; _org.broadinstitute.hellbender.engine.ProgressMeter_; _org.broadinstitute.hellbender.utils.nio.NioFileCopierWithProgressMeter_. ### Description; One `ProgressBar` to rule them all. One `ProgressBar` class hierarchy to bind them. Progress bars/meters should be consolidated into a single class hierarchy, with threaded updates that are triggered by both a `time interval` and a `percentage/# of records completed count` (whichever occurs first). This class hierarchy should have an abstract base `ProgressMeter` class, which has at least 2 concrete child classes - `GenomicProgressMeter` (equivalent to `ProgressMeter`), and `NumericProgressMeter` (which encapsulates the progress meter functionality inside `NioFileCopierWithProgressMeter`). . The progress meter functionality inside `NioFileCopierWithProgressMeter` should be replaced with the resulting progress meter class. The `ProgressMeter` class should be similarly updated / replaced within `GATKTool` to leverage the new class hierarchy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5178:373,update,updates,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5178,2,['update'],"['updated', 'updates']"
Deployability,"## Feature request. ### Tool(s) or class(es) involved; `SelectVariants`. ### Description; In order to run SelectVariants with VCF inputs that are in separate locations from their index files or to stream SelectVariants using https from Azure blob storage, we need a way to provide the index file in a separate argument from the `-V` input. @jamesemery started thinking this through (copying this from slack):. > In `featureDataSource.getTribbleFeatureReader()` we currently initialize the datasources in `getFeatureReader()` which gets called by `VariantWalker.initializeDrivingVariants()` . You could stick an override into that where you thread down the path for the index source through that path and optionally (only if the index is explicitly supplied by the user) push it down into the `getTribbleFeatureReader()` calls at the bottom of the stack there. @droazen any thoughts on this? @VJalili Would adding this feature to `SelectVariants` be useful for your pipelines at all?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8568:965,pipeline,pipelines,965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8568,1,['pipeline'],['pipelines']
Deployability,"## Feature request. ### Tool(s) or class(es) involved; gatk 4.1.4.0, PlotModeledSegments. ### Description; In exploring the CNV pipeline discussed [here](https://gatkforums.broadinstitute.org/gatk/discussion/11683), I ran into an issue where some of my CNVs that were at much higher copy ratios (upwards of 20/2) were not being plotted, since it appears the R script for part of this tool only limits to a maximum copy ratio of 4. . I think the best case would be to add an additional flag to PlotModeledSegments where a user can specify the exact height they want their output graph to go to. Alternatively, it might be useful to determine the highest copy ratio in the supplied `modelFinal.seg` file and pass that to `SetUpPlot()`. . I ended up rewriting part of `WriteModeledSegmentsPlot()` to use this for my own project, and this reflects my second suggestion of determining the highest ratio and plotting using that. This might not be ideal for all users, since you'll lose detail in the lower copy ratios, but I hope this is a good start! . --- ; ```; WriteModeledSegmentsPlot = function(sample_name, allelic_counts_file, ; denoised_copy_ratios_file, modeled_segments_file, ; contig_names, contig_lengths, output_dir, output_prefix) {; modeled_segments_df = ReadTSV(modeled_segments_file); max_log2_ratio = max(modeled_segments_df$LOG2_COPY_RATIO_POSTERIOR_10, ; modeled_segments_df$LOG2_COPY_RATIO_POSTERIOR_50,; modeled_segments_df$LOG2_COPY_RATIO_POSTERIOR_90); max_copy_ratio = (2^max_log2_ratio) + 1; ; num_plots = ifelse(all(file.exists(c(denoised_copy_ratios_file, allelic_counts_file))), 2, 1); png(output_file, 12, 3.5 * num_plots, units=""in"", type=""cairo"", res=300, bg=""white""); par(mfrow=c(num_plots, 1), cex=0.75, las=1); ; if (file.exists(denoised_copy_ratios_file) && denoised_copy_ratios_file != ""null"") {; denoised_copy_ratios_df = ReadTSV(denoised_copy_ratios_file); ; #transform to linear copy ratio; denoised_copy_ratios_df[[""COPY_RATIO""]] = 2^denoised_copy_ratios_df[[""LOG2_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6391:128,pipeline,pipeline,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6391,1,['pipeline'],['pipeline']
Deployability,"## Feature request. Make joint genotyping functionality available as a publicly accessible function to another class/program without passing through the GATK command line interface. ### Tool(s) or class(es) involved; VariantContext; GenotypeGVCFs; Underlying engine classes. ### Description; For various use cases where our pipelines produce in-memory VariantContext objects it would be faster and easier to pass these directly to a joint genotyping function and extract the results back into memory rather than writing to VCF, running the GenotypeGVCFs pipeline via the command line interface and then re-ingesting the resultant VCFs. From discussions during the GATK Working Group meetings it appears this request is similar in principle to existing functionality for the HaplotypeCaller that was implemented by ""extracting the engine"" from the HaplotypeCaller walkers so that it can be instantiated outside the command line utility. Ideally, this implementation should make it possible to instantiate any necessary engine classes pass VariantContext objects directly to the GenotypeGVCFs.apply or GenotypeGVCFs.regenotypeVC and receive the re-genotyped VariantContext objects back for further processing from Java code. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:324,pipeline,pipelines,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,## Feature request. Mitochondria Pipeline. ### Description; Many of the users on Terra that work with the GATK workflows get stuck working with requester-pays data. (e.g. [forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360067820111/comments/360011055131)). This request asks that the workflow include the requester pays option like the [pathseq](https://github.com/broadinstitute/gatk/blob/5e5747b76fa98a3b6731dbc328e292fa941f269b/scripts/pathseq/wdl/pathseq_pipeline.wdl#L83) workflow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6828:33,Pipeline,Pipeline,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6828,1,['Pipeline'],['Pipeline']
Deployability,"## Feature request. Since CombineVariants will not be ported, we need equivalent functionality to its ability to annotate ""set"", ie which callset(s) a site is present in. Here is an excerpt from a tutorial that describes this functionality in action:. ----. To find out which set each variant belongs to, we can use CombineVariants. CombineVariants has a way to annotate each site with which set the site belongs to. For example, if a site is in GIAB and failed hard filtering but passed VQSR, CombineVariants will annotate the site with set=G-filterInH-V. The ""filterIn"" flag before the filtering method tells us the site failed the filtering method, hence it was ""filtered"" in the set. java -jar GenomeAnalysisTK.jar \; 	-T CombineVariants \; 	-R ref/human_g1k_b37_20.fasta \; 	-V:G truth_dataset/NA12878.GIAB.vcf \; 	-V:H vcfs/NA12878.hard.filtered.vcf \; 	-V:V vcfs/NA12878.VQSR.filtered.vcf \; 	-o sandbox/NA12878.Combined.vcf . The set-annotated VCF looks like this:. ````; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT INTEGRATION NA12878; 20 61795 rs4814683 G T 2034.16 PASS AC=2;AF=0.500;AN=4;(...);set=Intersection‚Äã ‚Äã GT:AD:ADALL:DP :GQ:PL 0/1:218,205:172,169:769:99 0/1:30,30:.:60:99:1003,0,1027; ````. In this record, ""set=Intersection‚Äã"" indicates this record was present and unfiltered in all callsets considered. Here is a key of all the possible combinations for this 3-way venn:. | Meaning | Annotation |; |:-|:-|; | In GIAB only | G |; | In GIAB and failed VQSR only | G-H-filterInV |; | In GIAB and failed both hard filtering and VQSR | G-filterInH-filterInV |; | In GIAB and failed hard filtering only | G-filterInH-V |; | In GIAB and passed both hard filtering and VQSR | Intersection |; | Not in GIAB and failed VQSR only | H-filterInV |; | Not in GIAB and failed both hard filtering and VQSR | FilteredInAll |; | Not in GIAB and failed hard filtering only | filterInH-V |; | Not in GIAB and passed both hard filtering and VQSR | H-V |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2489:1026,INTEGRAT,INTEGRATION,1026,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2489,1,['INTEGRAT'],['INTEGRATION']
Deployability,## Feature request. The mitochondria pipeline should have new annotations and filters in Mutect2 and FilterMutectCalls. This is being addressed in #5193. An accompanying best practices WDL should also be developed and eventually be available in Firecloud. I'll update here once the PR is merged and has been released.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310:37,pipeline,pipeline,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310,3,"['pipeline', 'release', 'update']","['pipeline', 'released', 'update']"
Deployability,"## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1008,update,update,1008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['update'],['update']
Deployability,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:606,integrat,integration,606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,1,['integrat'],['integration']
Deployability,"## System; * Mac OS X 10.11.6 x86_64; * Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27. ## Problem; I'm trying to update my project ([ReadTools](https://github.com/magicDGS/ReadTools)) to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315:114,update,update,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315,1,['update'],['update']
Deployability,"## Tool(s) or class(es) involved; GenomicsDBImport(v4.1.8.1). ### Description; Hello, I was construct to genomicdb using GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Ser",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:934,update,update-workspace-path,934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['update'],['update-workspace-path']
Deployability,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6978:3,Update,Update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978,5,"['Update', 'install', 'upgrade']","['Update', 'install', 'upgrade', 'upgraded']"
Deployability,"## Update:. ### A [broad institute forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671/comments/360010377231) gave the solution:. #### If you paste this text into the `gatkcondaenv.yaml` file:. ```; # Conda environment for GATK Python Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3,Update,Update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,5,"['Update', 'update']","['Update', 'update', 'updated']"
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) is 75.711% (diff: 83.505%); > Merging [#2133](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.009%**. ```diff; @@ master #2133 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38515 +64 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8040 +13 ; ==========================================; + Hits 29108 29160 +52 ; - Misses 6840 6847 +7 ; - Partials 2503 2508 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2133/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 83% | *new* [...rg/broadinstitute/hellbender/utils/SATagBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F53415461674275696C6465722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ellbender/tools/walkers/rnaseq/SplitNCigarReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F53706C69744E436967617252656164732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../broadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F526561645574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...36e06a7](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...36e06a7d50089927fb966586c7e131fba99a534c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980:1694,update,update,1694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2167?src=pr) is 74.366% (diff: 100%). ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2167/graphs/sunburst.svg?size=150&src=pr). > No coverage report found for **master** at 4ec1b85.; > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [4ec1b85...b41efd8](https://codecov.io/gh/broadinstitute/gatk/compare/4ec1b8506fc56911333210c3fcf4d34dbd75300c...b41efd8d284f162d598a1e7c1e08e52c3d7494d3?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2167#issuecomment-247640830:324,update,update,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2167#issuecomment-247640830,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) is 74.268% (diff: 89.474%). > Merging [#2170](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.059%**. ``` diff; @@ master #2170 diff @@; ==========================================; Files 705 705 ; Lines 37924 37933 +9 ; Methods 0 0 ; Messages 0 0 ; Branches 8002 8005 +3 ; ==========================================; + Hits 28143 28172 +29 ; + Misses 7420 7396 -24 ; - Partials 2361 2365 +4 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2170/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 89% | [...r/tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F416C6C656C6553756273657474696E675574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../java/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F5574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [491f7f2...3ac63b8](https://codecov.io/gh/broadinstitute/gatk/compare/491f7f2436421c53204be5c0fb5226bed2b4842a...3ac63b82465b1e7fe1ac8a3b0542e321286d217c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291:1725,update,update,1725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2174?src=pr) is 74.42% (diff: 100%). > No coverage report found for **master** at 14d7191.; > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [14d7191...4c9affa](https://codecov.io/gh/broadinstitute/gatk/compare/14d71914fb97f163a975c13532430fe935e930a3...4c9affad9c8b0dc21e43fe3c07e9bffd9b1c405d?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2174#issuecomment-248339384:221,update,update,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2174#issuecomment-248339384,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) is 74.416% (diff: 84.211%). > Merging [#2179](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.148%**. ``` diff; @@ master #2179 diff @@; ==========================================; Files 705 706 +1 ; Lines 37933 38012 +79 ; Methods 0 0 ; Messages 0 0 ; Branches 8005 8030 +25 ; ==========================================; + Hits 28172 28287 +115 ; + Misses 7396 7349 -47 ; - Partials 2365 2376 +11 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2179/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 82% | _new_ [...nder/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C65417373656D626C79526567696F6E57616C6B65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...nstitute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F417373656D626C79526567696F6E57616C6B65722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [b4d9fb2...bdf6dc1](https://codecov.io/gh/broadinstitute/gatk/compare/b4d9fb2f6d9b487789bdd9405debdc260b58a229...bdf6dc1cb16f1d058575fec25667712974b46a96?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733:1444,update,update,1444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) is 74.446% (diff: 66.667%). > Merging [#2184](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.007%**. ``` diff; @@ master #2184 diff @@; ==========================================; Files 706 706 ; Lines 37972 37974 +2 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8009 +1 ; ==========================================; + Hits 28266 28270 +4 ; + Misses 7330 7328 -2 ; Partials 2376 2376 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2184/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 66% | [...calc/IndependentAllelesDiploidExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2184/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F496E646570656E64656E74416C6C656C65734469706C6F69644578616374414643616C63756C61746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3e20270...54f8615](https://codecov.io/gh/broadinstitute/gatk/compare/3e202701dc55ab49857643926a86a79680c96fc8...54f86158d4d727fe97d266cb99957991ff823229?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120:1184,update,update,1184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) is 75.892% (diff: 100%). > Merging [#2187](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.011%**. ``` diff; @@ master #2187 diff @@; ==========================================; Files 711 711 ; Lines 38290 38315 +25 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8066 +8 ; ==========================================; + Hits 29055 29078 +23 ; Misses 6765 6765 ; - Partials 2470 2472 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2187/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...30e9a42](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...30e9a4244a26e00ae4d02b378f63dc30f6bb0e20?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572:750,update,update,750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) is 75.894% (diff: 100%). > Merging [#2188](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.012%**. ``` diff; @@ master #2188 diff @@; ==========================================; Files 711 711 ; Lines 38290 38301 +11 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29055 29068 +13 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2188/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...itute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B564346436F6E7374616E74732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ute/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B5643464865616465724C696E65732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...3b78e79](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...3b78e792b93605bfdaabe8db24219783d3df9209?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221:1409,update,update,1409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) is 75.893% (diff: 0.000%). > Merging [#2194](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2194 diff @@; ==========================================; Files 711 711 ; Lines 38303 38300 -3 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8057 -1 ; ==========================================; - Hits 29068 29067 -1 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2194/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...genotyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F7479706543616C63756C6174696F6E417267756D656E74436F6C6C656374696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...a7af494](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...a7af494115524062df232c7b0cfb59e07124184e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184:1477,update,update,1477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) is 75.752% (diff: 100%); > Merging [#2205](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.013%**. ```diff; @@ master #2205 diff @@; ==========================================; Files 728 728 ; Lines 38433 38441 +8 ; Methods 0 0 ; Messages 0 0 ; Branches 8025 8026 +1 ; ==========================================; + Hits 29109 29120 +11 ; + Misses 6822 6820 -2 ; + Partials 2502 2501 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2205/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2205/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [dd7e19a...8a7c17f](https://codecov.io/gh/broadinstitute/gatk/compare/dd7e19a58fece8d165f5f8d2d17f88ad3ddf2666...8a7c17fad0808d6a40a07b4734f083d82951f136?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634:1085,update,update,1085,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) is 75.903% (diff: 100%). > Merging [#2215](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.014%**. ``` diff; @@ master #2215 diff @@; ==========================================; Files 711 711 ; Lines 38303 38304 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29068 29074 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2468 -2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2215/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2215/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...d0ce3c9](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...d0ce3c966be8ba767c0da18c995c3be27b9af1d0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345:1116,update,update,1116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) is 75.906% (diff: 100%). > Merging [#2227](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.016%**. ``` diff; @@ master #2227 diff @@; ==========================================; Files 711 711 ; Lines 38304 38304 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29069 29075 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2467 -3 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2227/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [13f88ae...7a4f692](https://codecov.io/gh/broadinstitute/gatk/compare/13f88aec9e10e76eb2445b7d2e430d33f24726ed...7a4f6927d2f4de11e24b2862a6223dd966ddc5c7?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005:747,update,update,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) is 56.038% (diff: 0.000%). > Merging [#2234](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.060%**. ``` diff; @@ master #2234 diff @@; ==========================================; Files 717 718 +1 ; Lines 38536 38579 +43 ; Methods 0 0 ; Messages 0 0 ; Branches 8073 8081 +8 ; ==========================================; + Hits 21618 21619 +1 ; - Misses 14670 14712 +42 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2234/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [...alkers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2234/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F76617269616E747574696C732F55706461746556434653657175656E636544696374696F6E6172792E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [5e17764...3107aa4](https://codecov.io/gh/broadinstitute/gatk/compare/5e17764f74fdf110d4ea09cc0b5508fbad9a1305...3107aa4310a538a66b41ddf19528787714a86a03?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243:784,Update,UpdateVCFSequenceDictionary,784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243,2,"['Update', 'update']","['UpdateVCFSequenceDictionary', 'update']"
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) is 75.932% (diff: 87.500%). > Merging [#2239](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.003%**. ``` diff; @@ master #2239 diff @@; ==========================================; Files 712 712 ; Lines 38201 38204 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8018 -1 ; ==========================================; + Hits 29008 29009 +1 ; - Misses 6720 6722 +2 ; Partials 2473 2473 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2239/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 75% | [...bender/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F446570746850657253616D706C6548432E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../tools/walkers/annotator/DepthPerAlleleBySample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F4465707468506572416C6C656C65427953616D706C652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [028c361...9f7c142](https://codecov.io/gh/broadinstitute/gatk/compare/028c3610f7414279f454c6bb2c1404d5d6ca0403...9f7c14286c7abfc63eebb85961199359cd5db21f?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571:1457,update,update,1457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) is 75.938% (diff: 35.714%). > Merging [#2242](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.051%**. ``` diff; @@ master #2242 diff @@; ==========================================; Files 712 712 ; Lines 38211 38214 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8022 +3 ; ==========================================; + Hits 4160 29019 +24859 ; + Misses 33469 6721 -26748 ; - Partials 582 2474 +1892 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2242/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢ 35% | [...llbender/engine/datasources/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2242/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F64617461736F75726365732F5265666572656E636546696C65536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [bc8318e...40072ed](https://codecov.io/gh/broadinstitute/gatk/compare/bc8318e1086f0ea9a6b67f0f658725baae6f0e90...40072ed1e8326e4698b2c6d0a06d3340ee298539?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160:1127,update,update,1127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2248?src=pr) is 76.042% (diff: 100%). ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2248/graphs/sunburst.svg?src=pr&size=150). > No coverage report found for **master** at c903e35.; > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [c903e35...2654781](https://codecov.io/gh/broadinstitute/gatk/compare/c903e35a34c69760956134edc11513b97d91886d...26547816f3758376388faf344bb14a824b9d57aa?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2248#issuecomment-257908442:324,update,update,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2248#issuecomment-257908442,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) is 75.907% (diff: 37.500%); > Merging [#2259](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.026%**. ```diff; @@ master #2259 diff @@; ==========================================; Files 731 731 ; Lines 38966 38994 +28 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8154 +3 ; ==========================================; + Hits 29588 29599 +11 ; - Misses 6855 6870 +15 ; - Partials 2523 2525 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2259/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢ 22% | [...broadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F50616972484D4D2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 64% | [...e/hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F566563746F724C6F676C65737350616972484D4D2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...558160e](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...558160ea5bfde8be3b6e4bdd5283c529fb905fca?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519:1388,update,update,1388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) is 76.058% (diff: 100%). > Merging [#2262](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **20.023%**. ``` diff; @@ master #2262 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; + Hits 21619 29344 +7725 ; + Misses 14714 6743 -7971 ; - Partials 2248 2494 +246 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2262/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...e0d7613](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...e0d761361fb9deb1b0b02cd995b02f6fea37b3e9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866:757,update,update,757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) is 56.035% (diff: 100%). > Merging [#2263](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2263 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2263/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...fb5f66b](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...fb5f66bd59c692950cf2c2a588685dd60888f10b?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945:722,update,update,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) is 56.035% (diff: 100%). > Merging [#2264](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2264 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2264/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...6d8ef09](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...6d8ef0980f0294a65354d6376bdea2d44ff3aed0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364:722,update,update,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) is 76.024% (diff: 75.000%). > Merging [#2271](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.028%**. ``` diff; @@ master #2271 diff @@; ==========================================; Files 731 731 ; Lines 38948 39102 +154 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8177 +31 ; ==========================================; + Hits 29599 29727 +128 ; - Misses 6840 6865 +25 ; - Partials 2509 2510 +1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2271/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 75% | [...rg/broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2271/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4C6F6767696E675574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [a9e304f...e0bd30d](https://codecov.io/gh/broadinstitute/gatk/compare/a9e304fd7dd2ad854c2115f23eb507eb6c502324...e0bd30d79bf2b0831e731bc74c35c7796708c5bb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512:1086,update,update,1086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) is 75.941% (diff: 100%); > Merging [#2272](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2272 diff @@; ==========================================; Files 731 731 ; Lines 38966 38966 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8151 ; ==========================================; + Hits 29588 29591 +3 ; + Misses 6855 6852 -3 ; Partials 2523 2523 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2272/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...stitute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2272/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B5265676973747261746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...60902e5](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...60902e55e33ebca62d204b7b5f808293e204e7f2?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856:1085,update,update,1085,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) is 75.937% (diff: 100%); > Merging [#2275](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.066%**. ```diff; @@ master #2275 diff @@; ==========================================; Files 731 731 ; Lines 38956 38961 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8147 8149 +2 ; ==========================================; - Hits 29608 29586 -22 ; - Misses 6838 6853 +15 ; - Partials 2510 2522 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2275/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...dinstitute/hellbender/cmdline/CommandLineParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2275/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E655061727365722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [4d29cf7...9c8ec35](https://codecov.io/gh/broadinstitute/gatk/compare/4d29cf7a9e1d6c9ee936303d452aa2ca92febae0...9c8ec352770b67bd2cfd9203a86253b088875ed3?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323:1093,update,update,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) is 76.012% (diff: 100%); > Merging [#2279](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2279 diff @@; ==========================================; Files 731 731 ; Lines 38948 39094 +146 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8176 +30 ; ==========================================; + Hits 29602 29716 +114 ; - Misses 6837 6867 +30 ; - Partials 2509 2511 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2279/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [4a844f0...c606f66](https://codecov.io/gh/broadinstitute/gatk/compare/4a844f03a080e68ccb2fd0bc0987f56fa2b7e6ed...c606f6695338bc38b01221760f26596ffe9a7fba?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440:758,update,update,758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) is 75.922% (diff: 100%); > Merging [#2286](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.200%**. ```diff; @@ master #2286 diff @@; ==========================================; Files 731 731 ; Lines 38994 38994 ; Methods 0 0 ; Messages 0 0 ; Branches 8154 8154 ; ==========================================; + Hits 4181 29605 +25424 ; + Misses 34231 6866 -27365 ; - Partials 582 2523 +1941 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2286/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [625ed04...5abaa38](https://codecov.io/gh/broadinstitute/gatk/compare/625ed042b6c6f4d9609e15064b494aa4bbd74f70...5abaa38b0a61d03626d57d625d459c259b1606a6?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678:757,update,update,757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) is 75.760% (diff: 89.744%); > Merging [#2306](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.058%**. ```diff; @@ master #2306 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38622 +171 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8073 +46 ; ==========================================; + Hits 29108 29260 +152 ; - Misses 6840 6847 +7 ; - Partials 2503 2515 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2306/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 89% | [...lbender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2306/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461736F75726365732F5265616473537061726B53696E6B2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...3381f1c](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...3381f1c44a38f48a3a3d56358e41c57c3ef7396e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166:1127,update,update,1127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) is 75.698% (diff: 80.000%); > Merging [#2307](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.008%**. ```diff; @@ master #2307 diff @@; ==========================================; Files 729 729 ; Lines 38515 38503 -12 ; Methods 0 0 ; Messages 0 0 ; Branches 8040 8039 -1 ; ==========================================; - Hits 29158 29146 -12 ; Misses 6849 6849 ; Partials 2508 2508 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2307/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 80% | [...broadinstitute/hellbender/utils/FisherExactTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2307/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4669736865724578616374546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2e5a15a...3348b9e](https://codecov.io/gh/broadinstitute/gatk/compare/2e5a15ac4bc9774e853abb6d26c2acb60f2f9c20...3348b9ee3f9d12a2c6898f344ffa1c290f439f17?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932:1074,update,update,1074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) is 75.706% (diff: 100%); > Merging [#2318](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ```diff; @@ master #2318 diff @@; ==========================================; Files 729 729 ; Lines 38506 38507 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8039 8039 ; ==========================================; + Hits 29150 29152 +2 ; Misses 6848 6848 ; + Partials 2508 2507 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2318/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...nder/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52656164506F7352616E6B53756D546573742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../hellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52616E6B53756D546573742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../annotator/allelespecific/AS_ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F52656164506F7352616E6B53756D546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [e1b4c8f...9a3e91c](https://codecov.io/gh/broadinstitute/gatk/compare/e1b4c8f4b781c6867e1eaea2dbb5587c6a6125a7...9a3e91c78ca9b0ce5f0da22a3cebd7199f255ff0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046:1798,update,update,1798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) is 76.172% (diff: 100%); > Merging [#2323](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.997%**. ```diff; @@ master #2323 diff @@; ==========================================; Files 743 743 ; Lines 38960 38958 -2 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8114 ; ==========================================; + Hits 3964 29675 +25711 ; + Misses 34451 6711 -27740 ; - Partials 545 2572 +2027 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2323/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/2323/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F66696C746572732F56617269616E7446696C74726174696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...4a1a5e4](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...4a1a5e4f9e909019226ac53ba1ab9d030a0c5463?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777:1126,update,update,1126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) is 76.365% (diff: 90.845%); > Merging [#2325](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.625%**. ```diff; @@ master #2325 diff @@; ==========================================; Files 729 743 +14 ; Lines 38479 40288 +1809 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8510 +474 ; ==========================================; + Hits 29144 30766 +1622 ; - Misses 6830 6887 +57 ; - Partials 2505 2635 +130 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2325/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 90% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 90% | *new* [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...d5f64bc](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...d5f64bceb32ac10ce42b09f6ff377cad0e446ced?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473:1422,update,update,1422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) is 76.019% (diff: 86.111%); > Merging [#2326](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.279%**. ```diff; @@ master #2326 diff @@; ==========================================; Files 729 729 ; Lines 38479 38505 +26 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8045 +9 ; ==========================================; + Hits 29144 29271 +127 ; + Misses 6830 6703 -127 ; - Partials 2505 2531 +26 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2326/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 86% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2326/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...f3d1e15](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...f3d1e158ca9dbf071e83a293e4e52bcae2be38c9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703:1126,update,update,1126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) is 76.230% (diff: 100%); > Merging [#2339](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **66.055%**. ```diff; @@ master #2339 diff @@; ==========================================; Files 743 743 ; Lines 38960 39112 +152 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8193 +79 ; ==========================================; + Hits 3964 29815 +25851 ; + Misses 34451 6719 -27732 ; - Partials 545 2578 +2033 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2339/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...d0c671e](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...d0c671e931c010f240af5c3a822af19052545b11?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279:1416,update,update,1416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) is 76.191% (diff: 100%); > Merging [#2342](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.001%**. ```diff; @@ master #2342 diff @@; ==========================================; Files 743 743 ; Lines 38962 38972 +10 ; Methods 0 0 ; Messages 0 0 ; Branches 8113 8118 +5 ; ==========================================; + Hits 29685 29693 +8 ; - Misses 6708 6710 +2 ; Partials 2569 2569 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2342/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/engine/filters/MappingQualityReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2342/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F4D617070696E675175616C6974795265616446696C7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [29569a9...51e6426](https://codecov.io/gh/broadinstitute/gatk/compare/29569a9ffae87623e3eeffaae3effc965c8307a7...51e64264cb8ae0ce96b446eec9eea5e9c721a870?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133:1114,update,update,1114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133,1,['update'],['update']
Deployability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) is 76.232% (diff: 0.000%); > Merging [#2374](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.161%**. ```diff; @@ master #2374 diff @@; ==========================================; Files 748 750 +2 ; Lines 39318 39401 +83 ; Methods 0 0 ; Messages 0 0 ; Branches 8196 8214 +18 ; ==========================================; Hits 30036 30036 ; - Misses 6686 6769 +83 ; Partials 2596 2596 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2374/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | *new* [...nstitute/hellbender/engine/MultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C7469506173734C6F63757357616C6B65722E6A617661) |; | 0% | *new* [...nder/tools/examples/ExampleMultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654D756C7469506173734C6F63757357616C6B65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2c85e82...d7e18ea](https://codecov.io/gh/broadinstitute/gatk/compare/2c85e8241179f03f71a0b2442caa4ba68373c03d...d7e18eac4f0edcf1c0352861a49444cb597b40fb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509:1684,update,update,1684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509,1,['update'],['update']
Deployability,### **Addresses** ; https://github.com/broadinstitute/dsp-spec-ops/issues/192. ### **Commit Summary**; - Updated StorageAPIAvroReader.java; > - To handle the use case if no data is returned from BQ. ### **Tested**; - Updated BigQueryUtilsUnitTest.java; > - testQueryWithEmptyDatasetStorageAPI() function to test code changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7082:105,Update,Updated,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7082,6,['Update'],['Updated']
Deployability,### **Addresses** ; https://github.com/broadinstitute/dsp-spec-ops/issues/246. ### **Commit Summary**; - Created AvroFileReader ; - Created a sampleAvroFile; - Update ExtractCohort and ExtractCohortEngine to accept a AvroFile. Testing:; Created a test for AvroFileReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7174:160,Update,Update,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7174,1,['Update'],['Update']
Deployability,### **Addresses** ; https://github.com/broadinstitute/gatk/pull/7115. ### **Commit Summary**; -Created AvroFileReader; - Update ExtractCohort and ExtractCohortEngine to accept a AvroFile. Testing:; Created a test for AvroFileReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7127:121,Update,Update,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7127,1,['Update'],['Update']
Deployability,"### Affected class(es); All test classes in GATK (and downstream projects) extending `BaseTest`. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch. ### Description ; The GATK toolkit assumes `US` locale (set in a `Main` static method), which in turn produces all the test files using the `US` locale; if the test suite is run in a different locale, it might fail unexpectedly. For example, if the locale has a comma-separated decimals instead of dot-separated, comparing the expected file output with `US` locale against the generated by the tests fail. . #### Expected behavior; `BaseTest` should set the locale in a `@BeforeSuite` method (or static method) to set the assumptions of the toolkit to all tests (also for downstream toolkits). #### Actual behavior; `BaseTest` picks default locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5012:142,release,release,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5012,1,['release'],['release']
Deployability,"### Affected tool(s) or class(es); Funcotator, but could be future tools as well. ### Affected version(s); - [ ] Latest master branch as of [June 14, 2018]. ### Description ; Currently, if you want to read a MAF the GATK will use AnnotatedIntervalCodec. This is fine in the majority of cases. However, under the hood, it is using a configuration setup that has an aliasing scheme. This alias scheme is fairly permissive and can lead to conflicts. For example, if a MAF has a column named ""END"", the MAF will not parse, since the default configuration will attempt to use the ""END"" column instead of ""End_Position"". This can be fixed if we have a MAF codec, but some decisions need to be made. For example, should it produce AnnotatedIntervals? Variant may be too difficult.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4897:332,configurat,configuration,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4897,2,['configurat'],['configuration']
Deployability,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:374,release,release,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,3,['release'],"['release', 'release-']"
Deployability,### Affected tool(s) or class(es); _EstimateDragstrParameters_. ### Affected version(s); - [ ] Latest public release version [version?]; - [X] Latest master branch as of [after PR 6634 has been merged in]. ### Description . Look for usages of ```Utils.runInParallel```. Change those to use Spark instead. There is a possibility of removing multi-threading all together if we change the way we decimate and filter sites.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6876:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6876,1,['release'],['release']
Deployability,"### Affected tool(s) or class(es); docker version GATK:4.1.1.0. ### Affected version(s); ; latest release. ### Description ; Funcotator shuts down part way through job. A configuration problem @ google?; [funcotator_crash.txt](https://github.com/broadinstitute/gatk/files/3652568/funcotator_crash.txt). RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; ; ### Description . 04:13:19.667 INFO ProgressMeter - 15:85753672 1834.2 199000 108.5; 04:17:42.593 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/1402; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/162233; 04:17:42.665 INFO Funcotator - Shutting down engine; [September 25, 2019 4:17:42 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1,845.78 minutes.; Runtime.totalMemory()=4523032576; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182:98,release,release,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182,2,"['configurat', 'release']","['configuration', 'release']"
Deployability,"### Affected tool; - CollectReadCounts. ### Affected version; - The Genome Analysis Toolkit (GATK) v4.2.3.0; - HTSJDK Version: 2.24.1. Downloaded from https://github.com/broadinstitute/gatk/releases/download/4.2.3.0/gatk-4.2.3.0.zip. ### Description ; When calling `CollectReadCounts` tool with symlink as input BAM-file, `java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE` occurs. Symlinks seem to work fine with Picard BAM-tools as well as `HaplotypeCaller` and `Mutect2`. Probably HTSJDK level issue, but popped up exception is kind of misleading. #### Stacktrace:; ```; java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:863); at htsjdk.samtools.MemoryMappedFileBuffer.<init>(MemoryMappedFileBuffer.java:23); at htsjdk.samtools.AbstractBAMFileIndex.<init>(AbstractBAMFileIndex.java:64); at htsjdk.samtools.CachingBAMFileIndex.<init>(CachingBAMFileIndex.java:56); at htsjdk.samtools.BAMFileReader.getIndex(BAMFileReader.java:418); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:931); at htsjdk.samtools.BAMFileReader.query(BAMFileReader.java:612); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:550); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); at java.lang.Iterable.spliterator(Iterable.java:101); at org.broadinstitute.hellbender.utils.Utils.stream(Utils.java:1176); at org.broadinstitute.hellbender.engine.GATKTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7579:190,release,releases,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7579,1,['release'],['releases']
Deployability,"### Bug Report. Hi, after installing the conda environment and running `conda activate gatk` without errors, I seem to still have a problem importing the gcnvkernel module. Is there a way I can install it through pip or what is something I may have done wrong? I already went over the README and standard documentation, and don't think I missed a step. ### Affected tool(s) or class(es); gvnvkernel, other expected modules. #### Expected behavior; Generate output file from my VCF. #### Actual behavior; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GermlineCNVCaller --input var.vcf --run-mode CASE --contig-ploidy-calls X/prefix-calls --output-prefix regular.vcf --output testfile.vcf; 21:21:12.277 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 23, 2020 9:21:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:21:12.543 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 21:21:12.544 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:21:12.544 INFO GermlineCNVCaller - Executing as gamer456148@gamer456148-Inspiron-15-7579 on Linux v4.15.0-88-generic amd64; 21:21:12.544 INFO GermlineCNVCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_191-b12; 21:21:12.544 INFO GermlineCNVCaller - Start Date/Time: February 23, 2020 9:21:12 PM EST; 21:21:12.544 INFO GermlineCNVCaller - -------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:26,install,installing,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,2,['install'],"['install', 'installing']"
Deployability,"### Feature request. ### Tool(s) or class(es) involved; Mitochondria pipeline (Mutect2). ### Description; This is a user request from the forum:. Other mitochondria tools notate the difference between heteroplasmy and homoplasmy variant calls. This is based only on the estimated AF so should be simple to implement and add an additional annotation. It is allele specific, so would fit better in the FORMAT field.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6257:69,pipeline,pipeline,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6257,1,['pipeline'],['pipeline']
Deployability,"### Goal; Our team try to explore the usage of GATK Spark tool for our internal WES and WGS data. ## Bug Report. ### Affected tool(s) or class(es); BwaSpark and ReadsPipelineSpark. ### Affected version(s); - [ X ] Latest public release version [gatk 4.0.11.0]. ### Description ; For both tools, we encountered an issue when the driver shutdown the command as the screenshot. However, for the bwaspark, the alignment ratio seems to be unaffected by the error, but the lines number of the VCF file from ReadsPipelineSpark varies randomly, and quite different from the non-spark version of GATK 4.0.5.2. #### Steps to reproduce; Before running the tool, we generated the image index for whole genome by using the fasta file from GATK official ftp site, and uploaded the reference file to Hadoop HDFS. ``` bash; gatk-4.0.11.0/gatk BwaMemIndexImageCreator -I Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.fasta.img; ```. and then, we preprocess our pair end fastq files into unaligned ubam file as, ; ``` bash; java -jar picard.jar FastqToSam \; F1=R1.fastq.gz; F2=R2.fastq.gz; O=unaligned_reads.bam \; SM=sample001 \; PL=illumina \; RG=rg001; ```. For BwaSpark, we used,; ``` {bash}; ../gatk-4.0.11.0/gatk --java-options ""-Dgatk.spark.debug=true -XX:+PrintGCDetails"" BwaSpark -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test3.bam -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --spark-runner SPARK --spark-master spark://master:7077 -- --num-executors 4 --driver-memory 4g --executor-cores 10 --executor-memory 20g; ```. For ReadsPipelineSpark, we used, ; ``` {bash}; time_gatk ""ReadsPipelineSpark --tmp-dir /tmp --align true -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test10.vcf -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --known-sites hdfs://ns/user/root/Homo_sapiens_assembly38.dbsnp138.vcf -pairHMM AVX_LOGLESS_CACHING --max-reads-per-alignment-start 50"" 4 44 88g 12g; ```. #### Expected behavior; Both tool s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5481:228,release,release,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5481,1,['release'],['release']
Deployability,"### Instructions. ## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls. ### Affected version(s); - [ ] Latest public release version [4.1.4.1]. ### Description ; Header is missing description for ""##FILTER=<ID=PASS"" , it causes inaccurate parsing of VCF . #### Steps to reproduce; Run the FilterMutectCalls on any mutect2 VCF available . Thanks, ; Nick",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6426:132,release,release,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6426,1,['release'],['release']
Deployability,"### Instructions. ## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark. ### Affected version(s); - [v ] Latest public release version [4.4.0.0]. ### Description ; Since switching to 4.4.0.0 we are experiencing an increased memory consumption of MarkDuplicatesSpark. We see it on large BAM/CRAM files, not tested on small files. #### Steps to reproduce; This command: ; ```; java -Xmx190g -jar /usr/gitc/GATK_ultima.jar MarkDuplicatesSpark \; --spark-master local[24] \; --input 019242_old.ua.aln.bam \; --output 019242_old.aligned.sorted.duplicates_marked.bam \; --create-output-bam-index true \; --spark-verbosity WARN \; --verbosity WARNING \; --flowbased; ```; required 90GB memory on 4.3.0.0. The input BAM is large: 270GB; However on the 4.4.0.0 it requires >160GB RAM. #### Expected behavior; The memory requirement is not expected to change ; #### Actual behavior; Significantly increased memory requirement",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8307:135,release,release,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8307,1,['release'],['release']
Deployability,"### Instructions. ## Bug Report. Hi GATK team , I'm afraid I found an exception in gatk HC related to https://github.com/broadinstitute/gatk/issues/6516. ### Affected tool(s) or class(es). GATK HC v4.3.0.0 . ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description . ```; + gatk --java-options '-Xmx5g -Djava.io.tmpdir=TMP' HaplotypeCaller -R /LAB-DATA/BiRD/resources/species/human/cng.fr/hs38me/hs38me_all_chr.fasta --minimum-mapping-quality 10 --sample-ploidy 2 --do-not-run-physical-phasing --alleles TMP/jeter.vcf.gz -L TMP/jeter.vcf.gz -I /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/87/5fa0df303dc4f06212547353be621c/BAMS/cluster.aaaaaaacx.bam.list -O TMP/jeter2.vcf.gz Using GATK jar /LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running: ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx5g -Dj; ava.io.tmpdir=TMP -jar /LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar HaplotypeCaller -R /LAB-DATA/BiRD/resources/species/human/cng.fr/hs38me/hs38me_all_chr.fasta --minimum-mapping-quality 10 --sample-ploidy 2 --do-not-run-physical-phasing --alleles TMP/jeter.vcf.gz -L TMP/jeter.vcf.gz -I /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/87/5fa0df303dc4f06212547353be621c/BAMS/cluster.aaaaaaacx.bam.list -O TMP/jeter2.vcf.gz; 18:15:19.107 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.j; ar!/com/intel/gkl/native/libgkl_compression.so ; 18:15:21.727 INFO HaplotypeCaller - ------------------------------------------------------------ ; 18:15:21.728 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0 ; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106:253,release,release,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106,1,['release'],['release']
Deployability,"### Instructions. ## Bug Report; ### Affected tool(s) or class(es); - tools: HaplotypeCaller perhaps Mutec. ; - classes: AlleleLikelihoods. ### Affected version(s); - [ X] Latest public release version [version?]; - [ X] Latest master branch as of [date of test?]. ### Description ; Right before calling annotators HC engine adds filtered reads as additional evidence in the AlleleLikelihoods instance that is passed down to the annotators. The code requests the new evidence to have 0.0 likelihoods so label them as uninformative. However due to an error in how the lk arrays are ""extended"" inside the AlleleLikelihoods these reads inherit past reads (removed) zombie likelihoods instead. Fix is easy. as simple as remove this enclosing ```if``` in AlleleLikelihoods, and simply executed its body; always:. ```; line 793:; if (initialLikelihood != 0.0) // the default array new value.; {; for (int a = 0; a < alleleCount; a++) {; Arrays.fill(sampleValues[a], sampleEvidenceCount, newSampleEvidenceCount, initialLikelihood);; }; }; ```. #### Steps to reproduce. Debug and active region with filtered reads. . #### Expected behavior. Those reads won't contribute to AD or DP. #### Actual behavior. They do contribute, at random, to those count annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7153:186,release,release,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7153,1,['release'],['release']
Deployability,"### Instructions. In one of the six samples that the DSP pipelines team ('lantern') uses for scientific testing, found bug in GATK 4.1.7.0's HaplotypeCaller. 'java.lang.IllegalArgumentException: evidence provided is not in sample'. Full stack trace below. This is found for Sample NA17-308, Shard 49.; https://cromwell.gotc-dev.broadinstitute.org/api/workflows/1/83938362-b9b5-49f3-a65d-715065d6eabd/metadata; Execution bucket is:; broad-gotc-dev-cromwell-execution (results will stay there for 30 days before being automatically cleaned up). ----. ## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - 4.1.7.0. ### Description ; Stack trace:; java.lang.IllegalArgumentException: evidence provided is not in sample; 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.lambda$removeEvidence$9(AlleleLikelihoods.java:1124); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:504); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.removeEvidence(AlleleLikelihoods.java:1128); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.contaminationDownsampling(AlleleLikelihoods.java:315); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:173); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:608); 	at org.broadinstitute.hellbender.tools.walkers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586:57,pipeline,pipelines,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586,1,['pipeline'],['pipelines']
Deployability,"### Instructions. Initially reported by a user on the [forum](https://gatkforums.broadinstitute.org/gatk/discussion/13680/variants-with-ad-0-0-and-dp-0#latest)... Aparently some variants with non-zero quals have 0 AD and DPs. Other annotations are also missing from the INFO columns. . After some debugging it turns out that the criteria to determine whether a read should be considered for a variant in terms of alignment overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:955,configurat,configuration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['configurat'],['configuration']
Deployability,"### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es). FilterMutectCalls. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . If there is germline variant within one read length of a somatic variant, the clustered_events filter can filter out the somatic variant. Clustered events, intention is to filter out noisy sites that are likely artifactual, but should ignore contributions from neighboring germline sites.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6532:1282,release,release,1282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6532,1,['release'],['release']
Deployability,"### Instructions; I use PathSeqPipelineSpark to analyze 10x Visium spatial transcribed data.; I did not download the data from the database on the GATK official website. But I prepared the database according to the tutorial [https://gatk.broadinstitute.org/hc/en-us/articles/360035889911--How-to-Run-the-Pathseq-pipeline] by myself.; The analysis has no results, and I don't know the reason for the lack of results. ## software / environment / log file informations; Using GATK jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx750g -jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar PathSeqPipelineSpark --input CRC_16/outs/possorted_genome_bam.bam --filter-bwa-image hsa_GRCh38/genome.fa.img --kmer-file hsa_GRCh38/genome.hss --min-clipped-read-length 60 --microbe-dict 16SrRNA/bacteria.16SrRNA.dict --microbe-bwa-image 16SrRNA/bacteria.16SrRNA.fa.img --taxonomy-file 16SrRNA/16SrRNA.db --output pathseq/CRC_16.pathseq.complete.bam --scores-output pathseq/CRC_16.pathseq.complete.csv --is-host-aligned false --filter-duplicates false --min-score-identity .7 --tmp-dir pathseq/tmp; 13:19:23.776 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:19:28.982 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 13:19:28.982 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0; 13:19:28.982 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:19:28.983 INFO PathSeqPipelineSpark - Executing as singlecellproject@d01.capitalbiotech.local on Linux v3.10.0-514.16.1.el7.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:312,pipeline,pipeline,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['pipeline'],['pipeline']
Deployability,"### This needs update after categorization changes are finalized and so counts are approximate. Tally of tools (excludes filters/annotations) :; ```; 127 GATK tools; 94 Picard tools; 221 total tools; ```. Per category:. category (14) | number of tools (221); -- | --; Reference | 6; Base Calling | 7; Diagnostics and Quality Control | 49; Contamination | 7; Intervals Manipulation | 11; Read Data Manipulation | 46; Alignment, Duplicate flagging and BQSR | 16; Short Variant Discovery | 8; Short Variant Filtering | 7; Short Variant Manipulation | 17; Short Variant Evaluation and Refinement | 14; Copy Number Variant Discovery | 28; Structural Variant Discovery | 4; Other | 1. ---; Per developer, assuming ~20 of us, this means ~11 tools per developer. If folks are feeling generous and will claim more, this frees up busy coworkers for other work. If I've forgotten anyone, please add to table. Megan is away until next year. developer (25) | number of tools updated (claimed); -- | --; Yossi | 0; Valentin | 0; Ted S. | 0; Ted B. | 0; Takuto | 0; Sara | 0; Sam L. | 0; Steve | 0; Sam F. | 0; Marton | 0; Mehrtash | 0; Mark W. | 0; Maddi | 0; Louis | 0; Lee | 0; Jose | 0; Jonn | 0; Laura | 0; Mark F. | 0; James | 0; David R. | 0; David B. | 0; Chris W. | 0; Chris N. | 0; Andrey | 0. Folks should claim the 11-12 tools they will work on, by putting their name on the spreadsheet next to the tools. Otherwise, we will assign you tools. SOP to follow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347356628:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347356628,2,['update'],"['update', 'updated']"
Deployability,"### Updates; A record with SVTYPE=CTX and CPX_TYPE=CTX_INV was added to a recent GATK-SV VCF after manual curation. The following changes were made to be able to properly annotate this type of event.; * CPX_TYPE will be checked for CTX records, and if it is CTX_INV, the INV interval from CPX_INTERVALS will be added to the annotation segments.; * Additionally, instead of annotating two breakpoint intervals CHROM:POS-END and CHR2:END2-END2+1 for CTX events, we will now annotate 4 individual breakpoints to cover the case where END != POS+1. Those 4 breakpoints are CHROM:POS-POS, CHROM:END-END, CHR2:END2-END2, and CHR2:END2+1-END2+1.; * In the future, to be able to represent intervals on CHR2, POS2 may be added. SVAnnotate will need to be updated accordingly at that time. ### Testing; * Unit tests for CTX_INV added; * Unit tests for other CTX updated; * A one-line VCF was created to test the real-life example CTX_INV event that was curated, and it was annotated correctly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8693:4,Update,Updates,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8693,3,"['Update', 'update']","['Updates', 'updated']"
Deployability,### Updates; Some GATK-SV VCFs contain MEI deletions with ALT in the format <DEL:ME:ALU> or <DEL:ME>. This change will allow SVAnnotate to recognize and annotate those records as deletions. ### Testing; * Added unit test with MEI DEL; * Ran all unit and integration tests for SVAnnotate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8125:4,Update,Updates,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8125,2,"['Update', 'integrat']","['Updates', 'integration']"
Deployability,"#### Hiding / deprecating tools and their docs. @samuelklee To add to @sooheelee's answer, if there are any tools that you definitely want gone and already have a replacement for, I would encourage you to kill them off (ie delete from the code) before the 4.0 launch. While we're still in beta we can remove anything at the drop of a hat. Once 4.0 is out, we'll have a deprecation policy (exact details TBD) that will allow us to prune unwanted tools over time, but it will be less trivial. And as Soo Hee said, everything that's in the current code release MUST be documented. We used to hide tools/docs in the past and it caused us more headaches than not. . That being said, as part of that TBD deprecation policy it will probably make sense to make a ""Deprecated"" program group where tools go to die. If there are tools you plan to kill but don't want to do it before 4.0 is released for whatever reason, you could put them there. Documentation standards can be less stringent for tools in that bucket. To be clear I think the deprecation group name should be generic, ie not named to match any particular use case or functionality. That will help us avoid seeing deprecation buckets proliferate for each variant class/ use case. Does that sound like a reasonable compromise?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346189138:550,release,release,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346189138,4,['release'],"['release', 'released']"
Deployability,"################ | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2133,install,install,2133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460,1,['install'],['install']
Deployability,#5663 Hooks up the `PossibleDeNovo` to the annotation engine and should hopefully resolve this issue when it gets in by the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-462866609:129,release,release,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-462866609,1,['release'],['release']
Deployability,"#6329 Bug Report. ### Affected tool(s) or class(es); Mutect2 / FilterMutectCalls. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Variants with alternative representations in gnomad are not recognized as being the same as called variants in some cases. This results in variants that are called and not filtered, but they should be filtered by ""germline"". As an example of this, in gnomad the site hg19 16:72991715 is represented as:; 16	72991715	.	ACCG	GCCG,*,AGCCGCCG	14986622.13	PASS	AC=33700,10,4;AF=0.83,2.463E-4,9.852E-5. But in M2 it is called as:; A->G. Although ACCG->GCCG and A->G are equivalent, they are not recognized as identical. #### Expected behavior; Mutect2 should filter these variants as germline. #### Actual behavior; Mutect2 does not filter these variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6972:127,release,release,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6972,1,['release'],['release']
Deployability,"#7359); - don't mix contigs, rightsize memory (#7361); - Add custom annotations as ac an af (#7351); - Add task for VAT validation #8 & 9 (#7364); - added bcftools, upgraded gcloud version (#7369); - fix wdl (#7378); - Update .dockstore.yml; - Add VAT validation rule #5 [VS-16] (#7365); - Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15] (#7379); - Batching of samples for create import TSVs (#7382); - Add VAT validation rule #2 [VS-19] (#7374); - Create VAT scripts directory (#7386); - fixing SA change from file to string (#7371); - add extract_subpop script (#7387); - Add is_loaded column to sample_info and logic to populate after ingest [VS-158] (#7389); - Add Gnomad subpopulation info into the VAT (#7381); - implement GVS ID assignment (#7355); - no longer loading sample info table in this wdl (#7407); - divide up creation/population of temp pet table [VS-48] (#7395); - Sample QC metrics (#7396); - update import for is_loaded (#7416); - fix partition end, add 1 (#7420); - Fixes to CreateFilterSet and ExtractCallset from 30K run (#7423); - Also changed file size from Int to Float in SumBytes task python (#7429); - Adding the subpopulation calculations to the VAT creation WDL (#7399); - 154 De obfuscate (#7435); - filter on gvs_ids for workflow (#7428); - update for assign ids and changes in import (#7439); - need to loop through sets when moving to done (#7440); - add option for create filter set to use sample_info with is_loaded (#7434); - remove dead branch (#7443); - Scaling the VAT -- switch the input to take in a file of vcf shard file names (#7446); - dockstore testing: move validate vat inputs (#7449); - Update GVS sample QC to support multiple callsets per datasset [VS-177] (#7451); - Update GvsImportGenomes.wdl (#7462); - Add extraction uuid BQ label to GvsPrepareCallstep from GvsExtractCohortFromSampleNames (#7458); - Add manifest summary file to GvsExtractCallset (#7457); - Create workflow to create and populate alt_allele table [VS-51] (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:17094,update,update,17094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,"['Update', 'update']","['Update', 'update']"
Deployability,"#; ===============================================; + Coverage 76.262% 76.279% +0.018% ; - Complexity 10880 10891 +11 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30192 30199 +7 ; + Misses 6776 6768 -8 ; - Partials 2622 2623 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `49.123% <100%> (+2.632%)` | `41 <0> (+9)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (√∏)` | `4% <0%> (+1%)` | :arrow_up: |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `78.175% <0%> (+0.179%)` | `176% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=footer). Last update [a85e0ff...985628d](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2531#issuecomment-289150335:2236,update,update,2236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2531#issuecomment-289150335,2,['update'],['update']
Deployability,"#Bug Report. ### Affected tool(s) or class(es); CNNScoreVariant. ### Affected version(s); 4.0.7.0. ### Description ; For 1,297,033 variant sites, the CNN_1D=-16.118. . #### Steps to reproduce; /run_cnn.sh adsp-5k.hg38.GATK.aws-batch_SNP_INDEL.chr22.4794samples.g.vcf.gz; Using GATK jar /share/pkg/gatk/4.0.7.0/install/bin/gatk-package-4.0.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /share/pkf/adsp-5k.hg38.GATK.aws-batch_SNP_INDEL.chr22.4794samples.g.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -O cnn/adsp-5k.hg38.GATK.aws-batch_SNP_INDEL.chr22.4794samples.g.vcf.gz; 11:29:43.339 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.7.0/install/bin/gatk-package-4.0.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:29:43.467 INFO CNNScoreVariants - ------------------------------------------------------------; 11:29:43.467 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.0.7.0; 11:29:43.467 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:29:43.468 INFO CNNScoreVariants - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-696.28.1.el6.x86_64 amd64; 11:29:43.468 INFO CNNScoreVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_151-b12; 11:29:43.469 INFO CNNScoreVariants - Start Date/Time: August 13, 2018 11:29:43 AM UTC; 11:29:43.469 INFO CNNScoreVariants - ------------------------------------------------------------; 11:29:43.469 INFO CNNScoreVariants - ------------------------------------------------------------; 11:29:43.469 INFO CNNScoreVariants - HTSJDK Version: 2.16.0; 11:29:43.469 INFO CNNScoreVariants - Picard Version: 2.18.7; 11:29:43.469 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:29:43",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5101:310,install,install,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5101,2,['install'],['install']
Deployability,"#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9XaW5kb3dTb3J0ZXIuamF2YQ==) | `100% <100%> (√∏)` | `5 <5> (?)` | |; | [...bender/tools/spark/sv/AlignedAssemblyOrExcuse.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `11.299% <11.299%> (√∏)` | `4 <4> (?)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <17.742%> (-18.009%)` | `28 <1> (√∏)` | |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `81.463% <40%> (-2.293%)` | `24 <0> (√∏)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `82.278% <44.231%> (-6.409%)` | `22 <1> (√∏)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=footer). Last update [f91f7ac...553ba12](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285180830:4305,update,update,4305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285180830,2,['update'],['update']
Deployability,% <100%> (+0.41%)` | `27 <0> (+1)` | :arrow_up: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `56.944% <0%> (-2.778%)` | `17% <0%> (√∏)` | |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.795% <0%> (√∏)` | `26% <0%> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (√∏)` | `13% <0%> (√∏)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <0%> (√∏)` | `5% <0%> (-1%)` | :arrow_down: |; | [...ollections/IntervalsSkipListOneContigUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdE9uZUNvbnRpZ1VuaXRUZXN0LmphdmE=) | | | |; | [...r/utils/collections/IntervalsSkipListUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdFVuaXRUZXN0LmphdmE=) | | | |; | [...broadinstitute/hellbender/engine/ContextShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606:2819,pipeline,pipelines,2819,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606,1,['pipeline'],['pipelines']
Deployability,% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <√∏> (√∏)` | `16 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195:2474,pipeline,pipelines,2474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195,1,['pipeline'],['pipelines']
Deployability,%> (-100%)` | `0% <0%> (-13%)` | |; | [...ols/examples/ExampleAssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `0% <0%> (-93.103%)` | `0% <0%> (-8%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (-92.381%)` | `0% <0%> (-14%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `24.324% <0%> (-63.176%)` | `5% <0%> (-5%)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-56.667%)` | `1% <0%> (√∏)` | |; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370:2492,pipeline,pipelines,2492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370,1,['pipeline'],['pipelines']
Deployability,&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ctions/OptionalVariantInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvT3B0aW9uYWxWYXJpYW50SW5wdXRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...lbender/tools/spark/pathseq/PSBwaAlignerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQndhQWxpZ25lclNwYXJrLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...hellbender/engine/datasources/ReferenceSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlU291cmNlLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...spark/pipelines/metrics/MetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmsuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...stitute/hellbender/utils/mcmc/ParameterReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlclJlYWRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...lbender/tools/spark/pathseq/PathSeqBuildKmers.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCdWlsZEttZXJzLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...hellbender/engine/spark/IntervalWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/3695?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3695#issuecomment-336929519:1859,pipeline,pipelines,1859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3695#issuecomment-336929519,1,['pipeline'],['pipelines']
Deployability,"' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 4 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details.; ```; The warnings show up in at least these tasks: gatkTabComplete, installDist, gatkDoc, shadowJar, sparkJar. Seems like it should be easy to fix, I'm not sure how we didn't see them when doing the upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:2320,install,installDist,2320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,2,"['install', 'upgrade']","['installDist', 'upgrade']"
Deployability,(-0.91%)` | `15% <0%> (+6%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `75.258% <0%> (-0.252%)` | `17% <0%> (√∏)` | |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `50.388% <0%> (√∏)` | `28% <0%> (√∏)` | :arrow_down: |; | [...er/tools/ConvertHeaderlessHadoopBamShardToBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db252ZXJ0SGVhZGVybGVzc0hhZG9vcEJhbVNoYXJkVG9CYW0uamF2YQ==) | `76.923% <0%> (√∏)` | `2% <0%> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <0%> (√∏)` | `4% <0%> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <0%> (√∏)` | `24% <0%> (√∏)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <0%> (√∏)` | `3% <0%> (√∏)` | :arrow_down: |; | ... and [34 more](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4095#issuecomment-356133946:3102,pipeline,pipelines,3102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4095#issuecomment-356133946,1,['pipeline'],['pipelines']
Deployability,(I just updated my previous reply),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2577#issuecomment-292605221:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2577#issuecomment-292605221,1,['update'],['updated']
Deployability,"(Linked to #7988); Feature additions (and integration tests) for CompareReferences tool, including:; * ability to run base-level comparison modes on specified sequences (not just detected mismatching sequences) using ""sequences-to-align"" option ; * changed wording for missing MD5 compatibility status ('COMPATIBLE' to 'MAYBE_COMPATIBLE,' or something similar) in compatibility tool ; * option to ignore case level differences in base level comparison modes . NOTE: integration test on using an equivalent sequences input file with more than one line (ie. specifying more than one sequences) not yet tested, and can probably do some refactoring to clean up the code for the equivalent sequence comparisons",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8163:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8163,2,['integrat'],['integration']
Deployability,"(SV) consolidate logic in simple chimera inference, update how variants are represented in VCF emitted by new code path",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663:52,update,update,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663,2,['update'],['update']
Deployability,"(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: export GATK_LOCAL_JAR=<path_to_local_jar>. export GATK_LOCAL_JAR=<path_to_local_jar>; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3958,Pipeline,PipelineSupportIntegrationTest,3958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['Pipeline'],['PipelineSupportIntegrationTest']
Deployability,(this may be related to recent upgrade of our cluster?). running the simples example blows up:. ```; ./bin/gatk/gatk-launch PrintReadsSpark -I hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.bam -O hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.out.bam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --num-executors 5 --executor-cores 2 --executor-memory 4g \; --conf spark.yarn.executor.memoryOverhead=600; ```. blows up with . ```; java.lang.ClassCastException: org.apache.hadoop.fs.RawLocalFileSystem cannot be cast to org.apache.hadoop.fs.LocalFileSystem; at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:350); at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getQualifiedLocalPath(Client.scala:1373); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:329); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:422); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:635); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:124); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:523); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(Comm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1389:31,upgrade,upgrade,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1389,7,"['deploy', 'upgrade']","['deploy', 'upgrade']"
Deployability,) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/f1e0349c2fc20df63a2f4e10b0288a0e25be0425?src=pr&el=desc) will **increase** coverage by `0.005%`.; > The diff coverage is `50%`. ```diff; @@ Coverage Diff @@; ## master #4091 +/- ##; ===============================================; + Coverage 78.999% 79.004% +0.005% ; - Complexity 16542 16543 +1 ; ===============================================; Files 1059 1059 ; Lines 59169 59169 ; Branches 9615 9615 ; ===============================================; + Hits 46743 46746 +3 ; + Misses 8687 8686 -1 ; + Partials 3739 3737 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4091?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `83.333% <0%> (√∏)` | `56 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (+0.851%)` | `65% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (√∏)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4091#issuecomment-356112798:1206,pipeline,pipelines,1206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4091#issuecomment-356112798,1,['pipeline'],['pipelines']
Deployability,") or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jul 26, 2020 10:20:35 AM shaded",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:1028,install,install,1028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,1,['install'],['install']
Deployability,") will **increase** coverage by `-0.005%`. ```diff; @@ Coverage Diff @@; ## master #2388 +/- ##; ===============================================; - Coverage 76.379% 76.374% -0.005% ; - Complexity 0 10845 +10845 ; ===============================================; Files 748 748 ; Lines 39325 39325 ; Branches 6849 6849 ; ===============================================; - Hits 30036 30034 -2 ; - Misses 6695 6697 +2 ; Partials 2594 2594; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.593% <√∏> (-1.476%)` | `45 <√∏> (+45)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91.667% <100%> (-0.194%)` | `24 <1> (+24)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=footer). Last update [14f73e2...ca6c34e](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2388#issuecomment-277262598:2019,update,update,2019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2388#issuecomment-277262598,2,['update'],['update']
Deployability,) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nstitute/hellbender/engine/spark/SparkSharder.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyLmphdmE=) | `91.156% <100%> (+0.184%)` | `30 <0> (-1)` | :arrow_down: |; | [.../hellbender/engine/spark/SparkSharderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyVW5pdFRlc3QuamF2YQ==) | `92.92% <100%> (+0.193%)` | `7 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `43.243% <0%> (-56.757%)` | `5% <0%> (-3%)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `50.649% <0%> (-42.454%)` | `4% <0%> (-2%)` | |; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `44.444% <0%> (-38.889%)` | `2% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `51.807% <0%> (-35.23%)` | `11% <0%> (-6%)` | |; | [...ls/spark/BaseRecalibratorSparkIntegrationTest.java](https://codecov.io/gh/broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698:1860,pipeline,pipelines,1860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698,1,['pipeline'],['pipelines']
Deployability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.4/tests/test/index.html) |; | unit | openjdk8 | [29984.3](https://travis-ci.com/broadinstitute/gatk/jobs/317851321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,1,['integrat'],['integration']
Deployability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.4/tests/test/index.html) |; | unit | openjdk8 | [29988.3](https://travis-ci.com/broadinstitute/gatk/jobs/317861681) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,1,['integrat'],['integration']
Deployability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Deployability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.4/tests/test/index.html) |; | unit | openjdk8 | [29992.3](https://travis-ci.com/broadinstitute/gatk/jobs/317887703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,1,['integrat'],['integration']
Deployability,) | `0% <√∏> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `75.796% <84.211%> (-0.593%)` | `44 <1> (-1)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `80.083% <92.157%> (+4.325%)` | `52 <11> (-1)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4645/diff?src=pr&el=tree#diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-389699780:2162,pipeline,pipelines,2162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-389699780,1,['pipeline'],['pipelines']
Deployability,) | `84.733% <100%> (+0.237%)` | `49 <1> (+1)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `86.869% <100%> (+0.41%)` | `27 <0> (+1)` | :arrow_up: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `56.944% <0%> (-2.778%)` | `17% <0%> (√∏)` | |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.795% <0%> (√∏)` | `26% <0%> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (√∏)` | `13% <0%> (√∏)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <0%> (√∏)` | `5% <0%> (-1%)` | :arrow_down: |; | [...ollections/IntervalsSkipListOneContigUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdE9uZUNvbnRpZ1VuaXRUZXN0LmphdmE=) | | | |; | [...r/utils/collections/IntervalsSkipListUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606:2500,pipeline,pipelines,2500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606,1,['pipeline'],['pipelines']
Deployability,"). Ah, ok. So keep it in the GATK3 repo then, for now? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-260642385). Yes. I believe @lucidtronix is doing VQSR development in GATK3 and we'll port later. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287837505). @ldgauthier @lucidtronix Any update on this since I heard VQSR got ported to GATK4?. ---. @ldgauthier commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287905381). It's unlikely the behavior has changed. For gnomad we used hard filters to; address the problem, which is probably a good global recommendation. On Mar 20, 2017 1:35 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @lucidtronix; > <https://github.com/lucidtronix> Any update on this since I heard VQSR; > got ported to GATK4?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287837505>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLRwdezIkmt3uPqIABWLggVjRN3yks5rnrjegaJpZM4Dt4t7>; > .; >. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287919609). OK, that makes sense, thanks. Do you want me to migrate the issue to GATK4? Otherwise I'll just close it out here as WONTFIX. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-288223457). Somewhere we need a record of updates to filtering best practices until we; publish a new thing, so yeah, please migrate. On Mar 20, 2017 6:36 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > OK, that makes sense, thanks. Do you want me to migra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:8725,update,update,8725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['update'],['update']
Deployability,"); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; 3. Change work directory into `/data/xieduo/Immun_genomics/data/≈Åuksza2022Nature` and used `./` as tmp directory. It also failed:; ```; cd /data/xieduo/Immun_genomics/data/≈Åuksza2022Nature; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:11671,pipeline,pipeline,11671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array extract tool (#6827); - fix enum (#6834); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebase conflicts; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - Moving the WDL for importing array manifest to BQ (#6860); - fix up after rebase; - Moving and testing ingest scripts from variantstore (#6881); - optionally provide sam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:2302,update,update,2302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['update'],['update']
Deployability,)` | `8 <0> (√∏)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1NjcmlwdEV4ZWN1dG9yLmphdmE=) | `66.667% <0%> (-14.583%)` | `7% <0%> (-3%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:2201,pipeline,pipelines,2201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961,1,['pipeline'],['pipelines']
Deployability,* Add a table of contents.; * Update out-of-date information.; * Merge in information from the old gatk-protected README; * Add section on git-lfs; * Add section on downloading GATK4; * Add section on documentation generation; * Add section on zenhub; * Remove no-longer-needed protected-root directory. Resolves #2775; Resolves #2978; Resolves #2487; Resolves #2461,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158:30,Update,Update,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158,1,['Update'],['Update']
Deployability,* Add new parameter to set filtered genotypes to no-calls to ExtractCohort; * Modified ExtractCohortEngine to optionally set genotypes that are filtered (FT flag set - at the genotype leve) to no-calls.; * Renamed VQSR Classic to 'VQSR'; * Renamed VQSR Lite to 'VETS'; * Updated VCF and pgen tests for code changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8797:271,Update,Updated,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8797,2,['Update'],['Updated']
Deployability,"* Added liftover chain file creation script.; * Added WDLs and some arguments to lift over gnomAD; * Added chain file for b37->hg38 and arguments for liftover.; * Limited to 1000 records in memory.; * Added stack trace option to all wdls and sub tasks.; * Fixed output to be consistent with local files for indexing.; * Added timing information on wdls.; * Added a wdl/json to create a TSV from gnomAD allele freq data.; * Updated indexFeatureFile wdl, added params for run to index gnomAD.; * Added json file for indexing a large gnomad file.; * Fixed critical issues with NIO data sources.; * Updates to the test script to save output and point to full cloud data.; * Added some logging hooks to SeekableByteChannelPrefetcher. I haven't reviewed this since I made the changes to it to see what should stay, so it may need a fair bit of work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5514:423,Update,Updated,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5514,2,['Update'],"['Updated', 'Updates']"
Deployability,"* Added new option --unfilteredBreakpointEvidenceDir; When set, this option dumps all evidence (even evidence that is; ultimately rejected) in an easy to parse text format. Some additional; info (cigarString, mappingQuality) is stored in ReadEvidence to output; information related to read quality.; * Updated option --readMetadata; When set, will additionaly output the map from contig number to contig; name. Added non-null ParitionBounds to readMetadata in; ReadMetadataTest::testEverything to prevent crash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3691:302,Update,Updated,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3691,1,['Update'],['Updated']
Deployability,"* Added support for annotating 5'/3' flanks via new FIVE_PRIME_FLANK and THREE_PRIME_FLANK funcotations. * Added --five-prime-flank-size and --three-prime-flank-size arguments to control the size of each flanking region. * Refactored datasource classes to allow for padded/custom queries to make this feature possible. * We now emit IGR funcotations in more cases (in particular, when a gene has no basic transcripts, and when the basic transcripts do not fully span a gene and the flank size is small). * Added comprehensive unit tests, and updated integration test data. Resolves #4771",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5403:542,update,updated,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5403,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,* Adding a beta version of http-nio which allows streaming http files and seeking within them.; * This allows using https urls including signed urls to access remote files.; * Bams/crams can be read by specifying the index manually. Automatic index resolution does not work correctly at the moment.; * known caveats; * some methods are not implement in the nio filesystem library yet; * failures are not retryied. I'm currently fighting with sonatype to get a real release pushed out... it seems close...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6526:465,release,release,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6526,1,['release'],['release']
Deployability,* Adding the dataproc-cluster-ui script to the release bundle so users can access it.; * Fixes #5400,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5401:47,release,release,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5401,1,['release'],['release']
Deployability,* Centralizes Docker image versioning to top-level WDLs; * Does away with GATK override jar in all cases except integration tests (override jar can still be specified during feature development and/or for emergencies); * Docker image versions can be captured as the inputs to tasks; * Freshens Variants Docker image. Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/815ef8ea-8cfe-47b6-be80-54250d1f180b),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8457:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8457,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,* Change extract so that when we filter at the genotype level (with FT) the VCF header has the FT filter definition in the comment/unspecified field.; * Also minor renaming of ExtractCohort argument.; * Point to updated truth.; ; [Here's](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/94129da8-6faf-419b-ab75-a46c228b1bbe) an integration test run. Passing everything except ValidateVDS because `reference_data` not being written due to issues beyond my control.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8850:212,update,updated,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8850,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"* For `PipelineOptions`, my understanding is that it is used for Google genomics API, and we seem to use it very infrequently in GATK (and never in SV), so it is safe to use null whenever engine level or other utility functions API needs it; * For the `END` and `START` annotation, there is NO`START` in VCF spec, but `POS`, so I don't know where the `start` comes from. And yes, I agree that BND records don't have a `start` either, it is merely a novel adjacency between two genomic locations, none of which is a start or end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125:7,Pipeline,PipelineOptions,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125,1,['Pipeline'],['PipelineOptions']
Deployability,* Have GvsCreateVATfromVDS.wdl take sites-only-vcf as an optional input.; * Added logic to allow/disallow CopyFile to overwrite. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/bb8906d4-7111-4fd1-a723-b5616b354c23) is a passing run using an existing sites-only VCF.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9c8be4d5-f707-4c54-bde5-18d9d23cde66) is a run where it tried to generate the sites-only VCF. Failing because of Echo issues with creating VDS.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f8cc493-b0ff-4d8c-8813-6c463dbf17c0) is an integration test. It's failing in ValidateVDS on two paths (the ones that create VDSes) since this is based off of EchoCallset branch - this is expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8866:671,integrat,integration,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8866,1,['integrat'],['integration']
Deployability,"* If you are adding a new allele specific INFO field, yeah, we would need a updateINFOFieldDescriptor() function. You would need to call this the first time an array is created. You can take the vid that GenomicsDB creates and modify the specific INFO fields of interest.; * If you wish to specify a new combine operation that doesn't exist in GenomicsDB yet (say element_wise_median), that would involved modifying the C++ code. I haven't documented that anywhere. If this is something that you wish to do, please let me know. I'll try to find a way of supporting such operations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415509584:76,update,updateINFOFieldDescriptor,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415509584,1,['update'],['updateINFOFieldDescriptor']
Deployability,* Optionally extract to bgz format.; * Set bgzipping to be off (everywhere) by default.; * Update assert_identical_outputs to handle bgzipped outputs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8820:91,Update,Update,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8820,1,['Update'],['Update']
Deployability,* Successful run in PMI land that finds nothing to clean up [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20First%20Look/job_history/ba861882-96ee-4635-b522-2fe9489b0076).; * Successful run in Integration land that finds loads to clean up [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/01667ae7-fd85-4a12-abcb-69e892500fa3).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8644:225,Integrat,Integration,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8644,1,['Integrat'],['Integration']
Deployability,* The previous attempt to fix requester pays didn't fix it in many cases.; This incorporates a newer version of the NIO library with several patches to fix; edge cases we were hitting.; * https://github.com/googleapis/java-storage-nio/issues/849; * https://github.com/googleapis/java-storage-nio/issues/856; * https://github.com/googleapis/java-storage-nio/issues/857; * upgrade com.google.cloud:google-cloud-nio:0.123.23 ->0.123.25; * fixes https://github.com/broadinstitute/gatk/issues/7716,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730:141,patch,patches,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730,2,"['patch', 'upgrade']","['patches', 'upgrade']"
Deployability,* This fixes an issue while installing gcloud on travis due to permissions in the root directories. @ldgauthier This should fix the issue you were seeing where test files weren't being uploaded.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7525:28,install,installing,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7525,1,['install'],['installing']
Deployability,* This updates us from commons-text:1.6.0 -> 1.10.0 to fix a vulnerability; * fixes https://github.com/broadinstitute/gatk/issues/8060,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8071:7,update,updates,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8071,1,['update'],['updates']
Deployability,* Upating disq 0.3.3 -> 0.3.4; * This release makes use of new features in htsjdk 2.21.0 which were previously part of disq itself.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6252:38,release,release,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6252,1,['release'],['release']
Deployability,* Update Picard 2.23.0 -> 2.25.0; * Add serialVersionUID to classes now marked as Serializable in picard.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7075:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7075,1,['Update'],['Update']
Deployability,* Update htsjdk 2.20.1 -> 2.20.2; * This release fixes https://github.com/broadinstitute/gatk/issues/6091,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6094:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6094,2,"['Update', 'release']","['Update', 'release']"
Deployability,"* Update htsjdk to 2.7.0; * Remove usage of deprecated `SAMRecordUtil`; * Remove usage of deprecated `IndexFactory.writeIndex(index, indexFile)`; * Cleaning `IndexFeatureFile`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247,1,['Update'],['Update']
Deployability,* Update picard 2.21.1 -> 2.21.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6253:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6253,1,['Update'],['Update']
Deployability,* Update picard from 2.20.7 -> 2.21.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6205:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6205,1,['Update'],['Update']
Deployability,* Updates htsjdk to 2.7.0; * Use `Index.write(File)` for write the index independently of type; * Removed unused imports,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2244:2,Update,Updates,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2244,1,['Update'],['Updates']
Deployability,"* Updating htsjdk 2.18.1 -> 2.18.2; * Remove deprecated method use; * Changing IntervalUtilsUnitTest due to changes in IntervalList; * IntervalList now rejects certain invalid intervals that it previously didn't and throw IllegalArgumentException.; * This ends up changing which exceptions are thrown in some cases, updated some tests to accept both MalformedFile and MalforedGenomeLoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5585:316,update,updated,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5585,1,['update'],['updated']
Deployability,* `JointVariantCalling` [does set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f3f98f0e-2a7f-460b-886f-3442551140a8) `tighter_gcp_quotas`.; * Integration tests [do not set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/51213d40-7583-49f1-a101-1842180a6470) `tighter_gcp_quotas`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8540:170,Integrat,Integration,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8540,1,['Integrat'],['Integration']
Deployability,* add a new deploy key for travis to use to authenticate to github,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7524:12,deploy,deploy,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7524,1,['deploy'],['deploy']
Deployability,* add an new option to VariantsToTable to allow output VCF style numeric GT fields; previously it always output the actual bases of the Allele in the GT spot; * resolves https://github.com/broadinstitute/gatk/issues/8160; * updates htsjdk to 3.0.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8219:224,update,updates,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8219,1,['update'],['updates']
Deployability,"* added a reference parameter to FeatureData source and FeatureManager methods; * genomicsDB requires a reference, previously this was being passed; through by hardcoding it in the required json files; * json files are now autogenerated by the importer tool, but the; reference wasn't being handled correctly. * updated the various walkers to pass the reference through if available. * gendb:// paths now point to the workspace directory instead of a; directory of jsons. * removed the ability to specify array, vidmap.json, and; callset.json paths in the importer tool since we now rely on the; structure and naming of the files when loading; moved some constants to GenomicsDBConstants. * updated GenomicsDBIntegration tests to use the new importer instead of a; prepackaged and very brittle set of json files. fixed a bug in GenomicsDBImporterIntegrationTests that made both tests; write to the same workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626:312,update,updated,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626,2,['update'],['updated']
Deployability,"* changing the key hash we use to download R package keys on travis from an insecure 32 bit hash that has been compromised to a more secure longer hash; * we will no longer be installing the ""Totally Legit Signing Key""; * see https://evil32.com/ for a summary of the problem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5214:176,install,installing,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5214,1,['install'],['installing']
Deployability,* com.intel.gkl:gkl:0.8.8 -> 0.8.10. @droazen @kachulis Maybe we should update to the newest version and rerun the tests?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8181:72,update,update,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8181,1,['update'],['update']
Deployability,* disables tests that use the now defunct google genomics reference API; * update BaseRecalibratorSparkIntegrationTest.testBQSRFailWithIncompatibleReference to not use the reference API; * fixes #4163; * these tests should be revisted and removed or replaced in #4166,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4178:75,update,update,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4178,1,['update'],['update']
Deployability,* improvements leading to tieout of cohort extract; * WDLs for running WARP pipeline for tieout; * tweaks to WDLs (memory size) for running extract,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7062:76,pipeline,pipeline,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7062,1,['pipeline'],['pipeline']
Deployability,* update gradle wrapper 8.2.1 -> 8.10.2; * remove 'versions' plugin because we don't use it; * update gradle plugins to new versions; * shadow plugin changed maintainers and coordinates com.github.johnrengelman.shadow:8.1.1 -> com.gradleup.shadow:8.3.3; * git-version 0.5.1 -> 3.1.0; * sonatype scan 2.6.1 -> 2.8.3; * download 5.4.0 -> 5.6.0; * use tasks.register() which is the newer style,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:2,update,update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,2,['update'],['update']
Deployability,* update setup-gcloud@v0 -> v2 since v0 is deprecated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8651:2,update,update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8651,1,['update'],['update']
Deployability,* updating Intel-GKL from 8.5 -> 8.6; * this is a very minor update that only changes a log message; * fixes https://github.com/broadinstitute/gatk/issues/5393,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5463:61,update,update,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5463,1,['update'],['update']
Deployability,* updating htsjdk 2.16.1 -> 2.18.0; * the most noticable change is that we will now produce bam 1.6 instead; of 1.5; * some test files updated to have the new version since they were being; compared with exact match tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5424:135,update,updated,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5424,1,['update'],['updated']
Deployability,* upgrade protobuf-java 3.19.4 -> 3.21.6,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8036:2,upgrade,upgrade,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8036,1,['upgrade'],['upgrade']
Deployability,"********************************; > org.broadinstitute.barclay.argparser.CommandLineException: deploy-mode is not a recognized option; > 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:1377,deploy,deploy,1377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,1,['deploy'],['deploy']
Deployability,****; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.java:148); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:277); at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:224); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:3624,pipeline,pipelines,3624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['pipeline'],['pipelines']
Deployability,"**Brief issue description:** ; When following the tutorial https://gatk.broadinstitute.org/hc/en-us/articles/360035531092--How-to-part-I-Sensitively-detect-copy-ratio-alterations-and-allelic-segments, the #4 Plot standardized and denoised copy ratios with PlotDenoisedCopyRatios have different results than the tutorial. Through the control vectors test, it seems that the samples that are used in step #2 to generate CNV PON used in the tutorial are different from the files stored in the tutorial.; **Results:**; Following steps 1 to 4, the resulting plots; ![hcc1143_T_clean denoised](https://github.com/broadinstitute/gatk/assets/89409924/3bce4382-5109-4c6e-b34d-1c6e365dcf62); ![hcc1143_T_clean denoisedLimit4](https://github.com/broadinstitute/gatk/assets/89409924/9d23987c-2747-43af-b72c-4e3754015531); The results have values However, the values in the tutorial are 0.134 and 0.125.; **Tests**; Using the files provided in the tutorial and script generated `cnvponC.pon.hdf5`, which seems to lead to this inconsistency result.; Using:; gatk --java-options ""-Xmx6500m"" CreateReadCountPanelOfNormals \; -I HG00133.alt_bwamem_GRCh38DH.20150826.GBR.exome.counts.hdf5 \; -I HG00733.alt_bwamem_GRCh38DH.20150826.PUR.exome.counts.hdf5 \; -I NA19654.alt_bwamem_GRCh38DH.20150826.MXL.exome.counts.hdf5 \; --minimum-interval-median-percentile 5.0 \; -O sandbox/cnvponC.pon.hdf5; **Files**; The script used to generate this result are attached. ; [gatk_tutorial11682_issue.zip](https://github.com/user-attachments/files/15930567/gatk_tutorial11682_issue.zip). Please help me understand this difference in reproducing the tutorial result. It will be extremely helpful for me to use the pipelines on our lab-generated data. Thank you very much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8884:1682,pipeline,pipelines,1682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8884,1,['pipeline'],['pipelines']
Deployability,"**Initial integration of GKL**; - Removed native build related items from `build.gradle`; - Removed native code from src tree; - Refactored `PairHMM.java` and `VectorLoglessPairHMM.java` to use GKL; - Updated `VectorPairHMMUnitTest.java` to use GKL; - Added integration tests to `IntelDeflaterIntegrationTest.java`. **Notes**; - PairHMM has been tested in HaplotypeCaller and GVCF output is md5sum equivalent to the PairHMM currently in GATK; - PairHMM in GKL is still single threaded, but about **_1.4x faster**_ than existing PairHMM, due to fixing a performance issue in the native code; - Next steps are captured in #1903 #1946",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935:10,integrat,integration,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935,3,"['Update', 'integrat']","['Updated', 'integration']"
Deployability,"**Summary**: ; A user reported `java.io.IOException: Stream closed` error with ApplyBQSRSpark. GATK 4.0.9.0 runs fine but when the user upgraded to gatk 4.1.1.0 version, they see his error. **User Report**:; I am getting the below error when running gatk-variant pipeline of bcbio. Bcbio using gatk 4.1.1.0 version. ; When I run ApplyBQSRSpark using GATK 4.0.9.0, it runs fine without any issues. Here is the command; **; gatk ApplyBQSRSpark --input test-sort.bam --output test-sort-recal.bam --bqsr-recal-file test-sort-recal.grp --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --spark-master local[8] --conf spark.local.dir=scratch/ --conf spark.driver.host=localhost --conf spark.network.timeout=800 --jdk-deflater --jdk-inflater**. Here is the error. [April 28, 2019 10:11:25 AM AST] org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=874512384; **htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed**; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readLong(IndexStreamBuffer.java:62); at htsjdk.samtools.AbstractBAMFileIndex.readLong(AbstractBAMFileIndex.java:436); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:311); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(Rea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919:136,upgrade,upgraded,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919,2,"['pipeline', 'upgrade']","['pipeline', 'upgraded']"
Deployability,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:256,pipeline,pipeline,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"**The input file :** ; bash-4.2$ hdfs dfs -ls /gatk4; Found 2 items; -rw-r--r-- 3 hdfs supergroup 62934 2017-10-11 13:38 /gatk4/output.bam; drwxr-xr-x - hdfs supergroup 0 2017-10-11 14:19 /gatk4/output_2.bam.parts. **The spark-submit:**. bash-4.2$ spark-submit; Usage: spark-submit [options] <app jar | python file> [app arguments]; Usage: spark-submit --kill [submission ID] --master [spark://...]; Usage: spark-submit --status [submission ID] --master [spark://...]. Options:; --master MASTER_URL spark://host:port, mesos://host:port, yarn, or local.; --deploy-mode DEPLOY_MODE Whether to launch the driver program locally (""client"") or; on one of the worker machines inside the cluster (""cluster""); (Default: client).; --class CLASS_NAME Your application's main class (for Java / Scala apps).; --name NAME A name of your application.; --jars JARS Comma-separated list of local jars to include on the driver; and executor classpaths.; ....... **the spark-shell**; bash-4.2$ spark-shell; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Failed to created SparkJLineReader: java.io.IOException: Permission denied; Falling back to SimpleReader.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 1.6.0; /_/. Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_91); Type in expressions to have them evaluated.; Type :help for more information.; Spark context available as sc (master = yarn-client, app id = application_1507683879816_0007).; Wed Oct 11 14:25:24 CST 2017 Thread[main,5,main] java.io.FileNotFoundException: derby.log (Permission denied); ----------------------------------------------------------------; Wed Oct 11 14:25:24 CST 2017:; Booting Derby version The Apache Software Foundation - Apache Derby - 10.11.1.1 - (1616546): instance a816c00e-015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:556,deploy,deploy-mode,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,1,['deploy'],['deploy-mode']
Deployability,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3432:2,UPDATE,UPDATE,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432,2,"['UPDATE', 'configurat']","['UPDATE', 'configurations']"
Deployability,"**Update:**. Here's how the coverage looks like using `CollectReadCounts` (w/ and w/o MQ > 30 filter) vs. `CollectFragmentCounts`. The lines are offset by +10 and +20 for better visibility. Summary: marked improvement in all cases, however, the error modes are different. `CollectFragmentCounts` tends to underestimate the size of SV regions and uniformly leads to coverage depletion near the breakpoints, `CollectReadCounts` estimates the size of SV regions better, however, coverage near the breakpoints tend to be less predictable (sometimes depletion, sometimes accumulation). Still, IGV seems to do the best job. Any improvement over `CollectReadCounts` requires using supplementary alignment information (e.g. weight sharing among supplementary alignments; this will likely fix the coverage asymmetry of translocation breakpoints), read clipping information, and mismatches. The latter two require a base-level coverage collection strategy (like IGV and `CollectTargetBaseCallCoverage`). _Unbalanced translocation:_. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37840319-1aba29ce-2e93-11e8-9d41-b9eafe450b6d.png). ![unbtr-2](https://user-images.githubusercontent.com/15305869/37840320-1bfff9a8-2e93-11e8-9842-39824f9fad64.png). ![unbtr-3](https://user-images.githubusercontent.com/15305869/37840321-1d82fa00-2e93-11e8-88ec-d7c40876594e.png). _Balanced translocation:_. ![baltr-1](https://user-images.githubusercontent.com/15305869/37840331-26a0962e-2e93-11e8-8dcf-0e69c8e45146.png). _Inversion:_. ![inv-1](https://user-images.githubusercontent.com/15305869/37840347-2f0d2f8e-2e93-11e8-8d36-64367951e7f2.png). ![inv-2](https://user-images.githubusercontent.com/15305869/37840350-306dedbe-2e93-11e8-9837-53369f5fb1f0.png). _Deletion:_. ![del-1](https://user-images.githubusercontent.com/15305869/37840366-3a32c0ea-2e93-11e8-99dc-d949985616d9.png). _Tandem Duplication:_. ![dup-1](https://user-images.githubusercontent.com/15305869/37840373-42052542-2e93-11e8-8891-fa9f79cc9f70.png",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743,1,['Update'],['Update']
Deployability,**increase** coverage by `0.139%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5251 +/- ##; ===============================================; + Coverage 86.903% 87.042% +0.139% ; - Complexity 30311 32163 +1852 ; ===============================================; Files 1849 1974 +125 ; Lines 140507 147466 +6959 ; Branches 15475 16232 +757 ; ===============================================; + Hits 122105 128358 +6253 ; - Misses 12793 13189 +396 ; - Partials 5609 5919 +310; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...spark/ReadsPreprocessingPipelineSparkTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZHNQcmVwcm9jZXNzaW5nUGlwZWxpbmVTcGFya1Rlc3REYXRhLmphdmE=) | `0% <0%> (-94.03%)` | `0% <0%> (-11%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-89.583%)` | `0% <0%> (-12%)` | |; | [...adinstitute/hellbender/engine/ReadContextData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671:1303,Integrat,IntegrationUtils,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671,1,['Integrat'],['IntegrationUtils']
Deployability,*ON HOLD*: Update SharedSequenceMerger.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4214:11,Update,Update,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214,1,['Update'],['Update']
Deployability,*Update*; I restarted the process and now everything works as intended. I have no Idea what went wrong.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7139#issuecomment-797478369:1,Update,Update,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7139#issuecomment-797478369,1,['Update'],['Update']
Deployability,*decrease** coverage by `6.763%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5672 +/- ##; ==============================================; - Coverage 87.05% 80.287% -6.763% ; + Complexity 31708 30237 -1471 ; ==============================================; Files 1940 1943 +3 ; Lines 146142 146770 +628 ; Branches 16128 16223 +95 ; ==============================================; - Hits 127216 117837 -9379 ; - Misses 13041 23220 +10179 ; + Partials 5885 5713 -172; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5672?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.521% <√∏> (√∏)` | `36 <0> (√∏)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-99.75%)` | `1% <0%> (-70%)` | |; | [...kers/filters/VariantFiltrationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2ZpbHRlcnMvVmFyaWFudEZpbHRyYXRpb25JbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.826% <0%> (-99.174%)` | `1% <0%> (-25%)` | |; | [...dorientation/CollectF1R2CountsIntegrationTest.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463373944:1298,pipeline,pipelines,1298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463373944,1,['pipeline'],['pipelines']
Deployability,*increase** coverage by `0.104%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5040 +/- ##; ==============================================; + Coverage 86.38% 86.485% +0.104% ; - Complexity 28640 29299 +659 ; ==============================================; Files 1782 1791 +9 ; Lines 132603 135334 +2731 ; Branches 14761 15341 +580 ; ==============================================; + Hits 114543 117043 +2500 ; - Misses 12740 12841 +101 ; - Partials 5320 5450 +130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5040?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `93.846% <100%> (+1.783%)` | `24 <0> (+2)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-1.399%)` | `2% <0%> (+1%)` | |; | [...lignment/AssemblyContigAlignmentsConfigPicker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlci5qYXZh) | `92.857% <0%> (-0.658%)` | `125% <0%> (+30%)` | |; | [.../AssemblyContigAlignmentsConfigPickerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlclVuaXRUZXN0LmphdmE=) | `99.279% <0%> (-0.326%)` | `42% <0%> (+22,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430:1279,integrat,integration,1279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430,1,['integrat'],['integration']
Deployability,"+ blaunch -no-wait -z hpcgenomicn24 /spark-1.6.2-bin-hadoop2.6//bin/spark-class org.apache.spark.deploy.worker.Worker spark://hpcgenomicn24:6311 -c 16; + echo --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:97,deploy,deploy,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['deploy'],['deploy']
Deployability,"+1 ; =============================================; + Hits 30028 30036 +8 ; + Misses 6693 6689 -4 ; + Partials 2594 2592 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=tree) | Coverage Œî | |; |---|---|---|; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `32.184% <√∏> (-0.757%)` | :x: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.389% <√∏> (+2.083%)` | :white_check_mark: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `82.707% <√∏> (+3.759%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=footer). Last update [8a42977...20a2c01](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2379#issuecomment-276752112:2304,update,update,2304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2379#issuecomment-276752112,2,['update'],['update']
Deployability,"+1 from me too. This is a problem with tools that read from genomics DB; when run on large sample sets. On Mon, Apr 9, 2018, 5:06 PM jamesemery <notifications@github.com> wrote:. > I have noticed that running print reads with a stringent filter which I; > expect to only return a handful of reads results in the progress meter; > never printing any progress. This makes it look like the gatk has hung; > despite the fact it is chugging away and filtering every read it passes; > over. This should be updated to include an indication of how many reads; > have been filtered. Additionally, it should be improved to use a second; > thread to make periodic updates based on execution time incase the tool; > really has hung in order to make it clearer to the user what is going on.; >; > ‚Äî; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4641>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLWElMXIsQZBXUpJLA6XHlVP-qd6ks5tm801gaJpZM4TNOh8>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4641#issuecomment-380086823:500,update,updated,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4641#issuecomment-380086823,4,['update'],"['updated', 'updates']"
Deployability,"+1 on updates -- there are now tools which are producing VCF 4.3, which is currently unreadable in IGV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-470732376:6,update,updates,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-470732376,1,['update'],['updates']
Deployability,", [chr1] and [chrM, chr1].; 	at htsjdk.tribble.index.tabix.TabixIndexMerger.processIndex(TabixIndexMerger.java:47); 	at htsjdk.tribble.index.tabix.TabixIndexMerger.processIndex(TabixIndexMerger.java:19); 	at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); 	at org.disq_bio.disq.impl.formats.vcf.VcfSink.save(VcfSink.java:120); 	at org.disq_bio.disq.HtsjdkVariantsRddStorage.write(HtsjdkVariantsRddStorage.java:150); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.writeVariantsSingle(VariantsSparkSink.java:103); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.writeVariants(VariantsSparkSink.java:79); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.java:189); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:308); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:224); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delega",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5997:1148,pipeline,pipelines,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5997,1,['pipeline'],['pipelines']
Deployability,",0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:6,0:6:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:1,0:1:0	0/0:5,0:5:0	0/0:4,0:4:0	0/0:5,0:5:00/0:4,0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:4,0:4:0	0/0:33,0:33:40	0/0:4,0:4:0	0/0:4,0:4:0	0/0:19,0:19:40	0/0:5,0:5:0	0/0:4,0:4:0	0/0:2,0:2:0	0/0:3,0:3:0	0/0:2,0:2:00/0:4,0:4:0	1/1:0,1:1:3:35,3,0	0/0:1,0:1:0	0/0:9,0:9:0	0/0:0,0:0:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:2,0:2:0	0/0:9,0:9:20	0/0:4,0:4:0	0/0:6,0:6:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:1,0:1:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:5,0:5:0	0/0:3,0:3:0	0/0:1,0:1:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:4,0:4:0	0/0:5,0:5:0	0/0:1,0:1:0	0/0:6,0:6:0	0/0:2,0:2:0	0/0:118,0:118:40	0/0:4,0:4:0	0/0:401,0:401:40	0/0:2,0:2:0; ```; Sadly a hom-var with RQQ (i.e. PL[0]) of 35 just shouldn't make it because of the prior, but all those GQ0 hom-refs had been giving it a boost. There are a LOT of differences in the WES results that I'm working on systematically summarizing, but everything I've spot-checked looks reasonable. Highlights from Picard variant_calling_summary_metrics for exome:; FILTERED_SNPS values differ. Value1: 14124 Value2: 15092 Changed by 968.0 (relative change of 0.06853582554517133); PCT_DBSNP values differ. Value1: 0.785208 Value2: 0.786779 Changed by 0.0015709996223449707 (relative change of 0.0020007433045657057); DBSNP_TITV values differ. Value1: 3.265418 Value2: 3.281538 Changed by 0.016119999999999912 (relative change of 0.004936580860398243); NOVEL_TITV values differ. Value1: 2.38526 Value2: 2.4175 Changed by 0.032239999999999824 (relative change of 0.01351634622640711); It's a pretty big difference in filtered SNPs, but the Ti/Tv values improve (keeping in mind we're looking at exome regions). I found an issue with the Picard variant calling detail metrics, so I don't trust the PCT_GQ0 values. With our low coverage exome data it makes a pretty significant difference in the unfiltered callrate, so we should point that out in the release notes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035522652:3399,release,release,3399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035522652,1,['release'],['release']
Deployability,"- 	ContextCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	CycleCovariate; 13:35:34.344 INFO ProgressMeter - Starting traversal; 13:35:34.344 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 13:35:44.363 INFO ProgressMeter - chr1:5384544 0.2 214000 1281820.9; ```. 2. Using full path with non-ascii characters in base directory as tmp path and it failed:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/≈Åuksza_2022_Nature"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/≈Åuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:36:33.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/int",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:5633,pipeline,pipeline,5633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:384,integrat,integrated,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943,1,['integrat'],['integrated']
Deployability,"- Adds the ‚Äúgatk‚Äù conda environment, with dependencies defined by the file scripts/gatkcondaenv.yml.; - Updates the docker image to include the activated conda environment.; - Adds a new entry to the travis test matrix for running tests that depend on Python and the conda environment.; - Adds a ‚Äúpython‚Äù test group. Any tests for tools or functionality that are dependent on Python should be put into this group. Tests in this group will be executed in a docker container on travis in the python build matrix entry only.; - The existing WDL tests are unchanged; so although they execute in the context of the docker container and conda environment, there are no tests (yet) that are actually dependent on the conda environment and run through cromwell.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912:104,Update,Updates,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912,1,['Update'],['Updates']
Deployability,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/815:45,pipeline,pipeline,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815,1,['pipeline'],['pipeline']
Deployability,- CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam is a very small input that triggers the bug.; - TestMath is a small demonstration of the underlying problem (order of operations changes the answer); - RecalDatum.java is updated to fix the problem; - BaseRecalibratorDataflowIntegrationTest runs the new code and confirms it's OK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/878:220,update,updated,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/878,1,['update'],['updated']
Deployability,"- Clarify tool documentation:; - Update `joint posteriors (JL)` to `joint posteriors (JP)`; - Remove statistical notes and provide link to GATK Article#11074 for background and math; - Consolidate Notes and Caveats sections; - Clarify at top the three different sources of priors and tool behavior regarding these; - Clarify for family priors the tool only considers trio groups; - Add Laura's comment that recent updates allow the tool to appropriately apply priors to indels; - Change logger.info to logger.warn for situation where trio pedigree file is incomplete; - Note that in this situation, in the absence of other refinement, the results are identical to the input",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601:33,Update,Update,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601,2,"['Update', 'update']","['Update', 'updates']"
Deployability,- Closes #5114 ; - Updates the WDL as well to expose the new files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5115:19,Update,Updates,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5115,1,['Update'],['Updates']
Deployability,- Creating PR for update to Funcotator documentation and to show off CARROT integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6920:18,update,update,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/523:120,integrat,integration,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523,1,['integrat'],['integration']
Deployability,- Extracted the order validation for GVCF files into a separate method and included; a check to reset the counter when a new contig is found. Contigs have to; occur in continuous blocks; validation for files in which contigs occur; alternatingly is not supported.; - Added a set of integration tests for GVCF files with two and three contigs. Fixes #6023,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6028:168,continuous,continuous,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6028,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"- Fixes https://github.com/broadinstitute/gatk/issues/4696, https://github.com/broadinstitute/gatk/issues/4342, https://github.com/broadinstitute/gatk/issues/4443, https://github.com/broadinstitute/gatk/issues/4444.; - Use a second FIFO for command acknowledgement instead of relying on prompt synchronization.; - Add a Python module for managing the Python side of GATK/Python interaction.; - Removed all timeouts.; - Install a Python exception handler for handling uncaught Python exceptions.; - Update CNNScoreVariants to use the new protocol.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4757:419,Install,Install,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4757,2,"['Install', 'Update']","['Install', 'Update']"
Deployability,- M2 WDL has explicit optional parameter for a list of fields that should be excluded from the output.; - Both M2 WDL files are updated. Manually tested mutect2.wdl on local backend. Closes #5141,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5242:128,update,updated,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5242,1,['update'],['updated']
Deployability,"- MAF is the output of Funcotator in M2 WDL. Closes #4935 ; - Updated mutect2.wdl manually tested locally and manually tested in FireCloud.; - Updated mutect2_nio.wdl manually tested in FireCloud.; - Updated automatic Cromwell WDL tests. Closes #4807 ; - Empty MAFs will be devoid of variants, not a file of 0 bytes. Closes #4937 ; - Fixed issue where multiple transcripts could be selected in edge cases, even when CANONICAL or BEST_EFFECT was selected. Closes #4952",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4941:62,Update,Updated,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4941,3,['Update'],['Updated']
Deployability,- Modified the files so that we can build libVectorLoglessPairHMM.so on Ubuntu/ppc64le platform; - Restored and modified the files for 128-bit vector that are on GATK3; - Added a new file to replace AVX with POWER8 vector instructions; - [Question] Is any unit test included in the repository to test the library?; - Confirmed that the library was built on Ubuntu 15.10/ppc64le. ```; ./gradlew installAll; :downloadGsaLibFile UP-TO-DATE; :extractIntelDeflater; :compileJava; :processResources; :classes; :compileVectorLoglessPairHMMSharedLibraryVectorLoglessPairHMMCpp; :linkVectorLoglessPairHMMSharedLibrary; :copySharedLib; :jar; :startScripts; :installDist; :sparkJar; :installSpark; :installAll. BUILD SUCCESSFUL; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748:394,install,installAll,394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748,4,['install'],"['installAll', 'installDist', 'installSpark']"
Deployability,- Move command line parser integration of read filters up to GATKTool (https://github.com/broadinstitute/gatk/issues/2175); - Added fromList method to ReadFilter and CountingReadFilter (https://github.com/broadinstitute/gatk/issues/2198); - Minor change/rationalization of naming and implementation of BQSR filter methods to match the rest of the framework; - Made a small change to the implementation of the base read filter class to improve clarity/testability; - Opportunistic removal of extraneous imports in unrelated classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218,1,['integrat'],['integration']
Deployability,"- Moved tools to ""Metagenomics"" program group; - Updated tool docs; - Changed tool arguments to kebab-case; - Defined argument strings as static variables that are cross-referenced in integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918:49,Update,Updated,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918,2,"['Update', 'integrat']","['Updated', 'integration']"
Deployability,"- No reblocking.; - Approximately equal-width of about 1 million bases intervals across human genome.; - [Import command used](https://github.com/Sydney-Informatics-Hub/Germline-ShortV/blob/master/gatk4_genomicsdbimport.sh) (university bioinformatics core facility's pipeline, not mine).; - 1 core and 4 GB RAM per task, but tasks seem to be using only about 1 GB RAM per task. 768 tasks (16 nodes) in total.; ```; %CPU WallTime Time Lim RSS mem memlim cpus; normal-exe = open&run; 105581211 R ds6924 hm82 genotype 4 00:18:25 02:00:00 1064GB 1064GB 3072GB 768; ```; - Jobs eventually finish if not running out of allocated time.; - Takes a long time to begin processing the first set of variants.; ```; 13:51:37.925 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:51:39.736 INFO GenotypeGVCFs - Done initializing engine; 13:51:39.923 INFO ProgressMeter - Starting traversal; 13:51:39.923 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:23:57.323 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr17:18363145 the annotation AS_RAW_MQ=64800.000|50400.000|0.000 was not a numerical value and was ignored; 14:23:57.346 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_RAW_MQ' detected, add -G Standard -G AS_Standard to the command to annotate in the final VC with this annotation.; 14:23:58.180 INFO ProgressMeter - chr17:18363854 32.3 1000 31.0; 14:24:13.258 INFO ProgressMeter - chr17:18376854 32.6 14000 430.0; 14:24:58.358 INFO ProgressMeter - chr17:18382854 33.3 20000 600.5; 14:32:49.287 INFO ProgressMeter - chr17:18393855 41.2 31000 753.2; 14:33:39.240 INFO ProgressMeter - chr17:18405856 42.0 43000 1024.1; 14:33:49.493 INFO ProgressMeter - chr17:18411856 42.2 49000 1162.3; 14:34:17.285 INFO ProgressMeter - chr17:18425856 42.6 63000 1478.1; ```. CPU utilisation does not improve after the variants begin proces",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879551089:267,pipeline,pipeline,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879551089,1,['pipeline'],['pipeline']
Deployability,- Now will count downloads of all artifacts in github releases instead of just the first one.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8418:54,release,releases,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8418,1,['release'],['releases']
Deployability,"- Now will detect variants on mitochondrial contigs and will use the; correct, alternate coding sequence to create protein change strings for; such variants.; - Added MT sequences to Gencode data source.; - Added tests for MT protein change strings.; - Now `FuncotatorUtils::getMitochondrialAminoAcidByCodon` has more; complete tests and handles special cases for known initiation site; differences by genus.; - Updated scripts to detect the directory in which the scripts are run.; - Added MT variants to integration tests.; - Added MT genes to gencode testing data source. Fixes #4863",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5361:412,Update,Updated,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5361,2,"['Update', 'integrat']","['Updated', 'integration']"
Deployability,- Picard Version: 2.18.16; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:33:26.276 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:33:26.276 INFO CountReadsSpark - Deflater: IntelDeflater; 11:33:26.276 INFO CountReadsSpark - Inflater: IntelInflater; 11:33:26.276 INFO CountReadsSpark - GCS max retries/reopens: 20; 11:33:26.276 INFO CountReadsSpark - Requester pays: disabled; 11:33:26.277 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4625,configurat,configuration,4625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['configurat'],['configuration']
Deployability,- Picard Version: 2.18.16; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:11.511 INFO CountReadsSpark - Deflater: IntelDeflater; 13:35:11.511 INFO CountReadsSpark - Inflater: IntelInflater; 13:35:11.512 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:35:11.512 INFO CountReadsSpark - Requester pays: disabled; 13:35:11.512 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4364,configurat,configuration,4364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['configurat'],['configuration']
Deployability,"- Push to `gvs` repo in `broad-dsde-methods` rather than `variantstore`.; - Fix the way image IDs are discovered.; - Support both `alpine` and non-`alpine` image types, setting up support for plink2. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/c1c2fc65-104b-46af-a536-882d7c1e8954).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8791:211,integrat,integration,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8791,1,['integrat'],['integration']
Deployability,"- Refactored GencodeGtfCodec to enable parsing of ENSEMBL GTF files.; - Created AbstractGtfCodec and EnsemblGtfCodec.; - Updated Funcotator and Funcotation Factories to allow ENSEMBL-based; GTF files.; - Added an e. coli data sources folder, reference, VCF, and expected; data for testing.; - Added tests for ENSEMBL GTF files. Fixes #6180",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477:121,Update,Updated,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477,1,['Update'],['Updated']
Deployability,- Relaxes restrictions for allowed samples in SVConcordance: the tool can now accept eval/truth VCFs with arbitrary sample sets and will have genotype concordance metrics computed on the intersection of the sample sets. All available samples are still used for AF/AC annotations. Integration tests added for cases when the samples sets are overlapping but not equal.; - Small additional improvements for sites-only VCFs: concordance annotations will now be `.` instead of `NaN` for example. Integration test added for this case.; - Improved behavior for eval AF annotations: these will not be recalculated if they already exist.; - Improved behavior for truth AF annotations: these will now only be recalculated if they don't exist in the input truth VCF.; - Updated tool doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8211:280,Integrat,Integration,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8211,3,"['Integrat', 'Update']","['Integration', 'Updated']"
Deployability,"- Released new data sources to google bucket and FTP site for both somatic and germline (clinical pipeline); - Updated data source download URL to point to the bucket for v1.6.20190124; - Updated minimum version of data sources to v1.6.20190124. With the release and these changes, the following issues are addressed:. Fixes #5259 ; Fixes #5428 ; Fixes #5429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5614:2,Release,Released,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5614,5,"['Release', 'Update', 'pipeline', 'release']","['Released', 'Updated', 'pipeline', 'release']"
Deployability,- Remove some unused VCF header fields from ExtractFeatures; - Renamed VQSR Lite fields to their original naming (e.g. AS_VQS_SENS becomes CALIBRATION_SENSITIVITY). Passing integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/67a00690-5b74-40fd-a0fb-5ab2b0407a4d) - uses updated truth. Example outputs can be found in [this](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/22134bb6-e4b5-4252-b674-860a1168fb6c) Extract run.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8412:173,integrat,integration,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8412,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,- Removed positive-negative training from TrainVariantAnnotationsModel along with associated integration and WDL tests.; - Added ability to run positive-unlabeled training by passing unlabeled annotations to a custom python backend (although no example backend or tests were added).; - Cleaned up some WDL arguments to allow distinct training and scoring python scripts.; - Removed the `useAlleleSpecificAnnotations` argument; we instead infer whether to run in allele-specific mode from the VCF header.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131:93,integrat,integration,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131,1,['integrat'],['integration']
Deployability,"- Running in mitochonrial mode; - Link to liquid biopsy blogpost will need to be added once it is posted; - Specifying tumor name is no longer necessary; - Af-of-alleles-not-in-resource is dynamically adjusted for modes; - Joint calling on multiple tumor and normal samples; - Mention and/or link to FilterMutectCalls, Funcotator and CreateSomaticPanelOfNormals; - Remove caveat and state instead M2's ability to handle extreme high depths; - Update HaplotypeCaller link from v3 to current; - Add 'Notes' section and make ordered list; - Move example AF resource snippet to 'Notes' section",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5769:443,Update,Update,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5769,1,['Update'],['Update']
Deployability,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802:102,Integrat,Integration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802,1,['Integrat'],['Integration']
Deployability,- Update htsjdk to 2.6.1; - Fix #2080,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2131:2,Update,Update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2131,1,['Update'],['Update']
Deployability,- Updated data sources to include variant sites for symbolic alleles.; - Fixed tests to be correct for new logic.; - Now has tests for symbollic alternate alleles and masked alleles. Fixes #5402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5406:2,Update,Updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5406,1,['Update'],['Updated']
Deployability,"- User defined transcripts were being used as a filter rather than a priority order. The filtering step has been eliminated. Closes #4918 ; - Fixed previously unidentified issue where locus level ranking was being reversed. Updated tests. This was identified thanks to the thousands of tests in Funcotator (only one failed, but that was all it took).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4931:224,Update,Updated,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4931,1,['Update'],['Updated']
Deployability,"- [ ] Currently [BaseRecalibrator runs with 4g of memory](https://github.com/broadinstitute/dsde-pipelines/blob/master/genomes_in_the_cloud/single_sample/PairedSingleSampleWf.wdl#L535-L554) in the production pipeline. We should check that it still does if we have bam index caching on. . - [ ] Similarly, make sure [ApplyBQSR runs with 3g of memory](https://github.com/broadinstitute/dsde-pipelines/blob/master/genomes_in_the_cloud/single_sample/PairedSingleSampleWf.wdl#L576-L597)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2380:97,pipeline,pipelines,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2380,3,['pipeline'],"['pipeline', 'pipelines']"
Deployability,- added GvsAssignIds to .dockstore.yaml; - added logic to GvsAssignIds to prevent bug from empty input; - updates to Quickstart README directions. Closes https://broadworkbench.atlassian.net/browse/VS-183,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463:106,update,updates,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463,1,['update'],['updates']
Deployability,- added up-to-date docker image for prepare step; - updated documentation to refer to the right past steps,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7522:52,update,updated,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7522,1,['update'],['updated']
Deployability,- error message was not updated when arguments were changed....,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5969:24,update,updated,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5969,1,['update'],['updated']
Deployability,"- improved baits count annotator (""lazy"" post processing); - included bait counts as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper; - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts; - missing test resource files from gatk-protected repo; - address PR review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183:341,integrat,integration,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183,2,['integrat'],['integration']
Deployability,"- matches the bootstrap updates for formatting ; - minor text tweaks, displays version clearly; - adds version switching menu. These changes will make it easier to upload new version docs quickly. This should definitely go in before the next version release. . Resulting docs are live at https://software.broadinstitute.org/gatk/documentation/tooldocs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4805:24,update,updates,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4805,2,"['release', 'update']","['release', 'updates']"
Deployability,"- new ""lazy"" annotation mode in TargetAnnotator (a hack for generating annotations that can not be done with a state-less FeatureWalker); - baits count target annotation; - included bait count as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper (PAR regions can not be blacklisted via CLI arguments); - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813:507,integrat,integration,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813,2,['integrat'],['integration']
Deployability,"- new version of BaseRecalibratorDataflow that fits into the skeleton framework; - new command-line BaseRecalibratorDataflow that uses the same code; - tests and test inputs for BaseRecalibrator. They pass, locally and on the cloud.; - fix for issue #791 via a new genomics-dataflow-java release; - smaller changes, like == -> .equals in SequenceDictionaryUtils and using getInstance() to follow the singleton pattern.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/812:288,release,release,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812,1,['release'],['release']
Deployability,- restore job stats collection to create_ranges_cohort_extract_data_table.py; - add writing of cost info to BigQuery table to create_ranges_cohort_extract_data_table.py and populate_alt_allele_table.py; - add task to GvsQuickstartIntegration.wdl that checks that expected cost data was written to BigQuery table; - tweaked schema for cost_observability table to include descriptions; ; Integration test run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/30a2d8ee-13dd-4829-b3a8-4e6a67409705; Closes https://broadworkbench.atlassian.net/browse/VS-480,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7915:386,Integrat,Integration,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7915,1,['Integrat'],['Integration']
Deployability,- update to gradle 8.4 and build with java 21; - fixing or supressing various warnings; - in progress; - allow warnings and update actions to 21 so we can run tetsts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8589:2,update,update,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8589,2,['update'],['update']
Deployability,"- updated integration test (removed that argument so it defaults to the same thing); - tested that using ""NONE"" as an argument works",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7206:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7206,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"- uses GvsExtractCohortFromSampleNames.wdl to generate VCFs for calculating P & S all in one WDL; - allows for use of an interval_list in P & S; - updates to docs; - Successful run here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/2537ea7b-f635-4609-8fbb-7eaec41a6df8; - integration run, since I touched the bulk ingest and extract VCF WDLs: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f71941ba-f02f-4472-a04c-aedff24fdd14",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8707:147,update,updates,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8707,2,"['integrat', 'update']","['integration', 'updates']"
Deployability,- |; | 0% | _new_ [.../hellbender/tools/examples/ExampleNioCountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654E696F436F756E7452656164732E6A617661) |; | 0% | _new_ [...oadinstitute/hellbender/utils/nio/ReadsIterable.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F52656164734974657261626C652E6A617661) |; | 0% | _new_ [...te/hellbender/utils/nio/ChannelAsSeekableStream.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4368616E6E656C41735365656B61626C6553747265616D2E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6763732F4275636B65745574696C732E6A617661) |; | 0% | _new_ [.../org/broadinstitute/hellbender/utils/nio/NioBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4E696F42616D2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 78% | _new_ [...lbender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F5365656B61626C65427974654368616E6E656C507265666574636865722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3e20270...3278411](https://codecov.io/gh/broadinstitute/gatk/compare/3e202701dc55ab49857643926a86a79680c96fc8...32784115864a989ac66eb482a9902c950302d744?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231:2583,update,update,2583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231,1,['update'],['update']
Deployability,"-- ; ; 00:12:21.142 INFO ¬†BaseRecalibrator - HTSJDK Version: 2.24.1 ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - Picard Version: 2.27.1 ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - Built for Spark Version: 2.4.5 ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:12:21.143 INFO ¬†BaseRecalibrator - Deflater: IntelDeflater ; ; 00:12:21.144 INFO ¬†BaseRecalibrator - Inflater: IntelInflater ; ; 00:12:21.144 INFO ¬†BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:12:21.144 INFO ¬†BaseRecalibrator - Requester pays: disabled ; ; 00:12:21.144 INFO ¬†BaseRecalibrator - Initializing engine ; ; 00:12:21.485 INFO ¬†FeatureManager - Using codec VCFCodec to read file file:///data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz ; ; 00:12:21.565 INFO ¬†FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz ; ; 00:12:21.688 INFO ¬†FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz ; ; 00:12:21.797 WARN ¬†IndexUtils - Feature file ""file:///data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file ; ; 00:12:21.895 WARN ¬†IntelInflater - Zero Bytes Written : 0 ; ; 00:12:21.966 INFO ¬†BaseRecalibrator - Done initializing engine ; ; 00:12:21.969 INFO ¬†BaseRecalibrationEngine - The covariates being used here: ; ; 00:12:21.969 INFO ¬†BaseRecalibrationEngine - ¬† ¬† ReadGroupCovariate ; ; 00:12:21.969 INFO ¬†BaseRecalibrationEngine - ¬† ¬† QualityScoreCovari",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:17815,pipeline,pipeline,17815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,-- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 72% | [...bender/utils/locusiterator/LocusIteratorByState.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6C6F6375736974657261746F722F4C6F6375734974657261746F72427953746174652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 83% | [...rg/broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4C6F63757357616C6B65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 87% | [...stitute/hellbender/tools/walkers/qc/CheckPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F71632F436865636B50696C6575702E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 96% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...broadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F417373656D626C79526567696F6E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...oadinstitute/hellbender/tools/walkers/qc/Pileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F71632F50696C6575702E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3e20270...7640a6f](https://codecov.io/gh/broadinstitute/gatk/compare/3e202701dc55ab49857643926a86a79680c96fc8...7640a6f668cfa87765af133f397ee1b26ecb6ded?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207:2577,update,update,2577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207,1,['update'],['update']
Deployability,"---------------------------------------------------; 01:07:02.003 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.004 INFO GenomicsDBImport - HTSJDK Version: 2.23.0; 01:07:02.005 INFO GenomicsDBImport - Picard Version: 2.22.8; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:07:02.005 INFO GenomicsDBImport - Deflater: IntelDeflater; 01:07:02.005 INFO GenomicsDBImport - Inflater: IntelInflater; 01:07:02.006 INFO GenomicsDBImport - GCS max retries/reopens: 20; 01:07:02.006 INFO GenomicsDBImport - Requester pays: disabled; 01:07:02.006 INFO GenomicsDBImport - Initializing engine; 01:07:02.331 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 01:07:02.702 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 01:07:02.868 INFO IntervalArgumentCollection - Processing 135534747 bp from intervals; 01:07:02.869 INFO GenomicsDBImport - Done initializing engine; 01:07:02.870 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10/callset.json; 01:07:02.870 INFO GenomicsDBImport - Incrementally importing to workspace - /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10; 01:07:02.871 INFO ProgressMeter - Starting traversal; 01:07:02.871 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 01:07:03.006 INFO GenomicsDBImport - Shutting down engine; [August 29, 2020 at 1:07:03 AM HKT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:12254,update,update-workspace-path,12254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['update'],['update-workspace-path']
Deployability,"---------------------------------------------------; 10:49:12.233 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.233 INFO GenomicsDBImport - HTSJDK Version: 2.23.0; 10:49:12.233 INFO GenomicsDBImport - Picard Version: 2.22.8; 10:49:12.234 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:49:12.234 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:49:12.234 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:49:12.234 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:49:12.234 INFO GenomicsDBImport - Deflater: IntelDeflater; 10:49:12.234 INFO GenomicsDBImport - Inflater: IntelInflater; 10:49:12.234 INFO GenomicsDBImport - GCS max retries/reopens: 20; 10:49:12.234 INFO GenomicsDBImport - Requester pays: disabled; 10:49:12.235 INFO GenomicsDBImport - Initializing engine; 10:49:12.577 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 10:49:12.938 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 10:49:13.163 INFO IntervalArgumentCollection - Processing 51304566 bp from intervals; 10:49:13.163 INFO GenomicsDBImport - Done initializing engine; 10:49:13.164 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1/callset.json; 10:49:13.164 INFO GenomicsDBImport - Incrementally importing to workspace - /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1; 10:49:13.164 INFO ProgressMeter - Starting traversal; 10:49:13.164 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:49:13.231 INFO GenomicsDBImport - Shutting down engine; [June 18, 2021 10:49:13 AM KST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport don",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:3164,update,update-workspace-path,3164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['update'],['update-workspace-path']
Deployability,"------------------------------------------------; 14:21:35.543 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 14:21:35.544 INFO PostprocessGermlineCNVCalls - HTSJDK Version: 2.15.1; 14:21:35.545 INFO PostprocessGermlineCNVCalls - Picard Version: 2.18.2; 14:21:35.547 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:21:35.548 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:21:35.549 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:21:35.550 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:21:35.552 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 14:21:35.553 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 14:21:35.554 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 14:21:35.555 INFO PostprocessGermlineCNVCalls - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:21:35.556 WARN PostprocessGermlineCNVCalls -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PostprocessGermlineCNVCalls is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:21:35.557 INFO PostprocessGermlineCNVCalls - Initializing engine; 14:21:35.976 INFO FeatureManager - Using codec BEDCodec to read file file:///bettik/tintest/NTM/bam/1-3-9-17-Y-M/Refseq_GrCh38_1-3-9-17-Y-M.bed; 14:21:36.034 INFO IntervalArgumentCollection - Processing 251589470 bp from intervals; 14:21:38.716 INFO PostprocessGermlineCNVCalls - Done initializing engine; 14:21:38.879 INFO PostprocessGermlineCNVCalls - Shutting down engine; [August 1, 2018 2:21:38 PM CEST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=226",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231:3830,patch,patch,3830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231,1,['patch'],['patch']
Deployability,---------------------------------------------; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Version: 2.24.0; 01:22:35.483 INFO GenomicsDBImport - Picard Version: 2.25.0; 01:22:35.483 INFO GenomicsDBImport - Built for Spark Version: 2.4.5; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:22:35.483 INFO GenomicsDBImport - Deflater: IntelDeflater; 01:22:35.483 INFO GenomicsDBImport - Inflater: IntelInflater; 01:22:35.483 INFO GenomicsDBImport - GCS max retries/reopens: 20; 01:22:35.483 INFO GenomicsDBImport - Requester pays: disabled; 01:22:35.484 INFO GenomicsDBImport - Initializing engine; 01:24:58.683 INFO FeatureManager - Using codec BEDCodec to read file file:///lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/intervals.bed; 01:24:58.801 INFO IntervalArgumentCollection - Processing 11500 bp from intervals; 01:24:58.803 INFO GenomicsDBImport - Done initializing engine; 01:24:59.055 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 01:25:02.076 INFO GenomicsDBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - I,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:2814,update,update,2814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,"--------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:28:44.641 INFO GenotypeGVCFs - Deflater: IntelDeflater; 22:28:44.641 INFO GenotypeGVCFs - Inflater: IntelInflater; 22:28:44.641 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 22:28:44.641 INFO GenotypeGVCFs - Requester pays: disabled; 22:28:44.641 INFO GenotypeGVCFs - Initializing engine; ```. #### Steps to reproduce; I've followed the recommendation to process my genome in parallel, each chromosome at a time, so I created the commands based on the following pipeline:; ```; # HC; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample1.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample2.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample3.HC.gvcf -ERC GVCF. # GenomicsDBImport for Chr1; export TILEDB_DISABLE_FILE_LOCKING=1 ; gatk GenomicsDBImport --java-options ""-Xmx4g -Xms4g"" -V sample1.HC.gvcf -V sample2.HC.gvcf -V sample3.HC.gvcf --genomicsdb-workspace-path GenomicsDB_1 --tmp-dir /tmp -L 1. # GenotypeGVCFs; gatk GenotypeGVCFs --java-options ""-Xmx12g -Xms12g"" -R GRCh38.fasta -V gendb://GenomicsDB_1 --tmp-dir /tmp -O samples.1.vcf; ```; The jobs were send to the HPC scheduler and were allocated 2 CPUs and up to 16GB of RAM each. Everything till the last genotype calling step worked fine (and quite quickly) ; #### Expected behavior; The tool should call variants from the G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7007:2740,pipeline,pipeline,2740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007,1,['pipeline'],['pipeline']
Deployability,"----. ## Bug Report. ### Affected tool(s) or class(es); - GATK; - gcnvkernel ; - theano. ### Affected version(s); - GATK 4.1.0.0; - gcnvkernel 0.0.7; - theano 0.9.0; - GCC 7.3.0. ### Description ; I have installed the python package theano(which is a requirement of gcnvkernel) with python 3.6.6 which is compiled with gcc 7.3.0. I am not using the conda environment to install these packages.; Then i tried to run theano-nose, but is giving me the following error:. ```sh. $ theano-nose; --; ; You can find the C code in this temporary file: /tmp/theano_compilation_error_gp0ar1kx; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x1a): is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x6b): is not found.; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:204,install,installed,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,3,"['INSTALL', 'install']","['INSTALLDIRGATK', 'install', 'installed']"
Deployability,"----. ## Bug Report. ### Affected tool(s) or class(es); GATK HaplotypeCaller and GenomicsDBImport . ### Affected version(s); Version=""4.1.1.0"". ### Description ; In 7% of 8M variants in a 9 sample variant calling there is a discordance at least once between the GT and PGT field of a sample. The discordance between the GT and PGT fields can be found in the GVCF files created by the HaplotypeCaller and in the multi-sample VCF created by GenomicsDBImport. . This issue and pullrequest might be related, but have not been updated since March. ; https://github.com/broadinstitute/gatk/issues/5727; https://github.com/broadinstitute/gatk/pull/5772. I also already created this post on the forum. ; https://gatkforums.broadinstitute.org/gatk/discussion/24465/how-can-a-homozygous-reference-0-0-genotype-gt-have-a-heterozygous-phased-genotype-pgt-of-0-1#latest. Just thought it might help to (also) ask here, for me and other people who encounter this issue. . #### Steps to reproduce. Run the script below on any multi-sample VCF file created by GenomicsDBImport. ; The GT and PGT discordance is already in the GVCF files. But I did not test this script on any GVCF file. . The most important bit of the script is this comparison between the allele sets of the GT and PGT field. ; ```; if gt_allele_set == {0} and pgt_allele_set == {0,1}:; variant_with_phase_homref_to_het_issue = True; if gt_allele_set == {2} and pgt_allele_set == {1}:; variant_with_phase_hom22_to_hom11_issue = True; elif gt_allele_set == {0,2} and pgt_allele_set == {0,1}:; variant_with_phase_het02_to_het01_issue = True; ```. ```; from cyvcf2 import VCF, Writer. path = ""/DA_1458/VSDA_1458-gatk-haplotype-joint-annotated.bcf""; output_path_hom_ref_to_het = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_homref_to_het.vcf""; output_path_hom22_to_hom11 = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_hom22_to_hom11.vcf""; output_path_het02_to_het01 = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_het02_to_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6220:522,update,updated,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6220,1,['update'],['updated']
Deployability,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:377,install,install,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,2,['install'],['install']
Deployability,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['release'],['release']
Deployability,"----. ## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF . ### Affected version(s); 4.2.0.0. ### Description ; When running ReblockGVCF the following exception occurs:. `java.lang.IllegalArgumentException: cannot add a genotype with GQ=-1 because it's not within bounds [0,20); `. #### Steps to reproduce. Using a gVCF created with 4.2.0.0 HaplotypeCaller... `gatk ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz`. #### Expected behavior; Should run to completion and create reblocked GVCF. #### Actual behavior; ```; Reblocking gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz to gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; 11:25:55.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 30, 2021 11:25:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:25:55.708 INFO ReblockGVCF - ------------------------------------------------------------; 11:25:55.709 INFO ReblockGVCF - The Genome Analysis Toolkit (GATK) v4.2.0.0; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334:870,install,install,870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334,1,['install'],['install']
Deployability,"----. ## Bug Report; Hi, I'm trying the CNV detection pipeline from GATK: https://gatk.broadinstitute.org/hc/en-us/categories/360002310591; However, when running the Determine Germline Contig Ploidy step, I stumble upon this error. Please guide me to solve this problem. ### Affected tool(s) or class(es); ```; gatk DetermineGermlineContigPloidy \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:54,pipeline,pipeline,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,1,['pipeline'],['pipeline']
Deployability,"----. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; CombineGVCFs. ### Affected version(s); - [ ] Latest public release version [version?] Yes; - [ ] Latest master branch as of [date of test?] singularity. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; I am trying to combine GVCFs for joint-calllings and I am using the latest singularity release of GATK. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I am trying to run GATK and CombineGVCF failed.; I am using the following code:; singularity exec /fs/scratch/PHS0338/appz/GVCF/gatk_latest.sif \; gatk CombineGVCFs -R /users/PHS0338/jpac1984/data/Autosome.fasta \; --variant PA113.vcf.gz --variant PA113corr.vcf.gz --variant PA112.vcf.gz --variant PA112corr.vcf.gz --variant IN33.vcf.gz\; --variant IN33corr.vcf.gz --variant AL82.vcf.gz \; -O test.vcf.gz; It has all the parameters as mentioned in the website: https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs. #### Expected behavior; _Tell us what should happen_; According to the website (https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs) about combineGVCF, it should have worked fine without any problems... I got the following error log:. 20:11:34.701 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 13, 2021 8:11:35 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 20:11:35.527 INFO CombineGVCFs - ------------------------------------------------------------; 20:11:35.527 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 20:11:3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:143,release,release,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,2,['release'],['release']
Deployability,--sparkRunner GCS \; --cluster methods-test-cluster \; --executor-cores 4 \; --executor-memory 20g; ```. ```; org.broadinstitute.hellbender.exceptions.GATKException: unable to write bam: org.apache.hadoop.fs.FileAlreadyExistsException: A directory with that name exists: gs://hellbender/test/output/gatk4-spark/recalibrated.bam; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:253); 	at org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark.runTool(ApplyBQSRSpark.java:49); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:349); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266830647:2022,deploy,deploy,2022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266830647,6,['deploy'],['deploy']
Deployability,--|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1934,Integrat,IntegrationUtils,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961,1,['Integrat'],['IntegrationUtils']
Deployability,-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\fireba,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4755,RELEASE,RELEASE,4755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"-Added a ""large files"" directory to src/test/resoureces containing files managed; by ""git lfs"" rather than checked directly into the hellbender repository.; Updated setup instructions in README appropriately to reflect new requirement; for git lfs. -Added a bam with ~600,000 reads from chromosomes 20 and 21, as well as ~50000; unmapped reads. -Added a snippet of the b37 reference with all of chromosomes 20 and 21. -Added a DBSNP vcf containing variants overlapping the reads in the bam above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/839:157,Update,Updated,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/839,1,['Update'],['Updated']
Deployability,-Changed sampling of denoised copy ratios to address memory spike and updated output formats and filenames. Partially addresses #5754.; -Updated theano version to 1.0.4 and changed numpy install source to conda defaults to enable MKL.; -Updated theano flags to use MKL and OpenMP elemwise. Closes #5764.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5781:70,update,updated,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781,4,"['Update', 'install', 'update']","['Updated', 'install', 'updated']"
Deployability,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/297:951,release,release,951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297,1,['release'],['release']
Deployability,"-Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar FilterMutectCalls -V tumor-vs-normal.mutect.temp1.vcf -O tumor-vs-normal.mutect.temp2.vcf; 22:58:25.052 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:58:26.911 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.912 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.12.0; 22:58:26.912 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:58:26.912 INFO FilterMutectCalls - Executing as www-data@SpongeBob on Linux v4.15.0-39-generic amd64; 22:58:26.912 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 22:58:26.912 INFO FilterMutectCalls - Start Date/Time: January 6, 2019 10:58:24 PM SGT; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Version: 2.18.1; 22:58:26.913 INFO FilterMutectCalls - Picard Version: 2.18.16; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:58:26.914 INFO FilterMutectCalls - Deflater: IntelDeflater; 22:58:26.914 INFO FilterMutectCalls - Inflater: IntelInflater; 22:58:26.914 INFO FilterMutectCalls - GCS max retries/reopens: 20; 22:58:26.914 INFO FilterMute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:1171,release,release-,1171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085,1,['release'],['release-']
Deployability,-ERC BP_RESOLUTION mode in HaplotypeCaller needs an integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6833:52,integrat,integration,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6833,1,['integrat'],['integration']
Deployability,"-O output.bam. Mostly, I just get an identical 9GB bam over and over again (as confirmed by md5). However, sometimes (~10% of the time it seems), I get a MUCH larger ‚Äúbam‚Äù, more like ~45GB. In runs where I get these larger output files, they are not always the same size, sometimes 45GB, sometimes 47GB (still always with the same input file, same commandline, same wdl task, etc). The runs that produce these larger bam also take much longer, with slower ‚Äúreads per minute rate). They report exactly the same number of reads processed in the logs as the ‚Äúnormal‚Äù runs. Looking inside the large output ‚Äúbams‚Äù with gsutil cat, I see the header suddenly transitioning from compressed looking jibberish to a plaintext header, and then after a bit back to compressed looking jibberish again. Additionally, if I run these large bams through samtools view to get samtools to write them as a bam (ie samtools view big.bam -o samtools_out.bam) the resulting bam is much smaller ~6GB. It kind of seems like sometimes gatk will just stop compressing the output, and then start back up again, seemingly randomly??. I suspect this may be an issue with all gatk tools, I first encountered this recently with PostProcessReadsForRSEM, and then confirmed the behavior in PrintReads as a minimal example. Maybe it‚Äôs something to do with google hardware, I‚Äôve only seen this in Terra so far (not that I‚Äôve tried to reproduce it anywhere else).; seeing this in 4.2.6.0. Summary of investigative results:; * reproducible on very small files (at about same rate of ~10%); * appears to be related to intel deflater. when running with jdk deflater (--use-jdk-deflater) all 100/100 runs result in same sized bam. I‚Äôve run a version sweep, and it looks like the behavior begins in 4.2.1.0, but does not occur in earlier versions. Looking at the 4.2.1.0 release notes, **it seems highly likely that the issue was introduced by the upgrade from gkl 0.8.6 to gkl 0.8.8 in https://github.com/broadinstitute/gatk/pull/7203/files**",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8141:2027,release,release,2027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8141,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"-Prints the current locus, the elapsed time, number of records processed,; and the rate at which records are being processed. -Hooked up for ReadWalkers, VariantWalkers, and IntervalWalkers. -A new command-line arg in GATKTool allows control over the frequency of; progress meter updates. -Tweaked the log4j output format to create more screen space for logger output. Resolves #974 (for alpha purposes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1037:280,update,updates,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1037,1,['update'],['updates']
Deployability,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3519:1047,update,updated,1047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519,1,['update'],['updated']
Deployability,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:664,Update,Updated,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,2,"['Update', 'integrat']","['Updated', 'integration']"
Deployability,"-Tools can now customize the progress meter to use a different word than; ""records"" in its output (eg., ""reads"", ""regions"", etc.). -Updated standard walker classes to specify appropriate labels. -Hooked up GenomicsDBImport to the progress meter (it was always reporting; ""Processed 0 records"" at traversal end). Resolves #1943; Resolves #2683",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2690:132,Update,Updated,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2690,1,['Update'],['Updated']
Deployability,"-a-reference-with-alternate-contigs-like-grch38> for the implications. This section also gives the first hack--remove the `0x1` SAM flag to circumvent the now `MateOnSameContigOrNoMappedMateReadFilter`. ; - The second hack is in the current Mutect2 hands-on tutorial where I have users `--disableReadFilter MateOnSameContigOrNoMappedMateReadFilter`. This latter hack is particularly germane to somatic analyses where there can be many fusion events. The `MateOnSameContigOrNoMappedMateReadFilter` filter asks HaplotypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3764:2411,pipeline,pipelines,2411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764,1,['pipeline'],['pipelines']
Deployability,"-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL1NvbWF0aWNDbHVzdGVyaW5nTW9kZWwuamF2YQ==) | `99.35% <100%> (√∏)` | `65 <1> (√∏)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <0%> (-0.95%)` | `1% <0%> (√∏)` | |; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <0%> (√∏)` | `59% <0%> (+1%)` | :arrow_up: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (√∏)` | `2% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=footer). Last update [fb2b5a2...6cc5267](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133:4604,update,update,4604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133,2,['update'],['update']
Deployability,"-disable_annealing=false; Traceback (most recent call last):; File ""/data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-28-1-Test-gCNV_23-40-33/2-Output/8-GATK-Temp/cohort_denoising_calling.7177495255490777642.py"", line 10, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 16, in <module>; from pymc3.theanof import floatX; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/theanof.py"", line 89, in <module>; empty_gradient = tt.zeros(0, dtype='float32'); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 2558, in zeros; return alloc(np.array(0, dtype=dtype), *shape); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 3091, in __call__; ret = super(Alloc, self).__call__(val, *shapes, **kwargs); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 858, in make_c_thunk; outpu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019:4910,continuous,continuous,4910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019,1,['continuous'],['continuous']
Deployability,-haplotype-to-reference-mismatch-penalty -150 --smith-waterman-haplotype-to-reference-ga; p-open-penalty -260 --smith-waterman-haplotype-to-reference-gap-extend-penalty -11 --smith-waterman-read-to-haplotype-match-value 10 --smith-waterman-read-to-haplotype-mismatch-penalty -15; --smith-waterman-read-to-haplotype-gap-open-penalty -30 --smith-waterman-read-to-haplotype-gap-extend-penalty -5 --flow-assembly-collapse-hmer-size 0 --flow-assembly-collapse-partial-mode; false --flow-filter-alleles false --flow-filter-alleles-qual-threshold 30.0 --flow-filter-alleles-sor-threshold 3.0 --flow-filter-lone-alleles false --flow-filter-alleles-debug-graphs fal; se --min-assembly-region-size 50 --max-assembly-region-size 300 --active-probability-threshold 0.002 --max-prob-propagation-distance 50 --force-active false --assembly-region-padding 100 -; -padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-extension-into-assembly-region-padding-legacy 25 --max-reads-per-alignment-start 50 --enable-legacy-assemb; ly-region-trimming false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-pro; gress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md; 5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --dis; able-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false ; --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false --minimum-mapping-quality 20 --disable-tool-default-annotations false --enable-all-annotati; ons false --a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:9073,update,updates,9073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,1,['update'],['updates']
Deployability,"-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-iconv-perl libtie-ixhash-perl; libtimedate-perl libtinfo-dev libtk8.6 libtsan0 libubsan0 libunistring0; liburi-perl libwww-perl libwww-robotrules-perl libx11-protocol-perl libxaw7; libxcb-shape0 libxft2 libxml-parser-perl libxml-twig-perl; libxml-xpathengine-perl libxmu6 libxmuu1 libxpm4 libxss1 libxtables11 libxv1; libxxf86dga1 linux-libc-dev m4 make man-db manpages manpages-dev netbase; patch perl perl-modules-5.22 po-debconf python-pkg-resources python-scour; python-six r-base-core r-base-dev r-doc-html rename tzdata x11-utils; x11-xserver-utils xdg-utils zip zlib1g-dev```. -Not sure if moving the R install to the conda environment (which is not in the base image) will increase Travis time, but it doesn't appear to from the limited number of builds that have run so far. At some point we may want to move conda into the base image. However, I think that this would require that the base be rebuilt with every python code change, which is not optimal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:3378,patch,patch,3378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,4,"['install', 'patch']","['install', 'patch']"
Deployability,"-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see description. #### Actual behavior; see description. ----. ## Feature request; - Switch from pymc3/Theano to another framework that offers the same functio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3260,INSTALL,INSTALLDIRGCC,3260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGCC']
Deployability,-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - Th,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1569,pipeline,pipelines,1569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['pipeline'],['pipelines']
Deployability,". ---; ## FindBreakpointEvidenceSpark. 1. Assembles and aligns contigs of genomic breakpoint regions associated with structural variants ; 2. Overview and Notes could use finessing but let's leave this for next year. One thing to include is a reference to FermiLite for those seeking more information. A publication would be best. And `6. ` from above. ---; ## StructuralVariationDiscoveryPipelineSpark. 1. Runs the structural variant discovery workflow on a single sample in Spark ; 2. Fyi we sanction a ""Caveats"" section, which is likely more appropriate for the PE expectation and the fact that low coverage data less than 30x will give suboptimal results. Also, should mention this workflow is meant only for WGS. Or is it the case one case use exome data? Second note on BwaMemIndexImageCreator could be consolidated with the same under Inputs. Same with third note. And `6. ` from above. ---; ## SvDiscoverFromLocalAssemblyContigAlignmentsSpark. 1. ""Parse"" is vague. Please clarify one-line summary.; 2. Again place up top ""This tool is used in development and should not be of interest to most researchers."". ---; ## ParallelCopyGCSDirectoryIntoHDFSSpark. 1. Let's explain the acronyms or their use context, e.g.; Parallel copy a file or directory from Google Cloud Storage into the HDFS format used in Spark. 2. GCS refers to Google Cloud Storage and HDFS to Hadoop Distributed File System. The latter is used in Spark ... - What is the difference between RDD (resilient distributed datasets) and HDFS? ; - Can I use globbing? ; - Why do I need this tool in the SV pipeline? ; - Can the tool run in Spark and nonSpark modes?. And `6. ` from above.; ```; gatk ParallelCopyGCSDirectoryIntoHDFSSpark \; --input-gcs-path gs://my-bucket/my-data-directory/ \; --output-hdfs-directory hdfs://my-dataproc-spark-cluster-m:8020/my-data \; -- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```; - Can we update the example command so it is more concrete, e.g. takes a BAM or multiple BAMs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:4988,pipeline,pipeline,4988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,4,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,". Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2493,INSTALL,INSTALLDIRGATK,2493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,". Out of curiosity, we tried building the docker again without samtools, so in theory, the only possible change is that when each docker is built, apt update is run. The differences are small, but is that expected? That with and without samtools, and if `apt` packages change, mutect2 could be influenced?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I can't replicate scenario 1 in the table because it was built in 2019, so apt packages were different then.; Scenario 2 dockerPull: `docker pull kfdrc/gatk:4.1.1.0`; Scenario 3 dockerPull: `docker pull pgc-images.sbgenomics.com/d3b-bixu/gatk:4.1.1.0`; Scenario 4 dockerPull: `docker pull migbro/gatk:4.1.1.0L`. No samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. Yes samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1 tabix samtools; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. #### Expected behavior; _Tell us what should happen_; All `PASS` var counts are the same; #### Actual behavior; _Tell us what happens instead_; `PASS` var counts vary slightly +/- samtools and year docker built; ----; Thank you for your time!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269:1888,update,update,1888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269,6,"['install', 'release', 'update']","['install', 'releases', 'update']"
Deployability,"..............................................(BUG 001).......................................................... Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.3351404099122294482.py"", line 8, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 16, in <module>; from pymc3.theanof import floatX; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/theanof.py"", line 89, in <module>; empty_gradient = tt.zeros(0, dtype='float32'); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 2558, in zeros; return alloc(np.array(0, dtype=dtype), *shape); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 3091, in __call__; ret = super(Alloc, self).__call__(val, *shapes, **kwargs); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 858, in make_c_thunk; outpu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:2287,continuous,continuous,2287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['continuous'],['continuous']
Deployability,"....................................................(BUG 002)..........................................................; Stderr: Traceback (most recent call last):; File ""/tmp/segment_gcnv_calls.3402406683372415608.py"", line 9, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 16, in <module>; from pymc3.theanof import floatX; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/theanof.py"", line 89, in <module>; empty_gradient = tt.zeros(0, dtype='float32'); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 2558, in zeros; return alloc(np.array(0, dtype=dtype), *shape); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 3091, in __call__; ret = super(Alloc, self).__call__(val, *shapes, **kwargs); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 858, in make_c_thunk; outpu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:10354,continuous,continuous,10354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['continuous'],['continuous']
Deployability,...I mean tomorrow's release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5341#issuecomment-431919309:21,release,release,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5341#issuecomment-431919309,1,['release'],['release']
Deployability,...at which point we will write RELEASE NOTES with warnings about batch effects in BIG LETTERS!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-393219775:32,RELEASE,RELEASE,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-393219775,1,['RELEASE'],['RELEASE']
Deployability,..ender/tools/spark/sv/SVReadLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356526561644C696B656C69686F6F6443616C63756C61746F722E6A617661) |; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | [.../walkers/genotyper/GenotypeLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970654C696B656C69686F6F6443616C63756C61746F722E6A617661) |; | ‚Ä¢ 18% | _new_ [...ools/spark/sv/InversionReadLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F496E76657273696F6E526561644C696B656C69686F6F6443616C63756C61746F722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 54% | _new_ [...sv/SingleDiploidSampleBiallelicSVGenotyperSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53696E676C654469706C6F696453616D706C654269616C6C656C6963535647656E6F7479706572537061726B2E6A617661) |. > [Review all 23 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare); > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...ab2343e](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...ab2343eb97e055f29152a4b3c6d9b88db8d72190?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369:4134,update,update,4134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369,1,['update'],['update']
Deployability,..llbender/tools/genomicsdb/GenomicsDBConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJDb25zdGFudHMuamF2YQ==) | `0% <0%> (√∏)` | `0% <0%> (√∏)` | :arrow_down: |; | [...r/tools/walkers/annotator/ClippingRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9DbGlwcGluZ1JhbmtTdW1UZXN0LmphdmE=) | `100% <0%> (√∏)` | `4% <0%> (√∏)` | :arrow_down: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <0%> (+0.676%)` | `33% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.485% <0%> (+0.825%)` | `61% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (√∏)` | :arrow_down: |; | ... and [588 more](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431:3926,Integrat,IntegrationTestSpec,3926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431,1,['Integrat'],['IntegrationTestSpec']
Deployability,./gradlew install - turn off javadoc checks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1955:10,install,install,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1955,1,['install'],['install']
Deployability,".01%`.; > The diff coverage is `n/a`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/gatk/pull/5565/graphs/tree.svg?width=650&token=7RuX7LsQVf&height=150&src=pr)](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #5565 +/- ##; ============================================; - Coverage 87.09% 87.08% -0.01% ; + Complexity 31524 31522 -2 ; ============================================; Files 1930 1930 ; Lines 145231 145231 ; Branches 16095 16095 ; ============================================; - Hits 126482 126479 -3 ; - Misses 12900 12901 +1 ; - Partials 5849 5851 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (-0.95%)` | `33% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.6% <0%> (-0.26%)` | `144% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=footer). Last update [f9a2e5c...18a9e40](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810:2145,update,update,2145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810,2,['update'],['update']
Deployability,".076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(Se",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220:1808,patch,patch,1808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220,1,['patch'],['patch']
Deployability,".076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(Sequenc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384:1808,patch,patch,1808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384,1,['patch'],['patch']
Deployability,.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springfra,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4573,RELEASE,RELEASE,4573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,".267% <0%> (-1.635%)` | `36% <0%> (+4%)` | |; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (√∏)` | `2% <0%> (√∏)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.911% <0%> (+0.244%)` | `83% <0%> (+38%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+1.774%)` | `49% <0%> (+13%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=footer). Last update [dfa9cf1...5a67eb6](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-285786533:4510,update,update,4510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-285786533,2,['update'],['update']
Deployability,".433;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2871800,797;ReadPosRankSum=0.433	GT:AD:DP:GQ:PL:SB	0/2:414,2,357,0:773:99:14672,11361,50781,0,41338,45124,13972,52387,44158,56529:206,208,177,182; chr13	32944608	.	T	A,*,<NON_REF>	0	.	BaseQRankSum=5.453;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2869200,797;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I targe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:5839,pipeline,pipeline,5839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['pipeline'],['pipeline']
Deployability,.6.1-local.jar ; ; Running: ; ; ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam ; ; 00:11:11.683 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.697 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:11:11.700 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.700 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:11:11.812 INFO ¬†BaseRecalibrator - ------------------------------------------------------------ ; ; 00:11:11.813 INFO ¬†BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:11:11.813 INFO ¬†BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:11:11.813 INFO ¬†Base,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:9170,pipeline,pipeline,9170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,".77	.	BaseQRankSum=4.433;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQ=2871800.00;ReadPosRankSum=0.433	GT:AD:DP:GQ:PL:SB	0/2:414,2,357,0:773:99:14672,11361,50781,0,41338,45124,13972,52387,44158,56529:206,208,177,182; chr13	32944608	.	T	A,*,<NON_REF>	14811.77	.	BaseQRankSum=5.453;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQ=2869200.00;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	14802.73	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQ=2833200.00;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. And in the latest public release version [4.1.2.0], variant A>TAAAA was filtered as the QUAL is zero I guessed.; *vcf of 4.1.2.0*; ```vcf of 4.1.2.0; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	19B0117493; chr13	32944606	.	CTTT	C	9240.60	.	AC=1;AF=0.500;AN=2;BaseQRankSum=1.37;DP=813;ExcessHet=3.0103;FS=0.518;MLEAC=1;MLEAF=0.500;MQ=60.03;MQRankSum=0.00;QD=11.85;ReadPosRankSum=0.295;SOR=0.728	GT:AD:DP:GQ:PL	0/1:423,357:780:99:9248,0,45245; ```; *gvcf of 4.1.2.0*; ```gvcf of 4.1.2.0; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	19B0117493; chr13	32944440	.	T	<NON_REF>	.	.	END=32944605	GT:DP:GQ:MIN_DP:PL	0/0:592:99:352:0,120,1800; chr13	32944606	.	CTTT	C,<NON_REF>	9240.60	.	BaseQRankSum=1.374;DP=813;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2929400,813;ReadPosRankSum=0.295	GT:AD:DP:GQ:PL:SB	0/1:423,357,0:780:99:9248,0,45245,10522,46330,56852:212,211,175,182; chr13	32944607	.	T	A,*,<NON_REF>	0	.	BaseQRankSum=4.433;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:3907,release,release,3907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['release'],['release']
Deployability,".794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:373); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1966,release,release,1966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['release'],['release']
Deployability,".893 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:35:32.893 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:32.893 INFO BaseRecalibrator - Deflater: IntelDeflater; 13:35:32.893 INFO BaseRecalibrator - Inflater: IntelInflater; 13:35:32.894 INFO BaseRecalibrator - GCS max retries/reopens: 20; 13:35:32.894 INFO BaseRecalibrator - Requester pays: disabled; 13:35:32.894 INFO BaseRecalibrator - Initializing engine; 13:35:33.276 INFO FeatureManager - Using codec VCFCodec to read file file:///data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz; 13:35:33.545 INFO FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz; 13:35:33.884 INFO FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz; 13:35:34.129 WARN IndexUtils - Feature file ""file:///data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 13:35:34.232 WARN IntelInflater - Zero Bytes Written : 0; 13:35:34.282 INFO BaseRecalibrator - Done initializing engine; 13:35:34.285 INFO BaseRecalibrationEngine - The covariates being used here:; 13:35:34.285 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	ContextCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	CycleCovariate; 13:35:34.344 INFO ProgressMeter - Starting traversal; 13:35:34.344 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 13:35:44.363 INFO ProgressMeter - chr1:5384544 0.2 214000 1281820.9; ```. 2. Using full path with non-ascii characters in base directory as tmp path and it failed:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:4082,pipeline,pipeline,4082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/08/02 20:24:09 INFO util.ShutdownHookManager: Shutdown hook called; 16/08/02 20:24:09 INFO util.ShutdownHookManager: Deleting directory /ssd_hdfs2/spark_tmp/spark-42d0223f-b492-43e3-a6fa-d4edd98b2324,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:2874,deploy,deploy,2874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,6,['deploy'],['deploy']
Deployability,.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8299,Continuous,ContinuousBuildActionExecuter,8299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buil,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7447,Continuous,ContinuousBuildActionExecuter,7447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,".BwaMemIndex.createReferenceIndex(Native Method); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:227); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:196); at org.broadinstitute.hellbender.BwaMemIntegrationTest.loadIndex(BwaMemIntegrationTest.java:49); Running Test: Test method testChimericUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3328,Pipeline,PipelineSupportIntegrationTest,3328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['Pipeline'],['PipelineSupportIntegrationTest']
Deployability,".Main.main(Main.java:292); ```. ## Cases when the error does not occur; * If I rename `test a` folder in `test-a` as previously said.; * If I copy my current `test a` in the `/tmp/` directory (`/tmp/test a/`). This may suggest that the path length plays a role.; * If I renamed the VCF files (first VCF becomes `a.vcf.gz`, second `b.vcf.gz`) (`gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz`).; * If I rename the first VCF file with as many `a` character as characters found in the original filename. (aaaaaaaaaaaaaaaaaa.vcf.gz).; * If I rename the first VCF by replacing all alphabetical character with a (aaaa_aaaa2.aa_a7_1.vcf.gz); * If I introduce random `_` in the file name (aaaa_aaa_aaaa_aaaa.vcf.gz).; * If I rename the first VCF file by removing the first character (`cerc_prod2.SM_V7_1.vcf.gz` -> `erc_prod2.SM_V7_1.vcf.gz`); * If I rename the first VCF file by introducing a letter at the beginning (`cerc_prod2.SM_V7_1.vcf.gz` -> `ccerc_prod2.SM_V7_1.vcf.gz`). It really seems that the combination of the path lengh, white space and particular filename triggers this. I cannot get my head around this. I don't think this is coming from the content of the VCF as it works well in some cases. Let me know if you need me to make other tests. Fred. ----. ## Update. I investigated a little further after thinking about the tests I did. Because modifying the VCF filename did not trigger the issue and because of the presence of `tabix` related modules in the traces, I decided to see if removing `tbi` file will avoid having the error message. And it did!. After recreating the `tbi` file (`tabix data/calling/cerc_prod2.SM_V7_1.vcf.gz`), the error message appeared again. So it does not seem related to malformed index file. However, index file seems part of the problem. After renaming `test a` folder in `test-a` with the old or new index file, I did not get any error (as usual). Here is my tabix version in case:; ```bash; $ tabix -h. Version: 1.10.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:8353,Update,Update,8353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,1,['Update'],['Update']
Deployability,.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\reposito,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3323,RELEASE,RELEASE,3323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [42925293-731b-47bb-8e5e-7f375d9c3490] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:6561,deploy,deploy,6561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,6,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:23217,deploy,deploy,23217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:2149,deploy,deploy,2149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:2332,deploy,deploy,2332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,".broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:4479,deploy,deploy,4479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,".broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:4662,deploy,deploy,4662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonRespon,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676:2723,deploy,deploy,2723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonRespon,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:8750,deploy,deploy,8750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Existing mirrorFile and resourceId don't match isDirectory status! '/hadoop_gcs_connector_metadata_cache/hellbender/test/output/gatk4-spark/recalibrated.bam' (dir: 'false') vs 'gs://hellbender/test/output/gatk4-spark/recalibrated.bam/' (dir: 'true'); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.getCacheEntryInternal(FileSystemBackedDirectoryListCache.java:198); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.putResourceId(FileSystemBackedDirectoryListCache.java:363); 	at com.google.cloud.hadoop.gcsio.CacheSupplementedGoogleCloudStorage.createEmptyObjects(CacheSupplementedGoogleCloudStorage.java:150); 	at com.google.cloud.hadoop.gcsio.GoogleCloudStorageFile,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191:1572,deploy,deploy,1572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191,1,['deploy'],['deploy']
Deployability,.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: Pathname /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta from /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); 	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(Di,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:2639,deploy,deploy,2639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,".broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NullPointerException; 	at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106); 	at org.broadinstitute.hellbender.engine.AuthHolder.getOfflineAuth(AuthHolder.java:79); 	at org.broadinstitute.hellbender.engine.AuthHolder.makeStorageClient(AuthHolder.java:94); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:177); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [bd000687-f538-4201-b888-668612d46bad] entered state [ERROR] while waiting for [DONE].; ```. =========================. On a third note, if the reference is also provided with a GCS path, we see this:. ```; *****************************************************************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:7375,deploy,deploy,7375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,".broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.NotSerializableException: java.nio.HeapByteBuffer; Serialization stack:; **\- object not serializable (class: java.nio.HeapByteBuffer, value: java.nio.HeapByteBuffer[pos=0 lim=775456500 cap=775456500])**; - field (class: org.bdgenomics.adam.util.TwoBitFile, name: bytes, type: class java.nio.ByteBuffer); - object (class org.bdgenomics.adam.util.TwoBitFile, org.bdgenomics.adam.util.TwoBitFile@863c31e); - field (class: org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, name: twoBitFile, type: class org.bdgenomics.adam.util.TwoBitFile); - object (class org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:2611,deploy,deploy,2611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['deploy'],['deploy']
Deployability,".broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.makeMeansTable(VariantRecalibrator.java:986); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.writeModelReport(VariantRecalibrator.java:887); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:680); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms100g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar VariantRecalibrator -V /rprojectnb2/kageproj/gatk/pVCF/chr1/chr1.raw.excessHet.sites.vcf.gz -O snps.recal --tranches-file snps.tranches --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 -an AS_QD -an AS_ReadPosRankSum -an AS_MQRankSum -an AS_FS -an AS_MQ -an AS_SOR -an AS_MQ --use-allele-specific-annotations -mode SNP --output-model snps.model --max-gaussians 6 -resource:hapmap,known=false,training=true,truth=true,prior=15 /rprojectnb2/kageproj/gatk/bundle/hapmap_3.3.hg38.vcf.gz -resource:omni,known=false,training=true,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380:10025,install,install,10025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380,1,['install'],['install']
Deployability,.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3012,configurat,configuration,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19415,deploy,deploy,19415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644:4933,deploy,deploy,4933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644,1,['deploy'],['deploy']
Deployability,".engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseSt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7625,deploy,deploy,7625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,".file.spi.FileSystemProvider;; import java.util.ArrayList;; import java.util.List;; import java.util.ServiceLoader;. @CommandLineProgramProperties(summary = ""test"", oneLineSummary = ""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<FileSystemProvider> loadInstalledProviders() {; List<FileSystemProvider> list = new ArrayList<FileSystemProvider>();. ServiceLoader<FileSystemProvider> sl = ServiceLoader; .load(FileSystemProvider.class, TestGCS.class.getClassLoader());. // ServiceConfigurationError may be throw here; for (FileSystemProvider provider: sl) {; String scheme = provider.getScheme();. // add to list if the provider is not ""file"" and isn't a duplicate; if (!scheme.equalsIgnoreCase(""file"")) {; boolean found = false;; for (FileSystemProvider p: list) {; if (p.getScheme().equalsIgnoreCase(scheme)) {; found = true;; break;; }; }; if (!found) {; list.add(provider);; }; }; }; return list;; }; }; ```. We'd have to add an initial action to GATKS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:1877,install,installedProviders,1877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,2,['install'],['installedProviders']
Deployability,.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/04/27 18:49:12 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1231); at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229); at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); at org.apache.spark.api.java.JavaSparkContext.<i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:3447,deploy,deploy,3447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,".hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFile",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:5618,deploy,deploy,5618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJHZW5vdHlwaW5nRW5naW5lLmphdmE=) | `79.747% <0%> (-10.084%)` | `38% <0%> (-16%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `80.303% <0%> (-8.658%)` | `41% <0%> (-74%)` | |; | [.../basicshortmutpileup/BetaBinomialDistribution.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CZXRhQmlub21pYWxEaXN0cmlidXRpb24uamF2YQ==) | `65.385% <0%> (-7.343%)` | `5% <0%> (√∏)` | |; | [...lkers/contamination/MinorAlleleFractionRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vTWlub3JBbGxlbGVGcmFjdGlvblJlY29yZC5qYXZh) | `84.783% <0%> (-6.522%)` | `5% <0%> (-3%)` | |; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `88.532% <0%> (-4.325%)` | `31% <0%> (+29%)` | |; | [.../tools/walkers/mutect/SomaticGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `90.05% <0%> (-3.499%)` | `76% <0%> (+6%)` | |; | ... and [168 more](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5697#issuecomment-466073129:3531,pipeline,pipelines,3531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5697#issuecomment-466073129,1,['pipeline'],['pipelines']
Deployability,".jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:1256,deploy,deploy,1256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['deploy'],['deploy']
Deployability,".jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:09:41.541 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.554 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:09:41.557 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.558 WARN ¬†NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:09:41.678 INFO ¬†BaseRecalibrator - ------------------------------------------------------------ ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86\_64 amd64 ; ; 00:09:41.679 INFO ¬†BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087 ; ; 00:09:41.680 INFO ¬†BaseRecalibrator - Start Date/Time: August 21, 2022 at 12:09:41 AM CST ; ; 00:09:41.680 INFO ¬†BaseRecalibrator - --------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:2753,pipeline,pipeline,2753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3129,RELEASE,RELEASE,3129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,".java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it does not have a LoadSnappy class. Renaming the snappy-java jar file so gatk cannot find it allows FastqToSam to run through. ---. @akiezun commented on [Thu Jun 30 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-229843043). thanks for the report. Can you provide the whole commandline you used?. ---. @huangk3 commented on [Thu Sep 15 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-247467619). Hi @akiezun I experience the same error when running gate-launch FastqToSam. My command line is:; ""./gatk_launch FastqToSam -SM ""test"" -F1 $fq1 -F2 $fq2 -O test.spark.sam -SO coordinate -R $ref --STRIP_UNPAIRED_MATE_NUMBER true --VALIDATION_STRINGENCY LENIENT -PL ILLUMINA --CREATE_INDEX true"". My Spark version is 2.0.0; Thanks!. ---. @lbergelson commented on [Mon Sep 19 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-248086238). @huangk3 Unfortunately Adam moved on to a different job so he's longer working on GATK. . I believe this is the same problem as https://github.com/broadinstitute/gatk/issues/2026 and has been patched in gatk public with https://github.com/broadinstitute/gatk/pull/2028. You might try using FastqToSam in the public repo, or wait and try a new version of protected that incorporates an updated gatk public (coming soon..)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:3307,patch,patched,3307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,2,"['patch', 'update']","['patched', 'updated']"
Deployability,.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.proc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:3044,Pipeline,Pipeline,3044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['Pipeline'],['Pipeline']
Deployability,.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `49.333% <√∏> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `70.667% <100%> (+1.484%)` | `35 <0> (√∏)` | :arrow_down: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+1.265%)` | `70 <0> (-48)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+3.716%)` | `16 <5> (-3)` | :arrow_down: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+45.166%)` | `16 <6> (+6)` | :arrow_up: |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-15%)` | `3% <0%> (-1%)` | |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772:2908,Update,UpdateVCFSequenceDictionaryIntegrationTest,2908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772,1,['Update'],['UpdateVCFSequenceDictionaryIntegrationTest']
Deployability,".jetty.util.log: Logging initialized @3893ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.Server: Started @3988ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/27 20:39:44 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5569,pipeline,pipelines,5569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['pipeline'],['pipelines']
Deployability,".python.PythonScriptExecutorException: A nack was received from the Python process (most likely caused by a raised exception caused by): nkm received. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/regmova/miniconda3/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 22, in start_session_get_args_and_model; K.clear_session(). AttributeError: module 'keras.backend' has no attribute 'clear_session'; 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:222); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.initializePythonArgsAndModel(CNNScoreVariants.java:557); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:317); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289) ; ```. #### Steps to reproduce; `conda activate gatk; gatk CNNScoreVariants -V VCF.vcf.gz -R reference.fa -O VCF.CNNscored.vcf `. #### Expected behaviour; CNNScoreVariants should generate an annotated VCF. #### Actual behavior; CNNScoreVariants crashes. #### What I tried; I ran into this issue with an older build based on v4.1.9. I upgraded to v4.2.0, removed and built the Conda environment again, but the issue persisted. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250:5663,upgrade,upgraded,5663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250,1,['upgrade'],['upgraded']
Deployability,.runTool(MarkDuplicatesSpark.java:65); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.apache.spark.Logging; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:55); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 56 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [16ec1fd0-9528-4249-971e-f1447314bde4] entered state [ERROR] while waitin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183:4939,deploy,deploy,4939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183,1,['deploy'],['deploy']
Deployability,".samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); 	at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:124); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Exception creating BAM index for record i 1/2 76b aligned read.; 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:119); 	at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:139); 	... 5 more; Caused by: htsjdk.samtools.SAMException: IOException in BinaryBAMIndexWriter reference 0; 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:151); 	at htsjdk.samtools.BAMIndexer.advanceToReference(BAMIndexer.java:138); 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:115); 	... 6 more; Caused by: java.nio.channels.ClosedByInterruptException; 	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202); 	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:216); 	at java.nio.channels.Channels.writeFullyImpl(Channels.java:78); 	at java.nio.channels.Channels.writeFully(Channels.java:101); 	at java.nio.channels.Channels.access$000(Channels.java:61); 	at java.nio.channels.Channels$1.write(Channels.java:174); 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82); 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140); 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:149); 	... 8 more; ```. One of the logs is here: https://storage.googleapis.com/hellbender-test-logs/build_reports/12617.7/tests/test/index.html. We saw a whole host of those cigar validation errors you're seeing when we updated htsdjk the last time, it's a new validation that wasn't previously checked in htsjdk, so a lot of the test files had errors in them that no one had ever noticed/bothered fixing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977:2187,update,updated,2187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977,1,['update'],['updated']
Deployability,".scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Cli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:6801,deploy,deploy,6801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,".tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:146); 	at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:212); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.UpdateVCFSequenceDictionary.closeTool(UpdateVCFSequenceDictionary.java:174); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:983); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ``` . #### Steps to reproduce; Works: ``gatk UpdateVCFSequenceDictionary -V /dsde/working/ckachulis/UpdateVCFSequenceDictionary_Bug/na12878_hg38_giab_pg_hybrid_happy.vcf.gz -O corrected.dictionary.vcf --source-dictionary /seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.dict --replace ``. Crashes: ``gatk UpdateVCFSequenceDictionary -V /dsde/working/ckachulis/UpdateVCFSequenceDictionary_Bug/na12878_hg38_giab_pg_hybrid_happy.vcf.gz -O corrected.dictionary.vcf.gz --source-dictionary /seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.dict --replace `` . This is caused by the Tabix tools in htsjdk being given the dictionary from the input vcf to use for indexing instead of the source-dictionary. Can be fixed by overriding ``getBestAvailableSequenceDictionary()`` in UpdateVCFSequenceDictionary to return ``sourceDictionary``. However, this requires making ``VariantWalkerBase::getBestAvailableSequenceDictionary()`` non-final, so perhaps there is a better option.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5087:1794,Update,UpdateVCFSequenceDictionary,1794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5087,3,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"//github.com/broadinstitute/gatk/files/4091802/log.txt). ```; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in ind = [slice(None), 0]; arr[ind] should be changed to a tuple, e.g., ind = [slice(None), 0]; arr[tuple(ind)] or arr[(slice(None), 0)]. That change is necessary to avoid ambiguity in expressions such as arr[[[0, 1], [0, 1]]], currently interpreted as arr[array([0, 1]), ar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:1381,install,installation,1381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['install'],['installation']
Deployability,"/05/05 17:03:30 INFO ApplicationMaster: Preparing Local resources; 17/05/05 17:03:32 INFO ApplicationMaster: ApplicationAttemptId: appattempt_1493961816416_0010_000002; 17/05/05 17:03:32 INFO SecurityManager: Changing view acls to: yarn,hadoop; 17/05/05 17:03:32 INFO SecurityManager: Changing modify acls to: yarn,hadoop; 17/05/05 17:03:32 INFO SecurityManager: Changing view acls groups to: ; 17/05/05 17:03:32 INFO SecurityManager: Changing modify acls groups to: ; 17/05/05 17:03:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set(); 17/05/05 17:03:32 INFO ApplicationMaster: Starting the user application in a separate Thread; 17/05/05 17:03:32 INFO ApplicationMaster: Waiting for spark context initialization...; [May 5, 2017 5:03:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output hdfs:///output2.bam --input hdfs:///chr1.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [May 5, 2017 5:03:35 PM UTC] Executing as yarn@ip-172-30-0-122 on Linux 4.4.35-33.55.amzn1.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b13; Version: Version:4.alpha.2-252-gf627ed4-SNAPSHOT; 17/05/05 17:03:35 INFO SparkContext: Running Spark version 2.1.0; 17/05/05 17:03:35 INFO SecurityManager: Changing view acls to: yarn,hadoop; 17/05/05 17:03:35 INFO SecurityManager: Changing modify acls to: yarn,hadoop; 17/05/05 17:03:35 INFO SecurityManager: Changing view acls groups to: ; 17/05/05 17:03:35 INFO SecurityM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:2304,pipeline,pipelines,2304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,2,['pipeline'],['pipelines']
Deployability,/5879?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/8ab6604e7d91ed8885ef639fa9f00431d23464cf?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5879 +/- ##; ===========================================; Coverage 86.833% 86.833% ; - Complexity 32292 32293 +1 ; ===========================================; Files 1990 1990 ; Lines 149107 149107 ; Branches 16477 16477 ; ===========================================; Hits 129474 129474 ; Misses 13621 13621 ; Partials 6012 6012; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5879?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...te/hellbender/tools/CountReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `91.837% <100%> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...park/pipelines/CountReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `98.246% <100%> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.725% <0%> (-0.245%)` | `159% <0%> (√∏)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.773% <0%> (+0.474%)` | `33% <0%> (√∏)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5879#issuecomment-482624658:1181,pipeline,pipelines,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5879#issuecomment-482624658,1,['pipeline'],['pipelines']
Deployability,"/GATK/bundle/2.8/b37/human_g1k_v37.fasta -I /humgen/gsa-scr1/schandra/bgrenier_MixingAndMatchingGVCFAndBPRES/ind2.bam -L 9 -o Sheila.HaplotypeCallerGVCF.g.vcf -ERC GVCF`. GenotypeGVCFs:; `java -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T GenotypeGVCFs -R /humgen/gsa-hpprojects/GATK/bundle/2.8/b37/human_g1k_v37.fasta -V Sheila.HaplotypeCallerGVCF.g.vcf -o Sheila.GenotypeGVCFsGVCF.vcf`. ---. @chandrans commented on [Sat Dec 03 2016](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-264640941). User asked about this. Probably won't get to it anytime soon, but I told him/her I would check in. ---. @vdauwera commented on [Mon Dec 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-264964313). I responded that we're waiting on the tie-outs. . ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-265162286). Tie-outs?. I started on this, but I definitely won't finish it before the release. ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-265166347). Functional equivalence of GATK4 ports. That's my party line for now. Didn't realize you had actually started on this... but yeah, 3.7 is going out today. ---. @ronlevine commented on [Mon Jan 23 2017](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-274513719). @davidbenjamin Any thoughts on this? Laura thought she implemented a fix but it have any effect. I am becoming familiar with the HC code but it's slow going. While stepping though the code, I noticed it correctly identifies the events for the deletion and SNP. ---. @davidbenjamin commented on [Mon Jan 23 2017](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-274536654). @ronlevine I would put in a few breakpoints to see where the spanning deletion allele gets lost from the SNP site `VariantContext`. I just ran things wi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2960:3144,release,release,3144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2960,1,['release'],['release']
Deployability,/PathSeqBuildKmers/exampleFASTA.hss; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/e_coli_k12_mini.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/pipeline_output.bam.splitting-bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSBuildReferenceTaxonomyUtils/test.tar.gz; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSFilter/hg19mini_test_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark/SVBreakpointsTest.assembly.0; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.fastq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.rmdup-contigs.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:42462,pipeline,pipelines,42462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['pipeline'],['pipelines']
Deployability,/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/mast,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1253,integrat,integration,1253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Deployability,/broadinstitute/gatk/pull/4087?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...te/hellbender/utils/python/PythonExecutorBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uRXhlY3V0b3JCYXNlLmphdmE=) | `50% <100%> (-23.333%)` | `4 <0> (√∏)` | |; | [.../hellbender/utils/python/PythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `64.706% <100%> (√∏)` | `9 <1> (√∏)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `50% <0%> (-50%)` | `3% <0%> (√∏)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (√∏)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:1820,pipeline,pipelines,1820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662,1,['pipeline'],['pipelines']
Deployability,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29138,integrat,integration,29138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['integrat'],['integration']
Deployability,"/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. ```; 1 <?xml version=""1.0"" encoding=""UTF-8""?>; 2 <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; 3 <modelVersion>4.0.0</modelVersion>; 4 ; 5 <!--; 6 This pom is parent for all gatk poms; 7 See also:; 8 http://maven.apache.org/pom.html#Inheritance_v; 9 http://maven.apache.org/guides/introduction/introduction-to-the-pom.html#Project_Inheritance_vs_Project_Aggregation; 10 http://stackoverflow.com/questions/1992213/maven-parent-pom-vs-modules-pom; 11 -->; 12 ; 13 <groupId>org.broadinstitute.gatk</groupId>; 14 <artifactId>gatk-root</artifactId>; 15 <<<<<<< HEAD; 16 <version>3.8-1</version>; 17 =======; 18 <version>3.8-2-SNAPSHOT</version>; 19 >>>>>>> 0450e2531ee021e28bd7c5e92b5ba736d530d9af; 20 <packaging>pom</packaging>; 21 <name>GATK Root</name>; 22 ; 23 <prerequisites>; 24 <maven>3.0.4</maven>; 25 </prerequisites>; ```. Please make a new release, preferably 3.8.2 which unpacks as usual into `./gatk-3.8.2/`. Thank you. While making a bugfix release? because it is the last version supporting `old` syntax.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:3022,release,release,3022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,2,['release'],['release']
Deployability,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:112,pipeline,pipeline,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,5,['pipeline'],['pipeline']
Deployability,"/share/man/man1/git-lfs-locks.1.gz; git-lfs usr/share/man/man1/git-lfs-logs.1.gz; git-lfs usr/share/man/man1/git-lfs-ls-files.1.gz; git-lfs usr/share/man/man1/git-lfs-merge-driver.1.gz; git-lfs usr/share/man/man1/git-lfs-migrate.1.gz; git-lfs usr/share/man/man1/git-lfs-pointer.1.gz; git-lfs usr/share/man/man1/git-lfs-post-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-post-commit.1.gz; git-lfs usr/share/man/man1/git-lfs-post-merge.1.gz; git-lfs usr/share/man/man1/git-lfs-pre-push.1.gz; git-lfs usr/share/man/man1/git-lfs-prune.1.gz; git-lfs usr/share/man/man1/git-lfs-pull.1.gz; git-lfs usr/share/man/man1/git-lfs-push.1.gz; git-lfs usr/share/man/man1/git-lfs-smudge.1.gz; git-lfs usr/share/man/man1/git-lfs-standalone-file.1.gz; git-lfs usr/share/man/man1/git-lfs-status.1.gz; git-lfs usr/share/man/man1/git-lfs-track.1.gz; git-lfs usr/share/man/man1/git-lfs-uninstall.1.gz; git-lfs usr/share/man/man1/git-lfs-unlock.1.gz; git-lfs usr/share/man/man1/git-lfs-untrack.1.gz; git-lfs usr/share/man/man1/git-lfs-update.1.gz; git-lfs usr/share/man/man1/git-lfs.1.gz; git-lfs usr/share/man/man5/; git-lfs usr/share/man/man5/git-lfs-config.5.gz; ```. Then I run ; ```; git lfs pull --include src/main/resources/large; ./gradle localJar; ```; then; ```; error transferring ""1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46"": [0] remote missing object 1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46; error transferring ""bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d"": [0] remote missing object bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d; error transferring ""6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c"": [0] remote missing object 6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c; error transferring ""e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6"": [0] remote missing object e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6; error transferring ""4ed7feb034",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:3327,update,update,3327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['update'],['update']
Deployability,/spark/sv/evidence/BreakpointDensityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlci5qYXZh) | `97.183% <100%> (√∏)` | `27 <0> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `91.2% <100%> (+0.291%)` | `19 <0> (√∏)` | :arrow_down: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlclRlc3QuamF2YQ==) | `100% <100%> (√∏)` | `17 <0> (√∏)` | :arrow_down: |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `89.362% <100%> (+6.383%)` | `33 <1> (+1)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `94.118% <100%> (+1.81%)` | `1 <1> (√∏)` | :arrow_down: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `78.86% <57.303%> (-2.985%)` | `20 <4> (+8)` | |; | ... and [40 more](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530:3554,integrat,integration,3554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530,1,['integrat'],['integration']
Deployability,/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `85.915% <√∏> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.022% <√∏> (√∏)` | `23 <0> (√∏)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <√∏> (√∏)` | `24 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java],MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:1892,pipeline,pipelines,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187,1,['pipeline'],['pipelines']
Deployability,0% <0%> (-1%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...bender/tools/walkers/annotator/MappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9NYXBwaW5nUXVhbGl0eS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...alc/GeneralPloidyFailOverAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvR2VuZXJhbFBsb2lkeUZhaWxPdmVyQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...tractOpticalDuplicateFinderCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0Fic3RyYWN0T3B0aWNhbER1cGxpY2F0ZUZpbmRlckNvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | ... and [1044 more](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3114#issuecomment-308535831:3332,pipeline,pipelines,3332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3114#issuecomment-308535831,1,['pipeline'],['pipelines']
Deployability,0); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3252,deploy,deploy,3252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability,0); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:8818,deploy,deploy,8818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability,"0. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py files. commit 8348f546de6b3d32e1f02f6851730226c0dbffc9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:37:09 2023 -0500. update pymc version in init. commit 850d60ef95b6126c05af9cd7c2cb528a306e1224; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:32:42 2023 -0500. added pip editable docs. commit 9c51b311442b0796ab1224213e83290caea0f93f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:50 2023 -0500. whitespace. commit d9b180385168fdd1ef55cee8a1069fc1f7928f38; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:10 2023 -0500. update setup_gcnvkernel.py and pin pytensor. commit 7ccbd6da3d4afd1c987a66f6874bc4918495f943; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:20:49 2023 -0500. update conda in base and python packages. commit 693a1f9de10ee9950000abb83ef598cde82e026b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 08:55:53 2023 -0500. clean up Mixture, sample seeding, safelog. commit 2b211d7ed7875c798020ceaeed865523f25c7096; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:28:54 2023 -0500. fixed all determinism, need to clean up seeds. commit 799228dd5fafa2bf5d57e65e9aab256cdfc4698a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 22:22:18 2023 -0500. more dCR, Mixture. commit 124073d9af37c19573f90270c3cb0f4ae5ba4dd0; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 19:39:55 2023 -0500. fix dCR sampling?. commit f6871c9f12dbd52d84e78bba4f03d276ba1efb72; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 15:34:26 2023 -0500. logsumexp cleanup. commit 0c6cba790d8c3566a1a872d292e2b7acc692670e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 13:57:16 2023 -0500. revert backport of MeanField. commit 67fb3736",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:3205,update,update,3205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['update'],['update']
Deployability,"0/0:38,1:39:82:0,82,1231; 0/0:26,0:26:78:0,78,869; 0/0:22,0:22:66:0,66,734; 0/0:28,1:29:52:0,52,878; 0/0:36,0:36:99:0,108,1221; 0/0:39,0:39:99:0,117,1315; 0/0:31,1:32:86:0,86,1008; 0/0:38,0:38:99:0,114,1286; 0/0:37,0:37:99:0,111,1266; 0/0:35,0:35:99:0,105,1131; 0/0:32,0:32:96:0,96,1071; 0/0:46,0:46:99:0,138,1508; 0/0:27,0:27:81:0,81,918; 0/0:19,0:19:57:0,57,620; 0/0:45,0:45:99:0,135,1474; 0/0:50,0:50:99:0,150,1687; 0/0:29,0:29:87:0,87,968; 0/0:30,0:30:90:0,90,992; 0/0:55,1:56:99:0,158,1830; 0/1:8,2:10:19:19,0,248; 0/1:5,1:6:17:17,0,145; 0/1:4,1:5:10:10,0,124; 0/1:5,1:6:17:17,0,155; 0/1:3,2:5:34:34,0,79; 0/1:5,3:8:45:45,0,150; 0/1:2,1:3:26:26,0,61; 0/0:13,0:13:39:0,39,431; 0/0:17,0:17:51:0,51,571; 0/0:28,0:28:84:0,84,993; 0/0:10,0:10:30:0,30,328 . Freebayes has been run on these 57 samples and also get '0/0' but with GQ in the 140-160 range for most samples and are in line with the results with the HaplotypeCaller VCF direct results (see below). #### Actual behavior. Pipeline 2 is incorrectly setting GQ=0. This is the output for the 57 GQ=0 samples+ 1 extra sample GQ=99 with pipeline 2. The extra sample is needed to produce a variant record otherwise all the records would be homoz refer with GQ=0. . AC=1;AF=8.621e-03;AN=116;BaseQRankSum=-8.310e-01;DP=2213;ExcessHet=41.0061;FS=1.957;InbreedingCoeff=-0.3410;MLEAC=10;MLEAF=0.086;MQ=60.00;MQRankSum=0.00;QD=12.17;ReadPosRankSum=0.616;SOR=1.080; GT:AD:DP:GQ:PL; 0/1:9,8:17:99:227,0,272; 0/0:41,0:41:0:0,0,1097; 0/0:51,0:51:0:0,0,1216; 0/0:61,0:61:0:0,0,1373; 0/0:54,0:54:0:0,0,962; 0/0:49,0:49:0:0,0,1156; 0/0:53,0:53:0:0,0,729; 0/0:44,0:44:0:0,0,1161; 0/0:38,0:38:0:0,0,963; 0/0:68,0:68:0:0,0,1518; 0/0:33,0:33:0:0,0,841; 0/0:54,0:54:0:0,0,687; 0/0:44,0:44:0:0,0,1003; 0/0:33,0:33:0:0,0,709; 0/0:54,0:54:0:0,0,580; 0/0:31,0:31:0:0,0,790; 0/0:36,0:36:0:0,0,843; 0/0:49,0:49:0:0,0,978; 0/0:34,0:34:0:0,0,669; 0/0:39,0:39:0:0,0,898; 0/0:60,0:60:0:0,0,1270; 0/0:48,0:48:0:0,0,908; 0/0:30,0:30:0:0,0,780; 0/0:44,0:44:0:0,0,778; 0/0:24,0:2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:4039,Pipeline,Pipeline,4039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,1,['Pipeline'],['Pipeline']
Deployability,"00. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py files. commit 8348f546de6b3d32e1f02f6851730226c0dbffc9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:37:09 2023 -0500. update pymc version in init. commit 850d60ef95b6126c05af9cd7c2cb528a306e1224; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:32:42 2023 -0500. added pip editable docs. commit 9c51b311442b0796ab1224213e83290caea0f93f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:50 2023 -0500. whitespace. commit d9b180385168fdd1ef55cee8a1069fc1f7928f38; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:10 2023 -0500. update setup_gcnvkernel.py and pin pytensor. commit 7ccbd6da3d4afd1c987a66f6874bc4918495f943; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:20:49 2023 -0500. update conda in base and python packages. commit 693a1f9de10ee9950000abb83ef598cde82e026b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 08:55:53 2023 -0500. clean up Mixture, sample seeding, safelog. commit 2b211d7ed7875c798020ceaeed865523f25c7096; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:28:54 2023 -0500. fixed all determinism, need to c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:2570,update,update,2570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['update'],['update']
Deployability,"003 http://projecteuclid.org/download/pdf_1/euclid.aos/1056562461. -Add Metropolis-Hastings univariate sampler as alternative to SliceSampler. -Add Metropolis-Hastings/nested/etc. multivariate samplers as alternatives to GibbsSampler. This should only be tackled if a model/dataset necessitates it. -Implement hierarchical/multilevel models in an OOP way. Currently, the samplers operate on lists of global parameters and lists of lists of ""local"" parameters (i.e., segment-level or site-level parameters), which is a bit clunky. -Add convergence diagnostics (e.g., autocorrelation time). -Add ability to make trace plots and corner plots. -Implement more flexible discarding of burn-in. Currently, samples from all iterations are aggregated in memory. Depending on the maximum number of iterations we want to allow, it might be better to write samples to disk, only store samples in memory after burn-in, etc. so we don't run into memory issues. -Parallelization (again, only if a model/dataset necessitates it). ---. @LeeTL1220 commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153466956). @samuelklee Do we need this for the beta release?. ---. @samuelklee commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153471237). I'd say no to pretty much all of the points, except for whatever @davidbenjamin ends up needing to implement for the allele-fraction model (David, last time I looked at your branch there was some MH sampling going on?). Some of them will probably be relatively easy to address before beta (e.g., the first point about fixing up the SliceSampler), but I think they are low priority. The only thing that we'll definitely have to decide on for beta release is how to store/plot the MCMC chains (i.e., the posterior samples). If all people want to see is posterior point estimates + credible intervals, we can just discard the chains, but this seems somewhat wasteful to me.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2824:1522,release,release,1522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2824,2,['release'],['release']
Deployability,"03%`.; > The diff coverage is `63.636%`. ```diff; @@ Coverage Diff @@; ## master #2491 +/- ##; ===============================================; + Coverage 76.274% 76.277% +0.003% ; Complexity 10867 10867 ; ===============================================; Files 750 750 ; Lines 39560 39560 ; Branches 6915 6916 +1 ; ===============================================; + Hits 30174 30175 +1 ; + Misses 6767 6765 -2 ; - Partials 2619 2620 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `77.778% <63.636%> (-2.778%)` | `13 <0> (√∏)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=footer). Last update [e1e71d7...76fde41](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2491#issuecomment-287865370:2055,update,update,2055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2491#issuecomment-287865370,2,['update'],['update']
Deployability,033_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_YO_0034_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_ZC_0035_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_GV_0036_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_CW_0037_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_DL_0038_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_KS_0039_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_OF_0040_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_WR_0041_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_RI_0042_chr26.raw.g.vcf -nt 10 --max_genotype_count 1024 -L chr26 --dbsnp /usr/users/geibel/chicken/chickenrefgen/ENSEMBL_20170106/Gallus_gallus.updated.vcf -o /usr/users/geibel/chicken/pool_sequence_nov2016/data/rawVCF/IndandPool_chr26.raw.vcf ; ```. The user actually includes a shell script in the test data bundle called `JointGenotyping_chr26.sh`. ---; ### The error shows:; ```; ##### ERROR --; ##### ERROR stack trace ; java.lang.IllegalArgumentException: the number of genotypes is too large for ploidy 20 and allele 16: approx. 3247943160; 	at org.broadinstitute.gatk.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:319); 	at org.broadinstitute.gatk.tools.walkers.variantutils.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:461); 	at org.broadinstitute.gatk.tools.walkers.variantutils.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:164); 	at org.broadinstitute.gatk.tools.walkers.variantutils.GenotypeGVCFs.map(GenotypeGVCFs.java:302); 	at org.broadinstitute.gatk.tools.walkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2946:9678,update,updated,9678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2946,1,['update'],['updated']
Deployability,"0424175501-0004/2 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/3 is now RUNNING; 18/04/24 17:55:01 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.16:49734 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/4 is now RUNNING; 18/04/24 17:55:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:55:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/5 is now RUNNING; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:10 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:55:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.16:49734 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:55:05 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/0 is now RUNNING; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/6 is now RUNNING; 18/04/24 17:55:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.25:54754) with ID 2; 18/04/24 17:55:07 INFO BlockManagerMast",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:13906,update,updated,13906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['update'],['updated']
Deployability,"08.890 INFO PrintReadsSpark - Start Date/Time: July 24, 2018 9:02:08 PM UTC; 21:02:08.890 INFO PrintReadsSpark - ------------------------------------------------------------; 21:02:08.890 INFO PrintReadsSpark - ------------------------------------------------------------; 21:02:08.891 INFO PrintReadsSpark - HTSJDK Version: 2.16.0; 21:02:08.891 INFO PrintReadsSpark - Picard Version: 2.18.7; 21:02:08.891 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:02:08.892 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:02:08.892 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 21:02:08.892 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:02:08.892 INFO PrintReadsSpark - Deflater: IntelDeflater; 21:02:08.892 INFO PrintReadsSpark - Inflater: IntelInflater; 21:02:08.892 INFO PrintReadsSpark - GCS max retries/reopens: 20; 21:02:08.892 INFO PrintReadsSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 21:02:08.892 WARN PrintReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PrintReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:02:08.892 INFO PrintReadsSpark - Initializing engine; 21:02:08.892 INFO PrintReadsSpark - Done initializing engine; 18/07/24 21:02:08 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 18/07/24 21:02:09 INFO org.spark_project.jetty.util.log: Logging initialized @6492ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: Started @6584ms; 18/07/24 21:02:09 INFO org.spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:5719,patch,patch,5719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['patch'],['patch']
Deployability,"092 INFO HaplotypeCaller - Start Date/Time: January 15, 2018 12:18:41 PM GMT; 12:18:42.092 INFO HaplotypeCaller - ------------------------------------------------------------; 12:18:42.092 INFO HaplotypeCaller - ------------------------------------------------------------; 12:18:42.093 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 12:18:42.093 INFO HaplotypeCaller - Picard Version: 2.17.2; 12:18:42.093 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 12:18:42.093 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:18:42.093 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:18:42.093 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:18:42.093 INFO HaplotypeCaller - Deflater: IntelDeflater; 12:18:42.093 INFO HaplotypeCaller - Inflater: IntelInflater; 12:18:42.093 INFO HaplotypeCaller - GCS max retries/reopens: 20; 12:18:42.093 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 12:18:42.093 INFO HaplotypeCaller - Initializing engine; 12:18:42.597 INFO FeatureManager - Using codec VCFCodec to read file file:///beegfs/work/zxmai83/Reference/dbs/b37/dbsnp_138.b37.vcf; 12:18:42.723 INFO HaplotypeCaller - Done initializing engine; 12:18:42.732 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 12:18:42.732 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 12:18:43.546 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/bin/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 12:18:43.549 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/bin/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 12:18:43.599 WARN IntelPairHmm - Flush-to-zero (FTZ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:2769,patch,patch,2769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['patch'],['patch']
Deployability,0_121\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:1888,RELEASE,RELEASE,1888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,0aW9uL2NvdmFyaWF0ZXMvQ29udGV4dENvdmFyaWF0ZS5qYXZh) | `92.727% <√∏> (√∏)` | `34 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `85.475% <0%> (√∏)` | `62 <0> (√∏)` | :arrow_down: |; | [...er/tools/walkers/rnaseq/OverhangFixingManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9PdmVyaGFuZ0ZpeGluZ01hbmFnZXIuamF2YQ==) | `94.079% <100%> (+1.268%)` | `67 <0> (+1)` | :arrow_up: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (√∏)` | `0% <0%> (√∏)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (√∏)` | `74% <0%> (√∏)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `93.846% <0%> (+6.89%)` | `15% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (√∏)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274:3078,Update,UpdateVCFSequenceDictionary,3078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,1) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 92% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...argumentcollections/ReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F52656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...broadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6763732F4275636B65745574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../org/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F696F2F494F5574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...g/broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F746573742F42617365546573742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [13f88ae...ee6b523](https://codecov.io/gh/broadinstitute/gatk/compare/13f88aec9e10e76eb2445b7d2e430d33f24726ed...ee6b5239148af00243a8bb5c5303d1775be9d5c7?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772:3865,update,update,3865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772,1,['update'],['update']
Deployability,1); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Fi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:1978,deploy,deploy,1978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability,"1. AF in the FORMAT column can be used to represent heteroplasmy levels. ; 2. Currently the genotype is always reported as het (0/1). There is a request to change this but it hasn't been implemented yet: https://github.com/broadinstitute/gatk/issues/6257 If you'd like to fix this feel free to make a PR and I'd be happy to review it.; 3. Mitochondria mode in Mutect alone does not automatically shift the reference. However, you can use the full pipeline which does the shift automatically. You can find the WDL here: https://github.com/broadinstitute/gatk/blob/master/scripts/mitochondria_m2_wdl/MitochondriaPipeline.wdl or the Terra workspace here: https://app.terra.bio/#workspaces/help-gatk/Mitochondria-SNPs-Indels-hg38 Depending on the coverage of your data, if you don't need high sensitivity over the region with the breakpoint it also might not be worth doing the full realignment. You'll still be able to make calls on the edges of the linearized reference, you just might not have the full sensitivity you would if you realigned. I hope that helps!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297:447,pipeline,pipeline,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297,1,['pipeline'],['pipeline']
Deployability,"1. For spark - cloud dataproc works well; 2. For non-spark, the simplest setup seems to create a master-only dataproc cluster because it comes with a bunch of software already pre-installed. . Maybe that's all we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1610#issuecomment-211932533:180,install,installed,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1610#issuecomment-211932533,1,['install'],['installed']
Deployability,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6946:102,release,release-stats,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946,2,['release'],"['release', 'release-stats']"
Deployability,1.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\reposito,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4639,RELEASE,RELEASE,4639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"10 --max_calling_iters=10 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=1.000000e+00 --disable_caller=false --disable_sampler=false --disable_annealing=false; Stdout: 10:20:12.111 INFO case_denoising_calling - THEANO_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast_run,compute_test_value=ignore,openmp=true,blas.ldflags=-lmkl_rt,openmp_elemwise_minsize=10; 10:20:12.273 INFO root - Loading modeling interval list from the provided model...; 10:20:12.475 INFO gcnvkernel.io.io_intervals_and_counts - The given interval list provides the following interval annotations: {'GC_CONTENT'}; 10:20:12.491 INFO root - The model contains 11901 intervals and 23 contig(s); 10:20:12.491 INFO root - Loading 1 read counts file(s)...; 10:20:12.545 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 10:20:12.554 INFO root - Loading denoising model configuration from the provided model...; 10:20:12.555 INFO root - - bias factors enabled: True; 10:20:12.555 INFO root - - explicit GC bias modeling enabled: True; 10:20:12.555 INFO root - - bias factors in active classes disabled: False; 10:20:12.555 INFO root - - maximum number of bias factors: 5; 10:20:12.555 INFO root - - number of GC curve knobs: 20; 10:20:12.555 INFO root - - GC curve prior standard deviation: 1.0; 10:20:12.954 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the denoising model...; 10:20:15.806 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the sampler...; 10:20:15.807 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the copy number caller...; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Global model variables: {'log_mean_bias_t', 'psi_t_log__', 'W_tu', 'ard_u_log__'}; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'read_depth_s_log__', 'psi_s_log__', 'z_sg', 'z_su'}",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:6513,configurat,configuration,6513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['configurat'],['configuration']
Deployability,1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ===============================================; - Hits 46374 46140 -234 ; - Misses 8983 9228 +245 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4214?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/haplotypecaller/graphs/SharedSequenceMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2hhcmVkU2VxdWVuY2VNZXJnZXIuamF2YQ==) | `92.105% <100%> (√∏)` | `11 <6> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979:1589,pipeline,pipelines,1589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979,1,['pipeline'],['pipelines']
Deployability,"1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257). #### Steps to reproduce; The user's command line was. > nohup /opt/gatk/gatk-4.1.4.0/gatk ReadsPipelineSpark --spark-runner SPARK --spark-master yarn --spark-submit-command spark2-submit -I hdfs://cloudera08/gatk-test2/WES2019-022_S4.bam -O hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf -R hdfs://cloudera08/gatk-test1/ucsc.hg19.fasta --known-sites hdfs://cloudera08/gatk-test1/dbsnp_150_hg19.vcf.gz --known-sites hdfs://cloudera08/gatk-test1/Mills_and_1000G_gold_standard.indels.hg19.vcf.gz --align true --emit-ref-confidence GVCF --standard-min-confidence-threshold-for-calling 50.0 --conf deploy-mode=cluster --conf ""spark.driver.memory=2g"" --conf ""spark.executor.memory=18g"" --conf ""spark.storage.memoryFraction=1"" --conf ""spark.akka.frameSize=200"" --conf ""spark.default.parallelism=100"" --conf ""spark.core.connection.ack.wait.timeout=600"" --conf ""spark.yarn.executor.memoryOverhead=4096"" --conf ""spark.yarn.driver.memoryOverhead=400"" > WES2019-022_S4.out. #### Expected behavior; The tool should terminate normally and produce an output variants file. #### Actual behavior; The tool crashes with exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:3152,deploy,deploy-mode,3152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['deploy'],['deploy-mode']
Deployability,1080 1082 +2 ; Lines 63078 63275 +197 ; Branches 10176 10208 +32 ; ===============================================; + Hits 50522 50719 +197 ; + Misses 8570 8568 -2 ; - Partials 3986 3988 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4765?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4765/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `83.158% <100%> (√∏)` | `25 <0> (√∏)` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4765/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `97.297% <100%> (+1.379%)` | `31 <0> (+15)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4765/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.13% <100%> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4765/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <70%> (-0.671%)` | `33 <6> (+4)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4765/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `79.545% <83.333%> (-2.506%)` | `31 <2> (-13)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4765#issuecomment-390023475:1587,pipeline,pipelines,1587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4765#issuecomment-390023475,1,['pipeline'],['pipelines']
Deployability,1092 1092 ; Lines 64239 64239 ; Branches 10350 10350 ; ===============================================; - Hits 51685 51520 -165 ; - Misses 8504 8675 +171 ; + Partials 4050 4044 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4904?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `88.652% <√∏> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-10%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4904#issuecomment-398181642:1583,pipeline,pipelines,1583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4904#issuecomment-398181642,1,['pipeline'],['pipelines']
Deployability,"10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py files. commit 8348f546de6b3d32e1f02f6851730226c0dbffc9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:37:09 2023 -0500. update pymc version in init. commit 850d60ef95b6126c05af9cd7c2cb528a306e1224; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:32:42 2023 -0500. added pip editable docs. commit 9c51b311442b0796ab1224213e83290caea0f93f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:50 2023 -0500. whitespace. commit d9b180385168fdd1ef55cee8a1069fc1f7928f38; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:24:10 2023 -0500. update setup_gcnvkernel.py and pin pytensor. commit 7ccbd6da3d4afd1c987a66f6874bc4918495f943; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:20:49 2023 -0500. update conda in base and python packages. commit 693a1f9de10ee9950000abb83ef598cde82e026b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 08:55:53 2023 -0500. clean up Mixture, sample seeding, safelog. commit 2b211d7ed7875c798020ceaeed865523f25c7096; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:28:54 2023 -0500. fixed all determinism, need to clean up seeds. commit 799228dd5fafa2bf5d57e65e9aab256cdfc4698a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 22:22:18 2023 -0500. more dCR, Mixture. commit 124073d9af37c19573f90270c3cb0f4ae5ba4dd0; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 19:39:55 2023 -0500. fix dCR sampling?. commit f6871c9f12dbd52d84e78bba4f03d276ba1efb72; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 7 15:34:26 2023 -0500. logsumexp c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:3029,update,update,3029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['update'],['update']
Deployability,"11:05:38.056 INFO CountVariantsSpark - Shutting down engine; [May 12, 2016 11:05:38 AM AST] org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=3114270720; htsjdk.tribble.TribbleException: Input stream does not contain a BCF encoded file; BCF magic header info not found, at record 0 with position 0:; at htsjdk.variant.bcf2.BCF2Codec.error(BCF2Codec.java:492); at htsjdk.variant.bcf2.BCF2Codec.readHeader(BCF2Codec.java:153); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:109); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:89); at org.seqdoop.hadoop_bam.VCFInputFormat.addGuessedSplits(VCFInputFormat.java:254); at org.seqdoop.hadoop_bam.VCFInputFormat.fixBCFSplits(VCFInputFormat.java:242); at org.seqdoop.hadoop_bam.VCFInputFormat.getSplits(VCFInputFormat.java:221); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:95); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1910); at org.apache.spark.rdd.RDD.count(RDD.scala:1121); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:445); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:47); at org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark.runTool(CountVariantsSpark.java:39); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1815:134,pipeline,pipelines,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1815,1,['pipeline'],['pipelines']
Deployability,1291503ae8ca71bccc?src=pr&el=desc) will **decrease** coverage by `0.041%`.; > The diff coverage is `72.662%`. ```diff; @@ Coverage Diff @@; ## master #5127 +/- ##; ===============================================; - Coverage 86.796% 86.755% -0.041% ; + Complexity 29779 29766 -13 ; ===============================================; Files 1822 1825 +3 ; Lines 137732 137726 -6 ; Branches 15184 15188 +4 ; ===============================================; - Hits 119546 119484 -62 ; - Misses 12665 12721 +56 ; Partials 5521 5521; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5127?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `80% <100%> (-3.333%)` | `2 <0> (-2)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `90.476% <100%> (-2.627%)` | `4 <0> (-2)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.583% <100%> (+2.546%)` | `12 <4> (-5)` | :arrow_down: |; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `61.765% <100%> (√∏)` | `13 <2> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://code,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432:1237,pipeline,pipelines,1237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432,1,['pipeline'],['pipelines']
Deployability,1\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2383,RELEASE,RELEASE,2383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,1a901076785b0259255a126?src=pr&el=desc) will **decrease** coverage by `0.39%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4259 +/- ##; ==============================================; - Coverage 78.458% 78.068% -0.39% ; + Complexity 16439 16368 -71 ; ==============================================; Files 1039 1039 ; Lines 59173 59173 ; Branches 9686 9686 ; ==============================================; - Hits 46426 46195 -231 ; - Misses 8996 9237 +241 ; + Partials 3751 3741 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4259?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364:1246,pipeline,pipelines,1246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364,1,['pipeline'],['pipelines']
Deployability,"1st step towards bringing in fermi-lite as alternative option for local assembly.; Updated other classes accordingly.; Some teeny clean ups elsewhere. @cwhelan mind reviewing? Mostly trivial changes, should be very quick.; Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2136:83,Update,Updated,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2136,1,['Update'],['Updated']
Deployability,"2 Sep 16 11:31 genome.fa.bwt; -rw-rw---- 1 kh3 kh3 2984 Feb 4 2014 genome.fa.fai; -rw-rw---- 1 kh3 kh3 2984 Sep 16 13:18 genome.fai; -rw-r----- 1 kh3 kh3 784363628 Sep 16 11:32 genome.fa.pac; -rw-r----- 1 kh3 kh3 1568727304 Sep 16 11:44 genome.fa.sa. Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaAndMarkDuplicatesPipelineSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/ge; nome.2bit --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 15:47:28.760 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 15:47:28.809 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 3:47:28 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark --threads 16 --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark; .aligned.bam --reference /home/kh3/Resources/genome_b37/genome.2bit --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSiz; e 100000 --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedO; utput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [September 16, 2016 3:47:28 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.; 2-45-ga30af5a-SNAPSHOT; 15:47:28.835 INFO BwaAndMarkDuplicatesPipelineSpark - Defaults.BUFFER_SIZE : 131072; 15:47:28.835 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171:1447,pipeline,pipelines,1447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171,1,['pipeline'],['pipelines']
Deployability,2 changes to gatk-launch; - gcloud now requires arguments to the spark job to be separated from arguments to gcloud by `--`; - `--sparkMaster yarn-client` has been replaced with `--sparkMaster yarn --deploy-mode client`; this only requires the sparkMaster to be changed in gatk-launch gcs because the client mode is set by gcloud,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2263:200,deploy,deploy-mode,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2263,1,['deploy'],['deploy-mode']
Deployability,2); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file; 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:231); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:259); 	... 18 more; 17/10/13 18:11:54 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/13 18:11:54 INFO util.ShutdownHookManager: Deleting directory /tmp/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:24983,deploy,deploy,24983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['deploy'],['deploy']
Deployability,2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4730,RELEASE,RELEASE,4730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6349,release,releases,6349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['release'],['releases']
Deployability,"211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTabl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2108,INSTALL,INSTALLDIRGATK,2108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"237e-SNAPSHOT-spark.jar; Running:; spark2-submit --master yarn-client --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_3.bam --sparkMaster yarn-client; Warning: Master yarn-client is deprecated since 2.0. Please use master ""yarn"" with specified deploy mode instead.; 18:11:33.604 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 18:11:33.737 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 13, 2017 6:11:33 PM CST] PrintReadsSpark --output /gatk4/output_3.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:1598,deploy,deploy,1598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['deploy'],['deploy']
Deployability,"23:49023 with 16 cores, 1024.0 MB RAM; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180424173921-0001/6 on worker-20180424173107-xx.xx.xx.25-33478 (xx.xx.xx.25:33478) with 16 cores; 18/04/24 17:39:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180424173921-0001/6 on hostPort xx.xx.xx.25:33478 with 16 cores, 1024.0 MB RAM; 18/04/24 17:39:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/04/24 17:39:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.xx:42081 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/0 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/1 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/2 is now RUNNING; 18/04/24 17:39:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/6 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/4 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/3 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/5 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:12349,update,updated,12349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,6,['update'],['updated']
Deployability,"248, chrUn_gl000249]; reads contigs = []; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:163); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:469); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/01/09 18:31:26 INFO util.ShutdownHookManager: Shutdown hook called; 18/01/09 18:31:26 INFO util.ShutdownHookManager: Deleting directory /tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:35945,deploy,deploy,35945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,6,['deploy'],['deploy']
Deployability,2726174696F6E2F526563616C446174756D2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ls/walkers/genotyper/afcalc/AFCalculationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F414643616C63756C6174696F6E526573756C742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ools/walkers/annotator/HeterozygosityCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F48657465726F7A79676F7369747943616C63756C61746F722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/walkers/vqsr/GaussianMixtureModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F476175737369616E4D6978747572654D6F64656C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...g/broadinstitute/hellbender/utils/GenotypeUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F47656E6F747970655574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...der/tools/walkers/genotyper/afcalc/StateTracker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F5374617465547261636B65722E6A617661) |. > [Review all 13 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare); > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [2dfc80a...400186b](https://codecov.io/gh/broadinstitute/gatk/compare/2dfc80a139b55fc057a5e9286470defe43c9f706...400186bc7810f7b4ab28b6243209a1c3a37914a5?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095:4130,update,update,4130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095,1,['update'],['update']
Deployability,28 <0> (√∏)` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvci5qYXZh) | `88.372% <√∏> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `86.957% <100%> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.362% <100%> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | ... and [38 more](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087:3380,pipeline,pipelines,3380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087,2,['pipeline'],['pipelines']
Deployability,"2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or with some addition parameters.; 4. can GATK have ability to detect the `real` variant such as TTT>AAAA. #### Actual behavior; ~~_Tell us what happens instead_~~; unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6542,release,releases,6542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,3,['release'],['releases']
Deployability,"295127eab8.png). This dictionary uses a variable called **machine_mem** which is calculated using the workflow's **small_task_mem** input, which is configurable. ![image](https://user-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default_ram_mb** and **default_disk_space_gb** for a run of the Mutect2 workflow to be different from the amounts defined by [*small_task_mem*](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L140) and [**disk_space**](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L407). #### Expected behavior; Defining the input variables **default_ram_mb** and **default_disk_space_gb** allows you to specify your preferred memory and disk space configuration for the Funcotate task. #### Actual behavior; These variables do not define the runtime configuration for the task. Memory is defined by a workflow-level input that isn't clearly connected to Funcotate. #### Suggestion; Utiliz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:1730,configurat,configuration,1730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,1,['configurat'],['configuration']
Deployability,"29978 29989 +11 ; + Misses 6802 6791 -11 ; Partials 2592 2592; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <√∏> (√∏)` | `37 <√∏> (√∏)` | :x: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <√∏> (+0.901%)` | `38% <√∏> (+1%)` | :white_check_mark: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `79.747% <√∏> (+6.329%)` | `22% <√∏> (+4%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=footer). Last update [3c10554...efe544d](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2396#issuecomment-278174747:2389,update,update,2389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2396#issuecomment-278174747,2,['update'],['update']
Deployability,29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <√∏> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `90.476% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `70.811% <0%> (√∏)` | `40 <0> (√∏)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/IndexUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbmRleFV0aWxzLmphdmE=) | `80.702% <100%> (√∏)` | `16 <2> (√∏)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (√∏)` | `14 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <100%> (√∏)` | `6 <2> (√∏)` | :arrow_down: |; | [...der/tools/walkers/variantutils/SelectVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80.663% <100%> (√∏)` | `125 <0> (√∏)` | :arrow_down: |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/gh/broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785:2411,Update,UpdateVCFSequenceDictionary,2411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,2:35.484 INFO GenomicsDBImport - Initializing engine; 01:24:58.683 INFO FeatureManager - Using codec BEDCodec to read file file:///lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/intervals.bed; 01:24:58.801 INFO IntervalArgumentCollection - Processing 11500 bp from intervals; 01:24:58.803 INFO GenomicsDBImport - Done initializing engine; 01:24:59.055 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 01:25:02.076 INFO GenomicsDBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:3661,update,update,3661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,"2:66:0,66,734; 0/0:28,1:29:52:0,52,878; 0/0:36,0:36:99:0,108,1221; 0/0:39,0:39:99:0,117,1315; 0/0:31,1:32:86:0,86,1008; 0/0:38,0:38:99:0,114,1286; 0/0:37,0:37:99:0,111,1266; 0/0:35,0:35:99:0,105,1131; 0/0:32,0:32:96:0,96,1071; 0/0:46,0:46:99:0,138,1508; 0/0:27,0:27:81:0,81,918; 0/0:19,0:19:57:0,57,620; 0/0:45,0:45:99:0,135,1474; 0/0:50,0:50:99:0,150,1687; 0/0:29,0:29:87:0,87,968; 0/0:30,0:30:90:0,90,992; 0/0:55,1:56:99:0,158,1830; 0/1:8,2:10:19:19,0,248; 0/1:5,1:6:17:17,0,145; 0/1:4,1:5:10:10,0,124; 0/1:5,1:6:17:17,0,155; 0/1:3,2:5:34:34,0,79; 0/1:5,3:8:45:45,0,150; 0/1:2,1:3:26:26,0,61; 0/0:13,0:13:39:0,39,431; 0/0:17,0:17:51:0,51,571; 0/0:28,0:28:84:0,84,993; 0/0:10,0:10:30:0,30,328 . Freebayes has been run on these 57 samples and also get '0/0' but with GQ in the 140-160 range for most samples and are in line with the results with the HaplotypeCaller VCF direct results (see below). #### Actual behavior. Pipeline 2 is incorrectly setting GQ=0. This is the output for the 57 GQ=0 samples+ 1 extra sample GQ=99 with pipeline 2. The extra sample is needed to produce a variant record otherwise all the records would be homoz refer with GQ=0. . AC=1;AF=8.621e-03;AN=116;BaseQRankSum=-8.310e-01;DP=2213;ExcessHet=41.0061;FS=1.957;InbreedingCoeff=-0.3410;MLEAC=10;MLEAF=0.086;MQ=60.00;MQRankSum=0.00;QD=12.17;ReadPosRankSum=0.616;SOR=1.080; GT:AD:DP:GQ:PL; 0/1:9,8:17:99:227,0,272; 0/0:41,0:41:0:0,0,1097; 0/0:51,0:51:0:0,0,1216; 0/0:61,0:61:0:0,0,1373; 0/0:54,0:54:0:0,0,962; 0/0:49,0:49:0:0,0,1156; 0/0:53,0:53:0:0,0,729; 0/0:44,0:44:0:0,0,1161; 0/0:38,0:38:0:0,0,963; 0/0:68,0:68:0:0,0,1518; 0/0:33,0:33:0:0,0,841; 0/0:54,0:54:0:0,0,687; 0/0:44,0:44:0:0,0,1003; 0/0:33,0:33:0:0,0,709; 0/0:54,0:54:0:0,0,580; 0/0:31,0:31:0:0,0,790; 0/0:36,0:36:0:0,0,843; 0/0:49,0:49:0:0,0,978; 0/0:34,0:34:0:0,0,669; 0/0:39,0:39:0:0,0,898; 0/0:60,0:60:0:0,0,1270; 0/0:48,0:48:0:0,0,908; 0/0:30,0:30:0:0,0,780; 0/0:44,0:44:0:0,0,778; 0/0:24,0:24:0:0,0,531; 0/0:40,0:40:0:0,0,714; 0/0:50,0:50:0:0,0,794; 0/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:4149,pipeline,pipeline,4149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,1,['pipeline'],['pipeline']
Deployability,2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f9afec0957; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:38:15 2017 -0500. fixed arg issues in somatic WDL; exposed all missing args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; A,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:6385,update,updated,6385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['updated']
Deployability,2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <√∏> (√∏)` | `24 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `75% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <√∏> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <√∏> (√∏)` | `35 <0> (√∏)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <√∏> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | ... and [46 more](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:3705,pipeline,pipelines,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187,1,['pipeline'],['pipelines']
Deployability,"3#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""throwing out ideas for discussion"" phase, and alternate proposals are welcome provided they include the concept of a GATK-wide release, and make some provision for the situation where the CNV tools (or some other sub-category) are ready for release but other tools are not. ---. @vdauwera commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215498517). Frankly on the face of it I hate the idea of toolset-specific jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:2127,release,release,2127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,2,['release'],['release']
Deployability,3); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:120); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:141); 	at org.broadinstitute.hellbender.Main.main(Main.java:196); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.readIndex(SplittingBAMIndex.java:69); 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.<init>(SplittingBAMIndex.java:49); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeSplittingBaiFiles(SAMFileMerger.java:117); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503:1256,deploy,deploy,1256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503,1,['deploy'],['deploy']
Deployability,"3); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:3959,deploy,deploy,3959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability,3); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4424,deploy,deploy,4424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability,3); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.get,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2081,deploy,deploy,2081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability,"3,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,138,143,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,143,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,159,166,172,180,188,197,208,220,234,251,274,306,359,854,166,173,180,188,197,208,220,234,251,274,306,359,854,173,180,188,197,208,220,234,251,274,306,359,854,180,188,197,208,220,234,251,274,306,359,854,188,197,208,220,234,251,274,306,359,854,197,208,220,234,251,274,306,359,854,208,220,234,251,274,306,359,854,220,234,251,274,306,359,854,234,252,274,306,359,854,252,274,306,359,854,274,306,359,854,306,359,854,360,854,854:9,9,0,0. for samples --variant $path_calls/H1_1.spark.g.vcf.gz and --variant $path_calls/H1_2.spark.g.vcf.gz tis variant is unpresent. the whole analysis is against Arabidopsis thaliana reference ftp://ftp.ensemblgenomes.org/pub/plants/release-47/fasta/arabidopsis_thaliana/dna/. i think that could be a same error within next call too; 1	560578	.	A	AAAAG,<NON_REF>	768.01	.	BaseQRankSum=0.297;DP=22;MLEAC=50,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=79200,22;ReadPosRankSum=-0.232	GT:AD:DP:GQ:PL:SB	0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1:5,14,0:19:0:516,232,190,166,149,135,125,115,108,101,95,89,84,79,75,71,67,64,61,58,55,52,50,47,45,43,41,39,37,35,33,32,30,28,27,26,24,23,22,20,19,18,17,16,15,14,13,12,11,10,10,9,8,7,7,6,5,5,4,4,3,3,2,2,2,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,2,2,3,4,4,5,6,7,9,11,12,15,17,21,25,30,39,53,233,516,232,190,166,149,136,125,116,108,101,95,89,84,80,75,71,68,64,61,58,55,53,50,48,45,43,41,39,37,35,34,32,30,29,27,26,24,23,22,21,20,18,17,16,15,14,13,12,12,11,10,9,9,8,7,7,6,5,5,4,4,3,3,3,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,2,2,3,3,4,4,5,6,7,8,10,11,13,15,18,21,26",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-677396205:38226,release,release-,38226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-677396205,1,['release'],['release-']
Deployability,"3.0; 13:54:10.423 INFO ProgressMeter - chr22:41712333 9.2 6226000 676191.6; 13:54:20.447 INFO ProgressMeter - chrX:39799780 9.4 6342000 676514.9; 13:54:30.520 INFO ProgressMeter - chrX:91818371 9.5 6453000 676246.2; 13:54:40.591 INFO ProgressMeter - chrX:143619069 9.7 6568000 676399.8; 13:54:50.640 INFO ProgressMeter - chrUn_KI270743v1:125398 9.9 6674000 675662.2; 13:55:00.673 INFO ProgressMeter - chr20_KI270869v1_alt:62679 10.0 6792000 676161.8; 13:55:10.679 INFO ProgressMeter - chr19_GL949752v1_alt:485077 10.2 6910000 676673.7; 13:55:26.149 INFO ProgressMeter - HLA-DRB1*11:01:02:3272 10.5 6938356 662718.7; 13:55:26.149 INFO ProgressMeter - Traversal complete. Processed 6938356 total records in 10.5 minutes.; 13:55:26.149 INFO ComposeSTRTableFile - Shutting down engine; [April 4, 2021 1:55:26 PM EDT] org.broadinstitute.hellbender.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:55:31 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentia",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:11212,install,install,11212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['install'],['install']
Deployability,"32...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `64.286% <85.714%> (-7.666%)` | `28 <12> (+1)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `94.048% <√∏> (-1.19%)` | `46% <√∏> (-1%)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <√∏> (+1.429%)` | `24% <√∏> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <√∏> (+3.333%)` | `10% <√∏> (√∏)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2350?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2350?src=pr&el=footer). Last update [fcd103c...a28ecfd](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-274847005:3159,update,update,3159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-274847005,2,['update'],['update']
Deployability,32e31dc2105a4edcecc4131a6e1e?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `71.429%`. ```diff; @@ Coverage Diff @@; ## master #3485 +/- ##; =============================================; + Coverage 79.94% 79.94% +<.001% ; Complexity 17897 17897 ; =============================================; Files 1198 1199 +1 ; Lines 64980 64986 +6 ; Branches 10120 10120 ; =============================================; + Hits 51945 51950 +5 ; + Misses 9002 9001 -1 ; - Partials 4033 4035 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `83.019% <100%> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <66.667%> (√∏)` | `2 <2> (?)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `87.963% <0%> (-0.926%)` | `50% <0%> (-2%)` | |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `74.468% <0%> (+2.128%)` | `14% <0%> (√∏)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tre,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3485#issuecomment-324300515:1241,pipeline,pipelines,1241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3485#issuecomment-324300515,1,['pipeline'],['pipelines']
Deployability,34 ; Lines 146679 147213 +534 ; Branches 16218 16214 -4 ; ===============================================; + Hits 127707 128079 +372 ; - Misses 13060 13231 +171 ; + Partials 5912 5903 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5703?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1580,pipeline,pipelines,1580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961,1,['pipeline'],['pipelines']
Deployability,"3592?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #3592 +/- ##; ============================================; - Coverage 79.73% 79.73% -0.01% ; - Complexity 18148 18149 +1 ; ============================================; Files 1217 1217 ; Lines 66602 66602 ; Branches 10429 10429 ; ============================================; - Hits 53106 53104 -2 ; - Misses 9289 9292 +3 ; + Partials 4207 4206 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91% <100%> (√∏)` | `30 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.62% <0%> (-1.95%)` | `39% <0%> (√∏)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.88% <0%> (+0.46%)` | `52% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=footer). Last update [58108d0...c374339](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059:2375,update,update,2375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059,2,['update'],['update']
Deployability,35a3dcede3670208eb1a4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.007%`.; > The diff coverage is `33.333%`. ```diff; @@ Coverage Diff @@; ## master #4210 +/- ##; ==============================================; - Coverage 78.477% 78.47% -0.007% ; + Complexity 16424 16423 -1 ; ==============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ==============================================; - Hits 46379 46375 -4 ; - Misses 8978 8981 +3 ; - Partials 3742 3743 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (√∏)` | `14 <0> (√∏)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (√∏)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `78.71% <0%> (-1.29%)` | `39% <0%> (√∏)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841:1232,Update,UpdateVCFSequenceDictionary,1232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,36d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <57.143%> (-11.905%)` | `4 <1> (+4)` | |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `77.193% <77.193%> (√∏)` | `16 <16> (?)` | |; | [...ute/hellbender/utils/bwa/BwaMemIndexSingleton.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtSW5kZXhTaW5nbGV0b24uamF2YQ==) | `82.353% <82.353%> (√∏)` | `8 <8> (?)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:3153,pipeline,pipelines,3153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,2,['pipeline'],['pipelines']
Deployability,37117df?src=pr&el=desc) will **decrease** coverage by `0.477%`.; > The diff coverage is `80.556%`. ```diff; @@ Coverage Diff @@; ## master #3620 +/- ##; ===============================================; - Coverage 79.846% 79.368% -0.477% ; + Complexity 18309 17286 -1023 ; ===============================================; Files 1226 1140 -86 ; Lines 67177 62438 -4739 ; Branches 10507 9482 -1025 ; ===============================================; - Hits 53638 49556 -4082 ; + Misses 9288 9108 -180 ; + Partials 4251 3774 -477; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3620?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...llbender/utils/read/markduplicates/PairedEnds.java](https://codecov.io/gh/broadinstitute/gatk/pull/3620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL1BhaXJlZEVuZHMuamF2YQ==) | `84.783% <√∏> (√∏)` | `22 <0> (√∏)` | :arrow_down: |; | [...spark/pipelines/metrics/MetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmsuamF2YQ==) | `100% <√∏> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...ntationbiasvariantfilter/OrientationBiasUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9vcmllbnRhdGlvbmJpYXN2YXJpYW50ZmlsdGVyL09yaWVudGF0aW9uQmlhc1V0aWxzLmphdmE=) | `84.956% <√∏> (√∏)` | `56 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/3620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9GaWx0ZXJCeU9yaWVudGF0aW9uQmlhcy5qYXZh) | `83.019% <√∏> (√∏)` | `14 <0> (√∏)` | :arrow_down: |; | [...iantfilter/OrientationSampleTransitionSummary.java](https://codecov.io/gh/br,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332576432:1251,pipeline,pipelines,1251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332576432,1,['pipeline'],['pipelines']
Deployability,3:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.CREATE_MD5 : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.CUSTOM_READER_FACTORY :; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.REFERENCE_FASTA : null; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; > 21:13:04.224 DEBUG ConfigFactory - Configuration file values:; > 21:13:04.230 DEBUG ConfigFactory - gcsMaxRetries = 20; > 21:13:04.230 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.compression_level = 1; > 21:13:04.230 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; > 21:13:04.230 DEBUG ConfigFactory - spark.io.compression.codec = lzf; > 21:13:04.230 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; > 21:13:04.230 DEBUG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:3351,Configurat,Configuration,3351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['Configurat'],['Configuration']
Deployability,"3Rpb24uamF2YQ==) | `100% <0%> (√∏)` | `4% <0%> (+2%)` | :arrow_up: |; | [...efaultGATKVariantAnnotationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vRGVmYXVsdEdBVEtWYXJpYW50QW5ub3RhdGlvbkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <0%> (√∏)` | `11% <0%> (+6%)` | :arrow_up: |; | [...titute/hellbender/tools/walkers/GenotypeGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.55% <0%> (+0.46%)` | `50% <0%> (+3%)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.47% <0%> (+0.68%)` | `25% <0%> (+11%)` | :arrow_up: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `84.17% <0%> (+1.01%)` | `40% <0%> (+15%)` | :arrow_up: |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=footer). Last update [7628cc9...fc61689](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720:4697,update,update,4697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720,2,['update'],['update']
Deployability,"4). If you organize the inputs into blocks and keep all such knobs together at the end it's not too bad. A lot of our users will need to be able to tweak those settings -- and the others can ignore them. . See here for an example of how we do it: https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_pipelines/PublicPairedSingleSampleWf_160927.inputs.json. ---. @LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/925#issuecomment-286607287). So we are a slimmer version of what @vdauwera has. @takutosato I agree with your frustrations, but then we have to hardcode to the worst case, which will be quite expensive (in the cloud), underutilized (in all backends), and have trouble dispatching (in SGE). . ---. @LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/925#issuecomment-286607541). @vdauwera I will happily accept comments on our json templates. . https://github.com/broadinstitute/gatk-protected/tree/master/scripts/mutect2_wdl. ---. @LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/925#issuecomment-286607739). @davidbenjamin @takutosato The more I think about it, the more important I think this issue is. ---. @vdauwera commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/925#issuecomment-286613100). Yeah we need to parameterize the heck out of all our WDLs. If anything, the example I linked to is not parameterized nearly as much as I'd like (it's derived from the prod pipeline so we're a bit constrained). . It's not that much clutter if you make those parameters task-level and organize the JSONs clearly. And it makes it waaaay easier for people to adjust what they need without touching the WDL itself. This becomes even more important once you move the WDL into a platform like FireCloud, where changing the WDL is a huge pain, whereas tweaking parameters (via a method config) is trivial.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2949:2337,pipeline,pipeline,2337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2949,1,['pipeline'],['pipeline']
Deployability,4.0.0]; at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:986) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:825) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:93) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:233) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:119) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:374) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark.runTool(SortSamSpark.java:114) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.broadinstitute.hellbender.Main.mainEntry(Main.ja,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:17926,pipeline,pipelines,17926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['pipeline'],['pipelines']
Deployability,"4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu1.18.04; 12:57:16.775 INFO AnalyzeCova",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:1034,pipeline,pipeline,1034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['pipeline'],['pipeline']
Deployability,408 -79 ; =============================================; Files 1133 1133 ; Lines 63042 63042 ; Branches 9613 9613 ; =============================================; - Hits 50143 49866 -277 ; - Misses 9067 9360 +293 ; + Partials 3832 3816 -16; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3733?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3733#issuecomment-338711707:1514,pipeline,pipelines,1514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3733#issuecomment-338711707,1,['pipeline'],['pipelines']
Deployability,41.330011002Z 13:13:41.328 INFO GenotypeGVCFs - HTSJDK Version: 2.13.2; 2018-03-09T13:13:41.330022980Z 13:13:41.328 INFO GenotypeGVCFs - Picard Version: 2.17.2; 2018-03-09T13:13:41.330030226Z 13:13:41.329 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 2018-03-09T13:13:41.330036559Z 13:13:41.329 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 2018-03-09T13:13:41.330045071Z 13:13:41.329 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 2018-03-09T13:13:41.330051564Z 13:13:41.329 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 2018-03-09T13:13:41.330068542Z 13:13:41.329 INFO GenotypeGVCFs - Deflater: IntelDeflater; 2018-03-09T13:13:41.330102470Z 13:13:41.329 INFO GenotypeGVCFs - Inflater: IntelInflater; 2018-03-09T13:13:41.330111084Z 13:13:41.329 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 2018-03-09T13:13:41.330117286Z 13:13:41.329 INFO GenotypeGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 2018-03-09T13:13:41.330127806Z 13:13:41.329 INFO GenotypeGVCFs - Initializing engine; 2018-03-09T13:13:44.528605497Z 13:13:44.528 INFO GenotypeGVCFs - Done initializing engine; 2018-03-09T13:13:45.237843760Z 13:13:45.235 INFO ProgressMeter - Starting traversal; 2018-03-09T13:13:45.237903383Z 13:13:45.235 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 2018-03-09T13:13:56.665869885Z 13:13:56.662 INFO ProgressMeter - chr13:82078938 0.2 13000 68265.4; 2018-03-09T13:14:07.517952300Z 13:14:07.517 INFO ProgressMeter - chr13:82096938 0.4 31000 83475.5; 2018-03-09T13:14:17.546110604Z 13:14:17.545 INFO ProgressMeter - chr13:82123938 0.5 58000 107706.6; 2018-03-09T13:14:28.760222694Z 13:14:28.759 INFO ProgressMeter - chr13:82144938 0.7 79000 108905.4; 2018-03-09T13:14:39.292149466Z 13:14:39.289 INFO ProgressMeter - chr13:82169938 0.9 104000 115440.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4518:2766,patch,patch,2766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518,1,['patch'],['patch']
Deployability,4269fa8?src=pr&el=desc) will **increase** coverage by `0.022%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2811 +/- ##; =============================================; + Coverage 79.978% 80% +0.022% ; - Complexity 16726 16795 +69 ; =============================================; Files 1139 1139 ; Lines 60894 61155 +261 ; Branches 9436 9497 +61 ; =============================================; + Hits 48702 48924 +222 ; - Misses 8396 8422 +26 ; - Partials 3796 3809 +13; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <0%> (√∏)` | `15% <0%> (+7%)` | :arrow_up: |; | [...nstitute/hellbender/utils/help/GATKHelpDoclet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jbGV0LmphdmE=) | `100% <0%> (√∏)` | `9% <0%> (+3%)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.908% <0%> (+3.324%)` | `58% <0%> (+29%)` | :arrow_up: |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/2811?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2811#issuecomment-306008892:1263,pipeline,pipelines,1263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2811#issuecomment-306008892,1,['pipeline'],['pipelines']
Deployability,436276778bdee2060d13b4?src=pr&el=desc) will **decrease** coverage by `0.422%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3946 +/- ##; ==============================================; - Coverage 78.483% 78.06% -0.422% ; + Complexity 16560 16490 -70 ; ==============================================; Files 1058 1058 ; Lines 59682 59682 ; Branches 9712 9712 ; ==============================================; - Hits 46840 46588 -252 ; - Misses 9084 9346 +262 ; + Partials 3758 3748 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3946?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3946/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3946/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3946/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3946/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-60.294%)` | `8% <0%> (-25%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3946/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351112321:1247,pipeline,pipelines,1247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351112321,1,['pipeline'],['pipelines']
Deployability,"463); - formatting on sample QC README; - formatting change #2 to sample QC README; - address VS-152, remove extra headers from extract (#7466); - Update GvsExtractCallset.example.inputs.json (#7469); - Add ability to copy interval list files to gs directory [VS-191] (#7467); - add an expiration date to the temp tables (#7455); - fix the check for duplicates in import genomes (#7470); - added job ID to alt_allele population call output [VS-194] (#7473); - added steps and deliverables to GVS README [VS-181] (#7452); - Ah check the is loaded field in feature extract (#7475); - changes to put pet data directly into data table (#7478); - added override for ExtractTasks' preemptible value (#7477); - bcftools to the rescue (#7456); - execute_with_retry() refactor and error handling improvements [VS-159] (#7480); - Small updates to GvsExtractCallset from beta callset, new workflow for re-scattered shards (#7493); - add flag in prepare to print out sql instead of executing (#7501); - Workflow to re-scatter and then merge ""problematic"" intervals from ExtractCallset [VS-209] (#7495); - changed README to reflect comments from Lee [VS-210] (#7502); - Export the VAT into GCS (#7472); - addresses VS-219 (#7508); - small fix to MergeVCFs (#7517); - small fixes to GVS pipeline (#7522); - make sure ExtractTask is run on all interval files; - Revert ""make sure ExtractTask is run on all interval files""; - make sure ExtractTask is run on all interval files (#7527); - Remove Sites only step from the VAT creation WDL (#7510); - fix bad argument processing for bool (#7529); - Support for TDR DRS URIs in Import (#7528); - Match format of filename output in GvsRescatterCallsetInterval (#7539); - Reference block storage and query support (#7498); - update docs (#7540); - Kc fix rr load bug (#7550); - Update .dockstore.yml (#7553); - Ah add reblocking wdl (#7544); - Scatter over all interval files, not just scatter count (#7551); - fixed docker (#7558); - take advantage of fixed version of Spl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:19072,update,updates,19072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,"['Update', 'pipeline', 'update']","['Update', 'pipeline', 'update', 'updates']"
Deployability,472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mcmFnbWVudHMvRnJhZ21lbnRDb2xsZWN0aW9uLmphdmE=) | `57.143% <√∏> (-4.762%)` | `9% <√∏> (-4%)` | |; | [...lines/metrics/InsertSizeMetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9JbnNlcnRTaXplTWV0cmljc0NvbGxlY3RvclNwYXJrLmphdmE=) | `86.364% <√∏> (-4.545%)` | `7% <√∏> (-1%)` | |; | [...oadinstitute/hellbender/engine/FeatureContext.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZUNvbnRleHQuamF2YQ==) | `72.973% <√∏> (-2.703%)` | `26% <√∏> (-1%)` | |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.625% <√∏> (-1.042%)` | `10% <√∏> (√∏)` | |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `86.111% <√∏> (-0.926%)` | `39% <√∏> (-1%)` | |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658:2019,pipeline,pipelines,2019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658,2,['pipeline'],['pipelines']
Deployability,4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.409%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4207 +/- ##; ===============================================; - Coverage 78.477% 78.067% -0.409% ; + Complexity 16424 16352 -72 ; ===============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ===============================================; - Hits 46379 46137 -242 ; - Misses 8978 9231 +253 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4207?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626:1251,pipeline,pipelines,1251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626,1,['pipeline'],['pipelines']
Deployability,"4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <√∏> (+0.901%)` | `38% <√∏> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <√∏> (+0.926%)` | `40% <√∏> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <√∏> (+1.042%)` | `10% <√∏> (√∏)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <√∏> (+1.075%)` | `26% <√∏> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=footer). Last update [30365e7...09a6f24](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:4367,Integrat,IntegrationTestSpec,4367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,1,['Integrat'],['IntegrationTestSpec']
Deployability,5); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionRe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:4083,configurat,configuration,4083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,"5.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:2282,release,release-,2282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['release'],['release-']
Deployability,5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;E:\reposito,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5538,RELEASE,RELEASE,5538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,51 +8 ; Lines 38960 40319 +1359 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8477 +363 ; ==========================================; + Hits 3964 30719 +26755 ; + Misses 34451 6955 -27496 ; - Partials 545 2645 +2100 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2340/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ‚Ä¢ 10% | [...rc/main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F4D61696E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...institute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B537061726B546F6F6C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...institute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E6550726F6772616D2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...adinstitute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F657863657074696F6E732F55736572457863657074696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...706d53e](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...706d53e7bee5e795aaf42aa1a5c8fb348afa2d06?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241:2226,update,update,2226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241,1,['update'],['update']
Deployability,533); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.RuntimeException: Could not serialize lambda; 	at com.twitter.chill.java.ClosureSerializer.write(ClosureSerializer.java:70); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 44 more; Caused by: java.lang.NoSuchMethodException: htsjdk.samtools.reference.AbstractFastaSequenceFile$$Lambda$94/1029586776.writeReplace(); 	at java.lang.Class.getDeclaredMethod(Class.java:2130); 	at com.twitter.chill.java.ClosureSerializer.write(ClosureSerializer.java:61); 	... 46 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6091:4074,deploy,deploy,4074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6091,6,['deploy'],['deploy']
Deployability,56C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 50% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 51% | *new* [...llbender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F417373656D626C79416C69676E6D656E745061727365722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 57% | *new* [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D65726963416C69676E6D656E742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 64% | [...itute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E6D656E74526567696F6E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 86% | *new* [...ellbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E74436F6E73656E73757343616C6C2E6A617661) |; > [Review all 15 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [821d9fb...80b6c43](https://codecov.io/gh/broadinstitute/gatk/compare/821d9fb60190028cd328492eea2929a843bbb069...80b6c43fc1143e0f8357e935925ce6035adf847e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623:4038,update,update,4038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623,1,['update'],['update']
Deployability,56C6C62656E6465722F746F6F6C732F737061726B2F73762F53565574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 80% | _new_ [...institute/hellbender/tools/spark/sv/SVKmerShort.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D657253686F72742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 83% | _new_ [...nder/tools/spark/sv/ContainsKmerReadFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F436F6E7461696E734B6D65725265616446696C746572537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 83% | _new_ [...lbender/transformers/BaseQualityReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7472616E73666F726D6572732F426173655175616C697479526561645472616E73666F726D65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 88% | _new_ [...ute/hellbender/transformers/DUSTReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7472616E73666F726D6572732F44555354526561645472616E73666F726D65722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 90% | _new_ [...llbender/engine/filters/AmbiguousBaseReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F416D626967756F7573426173655265616446696C7465722E6A617661) |. > [Review all 20 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare); > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [127f9f1...0cf943d](https://codecov.io/gh/broadinstitute/gatk/compare/127f9f184dc0413b6283aa97e216a89a2e0b5d55...0cf943dd3bfc8ea489c55f9346994c9352d41e46?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944:4060,update,update,4060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944,1,['update'],['update']
Deployability,"588a4?src=pr&el=desc) will **increase** coverage by `-0.015%`. ```diff; @@ Coverage Diff @@; ## master #2392 +/- ##; ===============================================; - Coverage 76.157% 76.141% -0.015% ; + Complexity 10823 10820 -3 ; ===============================================; Files 748 748 ; Lines 39361 39361 ; Branches 6855 6855 ; ===============================================; - Hits 29976 29970 -6 ; - Misses 6798 6801 +3 ; - Partials 2587 2590 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `74.839% <√∏> (-3.226%)` | `18% <√∏> (-2%)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <√∏> (-1.429%)` | `23% <√∏> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=footer). Last update [99e0b84...aeeaff8](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2392#issuecomment-277394788:1999,update,update,1999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2392#issuecomment-277394788,2,['update'],['update']
Deployability,"5; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.rea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1233,Install,Install,1233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Install'],['Install']
Deployability,5?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.4% <√∏> (√∏)` | `50 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138:1839,pipeline,pipelines,1839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138,1,['pipeline'],['pipelines']
Deployability,5a2958a7ad565fdd32?src=pr&el=desc) will **decrease** coverage by `0.396%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4217 +/- ##; ===============================================; - Coverage 78.479% 78.083% -0.396% ; + Complexity 16425 16356 -69 ; ===============================================; Files 1041 1041 ; Lines 59113 59113 ; Branches 9673 9673 ; ===============================================; - Hits 46391 46157 -234 ; - Misses 8983 9228 +245 ; + Partials 3739 3728 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4217?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718:1251,pipeline,pipelines,1251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718,1,['pipeline'],['pipelines']
Deployability,"5qYXZh) | `73.68% <77.14%> (-1.32%)` | `41 <17> (+1)` | |; | [...ools/walkers/validation/InfoConcordanceRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vSW5mb0NvbmNvcmRhbmNlUmVjb3JkLmphdmE=) | `93.93% <93.93%> (√∏)` | `8 <8> (?)` | |; | [...n/EvaluateInfoFieldConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZUludGVncmF0aW9uVGVzdC5qYXZh) | `96% <96%> (√∏)` | `3 <3> (?)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (√∏)` | `2% <0%> (√∏)` | :arrow_down: |; | ... and [2 more](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=footer). Last update [ce669d1...65d0edd](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-423756354:4435,update,update,4435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-423756354,2,['update'],['update']
Deployability,5zdGFudHMuamF2YQ==) | `0% <√∏> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.286% <60%> (-0.897%)` | `40 <0> (-2)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `74.621% <77.778%> (-1.643%)` | `54 <0> (-1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.258%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3994/diff?src=pr&el=tree#diff-c3JjL,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-352581848:2152,pipeline,pipelines,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-352581848,1,['pipeline'],['pipelines']
Deployability,6 +34 ; =============================================; Files 1140 1140 ; Lines 62494 62583 +89 ; Branches 9489 9495 +6 ; =============================================; + Hits 49610 49691 +81 ; - Misses 9108 9112 +4 ; - Partials 3776 3780 +4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `69.231% <100%> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.03% <100%> (+0.81%)` | `9 <2> (+2)` | :arrow_up: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <100%> (√∏)` | `4 <1> (√∏)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (√∏)` | |; | [...der/tools/walkers/contamination/PileupSummary.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeS5qYXZh) | `90.196% <0%> (-1.232%)` | `26% <0%> (+12%)` | |; | [...ools/walkers/contamination/GetPileupSummaries.java](https://codecov.io/gh/broadinstitute/gatk/pull/3643?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3643#issuecomment-333500497:1502,pipeline,pipelines,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3643#issuecomment-333500497,1,['pipeline'],['pipelines']
Deployability,6% <100%> (+0.926%)` | `8 <1> (+1)` | :arrow_up: |; | [...bender/engine/spark/AssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `100% <100%> (+22.917%)` | `13 <0> (-2)` | :arrow_down: |; | [...nstitute/hellbender/engine/spark/SparkSharder.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyLmphdmE=) | `90.789% <100%> (-0.367%)` | `28 <3> (-3)` | |; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `68.293% <100%> (+9.563%)` | `16 <5> (+4)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <100%> (+0.175%)` | `13 <0> (√∏)` | :arrow_down: |; | [...nstitute/hellbender/engine/ShardBoundaryShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvU2hhcmRCb3VuZGFyeVNoYXJkLmphdmE=) | `100% <100%> (√∏)` | `5 <1> (+1)` | :arrow_up: |; | [...ampleAssemblyRegionWalkerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5416/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (+88.889%)` | `4 <1> (+2)` | :arrow_up: |; | [...tute/hellbender/engine/ReadlessAssemblyRegion.java](https://codecov.io/gh,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439324985:2187,pipeline,pipelines,2187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439324985,1,['pipeline'],['pipelines']
Deployability,"635 INFO HaplotypeCaller - Start Date/Time: October 29, 2018 10:25:20 PM EDT; 22:25:20.635 INFO HaplotypeCaller - ------------------------------------------------------------; 22:25:20.635 INFO HaplotypeCaller - ------------------------------------------------------------; 22:25:20.635 INFO HaplotypeCaller - HTSJDK Version: 2.14.3; 22:25:20.635 INFO HaplotypeCaller - Picard Version: 2.17.2; 22:25:20.635 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:25:20.635 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:25:20.636 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:25:20.636 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:25:20.636 INFO HaplotypeCaller - Deflater: IntelDeflater; 22:25:20.636 INFO HaplotypeCaller - Inflater: IntelInflater; 22:25:20.636 INFO HaplotypeCaller - GCS max retries/reopens: 20; 22:25:20.636 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 22:25:20.636 INFO HaplotypeCaller - Initializing engine; 22:25:21.061 INFO HaplotypeCaller - Done initializing engine; 22:25:21.069 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 22:25:21.069 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 22:25:21.070 INFO HaplotypeCaller - Shutting down engine; [October 29, 2018 10:25:21 PM EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1506344960; USAGE: HaplotypeCaller [arguments]. Call germline SNPs and indels via local re-assembly of haplotypes; Version:4.0.3.0. ***********************************************************************. A USER ERROR has occurred: Argument --emitRefConfidence has a bad value: Can onl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5372:2819,patch,patch,2819,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5372,1,['patch'],['patch']
Deployability,"64e; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:04:19 2017 -0500. mkl. commit 43e2a65201286161fcd5bfe7dbb21ae888e19dac; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 06:56:20 2017 -0500. added cpu argument for germline tasks. commit 4433a62c2173c7f29d0f264c084bbaf2f6738782; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 02:45:38 2017 -0500. revert travis yml forks; verbose logging germline wdl. commit ae05801e33c37b3bf2685fba202032a270804873; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4213,update,update,4213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['update']
Deployability,656?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `80.241% <0%> (-0.194%)` | `142 <2> (+2)` | |; | [...ections/MarkDuplicatesSparkArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvTWFya0R1cGxpY2F0ZXNTcGFya0FyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.13% <100%> (-0.231%)` | `12 <0> (√∏)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `77.778% <100%> (-1.17%)` | `4 <0> (√∏)` | |; | [...s/read/markduplicates/sparkrecords/PairedEnds.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyZWRFbmRzLmphdmE=) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `82.051% <100%> (√∏)` | `44 <5> (√∏)` | :arrow_down: |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://codecov.io/gh/broa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4656#issuecomment-380909365:1836,pipeline,pipelines,1836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4656#issuecomment-380909365,1,['pipeline'],['pipelines']
Deployability,"66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). 16/11/16 23:25:11 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Cancelling stage 1; 16/11/16 23:25:11 INFO DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) failed in 0.276 s; 16/11/16 23:25:11 INFO DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 1.029776 s; 16/11/16 23:25:11 INFO SparkContext: SparkContext already stopped.; [November 16, 2016 11:25:11 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2058354688; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:16839,pipeline,pipelines,16839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['pipeline'],['pipelines']
Deployability,661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F42515352506970656C696E65537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...adinstitute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F56617269616E7457616C6B6572426173652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...bender/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F42617365526563616C69627261746F72537061726B536861726465642E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/spark/pipelines/SortReadFileSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F536F72745265616446696C65537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...nes/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F6D6574726963732F436F6C6C65637442617365446973747269627574696F6E42794379636C65537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...dline/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F4741544B506C7567696E2F4741544B5265616446696C746572506C7567696E44657363726970746F722E6A617661) |; | ‚Ä¢‚Ä¢,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913:2693,pipeline,pipelines,2693,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913,1,['pipeline'],['pipelines']
Deployability,667% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...tools/walkers/haplotypecaller/HaplotypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXIuamF2YQ==) | `0% <0%> (-76.923%)` | `0% <0%> (-17%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3Jj,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405986092:2726,pipeline,pipelines,2726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405986092,1,['pipeline'],['pipelines']
Deployability,696E652F737061726B2F5265616457616C6B6572537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 87% | *new* [...itute/hellbender/engine/spark/ReadWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F5265616457616C6B6572436F6E746578742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 87% | [...titute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4C6F63757357616C6B6572537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 89% | *new* [...ender/tools/examples/ExampleIntervalWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C65496E74657276616C57616C6B6572537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 90% | *new* [...llbender/engine/spark/AssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F417373656D626C79526567696F6E57616C6B6572537061726B2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 92% | *new* [...ls/examples/ExampleReadWalkerWithReferenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C655265616457616C6B6572576974685265666572656E6365537061726B2E6A617661) |; > [Review all 19 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [e1b4c8f...bdb69f8](https://codecov.io/gh/broadinstitute/gatk/compare/e1b4c8f4b781c6867e1eaea2dbb5587c6a6125a7...bdb69f8fcb5d4582dbcce6f430cb6c75eadae8ee?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722:4099,update,update,4099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722,1,['update'],['update']
Deployability,6E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E7443616C6C6572496E7465726E616C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 71% | [...tute/hellbender/tools/spark/sv/BreakpointAllele.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C6C656C652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 78% | [...itute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E6D656E74526567696F6E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 80% | *new* [.../hellbender/tools/spark/sv/SVVariantCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E7443616C6C65725574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../hellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4741544B53565643464865616465724C696E65732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ute/hellbender/tools/spark/sv/ContigsCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F436F6E74696773436F6C6C656374696F6E2E6A617661) |; > [Review all 11 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [7315f31...8e1658e](https://codecov.io/gh/broadinstitute/gatk/compare/7315f3160e9eec3940363c75c3a3619a42da8b4a...8e1658e87bedbe7adf1af5d621b4c55baa14afcb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427:4056,update,update,4056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427,1,['update'],['update']
Deployability,"6](https://github.com/broadinstitute/gsa-unstable/issues/1438). ### Instructions. Follow up to #1432.; Remove the following code from `IntervalUtils. intervalFileToList()` when a new exome, correctly converted interval list (with no -1 length intervals) is released :. ```; if (interval.getStart() - interval.getEnd() == 1 ) { ; logger.warn(""Possible incorrectly converted length 1 interval : "" + interval);; }; ```. ---; ## Feature request; ### Tool(s) involved. Any tool using `IntervalUtils. intervalFileToList()` ; ### Description. Once this change is made, -1 length intervals will be validated and an exception will be thrown. ---. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927). From what I understand of the referenced thread, the ""incorrect"" interval list may always be around, so we may never be able to just blow up on it. Would it perhaps be more viable to add an option to toggle the level of stringency, ie choose in the command line whether to blow up or skip on these invalid intervals? . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260496001). @yfarjoun will want to opine on this, I think. . ---. @yfarjoun commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260513266). I hope that when we move exomes to hg38 we will correct this silly thing; and a few decades later we will no need this code (hehe). Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; > ‚Äî; > You are receiving this because y",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:1007,toggle,toggle,1007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['toggle'],['toggle']
Deployability,"6d11bef1c81f885c26b2b56c8616b7a705171e4f from [https://github.com/droazen/google-cloud-java/tree/dr\\\_all\\\_nio\\\_fixes](https://github.com/droazen/google-cloud-java/tree/dr\_all\_nio\_fixes) ; ; 12:52:16.269 INFO GenotypeGVCFs - Initializing engine ; ; terminate called after throwing an instance of 'VariantQueryProcessorException' ; ; what(): VariantQueryProcessorException : Could not open array genomicsdb\_array at workspace: /home/WES-VCFQC/S2\_GenomicsDBImport/temporary/tmp4. Hi, I used GenomicsDBImport to combined 2000 GVCFs. To speed up, I split the bed file and concatenated multiple intervals into a contig. I also met the file locking problem which can be solved by setting¬† TILEDB\_DISABLE\_FILE\_LOCKING=1 in my Linux system. Currently, I experience some issues with GenotypeGVCFs in GATK version 4.0.3.0. It cannot open ""genomicsdb\_array"" although the directory of genomicsdb\_array does exist. I found someone else has reported this issue here: [https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000](https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000)¬†, but except for using the latest version of GATK, it seems like there are no other solutions. I was wondering that how do I fix the issues with GATK 4.0.3.0? Does anyone have a better solution?. I also tried GenotypeGVCFs in GATK 4.2.1.0, but there is a problem in terms of MQ calculation. So I think it's better to stick to the same GATK version in the whole workflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:5208,a/b,a/broadinstitute,5208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['a/b'],['a/broadinstitute']
Deployability,7 <0> (√∏)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3187,pipeline,pipelines,3187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860,3,"['Integrat', 'pipeline']","['IntegrationUtils', 'pipelines']"
Deployability,7); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12493,deploy,deploy,12493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability,"72; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291be9bfeaea72fe479b8a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:56:24 2017 -0500. revert Dockerfile, change yml. commit 930d7486b7d2cf918fcb16dd03394bb9c9f0611b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:34:46 2017 -0500. more Dockerfile. commit 94112131526b514ef254bcc2c50a239dbae35aa1; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:25:13 2017 -0500. more Dockerfile. commit 7d2646240a65f5c0f09f5f25f3e19e9d9bf004d9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:06:11 2017 -0500. more Dockerfile. commit f1235c25aeba85570b5ce389a34975f1b7b5ec3c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 09:39:46 2017 -0500. Dockerfile edit. commit 3df84dd4693f28e4e8b34fd33f877e99749dffce; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 16:08:06 2017 -0500. Update test PoNs. commit 2c3b20e62a1cba7af24c0b0846eb1629422f51e6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:49:38 2017 -0500. Update test files. commit c65c6e9144ef396792364ab2e06b7b436bb97684; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:30:59 2017 -0500. Adding no-GC/do-GC WDL tests. commit 56451843066a456d9cf8e6eac55ae4df2c518ec3; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sampl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:9513,Update,Update,9513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['Update'],['Update']
Deployability,72F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7472616E73666F726D732F4170706C7942515352537061726B466E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../java/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F5574696C732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...tute/hellbender/utils/tsv/TableColumnCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F7473762F5461626C65436F6C756D6E436F6C6C656374696F6E2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ender/engine/spark/ShuffleJoinReadsWithRefBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F53687566666C654A6F696E52656164735769746852656642617365732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...broadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F7473762F5461626C655265616465722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...ools/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F4578616374414643616C63756C61746F722E6A617661) |; > [Review all 12 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [6a23efd...396922d](https://codecov.io/gh/broadinstitute/gatk/compare/6a23efd30f9c8e7d89444b0effe39a1d2daded0d...396922debe76ad2abcca5a8027df53d1498f4bb7?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994:3939,update,update,3939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994,1,['update'],['update']
Deployability,752d2748eda14b079387?src=pr&el=desc) will **increase** coverage by `0.237%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4261 +/- ##; =============================================; + Coverage 78.463% 78.7% +0.237% ; - Complexity 16440 16480 +40 ; =============================================; Files 1039 1040 +1 ; Lines 59173 59338 +165 ; Branches 9686 9706 +20 ; =============================================; + Hits 46429 46699 +270 ; + Misses 8993 8888 -105 ; Partials 3751 3751; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4261?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924:1249,pipeline,pipelines,1249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924,1,['pipeline'],['pipelines']
Deployability,"77 +/- ##; ============================================; + Coverage 79.07% 79.08% +<.01% ; - Complexity 16594 16595 +1 ; ============================================; Files 1050 1050 ; Lines 59969 59969 ; Branches 9831 9831 ; ============================================; + Hits 47419 47424 +5 ; + Misses 8741 8738 -3 ; + Partials 3809 3807 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.65% <0%> (+0.76%)` | `72% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (√∏)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=footer). Last update [1221e03...403ff93](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060:2439,update,update,2439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060,2,['update'],['update']
Deployability,7953756D506572416C6C656C65427953616D706C652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 50% | [...r/tools/walkers/annotator/LikelihoodRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F4C696B656C69686F6F6452616E6B53756D546573742E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 50% | [...ute/hellbender/tools/walkers/annotator/Coverage.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F436F7665726167652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 50% | [...nder/tools/walkers/annotator/StrandBiasBySample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F537472616E6442696173427953616D706C652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 57% | [...llbender/tools/walkers/annotator/OxoGReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F4F786F4752656164436F756E74732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 63% | [...walkers/annotator/allelespecific/AS_RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F52616E6B53756D546573742E6A617661) |. > [Review all 33 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare); > ; > Powered by [Codecov](https://codecov.io?src=pr). Last update [5874002...d627845](https://codecov.io/gh/broadinstitute/gatk/compare/5874002a4218c898117ead06837e947f81b60750...d6278451a8a5e2fabb945dbf63f1e7a102e4be2e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490:4201,update,update,4201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490,1,['update'],['update']
Deployability,"79b8a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:56:24 2017 -0500. revert Dockerfile, change yml. commit 930d7486b7d2cf918fcb16dd03394bb9c9f0611b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:34:46 2017 -0500. more Dockerfile. commit 94112131526b514ef254bcc2c50a239dbae35aa1; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:25:13 2017 -0500. more Dockerfile. commit 7d2646240a65f5c0f09f5f25f3e19e9d9bf004d9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:06:11 2017 -0500. more Dockerfile. commit f1235c25aeba85570b5ce389a34975f1b7b5ec3c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 09:39:46 2017 -0500. Dockerfile edit. commit 3df84dd4693f28e4e8b34fd33f877e99749dffce; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 16:08:06 2017 -0500. Update test PoNs. commit 2c3b20e62a1cba7af24c0b0846eb1629422f51e6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:49:38 2017 -0500. Update test files. commit c65c6e9144ef396792364ab2e06b7b436bb97684; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:30:59 2017 -0500. Adding no-GC/do-GC WDL tests. commit 56451843066a456d9cf8e6eac55ae4df2c518ec3; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:9662,Update,Update,9662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['Update'],['Update']
Deployability,"7:1024); 	at picard.sam.AbstractAlignmentMerger.mergeAlignment(AbstractAlignmentMerger.java:557); 	at picard.sam.SamAlignmentMerger.mergeAlignment(SamAlignmentMerger.java:186); 	at picard.sam.MergeBamAlignment.doWork(MergeBamAlignment.java:368); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:308); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:37); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Despite the fact that option `-SORT_ORDER ""unsorted""` is being used and the two BAM files have the reads in the same order:; ```; $ samtools view unmapped.bam | cut -f1; NB500989:333:HKYJNAFX2:1:11101:24447:1024; NB500989:333:HKYJNAFX2:1:11101:24447:1024; NB500989:333:HKYJNAFX2:1:11101:10000:1915; NB500989:333:HKYJNAFX2:1:11101:10000:1915. $ samtools view aligned.unmerged.bam | cut -f1; NB500989:333:HKYJNAFX2:1:11101:24447:1024; NB500989:333:HKYJNAFX2:1:11101:24447:1024; NB500989:333:HKYJNAFX2:1:11101:10000:1915; NB500989:333:HKYJNAFX2:1:11101:10000:1915; ```; Is there a way to run `MergeBamAlignment` letting the tool know that the order of the reads in the input BAMs is the same?. It seems then that the only workaround is to let `FastqToSam` sort the reads, which seems an unnecessary computational step since eventually the reads will be sorted by coordinate anyway. This problem was observed when running together the WDL pipelines [paired-fastq-to-unmapped-bam.wdl](https://github.com/gatk-workflows/seq-format-conversion/blob/master/paired-fastq-to-unmapped-bam.wdl) and [processing-for-variant-discovery-gatk4.wdl](https://github.com/gatk-workflows/gatk4-data-processing/blob/master/processing-for-variant-discovery-gatk4.wdl) where the former runs `FastqToSam` and the latter runs `SamToFastq` and `MergeBamAlignment`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:4739,pipeline,pipelines,4739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,1,['pipeline'],['pipelines']
Deployability,"7;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2869200,797;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6134,release,releases,6134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['release'],['releases']
Deployability,7a5236e879818910d9c9. and the stacktrace:. ```; java.util.ServiceConfigurationError: java.nio.file.spi.FileSystemProvider: Provider com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider could not be instantiated; at java.util.ServiceLoader.fail(ServiceLoader.java:232); at java.util.ServiceLoader.access$100(ServiceLoader.java:185); at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384); at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404); at java.util.ServiceLoader$1.next(ServiceLoader.java:480); at java.nio.file.spi.FileSystemProvider.loadInstalledProviders(FileSystemProvider.java:119); at java.nio.file.spi.FileSystemProvider.access$000(FileSystemProvider.java:77); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:169); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:166); at java.security.AccessController.doPrivileged(Native Method); at java.nio.file.spi.FileSystemProvider.installedProviders(FileSystemProvider.java:166); at java.nio.file.Paths.get(Paths.java:141); at org.broadinstitute.hellbender.engine.spark.datasources.NioProviderExceptionUnitTest.test(NioProviderExceptionUnitTest.java:12). Caused by:; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:208); at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:153); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64); at com.google.cloud.storage.StorageOptions.defaultInstance(StorageOptions.java:91); at com.google.cloud.storage.contrib.nio.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110:1259,install,installedProviders,1259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110,1,['install'],['installedProviders']
Deployability,8); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53727,deploy,deploy,53727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6322,pipeline,pipelines,6322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,1,['pipeline'],['pipelines']
Deployability,"85 13181 -4 ; - Partials 5915 5916 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (√∏)` | `59 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <66.66%> (-0.95%)` | `1 <0> (√∏)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (√∏)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `90% <0%> (+30%)` | `2% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=footer). Last update [fb2b5a2...e5bcca0](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849:2763,update,update,2763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849,2,['update'],['update']
Deployability,"86); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in sub-cohort prepare correctly [VS-772] (#8156); - Remove unused VAT Creation WDL (#8172); - Gg consistently use dataset name as input parameter (#8173); - AoU cleanup docs, round 1 [VS-671] (#8104); - VDS docs remove samples and correct GT [VS-807] (#8178); - [VS-693] Add support for VQSR Lite to GvsCreateFilterSet (#8157); - VAT Documentation Update Round 1 [VS-531]; - VS-530 VDS creation documentation for AoU (#8169); - Update beta docs to tell people not to use free credits (#8184); - VS-816 Keeping ingestion under quota (#8193); - CromwellOnAzure + Azure SQL DB + AAD first steps doc [VS-805] (#8191); - Edit and re-format VDS -> VAT doc [VS-821] (#8187); - VS-820 Incorporate code to stay un",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:31331,update,update,31331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['update'],['update']
Deployability,"8:01.493 INFO HaplotypeCaller - Start Date/Time: May 17, 2018 6:58:01 PM PDT. 18:58:01.493 INFO HaplotypeCaller - ------------------------------------------------------------. 18:58:01.493 INFO HaplotypeCaller - ------------------------------------------------------------. 18:58:01.494 INFO HaplotypeCaller - HTSJDK Version: 2.14.1. 18:58:01.494 INFO HaplotypeCaller - Picard Version: 2.17.2. 18:58:01.494 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1. 18:58:01.494 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 18:58:01.494 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 18:58:01.494 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 18:58:01.494 INFO HaplotypeCaller - Deflater: IntelDeflater. 18:58:01.494 INFO HaplotypeCaller - Inflater: IntelInflater. 18:58:01.494 INFO HaplotypeCaller - GCS max retries/reopens: 20. 18:58:01.494 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes. 18:58:01.494 INFO HaplotypeCaller - Initializing engine. 18:58:02.043 INFO HaplotypeCaller - Done initializing engine. 18:58:02.053 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output. 18:58:02.053 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output. 18:58:02.886 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/bigdata/operations/pkgadmin/opt/linux/centos/7.x/x86_64/pkgs/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar!/com/intel/gkl/native/libgkl_utils.so. 18:58:02.888 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/bigdata/operations/pkgadmin/opt/linux/centos/7.x/x86_64/pkgs/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so. 18:58:02.932 WARN IntelPairHmm - Flush-to-zero (FTZ) ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4788:2864,patch,patch,2864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4788,1,['patch'],['patch']
Deployability,"8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/≈Åuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:46:24.742 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:46:24.761 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:46:24.764 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:46:24.764 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:46:24.884 INFO BaseRecalibrator - ------------------------------------------------------------; 13:46:24.884 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:46:24.885 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:46:24.885 INFO BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86_64 amd64; 13:46:24.885 INFO BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087; 13:46:24.885 INFO BaseRecalibrator - Start Date/Time: September 22, 2022 at 1:46:24 PM CST; 13:46:24.885 INFO BaseRecalibrator - ------------------------------------------------------------; 13:46:24.885 INFO BaseRecalibrator - -------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:13212,pipeline,pipeline,13212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"9). However, the bug wasn't reported when I didn't assign the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz ¬†-O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ; ¬† ¬† java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/≈Åuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:12:20.992 INFO ¬†NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:12:21.140 INFO ¬†BaseRecalibrator - ------------------------------------------------------------ ; ; 00:12:21.141 INFO ¬†BaseRecalibrator - The Genome Analysis Toolkit (GATK)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:15113,pipeline,pipeline,15113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"9); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.contig-sam-file.sam\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///proj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4688,deploy,deploy,4688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,9); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:133); at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:21); ... 31 more; 2019-06-03 22:34:49 INFO ShutdownHookManager:54 - Shutdo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4567,deploy,deploy,4567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,"9); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41537,deploy,deploy,41537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,9.565% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `87.273% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <√∏> (√∏)` | `6 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.182% <√∏> (√∏)` | `75 <0> (√∏)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388:2497,pipeline,pipelines,2497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388,1,['pipeline'],['pipelines']
Deployability,93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `87.333% <100%> (√∏)` | `42 <0> (√∏)` | :arrow_down: |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `73.208% <100%> (√∏)` | `55 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvci5qYXZh) | `88.372% <100%> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/qc/CheckPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3FjL0NoZWNrUGlsZXVwLmphdmE=) | `64.151% <100%> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | ... and [16 more](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-311922508:3333,pipeline,pipelines,3333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-311922508,1,['pipeline'],['pipelines']
Deployability,"94 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Version: 2.14.3; 13:48:31.695 INFO CountReadsSpark - Picard Version: 2.17.2; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:48:31.695 INFO CountReadsSpark - Deflater: IntelDeflater; 13:48:31.695 INFO CountReadsSpark - Inflater: IntelInflater; 13:48:31.696 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:48:31.696 INFO CountReadsSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 13:48:31.696 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:48:31.696 INFO CountReadsSpark - Initializing engine; 13:48:31.696 INFO CountReadsSpark - Done initializing engine; 18/12/21 13:48:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED ServerConnector@1cba0321{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocke",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:3548,patch,patch,3548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['patch'],['patch']
Deployability,942%)` | `4 <0> (-1)` | :arrow_down: |; | [...lbender/tools/spark/bwa/BwaArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `85.437% <100%> (+0.437%)` | `57 <2> (+2)` | :arrow_up: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <83.333%> (+2.477%)` | `4 <1> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.362% <86.957%> (-2.067%)` | `12 <0> (+2)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `75% <87.5%> (+5.769%)` | `5 <2> (√∏)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `85% <0%> (+1.25%)` | `32% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-334530619:2183,pipeline,pipelines,2183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-334530619,1,['pipeline'],['pipelines']
Deployability,"96.final.cram -O test.g.vcf.gz`. The cram is HG0096.final.cram found here:. https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. #### Expected behavior; When I run an earlier version v4.1.7.0, it runs without an error.... ```; gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:40:45.497 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:40:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:40:45.786 INFO HaplotypeCaller - ------------------------------------------------------------; 14:40:45.787 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 14:40:45.787 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:40:45.788 INFO HaplotypeCaller - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.6.1.el7.x86_64 amd64; 14:40:45.788 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 14:40:45.789 INFO HaplotypeCaller - Start Date/Time: February 10, 2021 2:40:45 PM EST; 14:40:45.789 INFO HaplotypeCaller - ------------------------------------------------------------; 14:40:45.789 INFO HaplotypeCaller - -----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:6032,install,install,6032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['install'],['install']
Deployability,"97968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but certainly it could fit into whatever framework we come; > up with.; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGKhCDUca-ZFaXWUoM6bn-LrGlgzx8jDks5tuE_QgaJpZM4TtIPq>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:2027,release,release,2027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['release'],['release']
Deployability,9:12 ERROR org.apache.spark.SparkContext: Error initializing SparkContext.; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1234,deploy,deploy,1234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"9:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:31828,pipeline,pipelines,31828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['pipeline'],['pipelines']
Deployability,9aeaf3a4753692e591e3ac?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `86.111%`. ```diff; @@ Coverage Diff @@; ## master #2620 +/- ##; ===============================================; + Coverage 77.718% 77.718% +<.001% ; - Complexity 11526 11536 +10 ; ===============================================; Files 787 788 +1 ; Lines 41697 41724 +27 ; Branches 7243 7248 +5 ; ===============================================; + Hits 32406 32427 +21 ; - Misses 6556 6559 +3 ; - Partials 2735 2738 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `92% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `95.238% <100%> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.016% <50%> (+0.416%)` | `39 <1> (+2)` | :arrow_up: |; | [...bender/engine/spark/AddContextDataToReadSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2620?src=pr&el=tree#diff-c3Jj,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-297073887:1248,pipeline,pipelines,1248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-297073887,1,['pipeline'],['pipelines']
Deployability,9cd5d45835890fff4fa34c/intervals.bed; 01:24:58.801 INFO IntervalArgumentCollection - Processing 11500 bp from intervals; 01:24:58.803 INFO GenomicsDBImport - Done initializing engine; 01:24:59.055 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 01:25:02.076 INFO GenomicsDBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:3859,update,update,3859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,9scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZS5qYXZh) | `72.581% <0.000%> (+1.613%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `98.333% <0.000%> (+1.667%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.207% <0.000%> (+1.724%)` | :arrow_up: |; | ... and [210 more](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278:5098,Update,UpdateVCFSequenceDictionary,5098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jbGV0LmphdmE=) | `100.000% <100.000%> (√∏)` | |; | [...utectReadThreadingAssemblerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/8100/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9NdXRlY3RSZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `57.143% <0.000%> (-7.143%)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/8100/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `83.333% <0.000%> (-5.556%)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/8100/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <0.000%> (-5.263%)` | :arrow_down: |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/8100/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95.000% <0.000%> (-5.000%)` | :arrow_down: |; | ... and [172 more](https://codecov.io/gh/broadinstitute/gatk/pull/8100/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8100#issuecomment-1324344229:4882,pipeline,pipelines,4882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8100#issuecomment-1324344229,1,['pipeline'],['pipelines']
Deployability,: IntelDeflater; 01:22:35.483 INFO GenomicsDBImport - Inflater: IntelInflater; 01:22:35.483 INFO GenomicsDBImport - GCS max retries/reopens: 20; 01:22:35.483 INFO GenomicsDBImport - Requester pays: disabled; 01:22:35.484 INFO GenomicsDBImport - Initializing engine; 01:24:58.683 INFO FeatureManager - Using codec BEDCodec to read file file:///lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/intervals.bed; 01:24:58.801 INFO IntervalArgumentCollection - Processing 11500 bp from intervals; 01:24:58.803 INFO GenomicsDBImport - Done initializing engine; 01:24:59.055 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 01:25:02.076 INFO GenomicsDBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:3450,update,update,3450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,": v4.1.9 ; ; b) Exact command used:. /gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar \\ ; ; VariantEval \\ ; ; \-R /$PATH\_TO\_REFERENCE/chm13/t2t-chm13.20200921.withGRCh38chrY.chrEBV.chrYKI270740v1r.fasta \\ ; ; \--eval /$PATH\_TO\_VCF/1kgp.chrX.recalibrated.snp\_indel.pass.vcf.gz \\ ; ; \--pedigree /$PATH\_TO\_PED/1kgp\_trios.ped \\ ; ; \-no-ev -no-st -ST Family \\ ; ; \-EV MendelianViolationEvaluator \\ ; ; \-O 1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table. c) Entire error log:. 19:35:29.408 INFO VariantEval - ------------------------------------------------------------ 19:35:29.408 INFO VariantEval - The Genome Analysis Toolkit (GATK) v4.1.9.0 19:35:29.409 INFO VariantEval - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) 19:35:29.409 INFO VariantEval - Executing as root@0b79b5044551 on Linux v5.4.104+ amd64 19:35:29.409 INFO VariantEval - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 19:35:29.409 INFO VariantEval - Start Date/Time: May 27, 2021 7:35:29 PM UTC 19:35:29.409 INFO VariantEval - ------------------------------------------------------------ 19:35:29.409 INFO VariantEval - ------------------------------------------------------------ 19:35:29.410 INFO VariantEval - HTSJDK Version: 2.23.0 19:35:29.410 INFO VariantEval - Picard Version: 2.23.3 19:35:29.410 INFO VariantEval - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 19:35:29.410 INFO VariantEval - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false 19:35:29.410 INFO VariantEval - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true 19:35:29.410 INFO VariantEval - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false 19:35:29.410 INFO VariantEval - Deflater: IntelDeflater 19:35:29.410 INFO VariantEval - Inflater: IntelInflater 19:35:29.410 INFO VariantEval - GCS max retries/reopens: 20 19:35:29.410 INFO VariantEval - Requester pays: disabled 19:35:29.411 WARN VariantEval - \[1m\[31m !!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:1606,release,release-,1606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['release'],['release-']
Deployability,":+1: Thanks @kgururaj. We'll merge once tests pass and the release is in maven central. . How does this affect https://github.com/broadinstitute/gatk/pull/4047, by the way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067:59,release,release,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067,1,['release'],['release']
Deployability,":+1: on this one from me, although I think we should eventually move away from use of `IntegrationTestSpec`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788:87,Integrat,IntegrationTestSpec,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788,1,['Integrat'],['IntegrationTestSpec']
Deployability,"://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt -- --spark-runner SPARK --deploy-mode cluster --spark-master yarn; Using GATK jar /home/jacky/Exec/gatk/build/libs/gatk-spark.jar; Running:; /home/jacky/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.executor.memoryOverhead=600 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 20/10/22 12:02:26 INFO yarn.Client: Setting up container launch context for our AM; 20/10/22 12:02:26 INFO yarn.Client: Setting up the launch environment for our AM container; 20/10/22 12:02:26 INFO yarn.Client: Preparing resources for our ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:1307,deploy,deploy-mode,1307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['deploy'],['deploy-mode']
Deployability,":121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.clus",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:6876,deploy,deploy,6876,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,":49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:52:27,478 WARN : 	process exited with non-zero value: 134; ```. Does that give anything to suggest troubleshooting steps?. The full command is:; ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	Xmx497g -Xms497g -Xss2m \; 	-jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar \; 	GenomicsDBImport \; 	-V 25780.g.vcf.gz \; 	-V <total of 92 gVCFs> \; 	--genomicsdb-update-workspace-path WGS_1852_consolidated.gdb \; 	--batch-size 10 \; 	--reader-threads 12 \; 	--consolidate \; 	--genomicsdb-shared-posixfs-optimizations \; 	--bypass-feature-reader \; 	-R 128_Mmul_10.fasta; ```. this is GATK v4.2.5.0. Thanks i advance for any ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:2789,update,update-workspace-path,2789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,1,['update'],['update-workspace-path']
Deployability,":54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Util",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36550,pipeline,pipelines,36550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['pipeline'],['pipelines']
Deployability,:56); at htsjdk.samtools.AbstractBAMFileIndex.readInteger(AbstractBAMFileIndex.java:432); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:272); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:120); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:361); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:35); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:3208,pipeline,pipelines,3208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['pipeline'],['pipelines']
Deployability,:995); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:986); at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:825); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:93); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:233); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:119); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:374); at org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark.runTool(SortSamSpark.java:114); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required arr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:26519,pipeline,pipelines,26519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['pipeline'],['pipelines']
Deployability,":; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3067,deploy,deploy,3067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['deploy'],['deploy']
Deployability,:arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <100%> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <100%> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.286% <76.923%> (-0.147%)` | `78 <9> (+10)` | |; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvTWFya0R1cGxpY2F0ZXNTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `91.144% <93.103%> (-0.262%)` | `42 <1> (+6)` | |; | [...hellbender/utils/runtime/RuntimeUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1J1bnRpbWVVdGlsc1VuaXRUZXN0LmphdmE=) | `87.5% <0%> (-12.5%)` | `4% <0%> (+1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.857% <0%> (-7.143%)` | `4% <0%> (√∏)` | |; | ... and [17 more](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021:3243,pipeline,pipelines,3243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021,1,['pipeline'],['pipelines']
Deployability,; 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3618,Integrat,IntegrationTestSpec,3618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Deployability,; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:120); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:141); 	at org.broadinstitute.hellbender.Main.main(Main.java:196); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.readIndex(SplittingBAMIndex.java:69); 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.<init>(SplittingBAMIndex.java:49); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeSplittingBaiFiles(SAMFileMerger.java:117); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:119); 	at org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark.runTool(BwaSpark.java:49); 	... 17 more,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503:1478,deploy,deploy,1478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503,2,['deploy'],['deploy']
Deployability,"; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e"" (or dumping to /bigdata/ramadugulab/luy/SNPcallingBreeding/core.1058615); #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- S U M M A R Y ------------. Command Line: -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /bigdata/operations/pkgadmin/opt/linux/centos/8.x/x86_64/pkgs/gatk/4.6.0.0/gatk-package-4.6.0.0-local.jar HaplotypeCaller -R /rhome/luy/bigdata/genomes/Cclementina_182_v1_2.fa -I AlignedCalToCcl_Scaffolds_MarkDupOut.bam -O AlignedCalToCcl_Scaffolds.vcf.gz -ERC GVCF. Host: Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz, 64 cores, 20G, Rocky Linux release 8.8 (Green Obsidian); Time: Sat Sep 28 04:11:19 2024 PDT elapsed time: 58592.788414 seconds (0d 16h 16m 32s). --------------- T H R E A D ---------------. Current thread (0x00007f06e4025b70): JavaThread ""main"" [_thread_in_native, id=1058616, stack(0x00007f06edc7a000,0x00007f06edd7b000)]. Stack: [0x00007f06edc7a000,0x00007f06edd7b000], sp=0x00007f06edbe6458, free space=18014398509481393k; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0xcf291] __memset_avx2_erms+0x11; C [libgkl_pairhmm_omp5311772482084658743.so+0x1500f] Java_com_intel_gkl_pairhmm_IntelPairHmm_computeLikelihoodsNative._omp_fn.0+0xcf. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 8942 com.intel.gkl.pairhmm.IntelPairHmm.computeLikelihoodsNative([Ljava/lang/Object;[Ljava/lang/Object;[D)V (0 bytes) @ 0x00007f06d563401c [0x00007f06d5633fa0+0x000000000000007c]; J 10003 c2 com.intel.gkl.pairhmm.IntelPairHmm.computeLikelihoods([Lorg/broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988:1784,release,release,1784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988,1,['release'],['release']
Deployability,"; - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); - GvsUnified WDL to wrap the 6 core GVS WDLs [VS-382] (#7789); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:23797,integrat,integration,23797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['integrat'],['integration']
Deployability,"; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:2098,deploy,deploy,2098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['deploy'],['deploy']
Deployability,"; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:58:10.116 INFO PrintVariantsSpark - Deflater: IntelDeflater; 16:58:10.116 INFO PrintVariantsSpark - Inflater: IntelInflater; 16:58:10.116 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 16:58:10.116 INFO PrintVariantsSpark - Requester pays: disabled; 16:58:10.116 WARN PrintVariantsSpark - . ?[1m?[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PrintVariantsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:3977,configurat,configuration,3977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['configurat'],['configuration']
Deployability,"; Date: Wed Dec 13 00:14:34 2023 -0500. staged base rc1. commit 74f8fa724dfac142ccd7ac79a757c0e5ac3bb06c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:01:38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1418,update,update,1418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"; ```. 3. java.lang.NullPointerException occurs. ; 4. No variants output into VCF. This is the log:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:1-105581 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-1-105581.vcf.gz; 00:05:54.259 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 00:05:54.319 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 12:05:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:05:54.582 INFO GenotypeGVCFs - ------------------------------------------------------------; 00:05:54.583 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 00:05:54.583 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:05:54.583 INFO GenotypeGVCFs - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 00:05:54.583 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 00:05:54.584 INFO GenotypeGVCFs - Start Date/Time: August 25, 2021 12:05:54 AM EDT; 00:05:54.584 INFO GenotypeGVCFs - ------------------------------------------------------------; 00:05:54.584 INFO GenotypeGVCFs - --------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:1673,install,install,1673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['install'],['install']
Deployability,; and I entered ; ./gradlew bundle ; or; ./gradlew. but it failed to build GATK4 with following errors. . ====================================; OpenJDK 64-Bit Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1444,Configurat,ConfigurationResolver,1444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Configurat'],['ConfigurationResolver']
Deployability,"; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Using GATK jar /home/parashar/anaconda3/share/gatk4-4.1.4.0-0/gatk-package-4.1.4.0-local.jar. I used the following command; `gatk Mutect2 -R /archive/GRCh38_GATK/Homo_sapiens_assembly38.fasta -I /scratch/pixel_dis/BCC199N_S12_dedup.bam --max-mnp-distance 0 -O /scratch/pixel_dis/BCC199N_S12_dedup_normal.vcf.gz 2> /scratch/pixel_dis/BCC199N_S12_dedup_normal.stderr; `. to create PONs. But ending up with the same error. I also updated GATK. However, with `--independent-mates` option, it works fine. Why not make that as a default option?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:2791,update,updated,2791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['update'],['updated']
Deployability,"; at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; sudo apt-get -qq update > /dev/null; sudo apt-get -qq install -y gradle. echo ""Downloading binaries for Spark""; wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.1-bin-hadoop2.6.tgz; tar -xzf spark-1.5.1-bin-hadoop2.6.tgz; export SPARK_HOME=spark-1.5.1-bin-hadoop2.6. echo ""Set up Spark for standalone mode processing""; $SPARK_HOME/sbin/start-master.sh -h localhost; $SPARK_HOME/sbin/start-slave.sh spark://localhost:7077. echo ""Downloading source for GATK4""; wget https://github.com/broadinstitute/gatk/archive/4.alpha.tar.gz; tar -xvzf 4.alpha.tar.gz; export GATK_DIR=gatk-4.alpha. echo ""Building GATK4""; cd $GATK_DIR; gradle installAll; cd .. ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3882,Install,Installing,3882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,8,"['Install', 'install', 'update']","['Installing', 'install', 'installAll', 'installer', 'update']"
Deployability,; | [...lines/metrics/CollectQualityYieldMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0UXVhbGl0eVlpZWxkTWV0cmljc1NwYXJrLmphdmE=) | `100% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `86.792% <√∏> (√∏)` | `8 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <√∏> (√∏)` | `9 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195:1850,pipeline,pipelines,1850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195,1,['pipeline'],['pipelines']
Deployability,; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 66% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 68% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 73% | *new* [...broadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F746573742F586F72577261707065722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [.../hellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F5374616E64617264417267756D656E74446566696E6974696F6E732E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F5365656B61626C65427974654368616E6E656C507265666574636865722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...broadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6763732F4275636B65745574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [821d9fb...b497d23](https://codecov.io/gh/broadinstitute/gatk/compare/821d9fb60190028cd328492eea2929a843bbb069...b497d23dcdfcdbdec30b5a4109529e89d1bef4bc?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025:2578,update,update,2578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025,1,['update'],['update']
Deployability,;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-pa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3038,RELEASE,RELEASE,3038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,<0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `43.243% <0%> (-56.757%)` | `5% <0%> (-3%)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `50.649% <0%> (-42.454%)` | `4% <0%> (-2%)` | |; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `44.444% <0%> (-38.889%)` | `2% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `51.807% <0%> (-35.23%)` | `11% <0%> (-6%)` | |; | [...ls/spark/BaseRecalibratorSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `23.626% <0%> (-27.453%)` | `5% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `73.864% <0%> (-18.783%)` | `8% <0%> (+2%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698:2510,pipeline,pipelines,2510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698,1,['pipeline'],['pipelines']
Deployability,"<img width=""745"" alt=""Screenshot 2023-11-14 at 12 44 24 AM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/8390c9a8-f343-4c9b-9636-15b4dfc5aefa"">. Integration run:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/3aa1545f-7f11-4919-9ecf-8b3a5900441a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8581:159,Integrat,Integration,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8581,1,['Integrat'],['Integration']
Deployability,<√∏> (√∏)` | `24 <0> (√∏)` | :arrow_down: |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `86.842% <√∏> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5528#issuecomment-447774744:2449,pipeline,pipelines,2449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5528#issuecomment-447774744,1,['pipeline'],['pipelines']
Deployability,==; Files 1089 1089 ; Lines 64161 64161 ; Branches 10344 10344 ; ===============================================; - Hits 51599 51434 -165 ; - Misses 8501 8672 +171 ; + Partials 4061 4055 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4889?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ools/walkers/haplotypecaller/graphs/BaseGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQmFzZUdyYXBoLmphdmE=) | `82.239% <50%> (√∏)` | `94 <2> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-10%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4889/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4889#issuecomment-396706300:1573,pipeline,pipelines,1573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4889#issuecomment-396706300,1,['pipeline'],['pipelines']
Deployability,==; Files 1822 1825 +3 ; Lines 137732 137726 -6 ; Branches 15184 15188 +4 ; ===============================================; - Hits 119546 119484 -62 ; - Misses 12665 12721 +56 ; Partials 5521 5521; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5127?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `80% <100%> (-3.333%)` | `2 <0> (-2)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `90.476% <100%> (-2.627%)` | `4 <0> (-2)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.583% <100%> (+2.546%)` | `12 <4> (-5)` | :arrow_down: |; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `61.765% <100%> (√∏)` | `13 <2> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5127/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `93.333% <100%> (+6.377%)` | `6 <1> (-3)` | :arrow_down: |; | [...ools/spark/transforms/BaseRecalibratorSparkFn.java](https://codecov.io/gh/broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432:1577,pipeline,pipelines,1577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416211432,1,['pipeline'],['pipelines']
Deployability,===; Files 1791 1814 +23 ; Lines 133601 135364 +1763 ; Branches 14920 15042 +122 ; ============================================; + Hits 115364 116914 +1550 ; - Misses 12834 12996 +162 ; - Partials 5403 5454 +51; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5056?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/tools/spark/sv/utils/GATKSVVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZDb25zdGFudHMuamF2YQ==) | `0% <0%> (-75%)` | `0% <0%> (-1%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5056/diff?src=pr&el=tree#diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5056#issuecomment-408053675:1563,pipeline,pipelines,1563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5056#issuecomment-408053675,1,['pipeline'],['pipelines']
Deployability,"=====; + Hits 30163 30192 +29 ; Misses 6772 6772 ; - Partials 2618 2619 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (-1.102%)` | `4 <0> (√∏)` | |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98% <96.552%> (-2%)` | `23 <9> (+9)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=footer). Last update [78f4f61...fc03f04](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2524#issuecomment-288804022:2417,update,update,2417,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2524#issuecomment-288804022,2,['update'],['update']
Deployability,======; Files 1056 1056 ; Lines 59150 59149 -1 ; Branches 9615 9616 +1 ; ===============================================; - Hits 46738 46487 -251 ; - Misses 8673 8932 +259 ; + Partials 3739 3730 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4044?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ngine/spark/datasources/ReferenceTwoBitSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlVHdvQml0U291cmNlLmphdmE=) | `90.909% <75%> (-9.091%)` | `6 <2> (-1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-60.294%)` | `8% <0%> (-25%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221:1569,pipeline,pipelines,1569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221,1,['pipeline'],['pipelines']
Deployability,======; Files 1074 1074 ; Lines 59186 59435 +249 ; Branches 9615 9686 +71 ; ==============================================; + Hits 46733 46962 +229 ; - Misses 8714 8719 +5 ; - Partials 3739 3754 +15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4066?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (√∏)` | `65% <0%> (-1%)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <0%> (√∏)` | `4% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.889% <0%> (+0.654%)` | `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:1566,pipeline,pipelines,1566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318,1,['pipeline'],['pipelines']
Deployability,=======; Files 1062 1062 ; Lines 61677 61676 -1 ; Branches 9983 9984 +1 ; ==============================================; - Hits 49243 49076 -167 ; - Misses 8539 8709 +170 ; + Partials 3895 3891 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4584?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ngine/spark/datasources/ReferenceTwoBitSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlVHdvQml0U291cmNlLmphdmE=) | `90.909% <75%> (-9.091%)` | `6 <2> (-1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4584/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4584#issuecomment-376279904:1565,pipeline,pipelines,1565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4584#issuecomment-376279904,1,['pipeline'],['pipelines']
Deployability,"==========; + Hits 120162 120170 +8 ; + Misses 12760 12758 -2 ; Partials 5551 5551; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.19% <100%> (+0.37%)` | `68 <0> (√∏)` | :arrow_down: |; | [...ls/spark/BaseRecalibratorSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `40.54% <100%> (+1.09%)` | `5 <0> (√∏)` | :arrow_down: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `100% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.97% <0%> (+2.73%)` | `11% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=footer). Last update [158f7f7...2cb7fd4](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5290#issuecomment-427852825:2705,update,update,2705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5290#issuecomment-427852825,2,['update'],['update']
Deployability,==========; Files 1822 1825 +3 ; Lines 137732 138108 +376 ; Branches 15184 15231 +47 ; ===============================================; + Hits 119546 119650 +104 ; - Misses 12665 12917 +252 ; - Partials 5521 5541 +20; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5248?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nstitute/hellbender/engine/spark/SparkSharder.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyLmphdmE=) | `91.156% <100%> (+0.184%)` | `30 <0> (-1)` | :arrow_down: |; | [.../hellbender/engine/spark/SparkSharderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyVW5pdFRlc3QuamF2YQ==) | `92.92% <100%> (+0.193%)` | `7 <0> (√∏)` | :arrow_down: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `43.243% <0%> (-56.757%)` | `5% <0%> (-3%)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `50.649% <0%> (-42.454%)` | `4% <0%> (-2%)` | |; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `44.444% <0%> (-38.889%)` | `2% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698:1567,pipeline,pipelines,1567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698,1,['pipeline'],['pipelines']
Deployability,=============; Files 1080 1081 +1 ; Lines 63131 63201 +70 ; Branches 10200 10215 +15 ; ===============================================; + Hits 50551 50618 +67 ; Misses 8587 8587 ; - Partials 3993 3996 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (+1.17%)` | `5 <1> (+1)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.388% <100%> (+0.083%)` | `94 <1> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.796% <100%> (+0.665%)` | `14 <2> (+2)` | :arrow_up: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `77.778% <100%> (+1.307%)` | `7 <1> (+1)` | :arrow_up: |; | [...equenceDictionaryValidationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvU2VxdWVuY2VEaWN0aW9uYXJ5VmFsaWRhdGlvbkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <100%> (√∏)` | `0 <0> (?)` | |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142:1563,pipeline,pipelines,1563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142,1,['pipeline'],['pipelines']
Deployability,=============; Files 1188 1188 ; Lines 64410 64543 +133 ; Branches 10004 10022 +18 ; ==============================================; + Hits 51579 51705 +126 ; Misses 8845 8845 ; - Partials 3986 3993 +7; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <100%> (+0.504%)` | `34 <0> (+2)` | :arrow_up: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.831% <0%> (-0.847%)` | `23% <0%> (-1%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `92.857% <0%> (-0.246%)` | `16% <0%> (+8%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.101% <0%> (+0.253%)` | `142% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/utils/GenomeLocSortedSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NTb3J0ZWRTZXQuamF2YQ==) | `93.793% <0%> (+0.69%)` | `59% <0%> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752:1559,pipeline,pipelines,1559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752,1,['pipeline'],['pipelines']
Deployability,==============; Files 1047 1047 ; Lines 59184 59186 +2 ; Branches 9670 9671 +1 ; ===============================================; - Hits 46786 46630 -156 ; - Misses 8640 8804 +164 ; + Partials 3758 3752 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4432?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `85.366% <57.143%> (-2.134%)` | `33 <0> (√∏)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181:1565,pipeline,pipelines,1565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181,1,['pipeline'],['pipelines']
Deployability,=================; Files 1187 1192 +5 ; Lines 65403 65457 +54 ; Branches 9932 9941 +9 ; ===============================================; - Hits 51987 51728 -259 ; - Misses 9429 9739 +310 ; - Partials 3987 3990 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3901?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...e/hellbender/engine/filters/LibraryReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <100%> (√∏)` | `3 <0> (-1)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (√∏)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3901/diff?src=pr&el=tree#diff-c3JjL,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3901#issuecomment-348476913:1559,pipeline,pipelines,1559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3901#issuecomment-348476913,1,['pipeline'],['pipelines']
Deployability,"====================; + Hits 30189 30196 +7 ; - Misses 6774 6802 +28 ; - Partials 2621 2626 +5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `58.479% <0%> (√∏)` | `28 <0> (√∏)` | :arrow_down: |; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <100%> (√∏)` | `30 <0> (√∏)` | :arrow_down: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <100%> (√∏)` | `24 <0> (√∏)` | :arrow_down: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `77.778% <38.462%> (-10.91%)` | `25 <5> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=footer). Last update [47d8c52...f2df0f7](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-288844391:2499,update,update,2499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-288844391,2,['update'],['update']
Deployability,====================; Files 1058 1057 -1 ; Lines 59682 59712 +30 ; Branches 9712 9723 +11 ; ===============================================; + Hits 46584 46879 +295 ; + Misses 9349 9078 -271 ; - Partials 3749 3755 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4152?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...hellbender/utils/linalg/FourierLinearOperator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvRm91cmllckxpbmVhck9wZXJhdG9yLmphdmE=) | `78.378% <√∏> (√∏)` | `12 <0> (√∏)` | :arrow_down: |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <0%> (√∏)` | `61 <0> (√∏)` | :arrow_down: |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `95.238% <100%> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (√∏)` | `29 <0> (√∏)` | :arrow_down: |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `100% <100%> (√∏)` | `8 <2> (√∏)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658:1571,Integrat,IntegrationUtils,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658,1,['Integrat'],['IntegrationUtils']
Deployability,"==========================; + Hits 30054 30059 +5 ; - Misses 6754 6759 +5 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXIuamF2YQ==) | `75% <71.429%> (-1.543%)` | `35 <3> (+2)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <0%> (-2.083%)` | `36% <0%> (√∏)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=footer). Last update [92cb860...f53692e](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2440#issuecomment-284888102:2401,update,update,2401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2440#issuecomment-284888102,2,['update'],['update']
Deployability,============================; Files 1041 1041 ; Lines 59122 59122 ; Branches 9674 9674 ; ===============================================; - Hits 46401 46165 -236 ; - Misses 8981 9229 +248 ; + Partials 3740 3728 -12; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4232?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <√∏> (√∏)` | `0 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526:1547,pipeline,pipelines,1547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526,1,['pipeline'],['pipelines']
Deployability,"==============================; + Hits 30163 30164 +1 ; + Misses 6772 6770 -2 ; - Partials 2618 2619 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <√∏> (√∏)` | `2 <0> (?)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (√∏)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=footer). Last update [78f4f61...c122c34](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2526#issuecomment-288832482:2381,update,update,2381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2526#issuecomment-288832482,2,['update'],['update']
Deployability,===============================; Files 1074 1080 +6 ; Lines 62907 64036 +1129 ; Branches 10181 10471 +290 ; ==============================================; + Hits 50225 51322 +1097 ; - Misses 8701 8704 +3 ; - Partials 3981 4010 +29; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4656?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `80.241% <0%> (-0.194%)` | `142 <2> (+2)` | |; | [...ections/MarkDuplicatesSparkArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvTWFya0R1cGxpY2F0ZXNTcGFya0FyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.13% <100%> (-0.231%)` | `12 <0> (√∏)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `77.778% <100%> (-1.17%)` | `4 <0> (√∏)` | |; | [...s/read/markduplicates/sparkrecords/PairedEnds.java](https://codecov.io/gh/broadinstitute/gatk/pull/4656/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyZWRFbmRzLmphdmE=) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4656#issuecomment-380909365:1546,pipeline,pipelines,1546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4656#issuecomment-380909365,1,['pipeline'],['pipelines']
Deployability,================================; Files 769 769 ; Lines 40058 40137 +79 ; Branches 6979 6995 +16 ; ==============================================; + Hits 30438 30506 +68 ; - Misses 6981 6990 +9 ; - Partials 2639 2641 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `86.957% <0%> (-8.282%)` | `9 <0> (+1)` | |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `74.766% <100%> (+1.657%)` | `23 <1> (-3)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:1543,pipeline,pipelines,1543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,2,['pipeline'],['pipelines']
Deployability,================================; Files 787 1139 +352 ; Lines 41743 61159 +19416 ; Branches 7251 9498 +2247 ; =============================================; + Hits 32417 48927 +16510 ; - Misses 6586 8422 +1836 ; - Partials 2740 3810 +1070; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ute/hellbender/utils/reference/ReferenceUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlVXRpbHMuamF2YQ==) | `64.706% <75%> (+3.167%)` | `4 <0> (+1)` | :arrow_up: |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.818% <0%> (√∏)` | `23% <0%> (+1%)` | :arrow_up: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <0%> (√∏)` | `15% <0%> (+7%)` | :arrow_up: |; | [...nstitute/hellbender/utils/help/GATKHelpDoclet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jbGV0LmphdmE=) | `100% <0%> (√∏)` | `9% <0%> (+3%)` | :arrow_up: |; | [...institute/hellbender/tools/exome/SNPSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TTlBTZWdtZW50ZXIuamF2YQ==) | `78.947% <0%> (√∏)` | `6% <0%> (?)` | |; | [...adinstitute/hellbender/tools/exome/AllelicCNV.java](https://codecov.io/gh/broadinstitute/gatk/pull/2803?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2803#issuecomment-305877779:1538,pipeline,pipelines,1538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2803#issuecomment-305877779,1,['pipeline'],['pipelines']
Deployability,======================================; Files 1172 1173 +1 ; Lines 64706 66787 +2081 ; Branches 9880 10565 +685 ; ===============================================; + Hits 51342 52977 +1635 ; - Misses 9446 9815 +369 ; - Partials 3918 3995 +77; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...lbender/tools/validation/CompareBaseQualities.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy92YWxpZGF0aW9uL0NvbXBhcmVCYXNlUXVhbGl0aWVzLmphdmE=) | `75.676% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...titute/hellbender/tools/walkers/CountVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvdW50VmFyaWFudHMuamF2YQ==) | `100% <√∏> (√∏)` | `3 <0> (√∏)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <√∏> (√∏)` | `11 <0> (√∏)` | :arrow_down: |; | [...bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `100% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `75.51% <√∏> (√∏)` | `17 <0> (√∏)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3880#issuecomment-347373155:1524,pipeline,pipelines,1524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3880#issuecomment-347373155,1,['pipeline'],['pipelines']
Deployability,=======================================; Files 2014 2014 ; Lines 151333 151333 ; Branches 16612 16612 ; ===============================================; + Hits 131548 131549 +1 ; Misses 13724 13724 ; + Partials 6061 6060 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5991?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90.909% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <√∏> (√∏)` | `5 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <√∏> (√∏)` | `2 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/CountVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRWYXJpYW50c1NwYXJrLmphdmE=) | `90.909% <√∏> (√∏)` | `4 <0> (√∏)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/PrintReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504:1538,pipeline,pipelines,1538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504,1,['pipeline'],['pipelines']
Deployability,===========================================; Files 1943 1943 ; Lines 146193 146213 +20 ; Branches 16141 16145 +4 ; ===============================================; + Hits 127242 127258 +16 ; - Misses 13064 13068 +4 ; Partials 5887 5887; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5093?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...institute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFdhbGtlckJhc2UuamF2YQ==) | `100% <√∏> (√∏)` | `14 <0> (√∏)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+1.505%)` | `16 <5> (+2)` | :arrow_up: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+0.044%)` | `16 <6> (+7)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (√∏)` | `2% <0%> (√∏)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5093#issuecomment-411427321:1559,Update,UpdateVCFSequenceDictionaryIntegrationTest,1559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5093#issuecomment-411427321,1,['Update'],['UpdateVCFSequenceDictionaryIntegrationTest']
Deployability,===============================================; Files 1048 1048 ; Lines 59579 59506 -73 ; Branches 9730 9718 -12 ; ===============================================; - Hits 47114 46833 -281 ; - Misses 8685 8908 +223 ; + Partials 3780 3765 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4283?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.466% <25%> (+9.733%)` | `43 <1> (+8)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262:1528,pipeline,pipelines,1528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262,1,['pipeline'],['pipelines']
Deployability,"=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:4040,upgrade,upgrade,4040,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,3,['upgrade'],['upgrade']
Deployability,=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2186 diff @@; ==========================================; Files 712 712 ; Lines 38214 38219 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8022 8022 ; ==========================================; + Hits 29013 29018 +5 ; Misses 6726 6726 ; Partials 2475 2475 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2186/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/walkers/vqsr/GaussianMixtureModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F476175737369616E4D6978747572654D6F64656C2E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...er/tools/walkers/vqsr/VariantRecalibratorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F72456E67696E652E6A617661) |; | ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ 100% | [...lbender/tools/walkers/vqsr/MultivariateGaussian.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F4D756C746976617269617465476175737369616E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [e07402e...1052657](https://codecov.io/gh/broadinstitute/gatk/compare/e07402e27457860fa3167eee9d58093c6dfff8fb...1052657a1023fd062b3f675accdc0be4042495a1?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338:2090,update,update,2090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338,1,['update'],['update']
Deployability,=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `57.407% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pathseq/PathSeqPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFQaXBlbGluZVNwYXJrLmphdmE=) | `81.25% <√∏> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `83.495% <100%> (+0.162%)` | `56 <0> (√∏)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `92.593% <100%> (+13.645%)` | `7 <0> (+3)` | :arrow_up: |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `67.391% <100%> (√∏)` | `7 <0> (√∏)` | :arrow_down: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.043% <50%> (-2.411%)` | `26 <2> (+2)` | |; | [...der/tools/walkers/mutect/M2ArgumentCollection.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4666#issuecomment-382129089:1853,pipeline,pipelines,1853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4666#issuecomment-382129089,1,['pipeline'],['pipelines']
Deployability,"> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <√∏> (+0.926%)` | `40% <√∏> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <√∏> (+1.042%)` | `10% <√∏> (√∏)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <√∏> (+1.075%)` | `26% <√∏> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=footer). Last update [30365e7...09a6f24](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:5220,update,update,5220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,2,['update'],['update']
Deployability,> (√∏)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `49.333% <√∏> (√∏)` | `13 <0> (√∏)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `70.667% <100%> (+1.484%)` | `35 <0> (√∏)` | :arrow_down: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+1.265%)` | `70 <0> (-48)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+3.716%)` | `16 <5> (-3)` | :arrow_down: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+45.166%)` | `16 <6> (+6)` | :arrow_up: |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-15%)` | `3% <0%> (-1%)` | |; | ... and [1 more](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772:2580,Update,UpdateVCFSequenceDictionary,2580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,> * `gatk_override`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` anyway. > * `interval_list`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` on exomes. > * `use_VQSR_lite`; > * `extract_do_not_filter_override`. these two will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` with VQSR classic anyway. > * `filter_set_name`; > * `extract_table_prefix`. these two can just default to the `call_set_identifier` with weird characters parsed out,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283:116,integrat,integration,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283,3,['integrat'],['integration']
Deployability,"> . @rsasch I don't believe that CreateFilteringFiles.java is used anywhere else except in GVS. As for JointVcfFiltering.wdl, I really tried to avoid changing it, but the changes I had to make were for memory and disk. At this point the changes are in our branch (ah_var_store) and when we merge with main, we can deal with the PR then. But, I also know there's an updated version of this WDL that we are supposed to update to - that will presumably happen before we merge with main.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1444234025:365,update,updated,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1444234025,2,['update'],"['update', 'updated']"
Deployability,"> > I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb.; > ; > SG! I also pushed this to Agora and will test it out using our genomic extraction workflow. our error is resolved with this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883,1,['integrat'],['integration']
Deployability,"> > Not to mention, in theory one could have some job trying to read the original workspace, which might get hosed if some other job is trying to edit that workspace in place.; > ; > This is not possible as new GenomicsDB workspace fragments are created for the incremental updates. During the actual finalization of the fragments, the array in the workspace is locked using Posix file locks for concurrency. As @nalinigans says, individual arrays/intervals in a GenomicsDB workspace will be consistent during incremental import. One caveat though, since each array is independently updated, different arrays/intervals will finish adding samples at different times while incremental import is in progress. So, querying a workspace that is being incrementally imported into isn't recommended.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617405801:274,update,updates,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617405801,2,['update'],"['updated', 'updates']"
Deployability,"> @Ben-Habermeyer We had a few PRs in late 2021 that may have fixed this. If it's still occurring in the latest GATK version I would like to take a look at it. ok @davidbenjamin I got a chance to test with latest release `4.3.0.0` and the issue seems to be mostly resolved when running `--alleles` on our test samples. Additionally, `FilterMutectCalls` works on low DP variants. . For control samples, using the `--alleles` option results in an error due to the value of the stats `callable`. . Combination of this call:; ```; chr18 77560878 . AA TT . . AS_SB_TABLE=0,0|0,0;DP=1;ECNT=2;MBQ=0,90;MFRL=0,100;MMQ=60,60;MPOS=29;POPAF=7.30;TLOD=4.20 GT:AD:AF:DP:F1R2:F2R1:FAD:PGT:PID:PS:SB 0|1:0,1:0.667:1:0,1:0,0:0,1:0|1:77560878_AA_TT:77560878:0,0,0,1; ```; and the stats file containing:; ```; callable 1.0; ```; results in FilterMutectCalls exception; ```; java.lang.IllegalArgumentException: logValues must be non-infinite and non-NAN; at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047:213,release,release,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047,2,['release'],['release']
Deployability,> @Bowen1992 Could you please try running with the latest GATK release (`4.2.6.1`) and reporting whether the issue persists?. Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -Djava.io.tmpdir=./tmp -jar /public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R /public/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR7_gvcf_database -G StandardAnnotation --genomicsdb-shared-posixfs-optimizations true -O new_ALL_MATERIALS_chr7.g.vcf.gz; 17:49:50.404 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 17:49:50.653 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:49:51.271 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.273 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.6.1; 17:49:51.273 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:49:51.273 INFO GenotypeGVCFs - Executing as gaoshibin@comput6 on Linux v3.10.0-693.el7.x86_64 amd64; 17:49:51.274 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_211-b12; 17:49:51.274 INFO GenotypeGVCFs - Start Date/Time: 2022Âπ¥5Êúà22Êó• ‰∏ãÂçà05Êó∂49ÂàÜ50Áßí; 17:49:51.274 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.275 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.276 INFO GenotypeGVCFs - HTSJDK Version: 2.24.1; 17:49:51.276 INFO GenotypeGVCFs - Picard Version: 2.27.1; 17:49:51.276 INFO GenotypeGVCFs - Built for Spark Version: 2.4.5; 17:49:51.277 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:49:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135302097:63,release,release,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135302097,1,['release'],['release']
Deployability,"> @bbimber The test that failed just got fixed in master so you should be good to ignore it... it is @lbergelson PR into your code that you are patching so i don't know if he should approve this or not... Thanks @jamesemery. The PR in question was initiated by me, but having @lbergelson approving seems fine. The goal here is to get https://github.com/broadinstitute/gatk/pull/8752 approved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189877643:144,patch,patching,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189877643,1,['patch'],['patching']
Deployability,"> @colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know. In reference to your reply, I wish to inform you the problem still stands. > java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:100,release,release,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['release'],['release']
Deployability,"> @droazen, note that I have published only a 1.5.3 snapshot version of genomicsdb. If these changes are good, I will make a full release of 1.5.3 and reference that in `build.gradle`. @droazen, `build.gradle` references [1.5.3 ](https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.5.3)version now. Feel free to merge these changes. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8759#issuecomment-2047860338:130,release,release,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8759#issuecomment-2047860338,2,['release'],"['release', 'releases']"
Deployability,"> @javad30 Hi, it looks like you're running a gatk built for java 8 with java 11. Pre-built gatk jars only support java 8. Could you install openjdk 8 and try again?. It did work. Thank you so much for your help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604#issuecomment-628951385:133,install,install,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604#issuecomment-628951385,1,['install'],['install']
Deployability,> @lbergelson @gokalpcelik any chance of giving me access to the workspace for the 330 whole exomes?. Hi @nalinigans ; Unfortunately this is on my private company server but I may be able to conduct tests if you need me to. I can generate a fork of gatk and update GenomicsDB to test it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434590689:258,update,update,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434590689,1,['update'],['update']
Deployability,"> @nalinigans Back to you with my comments. If you're able to address them by Friday morning, this PR can go into the next GATK release. Hopefully, this can make it into the releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6675#issuecomment-649875450:128,release,release,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6675#issuecomment-649875450,2,['release'],"['release', 'releases']"
Deployability,"> @nalinigans Yes, we just need to take a peek inside the VCF file you updated. Were there any additional changes to that VCF when you updated to the latest master?. @droazen I did not have to change the VCF when I merged with master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8759#issuecomment-2072138079:71,update,updated,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8759#issuecomment-2072138079,2,['update'],['updated']
Deployability,"> @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Thanks, @samuelklee for keeping me updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065:38,update,update,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065,2,['update'],"['update', 'updated']"
Deployability,"> @zaneChou1 are you interested in continuing this work? I have not been able to work on the issue myself just yet. As noted in the the thread linked above, it will require nontrivial changes beyond the updates to package versions you've made here, including changes to the gCNV to account for PyMC3 API updates. Yes, I am interested. And I will try to change to the gCNV to account for PyMC3 API updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6979#issuecomment-759142391:203,update,updates,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6979#issuecomment-759142391,3,['update'],['updates']
Deployability,"> Are there more beta-user-visible changes we'd want to document since March? e.g. ploidy, FT header changes, possibly others. We never documented those two things, but I'll include them in new documentation I'm writing where appropriate. But if we have a release notes doc we maintain for each version, we should def put things there as they are released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2182867636:256,release,release,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2182867636,2,['release'],"['release', 'released']"
Deployability,"> Assuming it has a sane license. https://aws.amazon.com/corretto/faqs/#Licensing_and_Open_Source; - Corretto is released under the same open source license as OpenJDK, which is licensed under the GNU Public License version 2 with the Class Path Exception ([GPLv2 with CPE](https://openjdk.java.net/legal/gplv2+ce.html)). You can use Corretto as you would use OpenJDK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123070470:113,release,released,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123070470,1,['release'],['released']
Deployability,> But I'd like to see some more analysis of the dynamic pruning for exomes before this goes into our exome pipeline in the future. @ldgauthier Do you mean somatic exomes or mitochondrial reads from germline exomes?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-448740689:107,pipeline,pipeline,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-448740689,1,['pipeline'],['pipeline']
Deployability,"> Can has! Please ignore the confusingness of the branch name üôà; > https://job-manager.dsde-prod.broadinstitute.org/jobs/245e1b69-a628-41c0-8e64-ebd3ae37ce30. Sorry if this is a dumb question, but how do I verify that the new image is being used since we can't see the WDLs of the subworkflows that are being called by the integration WDL?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971:323,integrat,integration,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971,1,['integrat'],['integration']
Deployability,"> Doesn't seem to be the subject of this ticket, but are all the `call_PS` supposed to be null?. Yeah, that's (I'm pretty sure anyway) because the WGS test data has no PS fields in them. I have that other ticket to update the test data. And need to resolve that.; I did do an export of Avros using some Exomes that have PS and they were defined in the AVRO. Will mention that above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8536#issuecomment-1741454224:215,update,update,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8536#issuecomment-1741454224,1,['update'],['update']
Deployability,"> Hello, @oldmikeyang I'm in the middle of doing a tie out for MarkDuplicatesSpark right now. I just recently fixed (and it will hopefully be released soon) some counting issues involving the metrics collection (it was over-counting the number of duplicate pairs marked compared to picard) I suspect it is likely that the actual bam output is correct. I will have a branch soon that I would ask you to try markDuplicatesSpark again on and tell me if it's still causing problems, unfortunately an unrelated fix requires a change to go into picard [broadinstitute/picard#1230](https://github.com/broadinstitute/picard/pull/1230).; > ; > I will let you know when the PR is open, as I would love to know if it fixes this mismatch. I would like to try it. By the way, I am running the whole SPARK version, MarkDuplicatesSpark + BQSRPipelineSpark + HaplotypeCallerSpark to get the vcf file. ; I found the output of the vcf is different with the GATK standard pipeline MarkDuplicates + BaseRecalibrator + ApplyBQSR + HaplotypeCaller.; The SPARK version is 3% less than the standard pipeline.; So I am debugging where these difference come from.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427538451:142,release,released,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427538451,3,"['pipeline', 'release']","['pipeline', 'released']"
Deployability,"> Hi, I am trying to generate vcf using GATK pipeline from bam file, but everytime, I am getting the following exception: 01:13:15.801 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/ngs/programs/gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so 01:13:16.075 INFO HaplotypeCaller - ------------------------------------------------------------ 01:13:16.075 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.0.0.0 01:13:16.075 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/ 01:13:16.076 INFO HaplotypeCaller - Executing as shashank@grande on Linux v3.13.0-79-generic amd64 01:13:16.076 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_72-internal-b15 01:13:16.076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------ 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------ 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes 01:13:16.078 INFO HaplotypeCaller - Initializing engine 01:13:17.087 INFO HaplotypeCaller - ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955:45,pipeline,pipeline,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955,1,['pipeline'],['pipeline']
Deployability,"> How can I install GATK4 successful?. If you just want to install (as opposed to build), you can download a [release .zip or .tar](https://github.com/broadinstitute/gatk/releases) directly. If you want to build, then as @magicDGS suggested, you need to have git-lfs installed. If you already have that, I would try manually running the command `git lfs pull --include src/main/resources/large` from the root of the repo clone and see if you get a more detailed failure message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528:12,install,install,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528,5,"['install', 'release']","['install', 'installed', 'release', 'releases']"
Deployability,"> How was this gvcf created can you post us your steps as well?. I'm afraid that's non-public information. Perhaps after consulting with my employer, I will publish some of the pipelines' code. > Also are you trying to combine gvcfs generated by different tools with haplotypecallers gvcf ?. Yes, I am merging the gVCFs generated by HaplotypeCaller, DeepVariant, BCFtools mpileup&call and FreeBayes. Before merging, I try to unify the source gVCFs using self-written Bash and Python scripts. > What version of GATK are you using?. ```; gatk --version; ```; ```; Using GATK jar /home/pbykadorov/miniconda3/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pbykadorov/miniconda3/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar --version; The Genome Analysis Toolkit (GATK) v4.4.0.0; HTSJDK Version: 3.0.5; Picard Version: 3.0.0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755478373:177,pipeline,pipelines,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755478373,1,['pipeline'],['pipelines']
Deployability,"> I guess my objection boils down to the fact that by outputting . Instead of PASS you're throwing away information. I agree that we need to address that. What if an allele whose failing filters were all passed to the site got a concise tag like `site` to indicate that it has no additional filters, is not a passing allele, and that allele-specific filters were applied?. Besides the aesthetics of the word ""PASS"" being associated in any way with something failing, I'm worried about users shooting themselves in the foot with pipelines that only check the allele filters. You could imagine cases where failing to check the site filters wouldn't be so egregious as to be obvious.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590029834:528,pipeline,pipelines,528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590029834,1,['pipeline'],['pipelines']
Deployability,"> I have no objection to these changes, especially since this is just bringing us back to where we were in genomicsDB in the last release. We should spawn a ticket to track reintroducing these improvements and perhaps we should also add a macos test to our travis array so we can catch this kind of issue in the future? I think there is a macOS VM availible on travis that we could rerun some of the integration tests on. Yes, travis has macOS VM. It is very slow, so would recommend only sanity checks on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124:130,release,release,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124,2,"['integrat', 'release']","['integration', 'release']"
Deployability,"> I think we've seen similar issues before. Libgomp needs to be installed and findable. I think it typically is installed when you install gcc. See #6012 for more discussion. Thank you, I checked my system and found gcc module not loaded. I reloaded my gcc by typing; `module load gcc/5.4.0`; and it works now. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8194#issuecomment-1425155969:64,install,installed,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8194#issuecomment-1425155969,3,['install'],"['install', 'installed']"
Deployability,"> I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb. SG! I also pushed this to Agora and will test it out using our genomic extraction workflow",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093,1,['integrat'],['integration']
Deployability,"> Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing. Unit test fixed to include checking of variant type (which it did not include before - hence the non-failure). Test data adjusted accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412,2,['integrat'],"['integration', 'integrationtest']"
Deployability,> Is there a successful integration run?. yes [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6c033078-f6d3-47c8-926a-07176478823d),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330,1,['integrat'],['integration']
Deployability,"> It seems like the patch in 4.1.6 didn't go far enough and that exception needs to be replaced with a continue in all cases. That would work, but I see where I caused the regression upstream. I chopped leading and trailing deletions from haplotype cigars, same as for read cigars, but for haplotypes we want to keep these deletions because the start and end positions need to remain pegged to the reference start and end. I have a fix + regression test branch, which is running on every M2 validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-609115892:20,patch,patch,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-609115892,1,['patch'],['patch']
Deployability,"> It's worth noting that the ""true"" fix for this is to have distinct datasources for each reference. In this case, two sets of datasources - one for B37 and one for HG19 - would be needed. Do you have any plan to providing B37 data source? We are using BROAD B37 in our pipeline but Funcotator didn't work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7761#issuecomment-1522229364:270,pipeline,pipeline,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7761#issuecomment-1522229364,1,['pipeline'],['pipeline']
Deployability,"> Jupollet, This is a known issue and should be resolved by the most recent release gatk4-4.1.4.1. This was released last week, so you may need to just update. If that doesn‚Äôt work, you may need to disable supplementary reads. Thanks, Mark; > [‚Ä¶](#); > On Mon, Dec 2, 2019 at 10:52 AM jupollet ***@***.***> wrote: I verify with sacct SLURM command and the job have no problem with RAM memory, he run through the end but no produce .stat file and output only .vcf and .vcf.idx ‚Äî You are receiving this because you were assigned. Reply to this email directly, view it on GitHub <#6271?email_source=notifications&email_token=ACRX2DIR7ZYRDCNPZNOLET3QWU4L3A5CNFSM4JPWZLUKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFUEKKA#issuecomment-560481576>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ACRX2DJECNGRYUGBY62LLN3QWU4L3ANCNFSM4JPWZLUA> . Dear @fleharty. I have 4.2.2. version of GATK, however the problem is exactly like that, I get vcf and its index file without stats: . ***********************************************************************. A USER ERROR has occurred: Mutect stats table somatic_449_WT_vs_6KO_Pd.vcf.gz.stats not found. When Mutect2 outputs a file calls.vcf it also creates a calls.vcf.stats file. Perhaps this file was not moved along with the vcf, or perhaps it was not delocalized from a virtual machine while running in the cloud.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-979278929:76,release,release,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-979278929,3,"['release', 'update']","['release', 'released', 'update']"
Deployability,"> Looks good. Have you run the integration tests. I didn't run the integration test because it didn't seem necessary (no changes that effect the data, just the table(s) TTL). If you think I should, happy to kick it off.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772,2,['integrat'],['integration']
Deployability,"> OK, looks like you can get around the compiler lock issues by pointing each invocation of GermlineCNVCaller to a different compilation directory. For example, invoke `gatk` by; > ; > `THEANORC=PATH/TO/THEANORC_# gatk GermlineCNVCaller ...`; > ; > This uses the `THEANORC` environment variable to set the `.theanorc` configuration file to `PATH/TO/THEANORC_#` for this instance of GATK (where you should fill in `#` appropriately). Each `PATH/TO/THEANORC_#` should be a file containing the following:; > ; > ```; > [global]; > base_compiledir = PATH/TO/COMPILEDIR_#; > ```; > ; > Where again, `#` is filled in appropriately. The goal is to point each GermlineCNVCaller instance to a different compilation directory. @xysj1989 can you let me know if this works for you?; > ; > This is a bit of a hack. We could probably avoid this by changing the GATK code to use a specified or temporary directory for the theano directory without too much effort.; > ; > However, there is an upside to using a non-temporary directory to avoid recompilation of the model upon subsequent runs. In this case, we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?; > ; > @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?. Dear samuelklee,. Thank you very much for you reply. I also found this problem last night. It seems that the problem is originally from Theano and Pymc3, rather than GATK 4.0. Some similar problems have been reported just like (1) https://github.com/pymc-devs/pymc3/issues/1463 (2) https://stackoverflow.com/questions/52270853/how-to-get-rid-of-theano-gof-compilelock and (3) https://groups.google.com/forum/#!topic/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073:318,configurat,configuration,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073,1,['configurat'],['configuration']
Deployability,"> One final thing: i'm happy to try to debug this, and was going to write a test case based on the existing GenomicsDB integration tests. However, when I try to run any integration test involving genomicsdb, I get an exception like the following. I am on windows, so perhaps this is the issue?; > ; > 09:03:37.460 FATAL GenomicsDBLibLoader -; > java.io.FileNotFoundException: File /tiledbgenomicsdb.dll was not found inside JAR.; > at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:118) ~[genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:55) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtilsJni.(GenomicsDBUtilsJni.java:30) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:46) [genomicsdb-1.3.2.jar:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:1005) [classes/:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:661) [classes/:?]; > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056) [classes/:?]. Yes, Windows is not supported by GenomicsDB. This is mentioned obliquely in the requirements for gatk too -; ```; Operating system. The GATK runs natively on most if not all flavors of UNIX, which includes MacOSX, Linux and BSD. It is possible to get it ; running on some recent versions of Windows, but we don't provide any support nor instructions for that. If you need to run on; a Windows machine, consider using Docker.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359,2,['integrat'],['integration']
Deployability,"> Running with default arguments locally the runtime (for a WGS full chr15) drops from ~8.9 minutes to ~4.7 minutes after this patch. If I had to peg something else to optimize it would be replacing CSVWriter which seems to be somewhat slow but I can be contented that this tool is reasonably fast when nothing pathological is being triggered. Hello, you mentioned that running DepthOfCoverage for a WGS full chr15 only takes ~4.7 minutes. Would you mind letting me know what is the coverage for the BAM you use? It took days for me to run DepthOfCoverage on a 80X WGS. And, will there be a Spark implementation for DepthOfCoverage in the near future? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6740#issuecomment-723391687:127,patch,patch,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6740#issuecomment-723391687,1,['patch'],['patch']
Deployability,"> Thanks Kevin! I've built the updated GATK Docker so I would change line 76 of `GvsUtils.wdl` to say; > ; > ```; > String gatk_docker = ""us.gcr.io/broad-dsde-methods/broad-gatk-snapshots:varstore_2024_03_19_dfd45f6""; > ```. Okay awesome, I just pushed that change. Am I clear to merge, or is there anything else that needs doing before that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2007913072:31,update,updated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2007913072,2,['update'],['updated']
Deployability,> Thats a good idea. I don't know what our release plan is. I think we might do one more minor release on java 8 for someone internal and then give a bit of time before a java 17 release to let things shake out a bit. . @lbergelson: were you able to kick off a build? thanks in advance.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1458500126:43,release,release,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1458500126,3,['release'],['release']
Deployability,"> The new changes to the base image Dockerfile look good to me, @kevinpalis ! Can you tell us how many layers we have total after these changes? Is there any value in pursuing a full squash, or do you think that with this patch most users' issues will be resolved?. @droazen , the total layers is now down to **16** (from 44). I honestly don't see the value of doing a full squash, mainly because if we are hosting this in a premium ACR, the limit is 10,000 readOps per minute. So with 16 layers, you get around 625 pulls per minute. Also, this will be able to still take advantage of parallel pulls (default is 3, but at most 16 threads in this case, I believe) as opposed to one big layer which will not download in parallel. There's the potential of that being a lot slower and subsequent jobs falling into the same ""minute"" because others are not done, making it easier to hit that 10k readOps limit. Lastly, people using GATK outside data pipelines will not be able to take advantage of layer caching too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281:222,patch,patch,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281,2,"['patch', 'pipeline']","['patch', 'pipelines']"
Deployability,"> The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator?. @jonn-smith Is Funcotator ready to go in the wdl? Should it even *replace* Oncotator? Does it need its own docker or does one just invoke it like the rest of the GTK tools? Do we need to do anything special to toggle between references?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358987029:335,toggle,toggle,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358987029,1,['toggle'],['toggle']
Deployability,"> This Python scripts could use some docs (and perhaps tests?); it's not clear to me when / how one would use them. yes, that's fair. I modified the doc I created (CREATING_WEIGHTED_BED_FILES_ORIGINAL.md). In truth, ""original"" may be a misnomer. It's the information in the github issue ALONG WITH updated instructions for when to use the new python files. Given the feedback, I further updated the document with a comment at the top saying when they should be run (TL;DR, on a new genome or a new reference... so basically extremely rarely). Given this, I don't think unit test or extensive documentation are needed for them. The files are small, the inputs are few, and the code is commented. We are likely to not need to run them for again for years, so I don't consider extra documentation or testing to be worth the effort at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1717680203:298,update,updated,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1717680203,4,['update'],['updated']
Deployability,"> This is almost certainly a duplicate of the issue recently patched in #3122 -- @davidbenjamin do you concur?. @droazen Yes, this looks like the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310876878:61,patch,patched,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310876878,1,['patch'],['patched']
Deployability,"> We don't expect AD or PL to contain '.''s in practice, and GATK can't handle this. For AD, 0 should be used instead. `0` seems to be a valid value for both `AD` and `PL` attributes, whereas `.` is a missing value. How will that be distinguished by the Codecs in htsjdk?. > Where are the '.''s in the AD attribute actually coming from in the user's pipeline (Mutect2 -> GenomicsDB -> CreateSomaticPanelOfNormals)? Are they being added internally in GenomicsDB due to its reliance on htslib?. They are from the GenomicsDB query stream to CreateSomaticPanelOfNormals. FWIW : both `BCF2Codec`(drops all elements after encountering a missing value) and `VCF2Codec`(drops the entire format field when it encounters any missing value) are problematic in different ways.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-675760592:350,pipeline,pipeline,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-675760592,1,['pipeline'],['pipeline']
Deployability,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1181,integrat,integration,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906,1,['integrat'],['integration']
Deployability,"> actually it looks like there are legit failing tests. Yup, it looks like a hunk of the integration tests are operating in TSV mode (which we don't officially support any longer... but I suppose they can stay). So in order to make those pass, I had to put some things behind an explicit check for BQ being set as the output type",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879,1,['integrat'],['integration']
Deployability,"> do you have a run of the integration test for this branch?. Yup, [this run](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/ff9d7466-79f1-4c96-a7b9-dd2354dc1c76) utilized this `vs_464_update_quickstart_integration` branch to test the `vs_415_default_extract_scatter_width` changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388,1,['integrat'],['integration']
Deployability,> doesn't need to be this PR but I believe we also need to update [this](https://github.com/broadinstitute/gatk/blob/8813ed0fca9f98af8991db27ee3e8f95c5aeeec7/scripts/variantstore/wdl/GvsJointVariantCalling.wdl#L42) (and maybe somewhere similar for Quickstart?). I thought I did? (maybe I'm confused).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621848962:59,update,update,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621848962,1,['update'],['update']
Deployability,"> ls -l genome.*; -rw-rw---- 1 kh3 kh3 784809415 Sep 16 10:16 genome.2bit; -rw-rw---- 1 kh3 kh3 3168829906 Feb 4 2014 genome.fa; -rw-r----- 1 kh3 kh3 106669 Sep 16 11:32 genome.fa.amb; -rw-r----- 1 kh3 kh3 3276 Sep 16 11:32 genome.fa.ann; -rw-r----- 1 kh3 kh3 3137454592 Sep 16 11:31 genome.fa.bwt; -rw-rw---- 1 kh3 kh3 2984 Feb 4 2014 genome.fa.fai; -rw-rw---- 1 kh3 kh3 2984 Sep 16 13:18 genome.fai; -rw-r----- 1 kh3 kh3 784363628 Sep 16 11:32 genome.fa.pac; -rw-r----- 1 kh3 kh3 1568727304 Sep 16 11:44 genome.fa.sa. Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaAndMarkDuplicatesPipelineSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/ge; nome.2bit --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 15:47:28.760 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 15:47:28.809 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 3:47:28 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark --threads 16 --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark; .aligned.bam --reference /home/kh3/Resources/genome_b37/genome.2bit --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSiz; e 100000 --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedO; utput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [September 16, 2016 3:47:28 PM EDT] Executing ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171:1224,install,install,1224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171,1,['install'],['install']
Deployability,"> openjdk-8 can still be found on many major distributions albeit it is not the default one to be installed. Just check the package manager for openjdk-8 tags.; > If not check adoptopenjdk repos to install one from there. Or use the docker image. That's true now, but it is matter of months not being.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-876435445:98,install,installed,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-876435445,2,['install'],"['install', 'installed']"
Deployability,"> user chooses a set of defaults but then overrides some of them, we should; > make it so they don't have to go digging through the logs to see what; > parameters are actually used in the end. Nor should they have to go back; > and check what the defaults were for whatever version of the jar they were; > using at the time. Option 2 might also make it easier to inadvertently; > override parameters, etc. via command-line typos or copy-and-paste; > errors---it's much more straightforward to require and check that every; > parameter is specified once and fallback to a default if not, as we do now.; > Not to say that we couldn't get around any of these issues in Barclay, but; > I think it'll require some thought and careful design. Would be interested; > to hear Engine team's opinions.; >; > Finally, one point that I think will become more relevant as our tools and; > pipeline become more flexible and parameterized: I think we should start; > thinking of ""Best Practices Recommendations"" less as ""here is the best set; > of parameters to use with your data"" and more as ""here is *how to find*; > the best set of parameters to use with your data (for a given truth set,; > sensitivity requirement, etc.)"". After all, if we are putting together; > pipelines to do hyperparameter optimization, there is no reason not to; > share them with the community.; >; > This would also relax the requirement that the defaults in the WDL (which; > have to be kept in sync with those in the GATK jar) represent some sort of; > Best Practices Recommendation, which is awkward in exactly scenarios like; > the one you highlight.; >; > @vdauwera <https://github.com/vdauwera> @LeeTL1220; > <https://github.com/LeeTL1220> @sooheelee <https://github.com/sooheelee>; > might have some thoughts.; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289>,; > or mute the thread; > ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379:1949,pipeline,pipeline,1949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379,1,['pipeline'],['pipeline']
Deployability,">--af_of_alleles_not_in_resource: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations. This is the population AF assigned to a variant not found in the germline resource and is inversely proportional to the number of samples used to create that resource. For example, gnomAD contains about 16,000 wgs samples, or 32,000 homologs per locus. Thus the AF of an allele not found in gnomAD is probably 1/32,000 or less. This is useful because it lets us use absence from the germline resource as evidence that an allele is *not* a germline variant. >I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. Since allele depths (ADs) are subject to statistical error -- i.e. the exact number of reads for an allele is a random variable -- alleles' allele fractions are not known. Previously, M2 estimated allele fractions ffrom the ADs and proceeded with the likelihoods calculation. Now M2 uses nifty math to account for the uncertainty in the allele fraction when calculating likelihoods. In statistical language (which *will* be familiar to a decent-sized minority of users) we marginalize over allele fractions instead of using a maximum likelihood estimate. >The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?. `CalculateContamination` is invoked inside the `Filter` task in mutect2.wdl. We want users to use the new tool. You might mention that in the interest of speed you can pass it `-L 1` to use only variants on chromosome 1, which gives a very good estimate in a couple of minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618:795,integrat,integration,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618,1,['integrat'],['integration']
Deployability,">> interval_list. > this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run GvsJointVariantCalling.wdl on exomes. Genomes too, the integration test specifies a 20/X/Y interval list. >> filter_set_name; >> extract_table_prefix. > these two can just default to the call_set_identifier with weird characters parsed out. Yeah I think that would work for the integration test(s), each variation goes into a different BQ dataset anyway. @RoriCremer can correct me if I'm wrong, but I thought the raison d'√™tre of the beta WDL was specifically to hardcode away as many parameters as possible (even optional ones with defaults) to present a simplified interface for non-expert users. I agree we'll probably have to allow some additional parameters for testability (`gatk_override` at a minimum), but do we really want to add all of these?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008:115,integrat,integration,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008,6,['integrat'],['integration']
Deployability,">Integration test plz. Hmm, the existing integration test does not exercise `process_vcf_headers` so it wouldn't test these changes. However, in the spirit of ""the VDS integration tests should exercise what we intend to use for AoU"", perhaps at least the VDS integration tests should be modified to exercise this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880:1,Integrat,Integration,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880,4,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,">Not to mention, in theory one could have some job trying to read the original workspace, which might get hosed if some other job is trying to edit that workspace in place. This is not possible as new GenomicsDB workspace fragments are created for the incremental updates. During the actual finalization of the fragments, the array(if on a Posix filesystem) in the workspace is locked using Posix file locks for consistency at the level of the array in the workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617379827:264,update,updates,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617379827,1,['update'],['updates']
Deployability,?src=pr&el=desc) will **increase** coverage by `0.287%`.; > The diff coverage is `87.097%`. ```diff; @@ Coverage Diff @@; ## master #4545 +/- ##; ===============================================; + Coverage 80.355% 80.642% +0.287% ; - Complexity 17714 18478 +764 ; ===============================================; Files 1088 1089 +1 ; Lines 63975 66116 +2141 ; Branches 10313 10913 +600 ; ===============================================; + Hits 51407 53317 +1910 ; - Misses 8555 8661 +106 ; - Partials 4013 4138 +125; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4545?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <√∏> (√∏)` | `33 <0> (√∏)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (+29.412%)` | `6 <3> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.541% <40%> (-0.432%)` | `39 <1> (+2)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.208% <87.5%> (+0.663%)` | `31 <0> (√∏)` | :arrow_down: |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747:1275,pipeline,pipelines,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747,1,['pipeline'],['pipelines']
Deployability,?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `82.609% <√∏> (+5.942%)` | `4 <0> (-1)` | :arrow_down: |; | [...lbender/tools/spark/bwa/BwaArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <100%> (√∏)` | `1 <1> (?)` | |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `85.437% <100%> (+0.437%)` | `57 <2> (+2)` | :arrow_up: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <83.333%> (+2.477%)` | `4 <1> (√∏)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.362% <86.957%> (-2.067%)` | `12 <0> (+2)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3666/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `75% <87.5%> (+5.769%)` | `5 <2> (√∏)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-334530619:1827,pipeline,pipelines,1827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-334530619,1,['pipeline'],['pipelines']
Deployability,"@@ Coverage Diff @@; ## master #5628 +/- ##; ============================================; - Coverage 87.03% 87.03% -0.01% ; Complexity 31726 31726 ; ============================================; Files 1943 1943 ; Lines 146193 146193 ; Branches 16141 16141 ; ============================================; - Hits 127242 127239 -3 ; - Misses 13065 13067 +2 ; - Partials 5886 5887 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=tree) | Coverage Œî | Complexity Œî | |; |---|---|---|---|; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.24% <√∏> (√∏)` | `42 <0> (√∏)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (√∏)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.29% <0%> (-0.48%)` | `33% <0%> (√∏)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Œî = absolute <relative> (impact)`, `√∏ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=footer). Last update [78df6b2...8c3a18d](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796:2405,update,update,2405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796,2,['update'],['update']
Deployability,"@AishaShah No, this fix will be part of the next GATK release, which we expect to go out shortly (within the next several weeks).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1634541591:54,release,release,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1634541591,1,['release'],['release']
Deployability,"@Arhodes-Broad The fix for this issue has been merged into github, but GATK has not been released since that fix went in. So the bug exists in the currently released version `4.1.2.0`. In one of the forum threads, someone suggested they would try a recent nightly build:. > Will try the gatk-nightly build. (tag 2019-05-15-4.1.2.0-7-ga229b5646-NIGHTLY-SNAPSHOT). These can be gotten from https://hub.docker.com/r/broadinstitute/gatk-nightly/tags. I would expect the bug to be fixed in that build. If someone reproduces the bug with that build or any recent nightly build (one that contains https://github.com/broadinstitute/gatk/pull/5894, which was the fix), we can look into it again, but otherwise I think this will be resolved or users in the next release. Hope that helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493114962:89,release,released,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493114962,3,['release'],"['release', 'released']"
Deployability,"@Atahualkpa Could you try this again on V4.0.5.0? We have resolved a number of issues leading up to the release that might solve your problem. Next, How is the input file sorted? And how is that recorded in your bam header? Also, are you sure that file is indeed sorted correctly? You could try resorting to queryname order if its not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820#issuecomment-396331882:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820#issuecomment-396331882,1,['release'],['release']
Deployability,"@AthenACHY It looks like (in all of these cases) you're trying to use `Java 1.7`, but GATK requires `Java 17`. Installing `Java 17` should solve the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432#issuecomment-1647824603:111,Install,Installing,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432#issuecomment-1647824603,1,['Install'],['Installing']
Deployability,"@AxVE Have you tried using `--deploy-mode cluster`? That's the standard spark-submit option to set deploy-mode, we should passing any unknown spark options directly on to spark submit when using `--sparkRunner SPARK`. . It looks like it won't work when using `--sparkRunner GCS` because it's not in our table of things we translate for GCS, so we should that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350018396:30,deploy,deploy-mode,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350018396,2,['deploy'],['deploy-mode']
Deployability,"@AxVE Sorry, I totally missed this ticket. BWA-Spark requires a paired-ended file to be queryname sorted or grouped. It sounds like it's missing that check upfront. . We've improved SortReadFileSpark now. It's now called SortSamSpark and can sort into query-name order. . Doing the fastq -> sam as part of the spark pipeline would be a great addition, but we currently don't have a great way to read fastq files into spark so it's not a trivial addition.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-404327557:316,pipeline,pipeline,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-404327557,1,['pipeline'],['pipeline']
Deployability,"@AxVE Thanks for this PR. We really appreciate your interest and work on resolving this issue! It might take a little bit for me to get to reviewing it properly, we're currently preparing for our release and we're a bit swamped with various issues. I'm worried about changing the `userClassPathFirst` property. We added that a long time ago because it fixed some issues we were running into at the time. It's completely possible that we no longer have the same issue and it's a harmful remnant from a previous time, but I'm afraid that changing it might have unanticipated consequences in our own spark environment. Unfortunately we don't have good automated tests that would necessarily identify any issue. @cwhelan Would you be able to test your pipeline with - ""spark.driver.userClassPathFirst"" : ""false"" and see if you run into any issues? . I'm also a bit confused about why the change to the arguments is necessary. Clearly in your environment it is, but it goes against my understanding of how we set the arguments to spark submit, so I want to properly understand why the existing --deploy-mode arguments aren't working for you before adding an additional hardcoded argument to the launch script. (As I'm sure you've seen, the launch script is a pretty crufty and brittle piece of code that was really meant to be replaced with a more robust solution by now, so any additional complexity in would be great to avoid...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351430567:196,release,release,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351430567,3,"['deploy', 'pipeline', 'release']","['deploy-mode', 'pipeline', 'release']"
Deployability,@Bowen1992 Could you please try running with the latest GATK release (`4.2.6.1`) and reporting whether the issue persists?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135056151:61,release,release,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135056151,1,['release'],['release']
Deployability,@ConorMesser This was added in GATK 4.6 (https://github.com/broadinstitute/gatk/releases/tag/4.6.0.0):. * Added an --inverted-read-filter argument to allow for selecting reads that fail read filters from the command line easily (https://github.com/broadinstitute/gatk/pull/8724),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-2246107884:80,release,releases,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-2246107884,1,['release'],['releases']
Deployability,"@DanielAmsel @fpbarthel ; An update on this - for some test data Daniel sent me, Funcotator is choosing transcript `ENST00000559482.1`. For this transcript there are several exons that are not expressed, leading to `intron` annotations. This is in `CANONICAL` transcript selection mode (which is the default). For example, the locus `chr15:90631830` is intronic in that transcript:. ![image](https://user-images.githubusercontent.com/11667487/101508612-e4dac000-3945-11eb-8902-27dc889c3808.png). The details on how Funcotator chooses transcripts can be found here:; https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#2.2.2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094:29,update,update,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094,1,['update'],['update']
Deployability,"@DanielAmsel The genomic regions Funcotator uses are based on the [Genocde](https://www.gencodegenes.org/) GTF files. Sometime before Gencode v34 (the version used in the Funcotator v1.7 pre-bundled datasources) Gencode stopped natively creating gene annotations for HG19. The solution for them was to liftover their annotations from HG38. When the version 1.7 datasources release was created, we updated the Gencode datasources to use the latest and greatest at the time, and the only resource available was the lifted over files (full gencode releases live [here](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/)). I believe what you're seeing is a result of this liftover.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8403#issuecomment-1650020964:373,release,release,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8403#issuecomment-1650020964,3,"['release', 'update']","['release', 'releases', 'updated']"
Deployability,@DarioS There were a couple of known issues with `GenotypeGVCFs` in 4.2.5 -- could you try running with the latest release (4.2.6.1) and see if you get the same result?. @ldgauthier Any further insight into this one?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7847#issuecomment-1135068570:115,release,release,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7847#issuecomment-1135068570,1,['release'],['release']
Deployability,@DarioS Why don't you share your entire Mutect2 pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656491603:48,pipeline,pipeline,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656491603,1,['pipeline'],['pipeline']
Deployability,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155,1,['integrat'],['integration']
Deployability,"@DonFreed Thanks for the fix, though unfortunately as @droazen says the branch is going to have to be on hold for a little while until the Haplotype Caller has been updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324446155:165,update,updated,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324446155,1,['update'],['updated']
Deployability,"@Dream-sugar That approach should work, yes -- you should post this on our user forum (https://gatk.broadinstitute.org/hc/en-us/community/topics) for further assistance in setting up such a pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7482#issuecomment-928167086:190,pipeline,pipeline,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7482#issuecomment-928167086,1,['pipeline'],['pipeline']
Deployability,"@EEPuckett You are running a release that's several years old -- could you try with the latest GATK release and see if you encounter the same problem? Another thing you could try is running `GenomicsDBImport` instead of `CombineGVCFs`, since `GenomicsDBImport` does the same thing just more efficiently. Are you running any other tools in your pipeline besides `HaplotypeCaller`, `CombineGVCFs`, and `GenotypeGVCFs`?. @ldgauthier Have you ever encountered an issue like this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1081007082:29,release,release,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1081007082,3,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"@EdwardDixon I did not know that! In that case master does already require AVX. If it only impacts this tool and we provide sufficient warning and instructions, I think the single intel-optimized conda environment will be so much easier to test and maintain. Users who don't have AVX can simply install an older tensorflow in their environment, but GATK doesn't need to worry about it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429142837:295,install,install,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429142837,2,['install'],['install']
Deployability,"@EdwardDixon Isn't this a dupe of https://github.com/broadinstitute/gatk/pull/5142? Have you addressed our original concerns from that PR's discussion thread, some of which I've reproduced below?. ```; droazen commented on Aug 30; @EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including; university clusters that they have no power to upgrade), and we can't just cut these users off by ; imposing such a minimum hardware requirement. The best we can do is to use AVX when it's ; available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they; are often hard to diagnose and deal with. Things like SIGSEGV or SIGILL are a nightmare for our ; support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message; when AVX is not present rather than a crash, before we could make this the default in GATK. ldgauthier commented on Aug 30; Aside from the users with old hardware, very few of the GCS zones guarantee processors that ; support AVX, which would lead to sporadic failures except in central-1f, for example.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950:373,upgrade,upgrade,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950,1,['upgrade'],['upgrade']
Deployability,"@EdwardDixon Sure, here's my suggested repair process:. 1. If you haven't already, add an ""upstream"" remote to your git clone via `git remote add upstream git@github.com:broadinstitute/gatk.git` (or `https://github.com/broadinstitute/gatk.git` if you don't have ssh authentication set up with github). 2. `git fetch upstream`. 3. Copy the files you actually intended to change in this PR into a temp directory somewhere. 4. Create a new temporary branch off of `upstream/master`: `git checkout -b avxcheck_repaired upstream/master`. 5. Copy the files you saved in step 3 back into their original locations in the working tree. 6. `git commit -a`. 7. Examine the diff against upstream/master via `git diff upstream/master HEAD`. Verify that the diff is what you expect. 8. Run `git rev-parse HEAD` and save the commit ID it outputs. 9. Switch back to the broken version of the branch: `git checkout avxcheck`. 10. Run `git reset --hard commit_id_from_step_8`. This will force the branch to point to the repaired commit we created in step 6. 11. Run `git push -f origin avxcheck:avxcheck` to force-push the repaired version of the branch into your fork. Then check that it looks ok on github. For avoiding this sort of thing in the future, here's a few tips:. * Never run `git merge` or `git pull`. Always update your branch with changes from the latest gatk master branch via the command: `git fetch upstream && git rebase -i upstream/master`, followed by `git push -f` to push the rebased branch into your fork. * If you've never run `git rebase` before, read a tutorial on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495:1304,update,update,1304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495,1,['update'],['update']
Deployability,"@EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including university clusters that they have no power to upgrade), and we can't just cut these users off by imposing such a minimum hardware requirement. The best we can do is to use AVX when it's available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they are often hard to diagnose and deal with. Things like `SIGSEGV` or `SIGILL` are a nightmare for our support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message when AVX is not present rather than a crash, before we could make this the default in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038:141,upgrade,upgrade,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038,1,['upgrade'],['upgrade']
Deployability,"@EdwardDixon Well, you'd be surprised at some of the hardware we have to deal with. Even some machines here at the Broad don't have AVX. In general, our policy with hardware-dependent optimizations in GATK has been to insist on having a transparent fallback mechanism when the required hardware isn't present -- I'd really prefer not to start making exceptions to that rule. Could the Intel-optimized Tensorflow be patched to fall back to vanilla tensorflow when AVX is not present? Is that an option? Or could it at least be patched to not actually crash in that case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151:415,patch,patched,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151,2,['patch'],['patched']
Deployability,"@Fazulur I've managed to reproduce this issue. It's a bug in Disq which will require a Disq release and a GATK release before it's available. In the meantime, you can work around the problem by adding; `--create-output-bam-index false` to the command line, then creating the .bai file manually (e.g. with samtools). Hope that helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919#issuecomment-492282468:92,release,release,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919#issuecomment-492282468,2,['release'],['release']
Deployability,"@Firedrops It looks like you don't have `git-lfs` installed. See https://github.com/broadinstitute/gatk#requirements (look for ""To build GATK"") for more details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6019#issuecomment-506301075:50,install,installed,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6019#issuecomment-506301075,1,['install'],['installed']
Deployability,"@GATKSupportTeam @gbrandt6 We think that this might have been fixed by @ldgauthier 's just-merged PR https://github.com/broadinstitute/gatk/pull/7186. Can you ask the user to re-test with that patch? If the user is not comfortable building GATK from source, it will be included in an official release on 11/2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465#issuecomment-954938155:193,patch,patch,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465#issuecomment-954938155,2,"['patch', 'release']","['patch', 'release']"
Deployability,"@GATKSupportTeam Has the user tried running GATK 4.2+ in every step of their pipeline, instead of just swapping out the `GenotypeGVCFs` version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442#issuecomment-908569973:77,pipeline,pipeline,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442#issuecomment-908569973,1,['pipeline'],['pipeline']
Deployability,"@GuoYu-Peng I am able to extract the `.tar.gz` (https://github.com/broadinstitute/gatk/archive/4.1.8.1.tar.gz) fine on my end. Make sure you got a complete download -- the file size should be 69,129,515 bytes. Please note that the `.tar.gz` contains only the GATK source code. For a runnable GATK installation you should download the zip file instead (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6719#issuecomment-662529283:297,install,installation,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719#issuecomment-662529283,2,"['install', 'release']","['installation', 'releases']"
Deployability,"@Horneth I put together a new version for you to try, but it requires upgrading gcloud. Here's how to do it:. * clone the gcloud repo, switch to the [jp_aggressive_reopen](https://github.com/jean-philippe-martin/gcloud-java/tree/jp_aggressive_reopen) branch; ```; git clone https://github.com/jean-philippe-martin/gcloud-java; cd gcloud-java; git checkout jp_aggressive_reopen; ```. * install the modified version locally; (should report having installed version google-cloud-nio-0.17.3-alpha-SNAPSHOT-shaded.jar); ```; $ mvn install -DskipTests | tee log.txt; $ grep nio/ log.txt | grep -i installing | grep shaded; ```. * return to the gatk folder. ```; cd ../gatk; ```. * switch to the [jp_gcloud_17_snapshot](https://github.com/broadinstitute/gatk/tree/jp_gcloud_17_snapshot) branch; (this version uses google-cloud-nio-0.17.3-alpha-SNAPSHOT-shaded.jar). ```; $ git fetch --all; $ git checkout jp_gcloud_17_snapshot; ```. * compile gatk and try it out. ```; $ ./gradlew installAll; $ ./gatk-launch ...; ```. I'd like to test it myself but haven't yet been able to reproduce the bug on my end. Please let me know how this variant works for you! If this solves the problem then we'll go through the steps to push this into the main version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-302798685:385,install,install,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-302798685,5,['install'],"['install', 'installAll', 'installed', 'installing']"
Deployability,"@Horneth Ideally we'd just check up-front whether the bucket has requester pays enabled, and specify the user's default project as the billing project if it is. . It would also be good, I think, if we included a toggle that allows the client to tell the library to throw and refuse to proceed if an attempt is made to access requester-pays data, so that users who don't want to incur GCS access charges can get a hard guarantee that they won't.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394839598:212,toggle,toggle,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394839598,1,['toggle'],['toggle']
Deployability,@Ithinky `gatkcondaenv.yml` is included in the zip file for each official release (https://github.com/broadinstitute/gatk/releases). It's also checked into the repository at: https://github.com/broadinstitute/gatk/blob/master/scripts/gatkcondaenv.yml.template. Please let us know if the issue persists when running within the standard Python environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8827#issuecomment-2110627626:74,release,release,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8827#issuecomment-2110627626,2,['release'],"['release', 'releases']"
Deployability,@JJBio Unfortunately GATK 3 is end-of-life and will not have any more releases/bug-fixes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466489687:70,release,releases,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466489687,1,['release'],['releases']
Deployability,@K-zhangfengwei It looks like you're running GATK 3.x. This repository is for GATK 4.x and above -- can you try re-running with the latest release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7042#issuecomment-775388508:139,release,release,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042#issuecomment-775388508,1,['release'],['release']
Deployability,"@KPS-Malpe To start it would be useful to know what commandline you used, what version of GATK you're using, basic configuration info like that. If you could include the output of the commands you ran that could also be pertinent. It is interesting that not all the intervals you specified in your bed file show up in the Genomicsdb workspace. Along the lines of the question asked by @droazen, I presume you checked that the missing intervals do actually have data in the gvcfs?. Lastly, you could try running SelectVariants on the Genomicsdb workspace -- that should return the data that was ingested into the genomicsdb, i.e., matching the input gvcfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196207156:115,configurat,configuration,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196207156,1,['configurat'],['configuration']
Deployability,"@KevinCLydon @jamesemery That's probably because you need to activate the ubuntu ""universe"" repository in order to install the package. This can be done via the command `add-apt-repository universe && apt update`, I believe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696919018:115,install,install,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696919018,2,"['install', 'update']","['install', 'update']"
Deployability,@LeeTL1220 . * Updates command line arguments to conform to new GATK standard.; * Removes M2 wdl hacks no longer needed as of Cromwell 27,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3584:15,Update,Updates,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3584,1,['Update'],['Updates']
Deployability,"@LeeTL1220 @katevoss @ruchim I started exposing all optional task-level parameters in the somatic workflows so that they could be specified via json when the workflows are used as subworkflows. E.g., `CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` is an optional task-level parameter that can be specified properly via json when `CNVSomaticPanelWorkflow` is the top-level workflow, but not when `CNVSomaticPanelWorkflow` is used as a subworkflow. This is because `MetaWorkflow.CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` cannot be set, correct?. However, things quickly became very messy. For example, alongside parameters like `bin_length` which are unique to the PreprocessIntervals task, we also have a lot of optional runtime parameters that are named generic things like `mem` which are not. So to expose these, we'd have to have workflow-level parameters with names like `preprocess_intervals_mem`, etc. It seems like this is exactly the problem the expected functionality would solve, if only it worked past the subworkflow level and the namespace is propagated as one would expect. Requiring that these be exposed also partially obviates the reason for having optional task-level arguments in the first place---what's the point of having them be optional if I have to add lines of code to expose all of them at the workflow level?. So again, I'm strongly against exposing all inputs for a particular workflow on the off-chance that that workflow might be used as a subworkflow. This adds a lot of unnecessary boilerplate that quickly gets very messy. I think that this problem should instead be solved by dynamically bubbling up all inputs, optional or required, at all levels. Anyway, I'm not going to try to tackle this before release, which I think was OK with @LeeTL1220. However, after release, I'd be happy to sit down and discuss how we want to do this sort of thing going forward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670:1758,release,release,1758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670,2,['release'],['release']
Deployability,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341,1,['integrat'],['integration']
Deployability,"@LeeTL1220 Can you review, or appoint someone to review, the Mutect2 WDL and the tools/exome and tools/picard/analysis/artifacts packages part of this. Basically, I replaced most of the classes in the artifacts package with their Picard analogs, which also affected some embedded class names in metrics files (SequencingArtifactMetrics IIRC). The are multiple commits in here that delete various things, but the substantive changes are the last commit (""Integrate actual Picard tools via Picard""). Also, once this is in, we'll probably want to do [this](https://github.com/broadinstitute/gatk/issues/3625) separately as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122:454,Integrat,Integrate,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122,1,['Integrat'],['Integrate']
Deployability,@LeeTL1220 Currently there is no extra documentation going over the NIO functionality. This will be documented as part of the yet-to-be documentation updates that I am writing for the release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-440011054:150,update,updates,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-440011054,2,"['release', 'update']","['release', 'updates']"
Deployability,@LeeTL1220 I put in a test that fails without the patch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5121#issuecomment-413603322:50,patch,patch,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5121#issuecomment-413603322,1,['patch'],['patch']
Deployability,@LeeTL1220 I will merge now and open a separate ticket to update the multi sample wdl and all wdls that depend on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608:58,update,update,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608,1,['update'],['update']
Deployability,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126,1,['integrat'],['integration']
Deployability,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:38,rollback,rollback,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989,3,"['release', 'rollback', 'rolling']","['release', 'rollback', 'rolling']"
Deployability,"@LeeTL1220 OK by me, but please update the example command line in the javadoc (change the siteIntervals argument).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314458485:32,update,update,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314458485,1,['update'],['update']
Deployability,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:95,release,release,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979,1,['release'],['release']
Deployability,"@LeeTL1220 Should the default funcotation here be an empty string, or ""0""? Currently it's the latter, but with this update it seems that with this change we should switch to empty string.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420741241:116,update,update,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420741241,1,['update'],['update']
Deployability,@LeeTL1220 This fixes the bug preventing Beri from updating to 4.0.8.0. I will put in an integration test but could you start looking at it now?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5121:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5121,1,['integrat'],['integration']
Deployability,"@LeeTL1220 This fixes the issue. I tested it on SGE and the M2 integration tests now have a DREAM bam where I switched the sample to ""tumor sample"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4360:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360,1,['integrat'],['integration']
Deployability,@LeeTL1220 This is worth getting in before the release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4848:47,release,release,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4848,1,['release'],['release']
Deployability,"@LeeTL1220 This should fail earlier in situations like the one you ran into with the low coverage test data. I don't *think* there should be any unintended side effects. I'm fine if this doesn't make it in before the point release if you want to run some sanity checks on real data with it (since users should be able to figure out what is going on relatively quickly if they run into the issue), but I'll leave it up to you.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292:223,release,release,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292,1,['release'],['release']
Deployability,@LeeTL1220 This should go in before in the point release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360810738:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360810738,1,['release'],['release']
Deployability,"@LeeTL1220 We'll keep you updated here. Should be quick, but I want @asmirnov239 to finish up #4113 first. I think if we can point @asmirnov239 to a few public germline BAMs to use for building both gCNV and ModelSegments PoNs, and we can continue using HCC1143 for the tumor.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4007#issuecomment-356710582:26,update,updated,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4007#issuecomment-356710582,1,['update'],['updated']
Deployability,@LeeTL1220 When will Firecloud support Cromwell v33? We can't release an unforked M2 WDL until then.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4948#issuecomment-400417990:62,release,release,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4948#issuecomment-400417990,1,['release'],['release']
Deployability,@LeeTL1220 Your call if this is worth merging pre-release. @sooheelee @chandrans In case some users want to know how to generate the M2 resources for themselves.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4069:50,release,release,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4069,1,['release'],['release']
Deployability,"@LeeTL1220 commented on [Fri Jan 15 2016](https://github.com/broadinstitute/gatk-protected/issues/308). This may be as simple as adding a `ctx.close()` statement after the spark calculations are complete.; - [ ] Confirmed on our spark cluster that this is fixed... ---. @LeeTL1220 commented on [Tue Jan 26 2016](https://github.com/broadinstitute/gatk-protected/issues/308#issuecomment-175139853). Cannot close without the unit tests falling over. Putting this off for a later release. ---. @lbergelson commented on [Tue Jan 26 2016](https://github.com/broadinstitute/gatk-protected/issues/308#issuecomment-175154352). Possible solutions involve running `SparkContext.KillExecutors()` but I haven't looked into how it works exactly... ---. @samuelklee commented on [Thu May 11 2017](https://github.com/broadinstitute/gatk-protected/issues/308#issuecomment-300793994). @LeeTL1220 should I keep this open?. ---. @LeeTL1220 commented on [Thu May 11 2017](https://github.com/broadinstitute/gatk-protected/issues/308#issuecomment-300797579). I think this should be kept open, but low priority. On Thu, May 11, 2017 at 9:46 AM, samuelklee <notifications@github.com>; wrote:. > @LeeTL1220 <https://github.com/LeeTL1220> should I keep this open?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/308#issuecomment-300793994>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk06fX-Z26myWvz9Shn_c5e4I0xHqks5r4xEigaJpZM4HGA9T>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 7003EB; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2833:476,release,release,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2833,1,['release'],['release']
Deployability,@LeeTL1220 commented on [Tue Oct 18 2016](https://github.com/broadinstitute/gatk-protected/issues/742). Should now be `CallAllelicSplits`. Rename the task configuration as well.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2903:155,configurat,configuration,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2903,1,['configurat'],['configuration']
Deployability,@LeeTL1220 commented on [Tue Oct 18 2016](https://github.com/broadinstitute/gatk-protected/issues/743). Now called `CallAllelicSplits` . This should happen after (or right before) the next release.; - [ ] Update forum posts; - [ ] Add forum post explaining the output of the cnb_called files. See issue #585,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2904:189,release,release,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2904,2,"['Update', 'release']","['Update', 'release']"
Deployability,"@LeeTL1220 commented on [Wed May 17 2017](https://github.com/broadinstitute/gatk-protected/issues/1053). And upgrade ubuntu to 16.04. And leverage the ``broadinstitute/gatk:gatkbase-1.0`` image. Actually, this will handle the move to OpenJDK8 and ubuntu 16.04.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2990:109,upgrade,upgrade,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2990,1,['upgrade'],['upgrade']
Deployability,"@LeeTL1220 do you have any opinions on making the somatic CNV workflow scatter by contig? This could allow WGS to complete basically ~20x faster and could allow us to avoid issues such as #4734. A few issues:. 1) Do we want a single WDL that can optionally scatter, depending on WES vs. WGS? It would be nicer to have just one workflow, but I haven't thought about how an optional scatter might look in WDL. 2) For segmentation and modeling, scattering should have little impact on the final result (although there are a few global-level quantities in the models that would be reduced to contig-level quantities, which might slightly affect the quality of their inference). However, we'd want to concatenate all per-contig results for both plotting and segment calling. It'd be relatively easy to either have a separate tool to concatenate AbstractLocatableCollections (there is already a method to do this that is used for the gCNV pipeline), or to make the plotting and calling tools take in parallel inputs and combine them. I'd tend towards the former, just so we don't have to deliver per-contig files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150:933,pipeline,pipeline,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150,1,['pipeline'],['pipeline']
Deployability,"@LeeTL1220 done. I put it in the M2 integration test because it is part of a bigger potential issue, that of phantom alleles from the likelihoods that don't make it into the variant call. Back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263,1,['integrat'],['integration']
Deployability,"@LeeTL1220 that's totally fair. There are a few problems with putting in the tests, though. I don't know that I can publicly release the data that are being tested because of their provenance (pretty sure I can't). . The second reason is that the whole reference sequences are not checked into git lfs. Without it I can't annotate on a set of variants from around the whole genome, and the whole reference is pretty big. . The last thing I can think of is a data source problem - I don't have all the data sources checked into git lfs (for similar reasons, especially now with dbSNP in there). Also, these have already made their way into master. So if this is really a problem, we should get them out of there ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652:125,release,release,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652,1,['release'],['release']
Deployability,"@MartonKN I've labeled the update of the caller as a ""reach"", so I'm not expecting that it gets done before release. However, I expect that the tutorial data should be updated well before release. The tutorial data runs quickly (~1 hr for coverage collection, which is mostly limited by the slowest samples or cloud preemptions, and then ~minutes once collection has been call cached), so we should have plenty of time. Whether or not the actual tutorial itself will be ready depends on whether @sooheelee has available bandwidth and if it is a high priority for comms.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988:27,update,update,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988,4,"['release', 'update']","['release', 'update', 'updated']"
Deployability,"@MartonKN One more thing: the PR title is currently not very informative, so when you merge, be sure to write a descriptive commit message. These are very useful when we come out with release notes, among other things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052:184,release,release,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052,1,['release'],['release']
Deployability,"@Mentors4EDU This issue has been fixed for the next release, but see [this comment](https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330) for a short term fix. Feel free to reopen this ticket if you still have an issue or questions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467#issuecomment-590320315:52,release,release,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467#issuecomment-590320315,1,['release'],['release']
Deployability,"@MikeWLloyd Sorry you had to track that down. Although I sympathize, I doubt we would undertake to update the documentation for that, since its complicated to explain (there are other ramifications since many types of lines can be repaired), and I would guess that it affects about 50 GATK tools. We do have a plan and implementation for a better versioning strategy for VCFv4.3+.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861596930:99,update,update,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861596930,1,['update'],['update']
Deployability,"@NTNguyen13 Yes, I just merged the PR that fixes it - https://github.com/broadinstitute/gatk/pull/6613 so it will be available in the next release. Thank you again for bringing this up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573#issuecomment-634766708:139,release,release,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573#issuecomment-634766708,1,['release'],['release']
Deployability,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:344,release,releases,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274,1,['release'],['releases']
Deployability,@NeginValizadegan If you really mean picard 2.10.1 then you should definitely upgrade. That version is ancient. The current is [2.27.5](https://github.com/broadinstitute/picard/releases),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981:78,upgrade,upgrade,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"@Ning-310 Can you check your `Set12-3_L1_361361.sorted.marked.bam` and confirm that all reads are assigned to a read group? Also, can you try running with the latest GATK release (4.1.9.0), and see if the issue persists?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7031#issuecomment-758167756:171,release,release,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031#issuecomment-758167756,1,['release'],['release']
Deployability,"@Ning-310 I believe this was fixed in a later release. Can you please try running `Funcotator` with the latest GATK release (4.2.0.0), and see if the problem persists?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090#issuecomment-783465037:46,release,release,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090#issuecomment-783465037,2,['release'],['release']
Deployability,"@PamelaBretscher Our strong recommendation would be to upgrade the pipeline to a modern version of GATK, if at all possible. `4.0.3.0` is many years out of date at this point, and I'm not sure we'll be able to diagnose issues with the GenomicsDB version in use at that time. The user should also consider the many improvements and bug fixes to the HaplotypeCaller that have gone in since that version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442#issuecomment-908585066:55,upgrade,upgrade,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442#issuecomment-908585066,2,"['pipeline', 'upgrade']","['pipeline', 'upgrade']"
Deployability,@PlatonB Since this is a complex issue involving multiple non-gatk tools and a proprietary pipeline we can't really do much to debug it without a way to reproduce the problem. If you could provide (ideally minimal) inputs to reproduce the issue that would give us much more of a handle to look into it. Otherwise I don't think we can do much with the information you provided.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755582511:91,pipeline,pipeline,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755582511,1,['pipeline'],['pipeline']
Deployability,@RWilton Good catch! Thanks for reporting this -- we'll fix the broken read filter argument in the next GATK release,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7696#issuecomment-1054590018:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7696#issuecomment-1054590018,1,['release'],['release']
Deployability,"@RWilton There is a new version of the Intel GKL that we hope will resolve this issue -- we are in the process of moving GATK to it, and hope that it will be included in the next GATK release. @lbergelson and/or @Kmannth may have further details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187#issuecomment-816834848:184,release,release,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187#issuecomment-816834848,1,['release'],['release']
Deployability,"@Rohit-Satyam The bottom of your stack trace says you are running the 4.1.4.0 release, which came out before the fixes mentioned above. I expect the issue will be resolved if you run the most recent 4.1.5.0 release. Please let me know if if does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595817436:78,release,release,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595817436,2,['release'],['release']
Deployability,"@SHuang-Broad . I'm happy to update the documentation more and/or rename things to make them more clear, but I'm not sure what the best way to do it is. A couple of thoughts:. - Sorry about the erroneous mention of `BreakpointEvidence.getStrand` in the comment for `StrandedInterval`. This was renamed to `BreakpointEvidence.isEvidenceUpstreamOfBreakpoint` when the previous PR was being reviewed. I've updated the comment now. . - The comment for `BreakpointEvidence.getDistalTargets` currently reads:. ```; /**; * Returns the distal interval implicated as a candidate adjacency to the breakpoint by this piece of evidence.; * For example, in the case of a discordant read pair, this would be the region adjacent to the mate of the current; * read. Returns null if the evidence does not specify or support a possible targeted region (for example, the case; * of an read with an unmapped mate). Strands of the intervals indicate whether the distal target intervals are; * upstream or downstream of their proposed breakpoints: true indicates that the breakpoint is upstream of the interval; * start position; false indicates that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstrea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:29,update,update,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,4,['update'],"['update', 'updated']"
Deployability,"@SHuang-Broad . Nice hack using the cluster name. I don't see any other way to pass an arg to an initialization action. I have one suggestion to consider, but if you think it's too much work or not worth it feel free to skip: what if we separated out the reference bundle to copy from the data by specifying them both in the cluster name? That way we could, say, load either the hg19 or hg38 reference depending on the data we might be working with. So you could say ""cluster-hg38"" or ""cluster-hg19"" or ""cluster-hg19-na12878"". . Carrying it further, if we had a special convention for specifying data, like ""data-$SAMPLE"", we could just map $SAMPLE to a subdirectory on the bucket. That would provide a ton of flexibility. One minor note while you are messing with these scripts: the createCluster.sh script comment says ""This script deletes a Google Dataproc cluster used for running the GATK-SV pipeline."" Could you change to say it creates rather than deletes a cluster?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038:897,pipeline,pipeline,897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038,1,['pipeline'],['pipeline']
Deployability,"@SHuang-Broad @tedsharpe I think I've addressed all the comments. Does this look good now?. I just ran through the entire pipeline and it looks like our raw number of inversions called has dropped a bit relative to the experimental code I was running before, but I'll save investigating that for another PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-242839250:122,pipeline,pipeline,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-242839250,1,['pipeline'],['pipeline']
Deployability,@SHuang-Broad Could you update the links in HelpConstants while you're doing this?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6381#issuecomment-575688009:24,update,update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6381#issuecomment-575688009,1,['update'],['update']
Deployability,"@SHuang-Broad I see. So the conversion to SAM and back when we write the file actually changes the results (or at least their annotations). It makes me a little nervous that in one version of the pipeline the records go through `BwaMemAlignmentUtils.applyAlignment` and in the other they don't, since that method has some complex logic. Right now we have two possible paths:. `AlignedAssemblyOrExcuse -> SAMRecord -> writeToFile -> GATKRead -> AlignmentRegion`. or . `AlignedAssemblyOrExcuse -> AlignmentRegion`. What if we always converted to `SAMRecord`? It's a little more expensive but it would cut down on alternate code paths and conversion code, and IMO would make the code a lot simpler to read if I didn't have to think about which code path I was in. I'm also worried that the different conversions could lead to bugs that will be hard to debug since you have to know the code path that generated them. @tedsharpe what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022:196,pipeline,pipeline,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022,2,['pipeline'],['pipeline']
Deployability,@SHuang-Broad I'm going to try to take a crack at fixing this because it's breaking the main pipeline. Let me know if you're also working on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347557614:93,pipeline,pipeline,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347557614,1,['pipeline'],['pipeline']
Deployability,"@SHuang-Broad The bug was fixed upstream, so the next NIO release after 2019-5-28 will include it, and then it's just a matter of GATK updating to the latest version of NIO.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-496636838:58,release,release,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-496636838,1,['release'],['release']
Deployability,"@SHuang-Broad Two other potential options:; 1. Potentially modify bwa's xassert so that it instead of calling abort() directly, it has a function pointer that by default points to abort() but our JNI code instead points it to a new method which will throw a java exception instead. ; 2. Patch BWA to do something similar during the jbwa build process. (gross...). Is 1 feasible? It would be good if we could globally avoid exits and redirect them to java exceptions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243228784:287,Patch,Patch,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243228784,1,['Patch'],['Patch']
Deployability,@SHuang-Broad You can install a version locally with `mvn install` and then build a GATK with that snapshot.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6027#issuecomment-510139408:22,install,install,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6027#issuecomment-510139408,2,['install'],['install']
Deployability,"@SHuang-Broad hard to say. It's a small change once I get to it, but then it needs to go through review and wait for a release. To give a very rough estimate I'd say perhaps a month, with wide error bars.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-493513447:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-493513447,1,['release'],['release']
Deployability,@SHuang-Broad looks good. I still think you should rename that integration test though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411,1,['integrat'],['integration']
Deployability,@SHuang-Broad what is PipelineOptions needed for ... does one need it to access the reference if it stored in something that is not a ordinary file? (e.g. GS bucket?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607:22,Pipeline,PipelineOptions,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607,1,['Pipeline'],['PipelineOptions']
Deployability,"@SebastianHollizeck I believe the bug is not in `FilterMutectCalls` but upstream in `LearnReadOrientationModel` in the edge case of 3-base contexts that have no data in some of the samples. It's strange because we have an integration test for this already, and I would appreciate getting your input files to `LearnReadOrientationModel` for debugging. I think the following quick fix will work: untar your artifact priors, delete all but sample b, and re-tar, then run `FilterMutectCalls` as before. Is there a reason why all samples except b have very little data, and have no data at all for most 3-base contexts? To be clear, we want to fix the bug even if the data are weird, but I want to double-check that this is expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514,2,['integrat'],['integration']
Deployability,"@Siadjeu Could you try running the latest 4.1.9.0 release and reporting whether you get the same error? We updated a number of our dependencies for that release, including the Google cloud NIO library that the error is coming from.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225:50,release,release,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225,3,"['release', 'update']","['release', 'updated']"
Deployability,"@Stikus Yes, this is expected, and is mentioned in the release notes for 4.1.8.0:. * More flexible matching of dbSNP variants during variant annotation (#6626); * Add all dbsnp id's which match a particular variant to the variant's id, instead of just the first one found in the dbsnp vcf.; * Be less brittle to variant normalization issues, and match differing variant representations of the same underlying variant. This is implemented by splitting and trimming multiallelics before checking for a match, which I suspect are the predominant cause of these types of matching failures. For more details see the original pull request here: https://github.com/broadinstitute/gatk/pull/6626",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026:55,release,release,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026,1,['release'],['release']
Deployability,"@Stikus right, if you take a look at the PR, you‚Äôll see that only defaults for certain arguments of the FilterIntervals, DetermineGermlineContigPloidy, and GermlineCNVCaller tools were changed. So if you just manually specify the old values for these arguments, hopefully that should reproduce your previous results. Take care to make the appropriate changes to both COHORT and CASE modes for the latter two tools. It‚Äôs possible that this could be easily done in some kind of config file, e.g., if your pipeline is implemented in WDL you could just make the appropriate changes to your JSON config files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857781749:503,pipeline,pipeline,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857781749,1,['pipeline'],['pipeline']
Deployability,"@Sun-shan Currently it has to start with a bam file. You can use an unmapped bam file and then align it with bwa as part of the spark pipeline, but we can't currently read FASTQ directly. That's a feature we'd like to consider in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356035257:134,pipeline,pipeline,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356035257,1,['pipeline'],['pipeline']
Deployability,"@SusieX . Marking duplicates: I do recommend removing duplicates (we run MarkDuplicates from Picard). . BQSR: The pipeline we're developing is for Whole Genome data, so our bams have gone through BQSR in the whole genome pipeline. We're using those recalibrated base qualities. I haven't tested running BQSR only on the mitochondria so I don't know how well that would work. . If you do need to run BQSR only on the mitochondria I'd start by using the phylotree sites as `--known-sites`, but you'd need to have those sites in vcf format. Again, I haven't tested this so I don't know how well it will perform. If you end up using BQSR I think you're pipeline (BAM -> remove dup -> BQ recalibrate -> Mutect2 call -> FilterMutectCalls) is correct. Good luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431852996:114,pipeline,pipeline,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431852996,3,['pipeline'],['pipeline']
Deployability,@SusieX I'll comment here with updates.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310#issuecomment-430241723:31,update,updates,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310#issuecomment-430241723,1,['update'],['updates']
Deployability,"@SusieX Sorry for the delay, we're just trying to finalize some potentially disruptive changes before we merge. I'll open an issue so I can ping you there once this PR has been both merged and released. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430237566:193,release,released,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430237566,1,['release'],['released']
Deployability,@TedBrookings I implemented these suggestions of yours:. - replace CLUSTER_NAME with SANITIZED_BAM in the results directory; - allow output directory to be overridden by setting SV_OUTPUT_DIR; - rename `runWholePipeline` to `run-whole-pipeline`. I also found and fixed two other bugs:. - added a `set -f` to the create cluster script to avoid having bash expand the wildcard glob for that step (this caused a problem if a file matching the pattern was present locally); - changed how the copy results script got cluster info so that it parses the result header (this fixes a problem when using preemptible workers because the number of columns in the results of the `gcloud dataproc clusters list` command had a different number of columns. Can you give these changes a quick re-review?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4646#issuecomment-383718666:235,pipeline,pipeline,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4646#issuecomment-383718666,1,['pipeline'],['pipeline']
Deployability,"@TedBrookings which formats are you using, in particular? If there is a format out there that nicely fits our needs, we should adopt it. In the CNV package, I've taken pains to unify how tabular data are represented in Java, depending on whether each record is Locatable or whether the collection of records can be associated with a sample name or sequence dictionary. This allows us to represent records that extend Locatable with *multidimensional numerical or non-numerical annotations* along with some metadata (sample name and sequence dictionary) with a minimum of boilerplate. There are also base methods for producing interval trees, etc. This pretty much satisfies all of the CNV team's needs (and is, in my opinion, a necessary improvement over the horrowshow of read/write utility methods for each file format that we had previously...). However, this unification effort was a quick push I made before release, so some polishing or redesigning may be warranted. We may also want to add more forms of metadata, etc. if other teams would require more features. Another downside is that this code lacks the indexing, NIO support, etc. that some of the other standardized/Tribble formats enjoy. For CNV data, this isn't a huge issue, but I think it would be nice to unify how we represent such data GATK-wide. As I said above, I don't think VCF is the correct answer, but certainly it could fit into whatever framework we adopt or come up with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468:913,release,release,913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468,1,['release'],['release']
Deployability,"@TimothyStiles I never got back to you about this.. sorry! I think I pointed it out when we spoke in person, but there's a zip of every release attached to the release notes https://github.com/broadinstitute/gatk/releases",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449:136,release,release,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449,3,['release'],"['release', 'releases']"
Deployability,"@Tjitskedv Typically we ask people make a new issue in github or create a forum post, rather than commenting on open pull requests. . To answer your question directly - do not use v1.7 datasources with GATK 4.1.7.X or 4.1.8.X. Those data sources are not yet compatible with the Funcotator code in the Master branch. When we release GATK 4.1.9.0 they will work with Funcotator. This is not a bug in the code - it is an artifact of how we have to do data source releases. See issue #6708 for all the gory details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-674937596:324,release,release,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-674937596,2,['release'],"['release', 'releases']"
Deployability,"@TomofumiSaka It looks like you're using GATK 4.3, which uses Java 8. I would suggest upgrading to the most [recent version of GATK](https://github.com/broadinstitute/gatk/releases/tag/4.4.0.0), which uses Java 17 instead of Java 8. Java 17 uses strict floating point math by default. I haven't verified this, but I suspect upgrading would address the issue. If you try it, please let us know the results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1559489031:172,release,releases,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1559489031,1,['release'],['releases']
Deployability,"@Twojarshub Hi! Have you solved the problem? As I mentioned in my post, just adding ""--use-jdk-inflater true --use-jdk-deflater true"" in the step of GenotypeGVCFs could not solve the problem [https://github.com/broadinstitute/gatk/issues/7582](url) . In my case, I restarted from one step ahead (BQSR) with those options and could finish the pipelines without an error. Please try!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1005376853:342,pipeline,pipelines,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1005376853,1,['pipeline'],['pipelines']
Deployability,@U201412486 Thanks for reporting this! It looks like the issue was the `--read-name-regex null` not working with spark. I have a patch to fix it but in the meantime you should be able to run without nulling out the regex and it should fail gracefully and simply ignore counting OpticalDuplicates for reads that don't conform to the default regex.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-745356226:129,patch,patch,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-745356226,2,['patch'],['patch']
Deployability,"@Umutunaldi We can't debug the whole pipeline of commands, but it looks like the HaplotypeCaller issue is because the sequence dictionary in the bam file you're using is malformed. Are there '=' in the contig names in the header (check the output from samtools view -H mapped-bwa.bam).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6127#issuecomment-525739797:37,pipeline,pipeline,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6127#issuecomment-525739797,1,['pipeline'],['pipeline']
Deployability,"@V-Z As I suspected -- in that case I recommend running with `4.0.4.0` for now, and upgrade once https://github.com/broadinstitute/gatk/issues/4975 is fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402183492:84,upgrade,upgrade,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402183492,1,['upgrade'],['upgrade']
Deployability,"@Ziwei-Liu The gatkcondaenv.yml does not install or set up GATK - it is only used when you want to use one of the handful of GATK tools that use python. And even then, it only creates/establishes the python environment - it does not activate it (see the requirements section at https://github.com/broadinstitute/gatk#requirements). In the future, please post usage questions like this on the [GATK forum](https://gatk.broadinstitute.org/hc/en-us/community/topics) - this repo is for bugs and feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8120#issuecomment-1339644518:41,install,install,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8120#issuecomment-1339644518,1,['install'],['install']
Deployability,"@abalter The complete list of fields should be present in the VCF header, but unfortunately I don't know of a convenient way to extract them apart from the manual method. It would be pretty simple to write a script or GATK tool to parse the VCF header and list all the fields, but the best solution would be to patch the `VariantToTable` to default `-F` to all the fields, as discussed above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1061060581:311,patch,patch,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1061060581,2,['patch'],['patch']
Deployability,"@adamjorr We'd like to support newer versions of Java, but have historically been held back by our Apache Spark dependency. We'll take another look at our dependency situation, however, and see if an upgrade is possible at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684:200,upgrade,upgrade,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684,1,['upgrade'],['upgrade']
Deployability,@af8 The next release will also have a WDL workflow for creating the pon in the new way.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470666407:14,release,release,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470666407,1,['release'],['release']
Deployability,@af8 We are tentatively planning to release 4.1.1.0 with this bug fix next week.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610582:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610582,1,['release'],['release']
Deployability,"@ahaessly I've asked @jamesemery to review, as this touches some of his code. In the mean time, though, could you please add at least one good integration test for the new `ShiftFasta` tool?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477:143,integrat,integration,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477,1,['integrat'],['integration']
Deployability,@ahaessly It looks like you might have been the last one to touch the relevant lines in `StrandBiasUtils` -- mind looking at this one to check whether your work on the MT pipeline might have triggered this? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-683943978:171,pipeline,pipeline,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-683943978,1,['pipeline'],['pipeline']
Deployability,"@ahaessly and I have figured out what's triggering this error, and are working on a patch. It should be part of the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-698437515:84,patch,patch,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-698437515,2,"['patch', 'release']","['patch', 'release']"
Deployability,@ahaessly is going to incorporate these changes into a separate PR with more WDL updates so I'm going to close this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6333#issuecomment-604041361:81,update,updates,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6333#issuecomment-604041361,1,['update'],['updates']
Deployability,@ahwanpandey Could you try the most recent GATK release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5965#issuecomment-572182978:48,release,release,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5965#issuecomment-572182978,1,['release'],['release']
Deployability,"@akiezun @lbergelson Changed the Spark context configuration from ""local[*]"" to ""local[N]"", where N is specified by a environmental variable. Ran gradle test with ""--tests _SparkIntegration_"". Out of 203 tests, one failed: "" testBulkFragmentsNoDuplicates"", the rest passed. Here is the snippet of code change. Any suggestions?. ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:47,configurat,configuration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['configurat'],['configuration']
Deployability,"@akiezun I think there's a case to be made for having the ability to separate closure of resources from generation of final output on success, even if it's not currently needed -- I'd be ok with keeping both methods provided we can settle on the right names to avoid confusion, and provided we update the docs to make it clear when each method should be overridden. @lbergelson's suggestion of `onTraversalSuccess()` and `cleanup()` seems reasonable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212629504:294,update,update,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212629504,1,['update'],['update']
Deployability,"@alanhoyle Right now it's just in the code, so you'd have to compile it. If you can wait, we're planning on doing a release sometime in the next week or two.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-951268775:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-951268775,1,['release'],['release']
Deployability,"@alrafaykhan Did you clone (this) repository with git, and if so, is the root of that clone the location from which you're running ./gradlew ? I'm not sure how that happened, but it seems like you have build.gradle, but not the rest of the repo. You also can download a [zip file with GATK already built](https://github.com/broadinstitute/gatk/releases) if you just want to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074:344,release,releases,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074,1,['release'],['releases']
Deployability,"@als364 Can I request that you title your pull requests more descriptively? Ie., include the tool involved in the PR title, and a concise one-line description of the improvements/fixes. This would help when writing GATK release notes, as we use the PR titles as the basis for initial release notes. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829:220,release,release,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829,2,['release'],['release']
Deployability,@ameynert The fix just went in. It will be in the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4346#issuecomment-367372810:55,release,release,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4346#issuecomment-367372810,1,['release'],['release']
Deployability,"@amithasandur The Mutect2 pipeline output and the truth VCFs are both filtered, so whenever `variant.FILTER` is `None` it means in both VCFs that the variant is `PASS`. In intermediate stages of the pipeline -- after Mutect2 but before FilterMutectCalls -- there are VCFs with `.` in the FILTER column, but you may assume that your tool never needs to deal with that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7669#issuecomment-1039826708:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7669#issuecomment-1039826708,2,['pipeline'],['pipeline']
Deployability,@andrew-niaid Would changing the setting to only make it read/writeable by the owner of the gatk process be sufficient for you? I'm afraid changing the behavior to error on a non-writable tmpdir would cause people's pipelines to start failing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801:216,pipeline,pipelines,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801,1,['pipeline'],['pipelines']
Deployability,"@andrewrech it seems that some modules, such as FilterMutectCalls, CreateSomaticPanelOfNormals, etc, are changing significantly in recent gatk releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525342133:143,release,releases,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525342133,1,['release'],['releases']
Deployability,"@anowlcalledjosh and @bbimber Thanks for your contributions to GATK - I've updated the AUTHORs list with your names - can you verify that it looks correct ? (@bbimber not sure I got your name right, and let me know if you have an email address to include). Thx.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5033:75,update,updated,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5033,1,['update'],['updated']
Deployability,"@apete Thanks for the PR! That's really helpful to update and any svd improvements are definitely something we want. . It's failing to build though, because it can't locate `ojalgo-extensions-1.0.0`. I get the following error:; ```; Build file '/Users/louisb/Workspace/gatk/build.gradle' line: 511. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all dependencies for configuration ':runtime'.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; Required by:; project :; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://repo1.maven.org/maven2/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; Searched in the following locations:; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://jcenter.bintray.com/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206,2,"['configurat', 'update']","['configuration', 'update']"
Deployability,"@ashwini06 . This bam appears to be malformed and it fails Picard ValidateSamFile. I think you'll need to examine the earlier stages of your pipeline that produce your bam to ensure you get a correctly formed bam. I'm going to close this ticket now since this doesn't appear to be an issue with Mutect2. (base) wm462-624:Downloads fleharty$ java -jar $PICARD ValidateSamFile I=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam ; INFO	2020-07-14 11:25:52	ValidateSamFile	. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; ********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** ValidateSamFile -I concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:141,pipeline,pipeline,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['pipeline'],['pipeline']
Deployability,"@asmirnov239 @MartonKN @mbabadi Note the remaining TODOs. Let's be in a position where we can get all gCNV-related branches merged shortly after @mbabadi returns on 1/4 but with a margin before release on 1/9. I will spend some time over break to get my review in. I will also finish up docs for ModelSegments + update PreprocessIntervals this week. Review should be quick. I think we can consider preliminary evaluations complete; we'll run more and shore up evaluation infrastructure after break. @LeeTL1220 Following our discussion about evaluation tools, I added VCF output for the somatic pipeline as a TODO. Hopefully I can have some basic output by release, if not shortly thereafter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353148440:194,release,release,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353148440,4,"['pipeline', 'release', 'update']","['pipeline', 'release', 'update']"
Deployability,@asmirnov239 @MartonKN Comment now (or hold your peace until after release!) We will merge soon otherwise.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-355597944:67,release,release,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-355597944,1,['release'],['release']
Deployability,"@asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1063). Due to a bug in Nd4j library, INDArray.get() method does not work correctly for row or column vectors (that we work with when number of samples is 1). In these cases a call to `getNDArrayByIndices(array, indX, indY, int)` is made.; Note that this bug was fixed in later version of Nd4j (currently used version is 0.5.0), so the method can be removed when the dependency is updated",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3000:480,update,updated,480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3000,1,['update'],['updated']
Deployability,"@asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065). ---. @asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302528347). @mbabadi could you do it?. ---. @sooheelee commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302564888). Is the test <src/test/java/org/broadinstitute/hellbender/tools/coveragemodel/germline/GermlineCNVCallerIntegrationTest.java> not the integration test?. ---. @asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302565368). @sooheelee It's a collection of different tests, but it's missing some use cases. ---. @mbabadi commented on [Mon May 22 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-303249272). @asmirnov239 it covers PoN creation and calling (from the created PoN, and from the ""exact"" PoN). It certainly does not cover all combination of all advanced arguments, and we do not intend to do that either. Perhaps we should extend the test to include w/ and w/o ARD, and w/ and w/o bias covariates. I'm open to suggestions. ---. @asmirnov239 commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-303858968). @mbabadi What I meant is to write an extra test for a use case of calling events on a single sample (as it is a requirement for our workflows). Just a single test with most generic arguments should suffice I think.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3002:535,integrat,integration,535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3002,1,['integrat'],['integration']
Deployability,"@bbimber ; I just stumbled across this issue, and I have a quick question. How does this differ from GATK3 CombineVariants? Is it the same thing functionally? Does it produce the exact same output?. @cmnbroad ; I am just wondering because if it does, wouldn't it make sense to merge this into a later release?. Thank you for the clarification,; @skchronicles",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038#issuecomment-1191874924:301,release,release,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038#issuecomment-1191874924,1,['release'],['release']
Deployability,"@bbimber Ack! Sorry. The url changed at some point, and I copied an old version and updated it by hand and obviously messed it up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333646641:84,update,updated,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333646641,1,['update'],['updated']
Deployability,"@bbimber Ah, very nice. Yeah - readability of the annotations has always been an issue. I usually convert the output to TSV/MAF to visually inspect fields after running it (in the code there are other options). . FYI, The parser updates I need to make are so that Funcotator better supports other species. It's currently too restrictive on the GTF files used as the primary transcriptome references.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1355249901:229,update,updates,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1355249901,1,['update'],['updates']
Deployability,"@bbimber Can you try running `GenotypeGVCFs` with the `--genomicsdb-use-vcf-codec` argument and see if that resolves the NPE?. A second thing to try would be to see if the crash happens with the latest gatk/master, which was just updated to a newer version of the GenomicsDB library with many bug fixes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646077480:230,update,updated,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646077480,1,['update'],['updated']
Deployability,"@bbimber Could you please try running the following command on your GATK jar:. ```; jar tvf GenomeAnalysisTK4.jar; echo $?; ```. Then see whether the `jar` command reports any error, and whether the `echo` command shows an exit status of 0 for the command. Also try running this:. ```; jar tvf GenomeAnalysisTK4.jar | grep -i FileTruncatedException; ```. You should get output like:. ```; 765 Wed Mar 17 12:09:12 EDT 2021 htsjdk/samtools/FileTruncatedException.class; ```. Lastly, can you paste your complete Java classpath here?. We just checked the official release jar on github ourselves for corruption, and it seems fine, so we're not sure what's causing this issue on your end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042017121:560,release,release,560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042017121,1,['release'],['release']
Deployability,"@bbimber Good questions all. Whenever we do these ports we have to strike a balance between minimizing the changes and updating to GATK4 standards. Generally, though, we want the code to conform to GATK4. This PR is large and likely to require some iteration so I'd be ok with starting with just the minimal ""porting"" changes to keep things simple, and then doing a code hygiene pass at the end. The ""porting"" changes should include things like updated javadoc, GATK4-style command line arguments, updating of outdated GATK3 terminology such as ""ROD"", Utils.nonNull assertions, etc. The finals and curly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:445,update,updated,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['update'],['updated']
Deployability,"@bbimber I appreciate the attempt to update the tests, but I think your previous version was much better (modulo use of the data provider).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831449931:37,update,update,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831449931,1,['update'],['update']
Deployability,"@bbimber I believe we resolve it from jcenter. There were some issues around it because we removed jcenter resolution from our build at one point when it was slated to shut down. Testing didn't see any issue because it was being silently mirrored through our artifactory instance and we didn't realize that. Jcenter changed their plans from shutting down to going into indefinite read only mode, so we re-added it. . I think if you're seeing problems it's either because:; 1. You are building on a version of gatk which removed jcenter; 2. Your custom build doesn't resolve from jcenter; 3. We have a new issue I don't know about yet. . Can you rule out 1 and 2 before we start debugging 3? . In your build.gradle you should should see ` jcenter()` in your `repositories {}` block. It's very possible that we're relying on an outdated version and maybe we should update to a new one which isn't on the ill fated Jcenter only. @TedBrookings any thoughts about that? I think this is your dependency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145:863,update,update,863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145,1,['update'],['update']
Deployability,"@bbimber I did start to take a look at this today. We'd probably take many of the peripheral classes from GATK3 as they are (though there will be some exceptions, i.e., `VariantEvalUtils` calls `System.exit`, which we wouldn't want to do). And in some cases we may want to make tickets for places where we want to do refactoring, like we did for MendelianViolations. The code will need to conform to GATK4 in some areas (use hyphen-separated argument names, updated javadoc where it's GATK3-specific, etc). The easiest way to do this would be to add a commit with the raw GATK3 code as I mentioned above. We would then focus on reviewing the diffs, instead of line-by-line for all of the code. I can add that commit if you like - we'd just need to coordinate since I would have to push to your branch. Also, FYI, I'll be away all of next week so I won't be able to do any more on this until I return.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413988997:458,update,updated,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413988997,1,['update'],['updated']
Deployability,"@bbimber I don't think `IntegrationTestSpec` has any provisions for this, and it has a number of other limitations around output files as well. We mostly only keep it around to make it easier to port GATK3 test - I'd recommend writing new tests using `ArgumentsBuilder` and `runCommandLine`, and checking results manually, perhaps by delegating to the static assert* methods in `IntegrationTestSpec`. Take a look at `HaplotypeCallerIntegrationTest` as an example. For the case of multiple outputs, create a temporary directory and specify that for the prefix input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281:24,Integrat,IntegrationTestSpec,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281,2,['Integrat'],['IntegrationTestSpec']
Deployability,"@bbimber I have an updated version of this branch that contains the raw GATK3 sources as the first commit, but I don't want to clobber anything you may be in the process of pushing up, so I'll wait for you to tell me when to push it. One thing to note is that currently this branch doesn't compile (even without my commit). I just want to make sure github has all of your changes, since I know you had the old tests working with it. With my commit, the history looks like this:. ![image](https://user-images.githubusercontent.com/10062863/44674969-25280580-a9fd-11e8-94d2-c41c2d9be61e.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416303132:19,update,updated,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416303132,1,['update'],['updated']
Deployability,"@bbimber I have to do a bit more digging here, but one thing I noted was that the reference you provide has some soft-masked regions. If I convert that reference to all upper case, the REF base is actually populated correctly. I still have to dig into why that is the case, but wanted to let you about this potential workaround in case you want to use it. I'll update this with more as I find it...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7089#issuecomment-783553524:361,update,update,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7089#issuecomment-783553524,1,['update'],['update']
Deployability,"@bbimber I usually do it like this:. - run `./gradlew clean install printVersion` on gatk (this will build and install gatk into the local maven repo, and display a SNAPSHOT version number of the installed artifact); - add `mavenLocal()` to the repository list (in your case, to the VariantQC gradle file; you can see how its done in the gatk build.gradle by looking for `mavenLocal`); - update the gatk version in your gradle file to the use SNAPSHOT version printed out by the command above; - do a clean build",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759612272:60,install,install,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759612272,4,"['install', 'update']","['install', 'installed', 'update']"
Deployability,"@bbimber I'm making way through this, and will focus on the diffs from GATK3, especially the tool itself. There are a few things that I mentioned above that will absolutely need to be done though; the VariantEval tool javadoc needs to be updated to reflect GATK4 syntax (i.e. references to GenomeAnalysisTK.jar need to be updated, etc. - see other tools for examples), and the tool command line arguments need to be changed to reflect GATK4 conventions (i.e. `selectName` -> `select-name`). Ideally those would be done before I go any further. Also, it would be much easier if we could start this review process/comments with just two commits - the initial GATK3 source code commit, and one commit with all the changes. Can you squash down all of your commits (except the initial one) into a single commit ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433415826:238,update,updated,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433415826,2,['update'],['updated']
Deployability,@bbimber Just an update that I'm making my way through this and expect to have a review back to you some time next week.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-437043604:17,update,update,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-437043604,1,['update'],['update']
Deployability,"@bbimber Once that PR is merged, it will automatically go out as part of the next GATK nightly docker snapshot (https://hub.docker.com/r/broadinstitute/gatk-nightly). We are going to do a point release shortly after that PR goes in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048164086:194,release,release,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048164086,1,['release'],['release']
Deployability,@bbimber Release is currently slated for tomorrow morning,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1063379663:9,Release,Release,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1063379663,1,['Release'],['Release']
Deployability,@bbimber The test that failed just got fixed in master so you should be good to ignore it... it is @lbergelson PR into your code that you are patching so i don't know if he should approve this or not...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189743128:142,patch,patching,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189743128,1,['patch'],['patching']
Deployability,"@bbimber This issue is caused by an incompatibility between the version of snappy htsjdk uses and the versions that the rest of the world use. The workaround was to add the system property`-Dsnappy.disable=true` which is set automatically by gatk-launch. However, we just fixed the underlying problem in htsjdk and upgraded to use new version of snappy there, so it's a better idea to update to a newer gatk version that incorporates the newest htsjdk. . Annoyingly, we've been unable to publish the newer beta releases to maven central because they rely on snapshot builds of dependencies that aren't in central. We're working to fix that issue, but until then, we publish continuous snapshots of every commit on our artifactory https://broadinstitute.jfrog.io/. If you're using gradle you can add our repository to your project by adding this in your `repositories` block of the build file. ```; maven {; url ""https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/"" ; }; ```; (this url was updated to address the comment below) . Then you can add a newer gatk dependency to your project:. ```; compile(group: 'org.broadinstitute', name: 'gatk', version: '4.beta.5-53-g0598843-20170929.153234-1'); ```. There should be a similar solution if you use maven or a different build tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036:315,upgrade,upgraded,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036,5,"['continuous', 'release', 'update', 'upgrade']","['continuous', 'releases', 'update', 'updated', 'upgraded']"
Deployability,"@bbimber This looks like a good change, but I don't think it'll solve the problem. The `XsvLocatableTableCodec` works differently than other codecs. It was essentially created for Funcotator datasources, and it expects to be given a `.config` file rather than the XSV file itself. For example, if you wanted to index the Oreganno data source file, you'd need to first create a funcotator configuration file adjacent to it, and then use `IndexFeatureFile` to index the config file rather than the tsv. This is not a good design (my fault), but it's how the tool operates as of right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042:388,configurat,configuration,388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042,1,['configurat'],['configuration']
Deployability,"@bbimber Unfortunately it's not so simple -- some of the GATK3 test data cannot be shared externally at all due to, eg., IRB restrictions. Someone will have to look at the test data in question to make sure that it can be shared. We'll update you once we've done this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358032795:236,update,update,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358032795,1,['update'],['update']
Deployability,"@bbimber We believe that this should be fixed by https://github.com/broadinstitute/gatk/pull/7670, which will go out in the next GATK release. If you're able to test with that patch and give feedback on whether it resolves the error for you, that would be helpful!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591:134,release,release,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591,4,"['patch', 'release']","['patch', 'release']"
Deployability,"@bbimber Yes, most of those travis jobs are unique and do not overlap in terms of coverage. The unit and integration tests are each run in two separate jobs, one on Java 8 and one on Java 11, but the other jobs run python tools, cloud tests, WDL tests, etc. and do not overlap.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442:105,integrat,integration,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442,1,['integrat'],['integration']
Deployability,"@bbimber You may not want to restart at this point, but the latest release (https://github.com/broadinstitute/gatk/releases/tag/4.1.8.0) has some optimizations targeted towards shared posix filesystems -- a knob called `--genomicsdb-shared-posixfs-optimizations`. It also reduces the storage space requirements for the genomicsdb workspace substantially. You could also try to check on the size of the workspace where that scatter job is writing. The import should be writing to an ""invisible"" directory (i.e., one starting with a ""."") so it may not be visible under the contig directory. But if the process is making progress, the size should increase over time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-655897920:67,release,release,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-655897920,2,['release'],"['release', 'releases']"
Deployability,@bbimber thanks for the rebase and update. I'll take a closer look at this today.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744489932:35,update,update,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744489932,1,['update'],['update']
Deployability,"@bbimber, I have placed another version of consolidate_genomicsdb_array [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array). This allows for batch-wise consolidation with the `--batch-size` or `-b` option. The tool also does better reuse of the consolidation buffers between reads, so might work a little better. Be aware that the total time to consolidate increases with the batch option and the final batches require almost as much memory as consolidating all the fragments at once. Please try consolidating any one GenomicsDB array to see how it functions as we are still working at making this scalable in a better way. This is just a draft version and if you can share some of the resulting logs, that will be very helpful. Please do let me know the total size of all the `__book_keeping.tdb.gz` files in your fragments. Just a back-of-envelope calculation, you probably need about 40 times that total size of memory to successfully consolidate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081029205:120,release,releases,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081029205,1,['release'],['releases']
Deployability,"@bbimber, sorry that the import with consolidate did not complete. If you are amenable to using a native tool, please download the tool from [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array) for consolidation. This executable will consolidate a given array in a GenomicsDB workspace, it has been instrumented to output memory stats to help tune the segment size. Note that the executable is for Centos 7, if you find any unresolved shared library dependencies during usage, please let me know and I will work on getting another one to you. For usage from a bash shell:; ```; ~/GenomicsDB: ./consolidate_genomicsdb_array; Usage: consolidate_genomicsdb_array [options]; where options include:; 	 --help, -h Print a usage message summarizing options available and exit; 	 --workspace=<GenomicsDB workspace URI>, -w <GenomicsDB workspace URI>; 		 Specify path to GenomicsDB workspace; 	 --array-name=<Array Name>, -a <Array Name>; 		 Specify name of array that requires consolidation; 	 --segment-size=<Segment Size>, -z <Segment Size>; 		 Optional, default is 10M. Specify a buffer size for consolidation; 	 --shared-posixfs-optimizations, -p; 		 Optional, default is false. If specified, the array folder is not locked for read/write and file handles are kept open until a final close for write; 	 --version Print version and exit; ```. ```; ~/GenomicsDB.: ./consolidate_genomicsdb_array -w /Users/xxx/WGS.gdb/ -a ""1\$1\$249250621"" -z 1048576 -p; 21:09:47.100 info consolidate_genomicsdb_array - pid=30881 tid=30881 Starting consolidation of 1$1$249250621 in ws; Using buffer_size=1048576 for consolidation; 21:9:47 Memory stats(pages) beginning consolidation size=45821 resident=18998 share=1824 text=3530 lib=0 data=16810 dt=0; 21:9:47 Memory stats(pages) after alloc for attribute=END size=45821 resident=19009 share=1835 text=3530 lib=0 data=16810 dt=0; 21:9:48 Memory stats(pages) after alloc for attribute=REF size=46788 resident=19743 share=18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354:189,release,releases,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354,1,['release'],['releases']
Deployability,"@bbimber, thanks to @mlathara and @kgururaj, here is a suggestion. With `~36 attributes+offsets` and `~80 fragments` in GenomicsDB parlance getting stored, with `--genomicsdb-segment-size=1048576(1M default)`, we are looking at memory requirements in the range of 10G of memory for reading during consolidation. Just wondering, if you could try GenomicsDBImport with the following options to see if it helps.; ```; java heap options of say -Xmx100g -Xms 100g; --genomicsdb-update-workspace-path WGS_1852_consolidated.gdb \; --batch-size 10 \; --consolidate \; --genomicsdb-shared-posixfs-optimizations \; --bypass-feature-reader \; --genomicsdb-segment-size 32768 \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1051157333:473,update,update-workspace-path,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1051157333,1,['update'],['update-workspace-path']
Deployability,"@bbimber, there was an issue with `max-alternate-alleles` getting passed to the GenomicsDB layer from `GenotypeGVCFs`. That has been fixed in this [branch](https://github.com/broadinstitute/gatk/tree/ng_genomicsdb_args) if you would like to try. See this related [GenomicsDB Issue](https://github.com/GenomicsDB/GenomicsDB/commit/3c7d1ead0110fec26d56ff85a5871d8df673504d). This will hopefully help with memory usage. On another note, there is a [performance/bug fix ](https://github.com/broadinstitute/gatk/pull/7520) while reading/writing GenomicDB bookkeeping artifacts in the latest release and in this branch as well. This may help with memory while incrementally adding new batches and using the `--consolidate` option with import.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-974487707:586,release,release,586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-974487707,1,['release'],['release']
Deployability,"@bhanugandham ; I am just following gatk forum to here. I expect to find solution to go through this problem here, but this thread has not been updated for six months. So I post to ask for help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541476068:144,update,updated,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541476068,1,['update'],['updated']
Deployability,"@bhanugandham As a side note, you shouldn't be running GATK4 using `java -jar` directly. You should use the included `gatk` launcher script, which sets a lot of important configuration settings, some of which have a major effect on tool performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403:171,configurat,configuration,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403,1,['configurat'],['configuration']
Deployability,@bhanugandham Have people been having trouble installing java 8 recently? I just found out that you now need to log into an oracle account to download it which is gross and off putting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6024#issuecomment-507804068:46,install,installing,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6024#issuecomment-507804068,1,['install'],['installing']
Deployability,"@bhanugandham Is this something someone on the comms team could look at this quarter? The task is just to update the links in the javadoc, no actual coding necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-651282238:106,update,update,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-651282238,1,['update'],['update']
Deployability,@bhanugandham Its fixed (https://github.com/broadinstitute/gatk/pull/5480) and should be in the next release (today).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5245#issuecomment-447967733:101,release,release,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5245#issuecomment-447967733,1,['release'],['release']
Deployability,"@bhanugandham This message itself is harmless and won't affect results directly, but it can mask warning/error messages coming from Jexl (such as missing variable names!). I wouldn't expect a user to see it when running from a normal installation, and I'm not sure why it seems to be intermittent. I'll need to do some debugging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139:234,install,installation,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139,1,['install'],['installation']
Deployability,@bhanugandham can you take a stab at a docs update? I'm happy to review.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438741166:44,update,update,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438741166,1,['update'],['update']
Deployability,@biovia-rohit Thanks for reporting this! We'll look at our Apache Commons dependency and see if we can upgrade to a version not affected by this vulnerability.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679:103,upgrade,upgrade,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679,1,['upgrade'],['upgrade']
Deployability,"@brigranger @jnktsj Note when this gets into master and gets released. To keep the previous behavior, you will want to set `filter_oncotator_maf` to false. (The default is going to become `true`, since most cancer analysts will want it this way)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374648261:61,release,released,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374648261,1,['release'],['released']
Deployability,"@bshifaw I believe we fixed this in master in this PR: #6327, but we haven't released since then. I'll close this ticket based on that assumption, but please re-open if I'm wrong.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6419#issuecomment-578900921:77,release,released,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6419#issuecomment-578900921,1,['release'],['released']
Deployability,"@bshifaw Minor tweak to David's comment: you won't be able to run the WDL gen directly from this branch because it requires a barclay upgrade, but I did check a couple of output WDLs in as a temporary commit so you can look at those. If you'd like, I can generate WDL for all the tools and check those in, but I didn't do that because the tools will require some annotation in addition to this branch in order to get WDLs with proper output sections out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611037749:134,upgrade,upgrade,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611037749,1,['upgrade'],['upgrade']
Deployability,"@bshifaw found this bug in the M2 wdl where it requests eg 3500 GB of RAM instead of 3500 MB, causing disastrous ""no machines available"" errors. @LeeTL1220 any way to get this into a release?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4321:183,release,release,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4321,1,['release'],['release']
Deployability,@butlermgb Using a release more recent than the the September 13 fix should resolve the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5158#issuecomment-455637958:19,release,release,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5158#issuecomment-455637958,1,['release'],['release']
Deployability,@cai1991 @ericblanc20 @MarleyCodes @isidroc @nalcala I believe this was fixed in a recently-merged patch (https://github.com/broadinstitute/gatk/pull/6583). The fix will go out as part of the next GATK release. @fleharty @davidbenjamin Could one of you please confirm that https://github.com/broadinstitute/gatk/pull/6583 fixes this issue? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516#issuecomment-646089837:99,patch,patch,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516#issuecomment-646089837,2,"['patch', 'release']","['patch', 'release']"
Deployability,"@carbocation @droazen just to speed along the question and answer process, the index files that triggered this error were produced using samtools v1.3.1, and was run back in 2019. So the issue here is with compatibility between the current htsjdk cram implementation and older versions of htslib. The current GP pipeline uses a much newer version of samtools, which appears to be more compatible with htsjdk, and so shouldn't produce data that runs into this issue (@cmnbroad's explanation of the different allowances htsjdk makes is relevant here). Personally, I think the spec is (probably intentionally) quite lenient about this behavior, even more than htsjdk. The relevant line is, I believe, ""Slices containing solely unmapped unplaced data (reference ID -1) still require values for all columns, although the alignment start and span will be ignored. It is recommended that they are both set to zero."" towards the bottom of page 22 in https://samtools.github.io/hts-specs/CRAMv3.pdf. It's always a fun time when a spec uses the word ""recommended"" :). I'd guess this is a situation where earlier specs were too vague, and so too many different behaviors appeared in the wild, and now the spec can't be solidified without pushing a bunch of tools suddenly off-spec. Though a cram expert could probably give more detail on exactly the thinking around that wording.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099661674:312,pipeline,pipeline,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099661674,1,['pipeline'],['pipeline']
Deployability,"@ccastane9, looks like a memory issue. Some questions -. 1. What are the sizes of the book-keeping files in your GenomicsDB workspace? Try running `find /ECA3_GenomicsDB_260 -name __book_keeping.tdb.gz -ls`.; 2. Is /ECA3_GenomicsDB_260 on NFS or another shared Posix FS? Can you try running GenotypeGVCFs with `--genomicsdb-shared-posixfs-optimizations` turned on?; 3. What does your hardware configuration look like, memory wise?; 3. What are your `-Xmx` and `-Xms` java options?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-754244432:393,configurat,configuration,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-754244432,1,['configurat'],['configuration']
Deployability,@chadisaad What GATK version did you use? I was not able to reproduce your error with GATK releases from August 2019 and December 2019.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-572180647:91,release,releases,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-572180647,1,['release'],['releases']
Deployability,"@chandrans @davidbenjamin I'm not actually objecting to the idea of taking `Mutect2` out of beta, for the record. I'm just trying to get people used to the idea that removing the `@BetaFeature` tag is actually a ""big step"" that requires careful evaluation, since it can't be undone. It's not just something that affects tool documentation -- it affects our entire release and development process now that we're out of beta. If a tool is marked stable, it needs to be kept in a constantly releasable state in master, and major changes to stable tools need to be done in such a way that existing functionality is not compromised. If the latest master version of `Mutect2` has been run through and passed whatever evaluation criteria/scripts your team relies on @davidbenjamin, and you are comfortable at this point with the additional restrictions that come with doing development on a stable tool, then by all means take it out of beta!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387:364,release,release,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387,2,['release'],['release']
Deployability,"@chandrans Can you please ask the user to test with the `4.0.0.0` (or `4.0.1.0`) release, as there were major performance improvements to the `HaplotypeCaller` just before the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-361988531:81,release,release,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-361988531,2,['release'],['release']
Deployability,"@chandrans Can you try again with the latest 4.x release and report whether this is still an issue (I suspect it is, as it was a problem in GATK3 as well)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-363128411:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-363128411,1,['release'],['release']
Deployability,"@chandrans Please ask the user to repeat the test, with the following adjustments:. * Run both GATK 3.7 and GATK 4.0.1.1 (latest release) on the same machine, one right after another, on chromosome 20 only (using `-L` in both cases), and ensure that there are no other expensive processes running on this machine during the tests. Run each version 3 times, and take the average of the results.; * Add `-pairHMM AVX_LOGLESS_CACHING` to both the GATK3 and GATK4 command lines, to guarantee that the native PairHMM will be used in both cases.; * Get rid of the `--native-pair-hmm-threads 32` in the GATK 4 command line. Too many threads can sometimes make performance worse by introducing too much contention.; * Check both the GATK3 and GATK4 output to ensure that the Intel inflater and deflater were used in both cases.; * Check both the GATK3 and GATK4 command lines to be sure they are equivalent (eg., if one is running with -ERC GVCF, the other one should as well).; * Compute wall-clock time by running the Unix `time` command, if the user is not already doing so (eg., `time ./gatk HaplotypeCaller....`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464:129,release,release,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464,1,['release'],['release']
Deployability,@chandrans `IndexFeatureFile` has been enabled and runnable in all of the 4.x releases so far. It was only disabled temporarily in one of the betas.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556950:78,release,releases,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556950,1,['release'],['releases']
Deployability,"@chandrans commented on [Mon Jan 29 2018](https://github.com/broadinstitute/dsde-docs/issues/2881). User reports BaseRecalibratorSpark in gatk-4.beta.6-17 took 3.79 minutes vs 40 minutes in official release. ----; User Report; ----. Dear GATK_team, I'd like to run Spark-enabled GATK tools on a Spark cluster. Precisely I am launching a Spark cluster in the standalone mode submitting the `BaseRecalibratorSpark` application via Slurm. Before the official release, I was running the `gatk-4.beta.6-17` version, with the following allocated resources, and the following command line for the Spark arguments: `./gatk-launch BaseRecalibratorSpark \ --sparkRunner SPARK --sparkMaster spark://${MASTER} --driver-memory 80g --num-executors 16 --executor-memory 8g`. The speed-up achieved was 3.79 min. However, with the official release GATK-4.0.0.0, with the same datafiles and the same Spark arguments I don't see the same nice speed-up anymore (~ 40 min). Am I missing something with the new version? Or with the invoking command line? Thanks in advance for your time and kind answer. Best, Giuseppe. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/11260/gatk-4-0-0-0-baserecalibratorspark-low-performance/p1. ---. @chandrans commented on [Mon Jan 29 2018](https://github.com/broadinstitute/dsde-docs/issues/2881#issuecomment-361324925). @droazen @lbergelson Hi David and Louis. Do you have any comments? I was supposed to put this in gatk but put it in dsde-docs. Thanks. ---. @droazen commented on [Mon Jan 29 2018](https://github.com/broadinstitute/dsde-docs/issues/2881#issuecomment-361342262). @chandrans Could you move this ticket to the gatk repo so that we can remember to have a look at the tool? Someone will have to re-profile.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4300:199,release,release,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300,3,['release'],['release']
Deployability,@chandrans you missed quite a few instances of -o/-O and some other syntax updates (like dropping the -T).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2760#issuecomment-309644094:75,update,updates,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2760#issuecomment-309644094,1,['update'],['updates']
Deployability,"@chapmanb I forgot to say that with the fix I can run your test command successfully. Without the fix I was getting the same error that you got. If you want to try out the fix you will have to build Hadoop-BAM, see https://github.com/broadinstitute/gatk/wiki/Build-GATK-with-a-locally-built-htsjdk-or-Hadoop-BAM. When building GATK, do something like:. ```bash; ./gradlew clean installDist sparkJar -DhadoopBam.version=...; ```. For the record, here is the command I ran:; ```bash; ./gatk-launch HaplotypeCallerSpark -I hdfs:///user/$USER/debug-ref-name/gatkspark_refname.bam -R hdfs:///user/$USER/debug-ref-name/Homo_sapiens_assembly38.2bit -O hdfs:///user/$USER/debug-ref-name/out/NA24631-chr15_68578892_84670250-block.vcf.gz -pairHMM AVX_LOGLESS_CACHING -L regions.bed \; -- \; --sparkRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit \; --driver-memory 4G \; --num-executors 30 \; --executor-cores 1 \; --executor-memory 4G \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-341184164:378,install,installDist,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-341184164,1,['install'],['installDist']
Deployability,@chapmanb Is this still a problem for you in the 4.0 release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3736#issuecomment-358065856:53,release,release,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736#issuecomment-358065856,1,['release'],['release']
Deployability,"@chapmanb Singularity's default configuration has a line ""config passwd = yes"" and that will create a user entry in the /etc/passwd automatically. So it I understand the issue, spark would automatically find the user running the container in the /etc/passwd file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-382483335:32,configurat,configuration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-382483335,1,['configurat'],['configuration']
Deployability,"@chatchawit I just merged the code into master, so it should be live now. If you build the GATK from source you will get the latest update - do you need help doing this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-390326875:132,update,update,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-390326875,1,['update'],['update']
Deployability,"@chatchawit If you haven't already, try again with the latest release. It should help. There are also updated Data Sources in the usual place.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-396631902:62,release,release,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-396631902,2,"['release', 'update']","['release', 'updated']"
Deployability,"@chatchawit Like Louis said, there have been quite a few updates. The issue you're seeing is a data sources problem relating to HG38. This has been fixed in the latest release of funcotator and the data sources. If you grab the latest software and the latest data sources release this problem should go away. Sorry for the inconvenience.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385055029:57,update,updates,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385055029,3,"['release', 'update']","['release', 'updates']"
Deployability,"@chatchawit Thank you for the additional information, thats very helpful. ; It looks like you're using gatk 4.0.0.0, there have a been a lot of updates to funcotator since then. I might try running with the newest release 4.0.4.0 and see if that resolves the problem. @jonn-smith As the funcomaster, you may have some insight?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385029450:144,update,updates,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385029450,2,"['release', 'update']","['release', 'updates']"
Deployability,"@cheche0717 there hasn't been a release since the warnings were updated, but you can build a new jar yourself off of the master branch in the github repository or use the nightly Docker: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949:32,release,release,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949,2,"['release', 'update']","['release', 'updated']"
Deployability,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:379,integrat,integration,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['integrat'],['integration']
Deployability,@cmnbroad - hope all is well. I was wondering if there is any ETA when the fix that you made will be released? . Thanks!; Ilya,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2104303044:101,release,released,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2104303044,1,['release'],['released']
Deployability,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:202,configurat,configuration,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828,5,['configurat'],['configuration']
Deployability,"@cmnbroad . 1. We could write tests for some parts of the python package, e.g. those relating to I/O. The code also contains a number of stand-alone compiled theano functions that could be tested (e.g. forward-backward algorithm). Beyond that, most of the code juggle symbolic tensors that ultimately get compiled by theano into one giant _step function_. It is going to be hard to write surgical unit tests for such a code (and possibly unnecessary/wasteful). The ultimate requirement from the computational core is to (1) make correct inferences on simulated data, (2) pass certain sensitivity/specificity requirements on real data.; I vote for _not_ unit testing the python package (except for I/O), and to treat it as a black box with certain required specifications. The java-side integration tests can test most of the relevant cases. 2. Regarding logging, the scripts log both to console and optionally to a logfile at specified verbosity levels. At the moment, I am using the following formatter `%(asctime)s %(name)-12s %(levelname)-8s %(message)s`. We can easily change it to match GATK-style logs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623:786,integrat,integration,786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623,1,['integrat'],['integration']
Deployability,"@cmnbroad . The warning -> info change is from https://github.com/googleapis/google-auth-library-java/pull/199; That didn't get rid of the stack trace though, just made it an info trace which is still gross. I made a pr which is merged but not yet released which will move the stack trace to debug. . It should be in 0.75 I think...; https://github.com/googleapis/google-auth-library-java/pull/214. This includes two other prs that I made to fix other output issues in the auth library which made it into the 0.74 release. ; https://github.com/googleapis/google-auth-library-java/pull/205 ; https://github.com/googleapis/google-auth-library-java/pull/207",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781:248,release,released,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781,2,['release'],"['release', 'released']"
Deployability,"@cmnbroad : if getStratifierClasses() is the only sticking point, we can drop that. . Stepping back: as you probably know we have a tool, VariantQC, which basically sets up a number of instances of VariantEval and uses them to aggregate data as it iterates a VCF. this allows the tool to capture data aggregated/stratified at multiple levels with one pass through the VCF. . There are two related aims:. 1) my tool needs to know the allowable stratification classes. Instead of copy/paste the reflection code to find classes, this PR was exposing that getter as a public method. I'm not sure I understand why this is a sticking point, but we can remove this without that much problem for me. Like we discussed earlier, VariantEval should get refactored into a walker class and some kind of VariantEvalEngine class, and this refactor might be a time to address my concern here. This is not actively blocking us. I could also make this a protected getter on VariantEval if the public aspect is what you dont like. 2) The remaining changes serve a different purpose. Most VariantEvaluator classes are 'dumb' in that they are instantiated with no configuration and always aggregate the same fields. In our tool, we wanted to let the user specify a list of INFO fields to aggregate (i.e. we dont know the target until runtime). We wrote an InfoFieldAggregator class, which is instantiated with the name of an INFO field. This lets our code create multiple instances of that VariantEvaluator, potentially summarizing different fields. The remaining changes are designed to enable this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502946807:1143,configurat,configuration,1143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502946807,1,['configurat'],['configuration']
Deployability,"@cmnbroad : thanks for the reply. yes, obviously tests would need to be added/updated. there's no question it needs robust testing. . my main concern is that VariantEval is a fairly sprawling tool with all sorts of add-ons. The majority of the untouched code taken verbatim from GATK3 isnt going to pass muster based on the bar of our last PR without a lot of petty revision (and maybe some useful updates). There are certainly some code improvements one could make across VariantEval, but I'm just not that keen on combing through the whole thing if it can be avoided. . how about this: while tests need to be updated (as discussed above, they work on the GATK3 data, which isnt checked in), the code in this PR is functional. Would you be willing to review a couple classes, maybe VariantEval itself and a few ancillary classes to see what scope of work we're talking about?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413642544:78,update,updated,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413642544,3,['update'],"['updated', 'updates']"
Deployability,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‚Äòblocks‚Äô); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:822,Configurat,Configuration,822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699,2,"['Configurat', 'update']","['Configuration', 'update']"
Deployability,@cmnbroad @mbabadi Let‚Äôs go with the matplotlibrc workaround and add some documentation to the README and Javadoc for the tools. We can take a closer look after release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356139074:161,release,release,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356139074,1,['release'],['release']
Deployability,@cmnbroad @samuelklee Seems like there's at least one test failure on this branch: . ```; PythonEnvironmentIntegrationTest. testGATKPythonEnvironmentPackagePresent; java.lang.AssertionError: The installed version of r-backports does not match the 1.1.10 version that was requested. Check the build log to see the actual version that was resolved by conda.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-726961872:195,install,installed,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-726961872,1,['install'],['installed']
Deployability,@cmnbroad @tomwhite . Here it works fine with the earlier 4.0.3.0 with the Hadoop-Bam library (except it is very slow). It counted 806177853 reads. The issue is probably related to the upgrade from Hadoop-BAM library to the newly-developed Disq library. ```; gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:185,upgrade,upgrade,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,3,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"@cmnbroad After looking more, I have two comments: . 1) I agree that override of toString() was awkward. @ldgauthier or someone else at GATK might have more comments, but I think it can be dropped. 2) Some kind of getSimpleName() method directly on the interface, defaulting to getClass().getSimpleName() would be reasonable; however, it needs to be on Annotation, not VariantAnnotation, to be useful. . In this updated PR, I remoted the override of toString(), removed AbstractInfoFieldAnnotation, and left just the two interfaces: InfoFieldAnnotation and GenotypeAnnotation. The results in a relatively minor overall change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455:412,update,updated,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455,1,['update'],['updated']
Deployability,"@cmnbroad Another short one that might be easy to get in before release. However, as you can see from the comments here and in the code, there might be a better way to handle this issue. I was hoping @lbergelson might have some ideas (I think he previously suggested just suppressing stderr/stdout, not sure if that's preferred to hacky try-catches), but if you have bandwidth to review, I'd appreciate any suggestions you might have. For more context, you can see previous chatter in the dsde-methods Slack channel---just search for HDF5.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5055#issuecomment-408412233:64,release,release,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5055#issuecomment-408412233,1,['release'],['release']
Deployability,@cmnbroad Back to you -- `ReservoirDownsampler.consumeFinalizedItems()` still needs to be updated to return an empty list with no side effects when there are no finalized items.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457641779:90,update,updated,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457641779,1,['update'],['updated']
Deployability,@cmnbroad Can you have a look at this when you get a chance and provide high-level feedback related to eventual integration with the `PythonScriptExecutor` and any dependency-related issues? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455,2,['integrat'],['integration']
Deployability,"@cmnbroad Chris, could you update `Miniconda2` to `Mininconda3` in the docker config? here's the sh bundle + MD5:; ```; ENV CONDA_URL https://repo.continuum.io/miniconda/Miniconda3-4.3.30-Linux-x86_64.sh; ENV CONDA_MD5 = ""0b80a152332a4ce5250f3c09589c7a81""```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350194001:27,update,update,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350194001,1,['update'],['update']
Deployability,"@cmnbroad Could you get a PR in for this by Friday, if possible? I'd like to include it in the next point release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4367#issuecomment-367094730:106,release,release,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4367#issuecomment-367094730,1,['release'],['release']
